# Tá»”NG Há»¢P CÃC Dáº NG BÃ€I Táº¬P Há»† KHUYáº¾N NGHá»Š
### PhÃ¢n loáº¡i theo chá»§ Ä‘á» tá»« Lab 01 Ä‘áº¿n Lab 05

---

## ğŸ“Š I. TÃNH TOÃN KHOáº¢NG CÃCH & Äá»˜ TÆ¯Æ NG Äá»’NG

### **1.1. TÃ­nh khoáº£ng cÃ¡ch giá»¯a cÃ¡c vector**
- **Lab 01 - Problem 1a**: TÃ­nh Euclidean Distance vÃ  Manhattan Distance giá»¯a cÃ¡c users
- **CÃ´ng thá»©c sá»­ dá»¥ng:**
  - Euclidean: `scipy.spatial.distance.euclidean()`
  - Manhattan: `scipy.spatial.distance.cityblock()`
- **Má»¥c Ä‘Ã­ch**: So sÃ¡nh Ä‘á»™ gáº§n giá»¯a cÃ¡c users dá»±a trÃªn ratings

### **1.2. TÃ­nh Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng (Similarity)**
- **Lab 01 - Problem 1b**: Táº¡o ma tráº­n Pearson Similarity
- **Lab 02 - Problem 2**: Jaccard Similarity giá»¯a cÃ¡c phim
- **Lab 03**: Cosine Similarity trong lá»c cá»™ng tÃ¡c
- **CÃ´ng thá»©c sá»­ dá»¥ng:**
  - Pearson: `scipy.stats.pearsonr()`
  - Jaccard: `sklearn.metrics.jaccard_score()`
  - Cosine: `sklearn.metrics.pairwise.cosine_similarity()`
- **á»¨ng dá»¥ng**: TÃ¬m users/items tÆ°Æ¡ng tá»± nhau

---

## ğŸ¯ II. Há»† KHUYáº¾N NGHá»Š CÆ  Báº¢N (POPULARITY-BASED)

### **2.1. Weighted Rating (WR)**
- **Lab 01 - Problem 2**: Khuyáº¿n nghá»‹ theo xu hÆ°á»›ng cho ngÆ°á»i dÃ¹ng má»›i
- **CÃ´ng thá»©c IMDB:**
  ```
  WR = (v/(v+m) Ã— R) + (m/(v+m) Ã— C)
  ```
  - v: sá»‘ lÆ°á»£t vote
  - m: ngÆ°á»¡ng tá»‘i thiá»ƒu (quantile)
  - R: rating trung bÃ¬nh cá»§a phim
  - C: rating trung bÃ¬nh toÃ n bá»™
- **Xá»­ lÃ½**: Cold-start problem
- **BÃ i táº­p tÆ°Æ¡ng tá»±**: Táº¥t cáº£ bÃ i vá» popularity-based ranking

---

## ğŸ¤ III. Lá»ŒC Cá»˜NG TÃC (COLLABORATIVE FILTERING)

### **3.1. User-based Collaborative Filtering**
- **Lab 02 - Problem 1a**: Dá»± Ä‘oÃ¡n rating báº±ng User-based CF
- **Lab 03 - BÃ i 1**: Láº­p trÃ¬nh class CF vá»›i User-based
- **Lab 03 - BÃ i 2**: KNN vá»›i user similarity
- **NguyÃªn lÃ½**: TÃ¬m k users gáº§n nháº¥t vá»›i user má»¥c tiÃªu, láº¥y trung bÃ¬nh rating cá»§a há»
- **Similarity**: Pearson correlation
- **CÃ´ng thá»©c dá»± Ä‘oÃ¡n:**
  ```
  P(a,i) = rÌ„(a) + [Î£(r(u,i) - rÌ„(u)) Ã— w(a,u)] / Î£|w(a,u)|
  ```

### **3.2. Item-based Collaborative Filtering**
- **Lab 02 - Problem 1b**: Dá»± Ä‘oÃ¡n rating báº±ng Item-based CF
- **Lab 03 - BÃ i 1**: Láº­p trÃ¬nh class CF vá»›i Item-based
- **NguyÃªn lÃ½**: TÃ¬m k items tÆ°Æ¡ng tá»± vá»›i item má»¥c tiÃªu mÃ  user Ä‘Ã£ rated
- **Similarity**: Adjusted Cosine Similarity
- **CÃ´ng thá»©c:**
  ```
  w(i,j) = Î£[(r(u,i) - rÌ„(u))(r(u,j) - rÌ„(u))] / [âˆšÎ£(r(u,i) - rÌ„(u))Â² Ã— âˆšÎ£(r(u,j) - rÌ„(u))Â²]
  ```

### **3.3. K-Nearest Neighbors (KNN)**
- **Lab 03 - BÃ i 2**: XÃ¢y dá»±ng KNN model vá»›i `sklearn.neighbors.NearestNeighbors`
- **Lab 03**: Step-by-step KNN predictions
- **Lab 05 - BÃ i 1**: Content-based KNN vá»›i scikit-learn
- **Metric**: Cosine similarity
- **Sá»‘ neighbors**: ThÆ°á»ng k=20-30
- **á»¨ng dá»¥ng**: Item-item vÃ  User-user CF

### **3.4. So sÃ¡nh User-based vs Item-based**
- **Lab 03**: Comparing item-based and user-based models
- **RMSE Comparison**: Item-based thÆ°á»ng tá»‘t hÆ¡n User-based
- **Äá»™ phá»©c táº¡p**: Item-based nhanh hÆ¡n khi #users >> #items

---

## ğŸ“ IV. Há»† KHUYáº¾N NGHá»Š Dá»°A TRÃŠN Ná»˜I DUNG (CONTENT-BASED)

### **4.1. TF-IDF Features**
- **Lab 02 - Problem 2**: Táº¡o genre cross-table
- **Lab 04 - BÃ i 3**: TF-IDF cho movie genres
- **CÃ´ng cá»¥**: `sklearn.feature_extraction.text.TfidfTransformer`
- **Äáº§u vÃ o**: Ma tráº­n genres (binary hoáº·c text)
- **Äáº§u ra**: Feature vector cho má»—i item

### **4.2. Ridge Regression cho User Profile**
- **Lab 04 - BÃ i 3**: Ridge Regression vá»›i TF-IDF features
- **CÃ´ng thá»©c**: 
  ```
  minimize ||Xw - y||Â² + Î»||w||Â²
  ```
- **Má»¥c Ä‘Ã­ch**: Há»c user preference tá»« rated items
- **CÃ´ng cá»¥**: `sklearn.linear_model.Ridge`

### **4.3. One-Hot Encoding**
- **Lab 05 - BÃ i 1**: OneHotEncoder cho genres
- **Lab 02 - Problem 2**: pd.crosstab() cho genre matrix
- **á»¨ng dá»¥ng**: Chuyá»ƒn categorical data thÃ nh numerical

### **4.4. Count Vectorizer**
- **Lab 05 - BÃ i 3**: CountVectorizer cho combined features
- **Features**: keywords + cast + genres + director
- **Má»¥c Ä‘Ã­ch**: Táº¡o count matrix tá»« text data

---

## ğŸ”¢ V. MATRIX FACTORIZATION (MF)

### **5.1. Gradient Descent cho MF**
- **Lab 04 - BÃ i 2**: Class MF vá»›i gradient descent
- **Má»¥c tiÃªu**: PhÃ¢n tÃ­ch R â‰ˆ X Ã— W
  - X: item latent factors (n_items Ã— K)
  - W: user latent factors (K Ã— n_users)
  - K: sá»‘ chiá»u áº©n (thÆ°á»ng 2-20)
- **Loss function**: 
  ```
  L = 0.5 Ã— Î£(r - xÂ·w)Â² + Î»/2 Ã— (||X||Â² + ||W||Â²)
  ```
- **Regularization**: TrÃ¡nh overfitting vá»›i Î» (thÆ°á»ng 0.01-0.1)

### **5.2. SVD (Singular Value Decomposition)**
- **Lab 04 - BÃ i 1**: Decomposition vÃ  reconstruction
- **CÃ´ng thá»©c**: A = U Ã— Î£ Ã— V^T
- **CÃ´ng cá»¥**: `scipy.linalg.svd()`
- **á»¨ng dá»¥ng**: Dimensionality reduction, topic modeling

### **5.3. Truncated SVD**
- **Lab 05 - BÃ i 2**: TruncatedSVD tá»« sklearn
- **Sá»‘ components**: n_components=12
- **Correlation matrix**: `np.corrcoef()` trÃªn transformed matrix
- **á»¨ng dá»¥ng**: Collaborative filtering vá»›i ma tráº­n sparse

---

## ğŸ” VI. TÃŒM KIáº¾M ITEMS TÆ¯Æ NG Tá»°

### **6.1. Finding Movie Pairs**
- **Lab 01 - Problem 3**: TÃ¬m táº¥t cáº£ cáº·p phim Ä‘Æ°á»£c xem bá»Ÿi cÃ¹ng user
- **CÃ´ng cá»¥**: `itertools.combinations()` hoáº·c `permutations()`
- **GroupBy**: NhÃ³m theo userId Ä‘á»ƒ tÃ¬m pairs
- **Output**: Counting occurrences cá»§a tá»«ng pair

### **6.2. Making Recommendations**
- **Lab 01 - Problem 3**: Khuyáº¿n nghá»‹ dá»±a trÃªn movie co-occurrence
- **Lab 02 - Problem 2**: Recommendations based on Jaccard similarity
- **Lab 03**: Recommend function trong class CF
- **NguyÃªn táº¯c**: Predicted rating > threshold â†’ recommend

---

## ğŸ“ˆ VII. ÄÃNH GIÃ MÃ” HÃŒNH (EVALUATION)

### **7.1. Root Mean Squared Error (RMSE)**
- **Lab 03**: RMSE cho User-based vÃ  Item-based CF
- **Lab 04**: RMSE vá»›i Matrix Factorization
- **CÃ´ng thá»©c**: 
  ```
  RMSE = âˆš[Î£(predicted - actual)Â² / n]
  ```
- **Káº¿t quáº£ Ä‘iá»ƒn hÃ¬nh**:
  - Content-based: ~1.2-1.3
  - CF Neighborhood: ~0.99
  - Matrix Factorization: ~0.87-1.02

### **7.2. Train-Test Split**
- **Lab 04**: `sklearn.model_selection.train_test_split()`
- **Tá»· lá»‡**: 67% train, 33% test (hoáº·c 80-20)
- **MovieLens**: CÃ³ sáºµn ub.base vÃ  ub.test

---

## ğŸ§¹ VIII. Xá»¬ LÃ Dá»® LIá»†U (DATA PREPROCESSING)

### **8.1. Xá»­ lÃ½ Missing Values**
- **Lab 03**: Fill NaN vá»›i 0 sau khi center data
- **Lab 04**: Dropna() trÆ°á»›c khi train
- **Lab 05**: fillna('') cho text features

### **8.2. Normalization (Mean Centering)**
- **Lab 03**: Centered ratings = ratings - user_mean
- **Má»¥c Ä‘Ã­ch**: Loáº¡i bá» user bias
- **á»¨ng dá»¥ng**: User-based vÃ  Item-based CF

### **8.3. Pivot Table**
- **Lab 03**: `df.pivot(index='userId', columns='title', values='rating')`
- **Má»¥c Ä‘Ã­ch**: Táº¡o user-item matrix
- **Fill**: fillna(0) hoáº·c fillna(user_mean)

### **8.4. Sparse Matrix**
- **Lab 03**: `scipy.sparse.csr_matrix()` cho CF
- **LÃ½ do**: Tiáº¿t kiá»‡m memory khi ma tráº­n cÃ³ nhiá»u giÃ¡ trá»‹ 0
- **á»¨ng dá»¥ng**: MovieLens 1M, 100K

### **8.5. Removing Noise**
- **Lab 03 - BÃ i 2**: Lá»c movies cÃ³ vote_count >= threshold
- **Lab 03 - BÃ i 2**: Lá»c users cÃ³ votes >= threshold
- **NguyÃªn táº¯c**: Percentile (70th, 90th)

---

## ğŸ“Š IX. TRá»°C QUAN HÃ“A (VISUALIZATION)

### **9.1. Heatmap**
- **Lab 01**: Pearson similarity heatmap vá»›i seaborn
- **Code**: `sns.heatmap(matrix, annot=True, cmap='coolwarm')`

### **9.2. Bar Chart**
- **Lab 01**: Plotting top recommended movies
- **Code**: `df.plot.bar(x='movie', y='count')`

### **9.3. Scatter Plot**
- **Lab 03**: Vote count distribution
- **Má»¥c Ä‘Ã­ch**: XÃ¡c Ä‘á»‹nh threshold cho filtering

---

## ğŸ—‚ï¸ X. Cáº¤U TRÃšC Dá»® LIá»†U MOVIELENS

### **10.1. MovieLens 100K**
- ratings: userId, movieId, rating, timestamp
- movies: movieId, title, genres
- users: userId, age, sex, occupation, zip_code

### **10.2. MovieLens 1M**
- ~1 triá»‡u ratings
- 6000 users, 4000 movies
- Format tÆ°Æ¡ng tá»± 100K

### **10.3. Metadata CSV**
- title, genres, vote_count, vote_average
- keywords, cast, director
- DÃ¹ng cho content-based filtering

---

## ğŸ› ï¸ XI. THÆ¯ VIá»†N & CÃ”NG Cá»¤

### **11.1. Core Libraries**
- `pandas`: Data manipulation
- `numpy`: Matrix operations
- `scipy`: Distance, sparse matrix
- `sklearn`: ML algorithms

### **11.2. Recommendation Algorithms**
- `sklearn.neighbors.NearestNeighbors`: KNN
- `sklearn.decomposition.TruncatedSVD`: Matrix factorization
- `sklearn.linear_model.Ridge`: Regression
- `sklearn.metrics.pairwise`: Similarity measures

### **11.3. Feature Engineering**
- `sklearn.feature_extraction.text.TfidfTransformer`
- `sklearn.feature_extraction.text.CountVectorizer`
- `sklearn.preprocessing.OneHotEncoder`

---

## ğŸ“ XII. Dáº NG BÃ€I Táº¬P THÆ¯á»œNG Gáº¶P

### **Dáº¡ng 1: TÃ­nh toÃ¡n cÆ¡ báº£n**
âœ… TÃ­nh khoáº£ng cÃ¡ch/similarity giá»¯a users/items  
âœ… Normalize ratings (mean centering)  
âœ… Táº¡o utility matrix (pivot table)  

### **Dáº¡ng 2: Dá»± Ä‘oÃ¡n rating**
âœ… User-based CF: Dá»± Ä‘oÃ¡n r(u,i)  
âœ… Item-based CF: Dá»± Ä‘oÃ¡n r(u,i)  
âœ… Matrix Factorization: Dá»± Ä‘oÃ¡n báº±ng XÂ·W  

### **Dáº¡ng 3: XÃ¢y dá»±ng há»‡ thá»‘ng**
âœ… Láº­p trÃ¬nh class CF tá»« Ä‘áº§u  
âœ… Sá»­ dá»¥ng sklearn Ä‘á»ƒ build recommender  
âœ… TÃ­ch há»£p nhiá»u features (hybrid)  

### **Dáº¡ng 4: ÄÃ¡nh giÃ¡ & tá»‘i Æ°u**
âœ… TÃ­nh RMSE trÃªn test set  
âœ… So sÃ¡nh cÃ¡c phÆ°Æ¡ng phÃ¡p  
âœ… Hyperparameter tuning (k, Î», learning_rate)  

### **Dáº¡ng 5: Xá»­ lÃ½ dá»¯ liá»‡u**
âœ… Handle missing values  
âœ… Remove noise (low vote count)  
âœ… Feature engineering (TF-IDF, one-hot)  

### **Dáº¡ng 6: Cold-start problem**
âœ… Popularity-based cho user má»›i  
âœ… Content-based cho item má»›i  
âœ… Hybrid approaches  

---

## ğŸ“ XIII. Tá»”NG Káº¾T THEO LAB

| Lab | Chá»§ Ä‘á» chÃ­nh | Ká»¹ thuáº­t |
|-----|--------------|----------|
| **Lab 01** | Distance & Similarity, Popularity-based, Movie pairs | Euclidean, Manhattan, Pearson, Weighted Rating, Combinations |
| **Lab 02** | Collaborative Filtering (manual), Content-based basics | User-based CF, Item-based CF, Jaccard, Crosstab |
| **Lab 03** | CF with OOP, KNN, Sparse matrix | Class CF, NearestNeighbors, Mean centering, RMSE |
| **Lab 04** | SVD, Matrix Factorization, Content-based Ridge | Gradient descent, Regularization, TF-IDF, Ridge regression |
| **Lab 05** | Sklearn ecosystem | OneHotEncoder, TruncatedSVD, CountVectorizer, KNN |

---

## ğŸ’¡ XIV. TIPS & BEST PRACTICES

### **14.1. Lá»±a chá»n phÆ°Æ¡ng phÃ¡p**
- **User má»›i**: Popularity-based
- **Item má»›i**: Content-based
- **CÃ³ Ä‘á»§ ratings**: Collaborative Filtering
- **Large dataset**: Matrix Factorization
- **Cold-start**: Hybrid (Content + CF)

### **14.2. Hyperparameters**
- **k (neighbors)**: 20-30 cho CF
- **K (latent factors)**: 2-20 cho MF
- **Î» (regularization)**: 0.01-0.1
- **learning_rate**: 0.5-2.0
- **threshold (vote_count)**: 70th-90th percentile

### **14.3. Performance**
- **User-based CF**: Tá»‘t khi #users nhá»
- **Item-based CF**: Tá»‘t khi #items nhá» hÆ¡n #users
- **MF**: Tá»‘t cho large sparse matrix
- **Content-based**: KhÃ´ng phá»¥ thuá»™c ratings

### **14.4. Common Pitfalls**
âŒ QuÃªn normalize data â†’ bias  
âŒ KhÃ´ng xá»­ lÃ½ missing values â†’ error  
âŒ Overfitting â†’ regularization quÃ¡ tháº¥p  
âŒ Cold-start khÃ´ng handle â†’ poor UX  

---

## ğŸ“š XV. TÃ€I LIá»†U THAM KHáº¢O

### **Datasets**
- MovieLens 100K: https://grouplens.org/datasets/movielens/100k/
- MovieLens 1M: https://grouplens.org/datasets/movielens/1m/

### **Concepts**
- Weighted Rating (IMDB formula)
- Pearson Correlation vs Cosine Similarity
- Adjusted Cosine Similarity
- SVD for Recommendation Systems
- Matrix Factorization with SGD

### **Libraries Documentation**
- Scikit-learn: https://scikit-learn.org/
- Pandas: https://pandas.pydata.org/
- Scipy: https://scipy.org/

---

## ğŸ”¥ XVI. BÃ€I Táº¬P Má» Rá»˜NG

### **Advanced Topics (khÃ´ng trong lab nhÆ°ng liÃªn quan)**
1. **Deep Learning Recommenders**: Neural Collaborative Filtering
2. **Hybrid Systems**: Káº¿t há»£p CF + Content-based
3. **Contextual Recommendations**: ThÃªm time, location
4. **Implicit Feedback**: Click, view thay vÃ¬ rating
5. **Diversity & Serendipity**: KhÃ´ng chá»‰ accuracy
6. **Evaluation Metrics**: Precision@K, Recall@K, MAP, NDCG

---

**ğŸ“Œ LÆ°u Ã½**: File nÃ y tá»•ng há»£p Táº¤T Cáº¢ cÃ¡c dáº¡ng bÃ i tá»« Lab 01 Ä‘áº¿n Lab 05. Sinh viÃªn nÃªn:
- âœ… LÃ m láº§n lÆ°á»£t tá»«ng lab Ä‘á»ƒ hiá»ƒu concepts
- âœ… So sÃ¡nh cÃ¡c phÆ°Æ¡ng phÃ¡p trÃªn cÃ¹ng dataset
- âœ… Thá»­ thay Ä‘á»•i hyperparameters
- âœ… Äá»c code máº«u vÃ  tá»± implement láº¡i
- âœ… Váº½ sÆ¡ Ä‘á»“ Ä‘á»ƒ hiá»ƒu workflow

**Good luck! ğŸš€**
