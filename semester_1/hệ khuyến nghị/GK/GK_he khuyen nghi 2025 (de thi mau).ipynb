{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S8u8o4l8lqlW"
   },
   "source": [
    "# ƒê√™ÃÄ thi Gi∆∞ÃÉa kyÃÄ H·ªá khuy·∫øn ngh·ªã 2025 (ƒë·ªÅ thi m·∫´u).\n",
    "\n",
    "## Khoa hoÃ£c d∆∞ÃÉ li√™Ã£u IUH. Th∆°ÃÄi gian laÃÄm baÃÄi: 90 phuÃÅt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B√†i 1.** (*2.5 ƒëi·ªÉm*) V·∫•n ƒë·ªÅ v·ªÅ *cold-start*.\n",
    "\n",
    "Cho file d·ªØ li·ªáu csv v·ªÅ 20 b√†i h√°t ƒë∆∞·ª£c 100 users rate trong th√°ng qua, ƒëi·ªÉm t·ª´ 1 ƒë·∫øn 5. C·∫•u tr√∫c file: *id user, id b√†i h√°t, ƒëi·ªÉm rating*.\n",
    "\n",
    "1) S·ª≠ d·ª•ng k·ªπ thu·∫≠t t·ªïng h·ª£p 2 th√¥ng tin: s·ªë rating k·∫øt h·ª£p rating trung b√¨nh, h√£y ƒë·ªÅ xu·∫•t ra top 5 b√†i h√°t n√™n nghe cho m·ªôt user cold-start.\n",
    "2) Gi·∫£ s·ª≠ c√≥ m·ªôt user ƒë√£ nghe b√†i h√°t STT 1. S·ª≠ d·ª•ng k·ªπ thu·∫≠t ƒë·∫øm s·ªë c·∫∑p b√†i h√°t ƒë∆∞·ª£c nghe b·ªüi c√πng user, h√£y ƒë·ªÅ xu·∫•t ra top 5 b√†i h√°t m√† user n√†y c√≥ th·ªÉ c≈©ng mu·ªën nghe theo xu h∆∞·ªõng.\n",
    "3) H·ªèi n·∫øu c√≥ th√™m 1 item m·ªõi ƒë∆∞a v√†o h·ªá th·ªëng th√¨ ta n√™n x·ª≠ l√Ω th·∫ø n√†o? SV tham kh·∫£o th√™m t·∫°i ƒë√¢y:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Cold_start_(recommender_systems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lab 1, 2 c√≥ n√≥i "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating  timestamp\n",
      "0       1        1     4.0  964982703\n",
      "1       1        3     4.0  964981247\n",
      "2       1        6     4.0  964982224\n",
      "3       1       47     5.0  964983815\n",
      "4       1       50     5.0  964982931\n",
      "\n",
      "üéß Top 5 b√†i h√°t n√™n nghe cho user cold-start:\n",
      "      movieId  avg_rating  num_ratings     score\n",
      "277       318    4.429022          317  4.396816\n",
      "659       858    4.289062          192  4.243095\n",
      "2224     2959    4.272936          218  4.232872\n",
      "224       260    4.231076          251  4.197546\n",
      "46         50    4.237745          204  4.196535\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1Ô∏è‚É£ ƒê·ªçc d·ªØ li·ªáu\n",
    "df = pd.read_csv(\"ratings.csv\")   # file g·ªìm: user_id, song_id, rating\n",
    "print(df.head())\n",
    "\n",
    "# 2Ô∏è‚É£ T√≠nh trung b√¨nh v√† s·ªë l∆∞·ª£ng rating cho m·ªói b√†i h√°t\n",
    "song_stats = df.groupby('movieId').agg(\n",
    "    num_ratings=('rating', 'count'),\n",
    "    avg_rating=('rating', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# 3Ô∏è‚É£ T√≠nh c√°c gi√° tr·ªã trung gian cho c√¥ng th·ª©c IMDb\n",
    "C = song_stats['avg_rating'].mean()        # trung b√¨nh rating to√†n b·ªô b√†i h√°t\n",
    "m = song_stats['num_ratings'].quantile(0.75)  # ng∆∞·ª°ng 75% s·ªë l∆∞·ª£ng rating\n",
    "\n",
    "# 4Ô∏è‚É£ T√≠nh ƒëi·ªÉm weighted score\n",
    "def weighted_rating(x, m=m, C=C):\n",
    "    v = x['num_ratings']\n",
    "    R = x['avg_rating']\n",
    "    return (v / (v + m)) * R + (m / (v + m)) * C\n",
    "\n",
    "song_stats['score'] = song_stats.apply(weighted_rating, axis=1)\n",
    "\n",
    "# 5Ô∏è‚É£ S·∫Øp x·∫øp theo ƒëi·ªÉm gi·∫£m d·∫ßn v√† ch·ªçn top 5\n",
    "top_5 = song_stats.sort_values(by='score', ascending=False).head(5)\n",
    "\n",
    "print(\"\\nüéß Top 5 b√†i h√°t n√™n nghe cho user cold-start:\")\n",
    "print(top_5[['movieId', 'avg_rating', 'num_ratings', 'score']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéß Top 5 b√†i h√°t th∆∞·ªùng ƒë∆∞·ª£c nghe c√πng v·ªõi b√†i h√°t STT 1:\n",
      "     song_i  song_j  count\n",
      "2         1       6     24\n",
      "4         1       9     17\n",
      "194       1       7     15\n",
      "56        1      11     15\n",
      "90        1      13     15\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "\n",
    "# 1Ô∏è‚É£ ƒê·ªçc d·ªØ li·ªáu\n",
    "df = pd.read_csv(\"bai1_ratings.csv\")   # g·ªìm: user_id, song_id, rating\n",
    "\n",
    "# 2Ô∏è‚É£ X√¢y d·ª±ng ma tr·∫≠n co-occurrence (ƒë·∫øm s·ªë l·∫ßn 2 b√†i h√°t ƒë∆∞·ª£c nghe c√πng user)\n",
    "cooccur = defaultdict(int)\n",
    "\n",
    "# Duy·ªát qua t·ª´ng user\n",
    "for user, group in df.groupby('user_id'):\n",
    "    songs = group['song_id'].unique()\n",
    "    # T·∫°o t·∫•t c·∫£ c√°c c·∫∑p b√†i h√°t m√† user nghe\n",
    "    for i, j in combinations(sorted(songs), 2):\n",
    "        cooccur[(i, j)] += 1\n",
    "        cooccur[(j, i)] += 1   # song song, ƒë·∫£m b·∫£o t√≠nh ƒë·ªëi x·ª©ng\n",
    "\n",
    "# 3Ô∏è‚É£ T·∫°o DataFrame t·ª´ dict\n",
    "cooccur_df = pd.DataFrame([\n",
    "    {'song_i': i, 'song_j': j, 'count': c}\n",
    "    for (i, j), c in cooccur.items()\n",
    "])\n",
    "\n",
    "# 4Ô∏è‚É£ Ch·ªçn ra c√°c b√†i h√°t ƒë·ªìng xu·∫•t hi·ªán v·ªõi b√†i h√°t c√≥ ID = 1\n",
    "target_song = 1\n",
    "related_songs = cooccur_df[cooccur_df['song_i'] == target_song].sort_values('count', ascending=False)\n",
    "\n",
    "# 5Ô∏è‚É£ L·∫•y top 5 b√†i h√°t ƒë·ªìng nghe nhi·ªÅu nh·∫•t\n",
    "top5_related = related_songs.head(5)\n",
    "\n",
    "print(\"\\nüéß Top 5 b√†i h√°t th∆∞·ªùng ƒë∆∞·ª£c nghe c√πng v·ªõi b√†i h√°t STT 1:\")\n",
    "print(top5_related)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ 1. B·∫£n ch·∫•t c·ªßa v·∫•n ƒë·ªÅ item cold-start\n",
    "\n",
    "B√†i h√°t m·ªõi ‚Üí ch∆∞a c√≥ d·ªØ li·ªáu rating ho·∫∑c ng∆∞·ªùi nghe n√†o li√™n quan.\n",
    "\n",
    "Do ƒë√≥, c√°c ph∆∞∆°ng ph√°p d·ª±a v√†o l·ªãch s·ª≠ nh∆∞ Collaborative Filtering (CF) kh√¥ng th·ªÉ ho·∫°t ƒë·ªông ƒë∆∞·ª£c,\n",
    "v√¨ CF c·∫ßn m·ªëi li√™n h·ªá gi·ªØa item‚Äìuser (t·ª©c l√† ma tr·∫≠n rating ph·∫£i c√≥ d·ªØ li·ªáu).\n",
    "\n",
    "üß© 2. C√°c c√°ch x·ª≠ l√Ω ƒëi·ªÉn h√¨nh (theo l√Ω thuy·∫øt v√† t√†i li·ªáu Wikipedia)\n",
    "üîπ (a) D·ª±a tr√™n th√¥ng tin n·ªôi dung (Content-based Filtering)\n",
    "\n",
    "S·ª≠ d·ª•ng c√°c ƒë·∫∑c tr∆∞ng (features) c·ªßa b√†i h√°t m·ªõi ƒë·ªÉ g·ª£i √Ω:\n",
    "\n",
    "V√≠ d·ª•: th·ªÉ lo·∫°i (genre), ca sƒ©, nh·ªãp ƒëi·ªáu (tempo), ƒë·ªô d√†i, nƒÉm ph√°t h√†nh, m√¥ t·∫£ b√†i h√°t...\n",
    "\n",
    "Ta t√¨m nh·ªØng b√†i h√°t c√≥ n·ªôi dung t∆∞∆°ng t·ª± (content similarity) v√† g·ª£i √Ω cho ng∆∞·ªùi d√πng ƒë√£ th√≠ch c√°c b√†i ƒë√≥.\n",
    "\n",
    "üìò V√≠ d·ª•:\n",
    "B√†i h√°t m·ªõi thu·ªôc th·ªÉ lo·∫°i pop, do Taylor Swift h√°t ‚Üí ta c√≥ th·ªÉ g·ª£i √Ω n√≥ cho ng∆∞·ªùi d√πng t·ª´ng nghe nhi·ªÅu b√†i pop ho·∫∑c b√†i Taylor Swift kh√°c.\n",
    "\n",
    "‚û°Ô∏è ∆Øu ƒëi·ªÉm: x·ª≠ l√Ω ƒë∆∞·ª£c khi item ho√†n to√†n m·ªõi.\n",
    "‚û°Ô∏è Nh∆∞·ª£c ƒëi·ªÉm: c·∫ßn metadata phong ph√∫ (ƒë√¥i khi kh√¥ng c√≥).\n",
    "\n",
    "üîπ (b) K·∫øt h·ª£p (Hybrid Approach)\n",
    "\n",
    "K·∫øt h·ª£p CF + Content-based ƒë·ªÉ t·∫≠n d·ª•ng ∆∞u ƒëi·ªÉm c·ªßa c·∫£ hai.\n",
    "\n",
    "Ban ƒë·∫ßu d√πng content-based ƒë·ªÉ g·ª£i √Ω t·∫°m th·ªùi cho item m·ªõi.\n",
    "\n",
    "Khi b√†i h√°t ƒë√≥ ƒë√£ c√≥ v√†i rating ho·∫∑c ng∆∞·ªùi nghe, chuy·ªÉn d·∫ßn sang CF ƒë·ªÉ c·∫≠p nh·∫≠t xu h∆∞·ªõng th·ª±c t·∫ø.\n",
    "\n",
    "üìò V√≠ d·ª•: Netflix ho·∫∑c Spotify th∆∞·ªùng kh·ªüi ƒë·∫ßu b·∫±ng metadata (th·ªÉ lo·∫°i, di·ªÖn vi√™n, ca sƒ©, tags),\n",
    "sau ƒë√≥ h·ªçc d·∫ßn t·ª´ h√†nh vi ng∆∞·ªùi d√πng th·ª±c t·∫ø.\n",
    "\n",
    "üîπ (c) Kh·ªüi t·∫°o b·∫±ng chuy√™n gia ho·∫∑c qu·∫£ng b√°\n",
    "\n",
    "Khi item m·ªõi ƒë∆∞·ª£c ƒë∆∞a l√™n, c√≥ th·ªÉ ƒë·∫©y t·∫°m v√†o top trend, m·ª•c ‚Äúm·ªõi ph√°t h√†nh‚Äù ho·∫∑c ƒë∆∞·ª£c qu·∫£ng b√° ƒë·ªÉ thu h√∫t l∆∞·ª£t nghe ƒë·∫ßu ti√™n.\n",
    "\n",
    "Sau khi c√≥ ƒë·ªß d·ªØ li·ªáu, h·ªá th·ªëng recommender b·∫Øt ƒë·∫ßu h·ªçc.\n",
    "\n",
    "üîπ (d) S·ª≠ d·ª•ng m√¥ h√¨nh sinh embedding (Deep Learning / Transfer Learning)\n",
    "\n",
    "√Åp d·ª•ng c√°c m√¥ h√¨nh nh∆∞ Word2Vec, Doc2Vec, ho·∫∑c Transformer encoder ƒë·ªÉ sinh embedding cho item m·ªõi d·ª±a tr√™n n·ªôi dung m√¥ t·∫£ (lyrics, metadata...).\n",
    "\n",
    "D√πng embedding ƒë√≥ ƒë·ªÉ t√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng v·ªõi c√°c item kh√°c m√† kh√¥ng c·∫ßn rating ban ƒë·∫ßu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B√†i 2.** (*3 ƒëi·ªÉm*) V·∫•n ƒë·ªÅ x√¢y d·ª±ng *content-based data*.\n",
    "\n",
    "S·ª≠ d·ª•ng dataset movie_lens trong ƒë√≥ c√≥ file *movies.csv* m√¥ t·∫£ t√™n films v√† c√°c th·ªÉ lo·∫°i (m·ªôt phim c√≥ th·ªÉ thu·ªôc nhi·ªÅu th·ªÉ lo·∫°i).\n",
    "\n",
    "1. ƒê·ªçc d·ªØ li·ªáu v√† l·ªçc l·∫°i 100 films c√≥ nhi·ªÅu th·ªÉ lo·∫°i nh·∫•t.\n",
    "2. X√©t m·ªôt film X trong ƒë√≥, t√≠nh ra top 10 films t∆∞∆°ng ƒë·ªìng v·ªõi film X n√†y nh·∫•t b·∫±ng ƒë·ªô t∆∞∆°ng ƒë·ªìng Jaccard.\n",
    "3. Cho m·ªôt user Y ƒë√£ xem ƒë∆∞·ª£c 5 b·ªô films $1,2,3,4,5$ trong danh s√°ch 100 films ƒë√£ li·ªát k√™ ·ªü tr√™n, h√£y x√¢y d·ª±ng m·ªôt profile c∆° b·∫£n cho user n√†y v√† khuy·∫øn ngh·ªã ra top 10 films m√† user Y n√†y c√≥ th·ªÉ mu·ªën xem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movieId                               title  \\\n",
      "0        1                    Toy Story (1995)   \n",
      "1        2                      Jumanji (1995)   \n",
      "2        3             Grumpier Old Men (1995)   \n",
      "3        4            Waiting to Exhale (1995)   \n",
      "4        5  Father of the Bride Part II (1995)   \n",
      "\n",
      "                                        genres  \n",
      "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
      "1                   Adventure|Children|Fantasy  \n",
      "2                               Comedy|Romance  \n",
      "3                         Comedy|Drama|Romance  \n",
      "4                                       Comedy  \n",
      "\n",
      "üé¨ Top 5 trong 100 phim c√≥ nhi·ªÅu th·ªÉ lo·∫°i nh·∫•t:\n",
      "   movieId                                              title  \\\n",
      "0    81132                                      Rubber (2010)   \n",
      "1    26701  Patlabor: The Movie (Kid√¥ keisatsu patoreb√¢: T...   \n",
      "2    56152                                   Enchanted (2007)   \n",
      "3     2987                    Who Framed Roger Rabbit? (1988)   \n",
      "4    32031                                      Robots (2005)   \n",
      "\n",
      "                                              genres  num_genres  \n",
      "0  Action|Adventure|Comedy|Crime|Drama|Film-Noir|...          10  \n",
      "1  Action|Animation|Crime|Drama|Film-Noir|Mystery...           8  \n",
      "2  Adventure|Animation|Children|Comedy|Fantasy|Mu...           7  \n",
      "3  Adventure|Animation|Children|Comedy|Crime|Fant...           7  \n",
      "4  Adventure|Animation|Children|Comedy|Fantasy|Sc...           7  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ƒê·ªçc d·ªØ li·ªáu movies.csv (file c√≥ s·∫µn trong MovieLens)\n",
    "movies = pd.read_csv(\"movies.csv\")\n",
    "print(movies.head())\n",
    "\n",
    "# T√°ch c√°c th·ªÉ lo·∫°i\n",
    "movies['genre_list'] = movies['genres'].apply(lambda x: x.split('|') if isinstance(x, str) else [])\n",
    "\n",
    "# ƒê·∫øm s·ªë l∆∞·ª£ng th·ªÉ lo·∫°i\n",
    "movies['num_genres'] = movies['genre_list'].apply(len)\n",
    "\n",
    "# L·ªçc top 100 phim c√≥ nhi·ªÅu th·ªÉ lo·∫°i nh·∫•t\n",
    "top100 = movies.sort_values(by='num_genres', ascending=False).head(100).reset_index(drop=True)\n",
    "print(\"\\nüé¨ Top 5 trong 100 phim c√≥ nhi·ªÅu th·ªÉ lo·∫°i nh·∫•t:\")\n",
    "print(top100[['movieId', 'title', 'genres', 'num_genres']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéû Phim X: Rubber (2010) ‚Äî Th·ªÉ lo·∫°i: ['Action', 'Adventure', 'Comedy', 'Crime', 'Drama', 'Film-Noir', 'Horror', 'Mystery', 'Thriller', 'Western']\n",
      "\n",
      "üéØ Top 10 phim t∆∞∆°ng ƒë·ªìng nh·∫•t v·ªõi Rubber (2010)\n",
      "                                                title  \\\n",
      "20          Sherlock Holmes: A Game of Shadows (2011)   \n",
      "53                Seven-Per-Cent Solution, The (1976)   \n",
      "67               Ichi the Killer (Koroshiya 1) (2001)   \n",
      "1   Patlabor: The Movie (Kid√¥ keisatsu patoreb√¢: T...   \n",
      "90                             Negotiator, The (1998)   \n",
      "41                                Strange Days (1995)   \n",
      "55                                  Chase, The (1994)   \n",
      "56              Dragonheart 2: A New Beginning (2000)   \n",
      "37                               Blood Diamond (2006)   \n",
      "57                                  Mummy, The (1999)   \n",
      "\n",
      "                                               genres  similarity  \n",
      "20     Action|Adventure|Comedy|Crime|Mystery|Thriller    0.600000  \n",
      "53      Adventure|Comedy|Crime|Drama|Mystery|Thriller    0.600000  \n",
      "67          Action|Comedy|Crime|Drama|Horror|Thriller    0.600000  \n",
      "1   Action|Animation|Crime|Drama|Film-Noir|Mystery...    0.500000  \n",
      "90                Action|Crime|Drama|Mystery|Thriller    0.500000  \n",
      "41         Action|Crime|Drama|Mystery|Sci-Fi|Thriller    0.454545  \n",
      "55     Action|Adventure|Comedy|Crime|Romance|Thriller    0.454545  \n",
      "56     Action|Adventure|Comedy|Drama|Fantasy|Thriller    0.454545  \n",
      "37          Action|Adventure|Crime|Drama|Thriller|War    0.454545  \n",
      "57    Action|Adventure|Comedy|Fantasy|Horror|Thriller    0.454545  \n"
     ]
    }
   ],
   "source": [
    "# H√†m t√≠nh Jaccard similarity gi·ªØa 2 danh s√°ch th·ªÉ lo·∫°i\n",
    "def jaccard_similarity(genres_a, genres_b):\n",
    "    set_a, set_b = set(genres_a), set(genres_b)\n",
    "    if not set_a or not set_b:\n",
    "        return 0\n",
    "    return len(set_a & set_b) / len(set_a | set_b)\n",
    "\n",
    "# Ch·ªçn 1 phim X (v√≠ d·ª• phim ƒë·∫ßu ti√™n)\n",
    "film_X = top100.iloc[0]\n",
    "print(\"\\nüéû Phim X:\", film_X['title'], \"‚Äî Th·ªÉ lo·∫°i:\", film_X['genre_list'])\n",
    "\n",
    "# T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng Jaccard v·ªõi c√°c phim kh√°c\n",
    "top100['similarity'] = top100['genre_list'].apply(\n",
    "    lambda g: jaccard_similarity(film_X['genre_list'], g)\n",
    ")\n",
    "\n",
    "# L·ªçc ra top 10 phim t∆∞∆°ng ƒë·ªìng nh·∫•t (b·ªè ch√≠nh n√≥)\n",
    "similar_films = top100[top100['movieId'] != film_X['movieId']].sort_values(\n",
    "    by='similarity', ascending=False\n",
    ").head(10)\n",
    "\n",
    "print(\"\\nüéØ Top 10 phim t∆∞∆°ng ƒë·ªìng nh·∫•t v·ªõi\", film_X['title'])\n",
    "print(similar_films[['title', 'genres', 'similarity']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>genre_list</th>\n",
       "      <th>num_genres</th>\n",
       "      <th>similarity</th>\n",
       "      <th>user_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>78499</td>\n",
       "      <td>Toy Story 3 (2010)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy|IMAX</td>\n",
       "      <td>[Adventure, Animation, Children, Comedy, Fanta...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.352941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    movieId               title  \\\n",
       "70    78499  Toy Story 3 (2010)   \n",
       "\n",
       "                                              genres  \\\n",
       "70  Adventure|Animation|Children|Comedy|Fantasy|IMAX   \n",
       "\n",
       "                                           genre_list  num_genres  similarity  \\\n",
       "70  [Adventure, Animation, Children, Comedy, Fanta...           6    0.142857   \n",
       "\n",
       "    user_sim  \n",
       "70  0.352941  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top100[top100['title'].str.contains(\"Toy Story\", case=False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéû Phim X: Toy Story 3 (2010)\n",
      "Th·ªÉ lo·∫°i: ['Adventure', 'Animation', 'Children', 'Comedy', 'Fantasy', 'IMAX']\n",
      "\n",
      "üéØ Top 10 phim t∆∞∆°ng ƒë·ªìng nh·∫•t v·ªõi Toy Story 3 (2010)\n",
      "                                                title  \\\n",
      "43                              Ant Bully, The (2006)   \n",
      "73  Shrek Forever After (a.k.a. Shrek: The Final C...   \n",
      "4                                       Robots (2005)   \n",
      "80                    How to Train Your Dragon (2010)   \n",
      "14  Twelve Tasks of Asterix, The (Les douze travau...   \n",
      "25                 Madagascar: Escape 2 Africa (2008)   \n",
      "46                                        Home (2015)   \n",
      "47                             Kung Fu Panda 2 (2011)   \n",
      "50                                  Inside Out (2015)   \n",
      "52      Puss in Boots (Nagagutsu o haita neko) (1969)   \n",
      "\n",
      "                                               genres  similarity  \n",
      "43   Adventure|Animation|Children|Comedy|Fantasy|IMAX    1.000000  \n",
      "73   Adventure|Animation|Children|Comedy|Fantasy|IMAX    1.000000  \n",
      "4   Adventure|Animation|Children|Comedy|Fantasy|Sc...    0.857143  \n",
      "80          Adventure|Animation|Children|Fantasy|IMAX    0.833333  \n",
      "14  Action|Adventure|Animation|Children|Comedy|Fan...    0.714286  \n",
      "25    Action|Adventure|Animation|Children|Comedy|IMAX    0.714286  \n",
      "46  Adventure|Animation|Children|Comedy|Fantasy|Sc...    0.714286  \n",
      "47    Action|Adventure|Animation|Children|Comedy|IMAX    0.714286  \n",
      "50  Adventure|Animation|Children|Comedy|Drama|Fantasy    0.714286  \n",
      "52  Adventure|Animation|Children|Comedy|Fantasy|Ro...    0.714286  \n"
     ]
    }
   ],
   "source": [
    "film_title = \"Toy Story 3 (2010)\"\n",
    "\n",
    "# L·ªçc ra d√≤ng phim c√≥ t√™n kh·ªõp (d√≤ng ƒë·∫ßu ti√™n n·∫øu c√≥ tr√πng)\n",
    "film_X = top100[top100['title'] == film_title].iloc[0]\n",
    "\n",
    "print(\"\\nüéû Phim X:\", film_X['title'])\n",
    "print(\"Th·ªÉ lo·∫°i:\", film_X['genre_list'])\n",
    "\n",
    "# T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng Jaccard v·ªõi c√°c phim kh√°c\n",
    "top100['similarity'] = top100['genre_list'].apply(\n",
    "    lambda g: jaccard_similarity(film_X['genre_list'], g)\n",
    ")\n",
    "\n",
    "# L·ªçc ra top 10 phim t∆∞∆°ng ƒë·ªìng nh·∫•t (b·ªè ch√≠nh n√≥)\n",
    "similar_films = top100[top100['movieId'] != film_X['movieId']].sort_values(\n",
    "    by='similarity', ascending=False\n",
    ").head(10)\n",
    "\n",
    "print(\"\\nüéØ Top 10 phim t∆∞∆°ng ƒë·ªìng nh·∫•t v·ªõi\", film_X['title'])\n",
    "print(similar_films[['title', 'genres', 'similarity']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéû Phim X: Toy Story 3 (2010)\n",
      "Th·ªÉ lo·∫°i: ['Adventure', 'Animation', 'Children', 'Comedy', 'Fantasy', 'IMAX']\n",
      "\n",
      "üéØ Top 10 phim t∆∞∆°ng ƒë·ªìng nh·∫•t v·ªõi Toy Story 3 (2010)\n",
      "                                                title  \\\n",
      "43                              Ant Bully, The (2006)   \n",
      "73  Shrek Forever After (a.k.a. Shrek: The Final C...   \n",
      "4                                       Robots (2005)   \n",
      "80                    How to Train Your Dragon (2010)   \n",
      "14  Twelve Tasks of Asterix, The (Les douze travau...   \n",
      "25                 Madagascar: Escape 2 Africa (2008)   \n",
      "46                                        Home (2015)   \n",
      "47                             Kung Fu Panda 2 (2011)   \n",
      "50                                  Inside Out (2015)   \n",
      "52      Puss in Boots (Nagagutsu o haita neko) (1969)   \n",
      "\n",
      "                                               genres  similarity  \n",
      "43   Adventure|Animation|Children|Comedy|Fantasy|IMAX    1.000000  \n",
      "73   Adventure|Animation|Children|Comedy|Fantasy|IMAX    1.000000  \n",
      "4   Adventure|Animation|Children|Comedy|Fantasy|Sc...    0.857143  \n",
      "80          Adventure|Animation|Children|Fantasy|IMAX    0.833333  \n",
      "14  Action|Adventure|Animation|Children|Comedy|Fan...    0.714286  \n",
      "25    Action|Adventure|Animation|Children|Comedy|IMAX    0.714286  \n",
      "46  Adventure|Animation|Children|Comedy|Fantasy|Sc...    0.714286  \n",
      "47    Action|Adventure|Animation|Children|Comedy|IMAX    0.714286  \n",
      "50  Adventure|Animation|Children|Comedy|Drama|Fantasy    0.714286  \n",
      "52  Adventure|Animation|Children|Comedy|Fantasy|Ro...    0.714286  \n"
     ]
    }
   ],
   "source": [
    "film_id = 78499  # V√≠ d·ª• ch·ªçn movieId = 1\n",
    "\n",
    "# L·ªçc ra phim t∆∞∆°ng ·ª©ng\n",
    "film_X = top100[top100['movieId'] == film_id].iloc[0]\n",
    "\n",
    "print(\"\\nüéû Phim X:\", film_X['title'])\n",
    "print(\"Th·ªÉ lo·∫°i:\", film_X['genre_list'])\n",
    "\n",
    "# T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng Jaccard v·ªõi c√°c phim kh√°c\n",
    "top100['similarity'] = top100['genre_list'].apply(\n",
    "    lambda g: jaccard_similarity(film_X['genre_list'], g)\n",
    ")\n",
    "\n",
    "# L·ªçc ra top 10 phim t∆∞∆°ng ƒë·ªìng nh·∫•t (b·ªè ch√≠nh n√≥)\n",
    "similar_films = top100[top100['movieId'] != film_X['movieId']].sort_values(\n",
    "    by='similarity', ascending=False\n",
    ").head(10)\n",
    "\n",
    "print(\"\\nüéØ Top 10 phim t∆∞∆°ng ƒë·ªìng nh·∫•t v·ªõi\", film_X['title'])\n",
    "print(similar_films[['title', 'genres', 'similarity']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üßç‚Äç‚ôÇÔ∏è User profile: {'Drama', 'Mystery', 'Thriller', 'Film-Noir', 'Horror', 'Action', 'Comedy', 'Animation', 'Sci-Fi', 'Western', 'Children', 'Musical', 'Romance', 'Adventure', 'IMAX', 'Fantasy', 'Crime'}\n",
      "\n",
      "üé¨ Top 10 phim ƒë∆∞·ª£c khuy·∫øn ngh·ªã cho user Y:\n",
      "                                                title  \\\n",
      "5                                      Tangled (2010)   \n",
      "7                                Osmosis Jones (2001)   \n",
      "8                                Interstate 60 (2002)   \n",
      "9                                        Mulan (1998)   \n",
      "10                             Mars Needs Moms (2011)   \n",
      "11  Aqua Teen Hunger Force Colon Movie Film for Th...   \n",
      "12          Aelita: The Queen of Mars (Aelita) (1924)   \n",
      "13                                   Inception (2010)   \n",
      "6                                        Pulse (2006)   \n",
      "55                                  Chase, The (1994)   \n",
      "\n",
      "                                               genres  user_sim  \n",
      "5   Animation|Children|Comedy|Fantasy|Musical|Roma...  0.411765  \n",
      "7   Action|Animation|Comedy|Crime|Drama|Romance|Th...  0.411765  \n",
      "8   Adventure|Comedy|Drama|Fantasy|Mystery|Sci-Fi|...  0.411765  \n",
      "9   Adventure|Animation|Children|Comedy|Drama|Musi...  0.411765  \n",
      "10  Action|Adventure|Animation|Children|Comedy|Sci...  0.411765  \n",
      "11  Action|Adventure|Animation|Comedy|Fantasy|Myst...  0.411765  \n",
      "12  Action|Adventure|Drama|Fantasy|Romance|Sci-Fi|...  0.411765  \n",
      "13    Action|Crime|Drama|Mystery|Sci-Fi|Thriller|IMAX  0.411765  \n",
      "6   Action|Drama|Fantasy|Horror|Mystery|Sci-Fi|Thr...  0.411765  \n",
      "55     Action|Adventure|Comedy|Crime|Romance|Thriller  0.352941  \n"
     ]
    }
   ],
   "source": [
    "# Gi·∫£ s·ª≠ user Y ƒë√£ xem 5 phim ƒë·∫ßu ti√™n trong danh s√°ch\n",
    "watched_ids = top100.iloc[[0,1,2,3,4]]['movieId'].tolist()\n",
    "watched_genres = top100[top100['movieId'].isin(watched_ids)]['genre_list']\n",
    "\n",
    "# T·∫°o profile ng∆∞·ªùi d√πng (t·∫≠p h·ª£p c√°c th·ªÉ lo·∫°i y√™u th√≠ch)\n",
    "user_profile = set(g for sublist in watched_genres for g in sublist)\n",
    "print(\"\\nüßç‚Äç‚ôÇÔ∏è User profile:\", user_profile)\n",
    "\n",
    "# T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng Jaccard gi·ªØa user profile v√† t·ª´ng phim\n",
    "def user_similarity(user_genres, movie_genres):\n",
    "    if not movie_genres:\n",
    "        return 0\n",
    "    return len(set(user_genres) & set(movie_genres)) / len(set(user_genres) | set(movie_genres))\n",
    "\n",
    "top100['user_sim'] = top100['genre_list'].apply(lambda g: user_similarity(user_profile, g))\n",
    "\n",
    "# G·ª£i √Ω 10 phim ch∆∞a xem c√≥ ƒë·ªô t∆∞∆°ng ƒë·ªìng cao nh·∫•t\n",
    "recommendations = top100[~top100['movieId'].isin(watched_ids)].sort_values(\n",
    "    by='user_sim', ascending=False\n",
    ").head(10)\n",
    "\n",
    "print(\"\\nüé¨ Top 10 phim ƒë∆∞·ª£c khuy·∫øn ngh·ªã cho user Y:\")\n",
    "print(recommendations[['title', 'genres', 'user_sim']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B√†i 3.** (*2 ƒëi·ªÉm*) V·∫•n ƒë·ªÅ d·ª± ƒëo√°n *missing value* trong l·ªçc c·ªông t√°c.\n",
    "\n",
    "Cho m·ªôt b·∫£ng *utility matrix* gi·ªØa 4 user v√† 4 item nh∆∞ b√™n d∆∞·ªõi:\n",
    "\n",
    "|Rating     | $I_1$    | $I_2$  | $I_3$   |  $I_4$  |\n",
    "|----------|----------|--------|---------|---------|\n",
    "| $U_1$    | 4     | 3     | ?    |   4 | \n",
    "| $U_2$ | 3     | 3      | 5     |   5    |\n",
    "| $U_3$  | 5     | 4      |   3  |    4 |\n",
    "| $U_4$|   ?  |   2    | 3 |   5|\n",
    "\n",
    "1. D·ª± ƒëo√°n hai missing rating $r_{U_1, I_3}$ v√† $r_{U_4, I_1}$ b·∫±ng c√°ch d√πng ƒë·ªô t∆∞∆°ng ƒë·ªìng Pearson.\n",
    "2. C√¢u h·ªèi t∆∞∆°ng t·ª± tr√™n nh∆∞ng chu·∫©n ho√° b·∫£ng theo d·∫°ng center v√† sau ƒë√≥ d√πng ƒë·ªô t∆∞∆°ng ƒë·ªìng cosine. So s√°nh c√°c k·∫øt qu·∫£ thu ƒë∆∞·ª£c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Utility matrix:\n",
      "      I1  I2   I3  I4\n",
      "U1  4.0   3  NaN   4\n",
      "U2  3.0   3  5.0   5\n",
      "U3  5.0   4  3.0   4\n",
      "U4  NaN   2  3.0   5 \n",
      "\n",
      "üîπ Ma tr·∫≠n ƒë·ªô t∆∞∆°ng ƒë·ªìng Pearson:\n",
      "      U1        U2        U3        U4\n",
      "U1  0.0  0.500000  0.500000  1.000000\n",
      "U2  0.5  0.000000 -0.707107  0.755929\n",
      "U3  0.5 -0.707107  0.000000  0.188982\n",
      "U4  1.0  0.755929  0.188982  0.000000 \n",
      "\n",
      "üéØ D·ª± ƒëo√°n r_U1,I3 = 3.50\n",
      "üéØ D·ª± ƒëo√°n r_U4,I1 = 3.21\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# T·∫°o b·∫£ng utility matrix\n",
    "data = {\n",
    "    'I1': [4, 3, 5, np.nan],\n",
    "    'I2': [3, 3, 4, 2],\n",
    "    'I3': [np.nan, 5, 3, 3],\n",
    "    'I4': [4, 5, 4, 5]\n",
    "}\n",
    "ratings = pd.DataFrame(data, index=['U1','U2','U3','U4'])\n",
    "print(\"üîπ Utility matrix:\\n\", ratings, \"\\n\")\n",
    "\n",
    "# --- H√†m t√≠nh Pearson similarity gi·ªØa hai user ---\n",
    "def pearson_sim(u1, u2):\n",
    "    common = u1.dropna().index.intersection(u2.dropna().index)\n",
    "    if len(common) < 2:  # c·∫ßn √≠t nh·∫•t 2 ƒëi·ªÉm chung\n",
    "        return 0\n",
    "    u1_r = u1[common] - u1[common].mean()\n",
    "    u2_r = u2[common] - u2[common].mean()\n",
    "    num = np.sum(u1_r * u2_r)\n",
    "    den = np.sqrt(np.sum(u1_r**2)) * np.sqrt(np.sum(u2_r**2))\n",
    "    return num/den if den != 0 else 0\n",
    "\n",
    "# --- Ma tr·∫≠n similarity ---\n",
    "users = ratings.index\n",
    "sim_matrix = pd.DataFrame(np.zeros((4,4)), index=users, columns=users)\n",
    "\n",
    "for u in users:\n",
    "    for v in users:\n",
    "        if u != v:\n",
    "            sim_matrix.loc[u,v] = pearson_sim(ratings.loc[u], ratings.loc[v])\n",
    "\n",
    "print(\"üîπ Ma tr·∫≠n ƒë·ªô t∆∞∆°ng ƒë·ªìng Pearson:\\n\", sim_matrix, \"\\n\")\n",
    "\n",
    "# --- H√†m d·ª± ƒëo√°n rating ---\n",
    "def predict_rating(user, item):\n",
    "    user_mean = ratings.loc[user].mean(skipna=True)\n",
    "    sims, num, den = [], 0, 0\n",
    "    for other in users:\n",
    "        if other != user and not np.isnan(ratings.loc[other, item]):\n",
    "            sim = sim_matrix.loc[user, other]\n",
    "            sims.append(sim)\n",
    "            num += sim * (ratings.loc[other, item] - ratings.loc[other].mean(skipna=True))\n",
    "            den += abs(sim)\n",
    "    return user_mean + num / den if den != 0 else user_mean\n",
    "\n",
    "# D·ª± ƒëo√°n 2 gi√° tr·ªã missing\n",
    "r_U1_I3 = predict_rating('U1', 'I3')\n",
    "r_U4_I1 = predict_rating('U4', 'I1')\n",
    "\n",
    "print(f\"üéØ D·ª± ƒëo√°n r_U1,I3 = {r_U1_I3:.2f}\")\n",
    "print(f\"üéØ D·ª± ƒëo√°n r_U4,I1 = {r_U4_I1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Ma tr·∫≠n ƒë·ªô t∆∞∆°ng ƒë·ªìng Cosine (mean-centered):\n",
      "           U1        U2        U3        U4\n",
      "U1  0.000000  0.471405  0.408248  0.907959\n",
      "U2  0.471405  0.000000 -0.707107  0.712697\n",
      "U3  0.408248 -0.707107  0.000000  0.154303\n",
      "U4  0.907959  0.712697  0.154303  0.000000 \n",
      "\n",
      "üéØ D·ª± ƒëo√°n (Cosine) r_U1,I3 = 3.53\n",
      "üéØ D·ª± ƒëo√°n (Cosine) r_U4,I1 = 3.19\n"
     ]
    }
   ],
   "source": [
    "# --- Mean-center d·ªØ li·ªáu ---\n",
    "ratings_centered = ratings.sub(ratings.mean(axis=1), axis=0)\n",
    "\n",
    "# --- Cosine similarity ---\n",
    "def cosine_sim(u1, u2):\n",
    "    common = u1.dropna().index.intersection(u2.dropna().index)\n",
    "    if len(common) == 0:\n",
    "        return 0\n",
    "    u1_vec, u2_vec = u1[common], u2[common]\n",
    "    num = np.nansum(u1_vec * u2_vec)\n",
    "    den = np.sqrt(np.nansum(u1_vec**2)) * np.sqrt(np.nansum(u2_vec**2))\n",
    "    return num/den if den != 0 else 0\n",
    "\n",
    "cosine_sim_matrix = pd.DataFrame(np.zeros((4,4)), index=users, columns=users)\n",
    "for u in users:\n",
    "    for v in users:\n",
    "        if u != v:\n",
    "            cosine_sim_matrix.loc[u,v] = cosine_sim(ratings_centered.loc[u], ratings_centered.loc[v])\n",
    "\n",
    "print(\"\\nüîπ Ma tr·∫≠n ƒë·ªô t∆∞∆°ng ƒë·ªìng Cosine (mean-centered):\\n\", cosine_sim_matrix, \"\\n\")\n",
    "\n",
    "# --- D·ª± ƒëo√°n v·ªõi cosine similarity ---\n",
    "def predict_cosine(user, item):\n",
    "    user_mean = ratings.loc[user].mean(skipna=True)\n",
    "    num, den = 0, 0\n",
    "    for other in users:\n",
    "        if other != user and not np.isnan(ratings_centered.loc[other, item]):\n",
    "            sim = cosine_sim_matrix.loc[user, other]\n",
    "            num += sim * ratings_centered.loc[other, item]\n",
    "            den += abs(sim)\n",
    "    return user_mean + num/den if den != 0 else user_mean\n",
    "\n",
    "r_U1_I3_cos = predict_cosine('U1', 'I3')\n",
    "r_U4_I1_cos = predict_cosine('U4', 'I1')\n",
    "\n",
    "print(f\"üéØ D·ª± ƒëo√°n (Cosine) r_U1,I3 = {r_U1_I3_cos:.2f}\")\n",
    "print(f\"üéØ D·ª± ƒëo√°n (Cosine) r_U4,I1 = {r_U4_I1_cos:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sIq_EDrROtgv"
   },
   "source": [
    "**B√†i 4.** (*2.5 ƒëi·ªÉm*) V·∫•n ƒë·ªÅ thu·∫≠t to√°n l·ªçc c·ªông t√°c ·ªü d·∫°ng *user-based* v√† *item-based*.\n",
    "\n",
    "S·ª≠ d·ª•ng l·∫°i dataset ·ªü b√†i 1 ho·∫∑c dataset *movie_lens* v√† ch·ªçn m·ªôt thu·∫≠t to√°n *collaborative filtering* ƒë√£ chu·∫©n b·ªã s·∫µn, th·ª±c hi·ªán hai y√™u c·∫ßu:\n",
    "1) In ra ma tr·∫≠n t∆∞∆°ng ƒë·ªìng gi·ªØa c√°c user v√† gi·ªØa c√°c item s·ª≠ d·ª•ng *sklearn.metrics.pairwise*.\n",
    "2) Duy·ªát theo t·ª´ng user v√† cho bi·∫øt s·∫Ω khuy·∫øn ngh·ªã item n√†o cho h·ªç.\n",
    "3) Duy·ªát theo t·ª´ng item v√† cho bi·∫øt s·∫Ω khuy·∫øn ngh·ªã item n√†y cho c√°c user n√†o. C√≥ nh·∫≠n x√©t g√¨ v·ªÅ k·∫øt qu·∫£ thu ƒë∆∞·ª£c ·ªü 2) v√† 3)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  song_id  rating\n",
      "0        1        1       2\n",
      "1        1       14       4\n",
      "2        1        9       5\n",
      "3        1        2       1\n",
      "4        1       16       4\n",
      "\n",
      "üîπ Ma tr·∫≠n user-item (hi·ªÉn th·ªã 5 d√≤ng ƒë·∫ßu):\n",
      "song_id   1    2    3    4    5    6    7    8    9    10   11   12   13   14  \\\n",
      "user_id                                                                         \n",
      "1        2.0  1.0  0.0  0.0  0.0  2.0  0.0  0.0  5.0  0.0  0.0  4.0  0.0  4.0   \n",
      "2        2.0  1.0  0.0  0.0  0.0  4.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0  0.0   \n",
      "3        0.0  0.0  0.0  0.0  4.0  0.0  0.0  0.0  2.0  2.0  0.0  0.0  0.0  2.0   \n",
      "4        1.0  3.0  5.0  0.0  1.0  5.0  0.0  0.0  0.0  4.0  1.0  0.0  1.0  0.0   \n",
      "5        0.0  0.0  0.0  3.0  0.0  1.0  0.0  0.0  0.0  0.0  3.0  0.0  5.0  0.0   \n",
      "\n",
      "song_id   15   16   17   18   19   20  \n",
      "user_id                                \n",
      "1        0.0  4.0  0.0  0.0  0.0  5.0  \n",
      "2        0.0  0.0  0.0  0.0  4.0  0.0  \n",
      "3        0.0  2.0  0.0  0.0  0.0  0.0  \n",
      "4        0.0  0.0  3.0  0.0  0.0  1.0  \n",
      "5        1.0  0.0  0.0  3.0  0.0  5.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# ƒê·ªçc d·ªØ li·ªáu (d√πng file b√†i 1)\n",
    "df = pd.read_csv(\"bai1_ratings.csv\")\n",
    "print(df.head())\n",
    "\n",
    "# Pivot ƒë·ªÉ t·∫°o ma tr·∫≠n user-item (users x songs)\n",
    "ratings_matrix = df.pivot_table(index='user_id', columns='song_id', values='rating')\n",
    "\n",
    "# ƒêi·ªÅn gi√° tr·ªã thi·∫øu b·∫±ng 0 (ng∆∞·ªùi ch∆∞a nghe b√†i h√°t)\n",
    "ratings_filled = ratings_matrix.fillna(0)\n",
    "\n",
    "print(\"\\nüîπ Ma tr·∫≠n user-item (hi·ªÉn th·ªã 5 d√≤ng ƒë·∫ßu):\")\n",
    "print(ratings_filled.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîπ 2Ô∏è‚É£ T√≠nh ma tr·∫≠n t∆∞∆°ng ƒë·ªìng\n",
    "üß† a. Gi·ªØa user‚Äìuser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Ma tr·∫≠n t∆∞∆°ng ƒë·ªìng gi·ªØa c√°c user:\n",
      "user_id   1     2     3     4     5     6     7     8     9     10   ...  \\\n",
      "user_id                                                              ...   \n",
      "1        1.00  0.20  0.44  0.20  0.29  0.34  0.22  0.23  0.46  0.18  ...   \n",
      "2        0.20  1.00  0.00  0.45  0.18  0.37  0.22  0.29  0.28  0.19  ...   \n",
      "3        0.44  0.00  1.00  0.22  0.00  0.00  0.18  0.19  0.56  0.11  ...   \n",
      "4        0.20  0.45  0.22  1.00  0.21  0.42  0.34  0.17  0.50  0.52  ...   \n",
      "5        0.29  0.18  0.00  0.21  1.00  0.76  0.23  0.44  0.35  0.34  ...   \n",
      "\n",
      "user_id   91    92    93    94    95    96    97    98    99    100  \n",
      "user_id                                                              \n",
      "1        0.03  0.43  0.56  0.13  0.15  0.77  0.43  0.61  0.26  0.01  \n",
      "2        0.13  0.00  0.54  0.37  0.58  0.19  0.42  0.14  0.67  0.14  \n",
      "3        0.56  0.14  0.13  0.00  0.12  0.63  0.19  0.18  0.09  0.21  \n",
      "4        0.21  0.08  0.57  0.29  0.72  0.28  0.25  0.47  0.41  0.44  \n",
      "5        0.34  0.14  0.36  0.39  0.28  0.07  0.53  0.23  0.46  0.44  \n",
      "\n",
      "[5 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "user_sim = cosine_similarity(ratings_filled)\n",
    "user_sim_df = pd.DataFrame(user_sim, index=ratings_filled.index, columns=ratings_filled.index)\n",
    "\n",
    "print(\"\\nüîπ Ma tr·∫≠n t∆∞∆°ng ƒë·ªìng gi·ªØa c√°c user:\")\n",
    "print(user_sim_df.round(2).head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß† b. Gi·ªØa item‚Äìitem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Ma tr·∫≠n t∆∞∆°ng ƒë·ªìng gi·ªØa c√°c item (b√†i h√°t):\n",
      "song_id    1     2     3     4     5     6     7     8     9     10    11  \\\n",
      "song_id                                                                     \n",
      "1        1.00  0.22  0.25  0.24  0.21  0.51  0.26  0.24  0.48  0.29  0.27   \n",
      "2        0.22  1.00  0.33  0.25  0.16  0.53  0.25  0.42  0.33  0.46  0.44   \n",
      "3        0.25  0.33  1.00  0.36  0.14  0.24  0.30  0.30  0.28  0.41  0.16   \n",
      "4        0.24  0.25  0.36  1.00  0.14  0.28  0.35  0.34  0.31  0.26  0.23   \n",
      "5        0.21  0.16  0.14  0.14  1.00  0.19  0.28  0.24  0.30  0.34  0.25   \n",
      "\n",
      "song_id    12    13    14    15    16    17    18    19    20  \n",
      "song_id                                                        \n",
      "1        0.34  0.28  0.19  0.23  0.30  0.36  0.32  0.40  0.25  \n",
      "2        0.26  0.35  0.23  0.17  0.31  0.28  0.19  0.25  0.34  \n",
      "3        0.19  0.38  0.26  0.29  0.20  0.34  0.31  0.36  0.23  \n",
      "4        0.23  0.28  0.18  0.34  0.30  0.18  0.25  0.21  0.30  \n",
      "5        0.35  0.21  0.18  0.23  0.41  0.34  0.19  0.24  0.17  \n"
     ]
    }
   ],
   "source": [
    "item_sim = cosine_similarity(ratings_filled.T)\n",
    "item_sim_df = pd.DataFrame(item_sim, index=ratings_filled.columns, columns=ratings_filled.columns)\n",
    "\n",
    "print(\"\\nüîπ Ma tr·∫≠n t∆∞∆°ng ƒë·ªìng gi·ªØa c√°c item (b√†i h√°t):\")\n",
    "print(item_sim_df.round(2).head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîπ 3Ô∏è‚É£ User-based Collaborative Filtering\n",
    "\n",
    "√ù t∆∞·ªüng:\n",
    "G·ª£i √Ω cho m·ªói user nh·ªØng item m√† ng∆∞·ªùi d√πng t∆∞∆°ng t·ª± ƒë√£ ƒë√°nh gi√° cao nh∆∞ng user ƒë√≥ ch∆∞a nghe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ G·ª£i √Ω cho user 1 (user-based CF):\n",
      "[(8, 2.997014084702143), (17, 2.9683107586830264), (11, 2.928379932791757), (19, 2.9102166000820326), (5, 2.853453324342054)]\n"
     ]
    }
   ],
   "source": [
    "def recommend_user_based(user_id, n_recommend=5):\n",
    "    user_index = ratings_filled.index.get_loc(user_id)\n",
    "    sim_scores = user_sim[user_index]\n",
    "    \n",
    "    # T√≠nh ƒëi·ªÉm d·ª± ƒëo√°n cho c√°c item ch∆∞a xem\n",
    "    user_ratings = ratings_filled.iloc[user_index]\n",
    "    unrated_items = user_ratings[user_ratings == 0].index\n",
    "    scores = {}\n",
    "    for item in unrated_items:\n",
    "        # L·∫•y c√°c user kh√°c ƒë√£ rating item n√†y\n",
    "        item_ratings = ratings_filled[item]\n",
    "        mask = item_ratings > 0\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        # D·ª± ƒëo√°n d·ª±a v√†o weighted average\n",
    "        num = np.dot(sim_scores[mask], item_ratings[mask])\n",
    "        den = np.sum(sim_scores[mask])\n",
    "        scores[item] = num/den if den != 0 else 0\n",
    "\n",
    "    # Tr·∫£ v·ªÅ top n item c√≥ ƒëi·ªÉm d·ª± ƒëo√°n cao nh·∫•t\n",
    "    return sorted(scores.items(), key=lambda x: x[1], reverse=True)[:n_recommend]\n",
    "\n",
    "# Th·ª≠ g·ª£i √Ω cho 1 user c·ª• th·ªÉ (v√≠ d·ª• user 1)\n",
    "print(\"\\nüéØ G·ª£i √Ω cho user 1 (user-based CF):\")\n",
    "print(recommend_user_based(1, n_recommend=5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîπ 4Ô∏è‚É£ Item-based Collaborative Filtering\n",
    "\n",
    "√ù t∆∞·ªüng:\n",
    "G·ª£i √Ω c√°c user n√™n nghe b√†i h√°t t∆∞∆°ng t·ª± v·ªõi c√°c b√†i h·ªç ƒë√£ nghe v√† th√≠ch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ G·ª£i √Ω cho user 1 (item-based CF):\n",
      "[(5, 3.593399442741836), (15, 3.5656591339864283), (4, 3.4387807230861784), (7, 3.426116463389561), (17, 3.3975871904328954)]\n"
     ]
    }
   ],
   "source": [
    "def recommend_item_based(user_id, n_recommend=5):\n",
    "    user_ratings = ratings_filled.loc[user_id]\n",
    "    scores = {}\n",
    "    for item in ratings_filled.columns:\n",
    "        if user_ratings[item] > 0:\n",
    "            continue  # b·ªè qua b√†i ƒë√£ nghe\n",
    "        # L·∫•y c√°c item t∆∞∆°ng t·ª± v·ªõi item hi·ªán t·∫°i m√† user ƒë√£ nghe\n",
    "        sim_items = item_sim_df[item]\n",
    "        rated_items = user_ratings[user_ratings > 0].index\n",
    "        num = np.dot(sim_items[rated_items], user_ratings[rated_items])\n",
    "        den = np.sum(np.abs(sim_items[rated_items]))\n",
    "        scores[item] = num/den if den != 0 else 0\n",
    "    return sorted(scores.items(), key=lambda x: x[1], reverse=True)[:n_recommend]\n",
    "\n",
    "# Th·ª≠ g·ª£i √Ω cho user 1 theo item-based CF\n",
    "print(\"\\nüéØ G·ª£i √Ω cho user 1 (item-based CF):\")\n",
    "print(recommend_item_based(1, n_recommend=5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîπ 5Ô∏è‚É£ G·ª£i √Ω theo t·ª´ng user v√† t·ª´ng item\n",
    "üéß a. Duy·ªát t·∫•t c·∫£ user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ G·ª£i √Ω item cho t·ª´ng user (user-based CF):\n",
      "User 1 ‚Üí g·ª£i √Ω c√°c b√†i h√°t: [8, 17, 11]\n",
      "User 2 ‚Üí g·ª£i √Ω c√°c b√†i h√°t: [13, 10, 3]\n",
      "User 3 ‚Üí g·ª£i √Ω c√°c b√†i h√°t: [8, 12, 6]\n",
      "User 4 ‚Üí g·ª£i √Ω c√°c b√†i h√°t: [8, 19, 16]\n",
      "User 5 ‚Üí g·ª£i √Ω c√°c b√†i h√°t: [8, 14, 17]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîπ G·ª£i √Ω item cho t·ª´ng user (user-based CF):\")\n",
    "for u in ratings_filled.index[:5]:  # in th·ª≠ 5 user ƒë·∫ßu\n",
    "    recs = recommend_user_based(u, n_recommend=3)\n",
    "    print(f\"User {u} ‚Üí g·ª£i √Ω c√°c b√†i h√°t: { [r[0] for r in recs] }\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéµ b. Duy·ªát t·∫•t c·∫£ item (g·ª£i √Ω ng∆∞·ªùi d√πng ph√π h·ª£p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ G·ª£i √Ω user cho t·ª´ng item (item-based CF ƒë·∫£o chi·ªÅu):\n",
      "Item 1 t∆∞∆°ng t·ª± v·ªõi c√°c item [6, 9, 19, 17, 12] ‚Üí n√™n g·ª£i √Ω cho user t·ª´ng nghe ch√∫ng.\n",
      "Item 2 t∆∞∆°ng t·ª± v·ªõi c√°c item [6, 10, 11, 8, 13] ‚Üí n√™n g·ª£i √Ω cho user t·ª´ng nghe ch√∫ng.\n",
      "Item 3 t∆∞∆°ng t·ª± v·ªõi c√°c item [10, 13, 19, 4, 17] ‚Üí n√™n g·ª£i √Ω cho user t·ª´ng nghe ch√∫ng.\n",
      "Item 4 t∆∞∆°ng t·ª± v·ªõi c√°c item [3, 7, 8, 15, 9] ‚Üí n√™n g·ª£i √Ω cho user t·ª´ng nghe ch√∫ng.\n",
      "Item 5 t∆∞∆°ng t·ª± v·ªõi c√°c item [16, 12, 17, 10, 9] ‚Üí n√™n g·ª£i √Ω cho user t·ª´ng nghe ch√∫ng.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîπ G·ª£i √Ω user cho t·ª´ng item (item-based CF ƒë·∫£o chi·ªÅu):\")\n",
    "for i in ratings_filled.columns[:5]:  # 5 item ƒë·∫ßu\n",
    "    # t√¨m user c√≥ nhi·ªÅu b√†i t∆∞∆°ng t·ª± v·ªõi i\n",
    "    sim_scores = item_sim_df[i].sort_values(ascending=False)[1:6]\n",
    "    print(f\"Item {i} t∆∞∆°ng t·ª± v·ªõi c√°c item {list(sim_scores.index)} ‚Üí n√™n g·ª£i √Ω cho user t·ª´ng nghe ch√∫ng.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## y√™u c·∫ßu th√™m\n",
    "### chu·∫©n b·ªã s·∫µn 1 thu·∫≠t to√°n l·ªçc c·ªông t√°c + d√πng kNN ƒë·ªÉ khuy·∫øn ngh·ªã theo h∆∞·ªõng user v√† h∆∞·ªõng item nha (xem trong c√°c b√†i lab ho·∫∑c l·∫•y tr√™n m·∫°ng ƒë·ªÅu ƒë∆∞·ª£c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-surprise\n",
      "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\anhtu\\anaconda3\\lib\\site-packages (from scikit-surprise) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\anhtu\\anaconda3\\lib\\site-packages (from scikit-surprise) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\anhtu\\anaconda3\\lib\\site-packages (from scikit-surprise) (1.13.1)\n",
      "Building wheels for collected packages: scikit-surprise\n",
      "  Building wheel for scikit-surprise (pyproject.toml): started\n",
      "  Building wheel for scikit-surprise (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp312-cp312-win_amd64.whl size=1290294 sha256=98513a76c77c6408d4424e6de7ef207415ed44ac0127e5fd117491dddcb9d25d\n",
      "  Stored in directory: c:\\users\\anhtu\\appdata\\local\\pip\\cache\\wheels\\75\\fa\\bc\\739bc2cb1fbaab6061854e6cfbb81a0ae52c92a502a7fa454b\n",
      "Successfully built scikit-surprise\n",
      "Installing collected packages: scikit-surprise\n",
      "Successfully installed scikit-surprise-1.1.4\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-surprise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader, KNNBasic\n",
    "from surprise.model_selection import train_test_split\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  song_id  rating\n",
      "0        1        1       2\n",
      "1        1       14       4\n",
      "2        1        9       5\n",
      "3        1        2       1\n",
      "4        1       16       4\n"
     ]
    }
   ],
   "source": [
    "# ƒê·ªçc d·ªØ li·ªáu ratings (user_id, song_id, rating)\n",
    "df = pd.read_csv(\"bai1_ratings.csv\")\n",
    "print(df.head())\n",
    "\n",
    "# Chu·∫©n h√≥a d·ªØ li·ªáu cho th∆∞ vi·ªán surprise\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df[['user_id', 'song_id', 'rating']], reader)\n",
    "\n",
    "# Chia t·∫≠p train/test\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "# C·∫•u h√¨nh KNN theo h∆∞·ªõng user\n",
    "sim_options = {\n",
    "    'name': 'cosine',   # c√≥ th·ªÉ thay b·∫±ng 'pearson'\n",
    "    'user_based': True  # True = user-based\n",
    "}\n",
    "\n",
    "# T·∫°o m√¥ h√¨nh\n",
    "user_cf = KNNBasic(k=5, sim_options=sim_options)\n",
    "\n",
    "# Hu·∫•n luy·ªán\n",
    "user_cf.fit(trainset)\n",
    "\n",
    "# D·ª± ƒëo√°n\n",
    "predictions_user = user_cf.test(testset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "# C·∫•u h√¨nh theo h∆∞·ªõng item\n",
    "sim_options = {\n",
    "    'name': 'cosine',\n",
    "    'user_based': False  # False = item-based\n",
    "}\n",
    "\n",
    "item_cf = KNNBasic(k=5, sim_options=sim_options)\n",
    "item_cf.fit(trainset)\n",
    "predictions_item = item_cf.test(testset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ G·ª£i √Ω cho user 1 (user-based CF):\n",
      "[(11, 3.8), (7, 3.4), (5, 3.2), (3, 3.0), (8, 3.0)]\n",
      "\n",
      "üéØ G·ª£i √Ω cho user 1 (item-based CF):\n",
      "[(11, 3.43), (3, 3.37), (8, 3.36), (5, 3.32), (7, 3.3)]\n"
     ]
    }
   ],
   "source": [
    "# H√†m khuy·∫øn ngh·ªã top-N item cho m·ªôt user\n",
    "def recommend_top_n(model, user_id, n=5):\n",
    "    # L·∫•y t·∫•t c·∫£ item\n",
    "    all_items = df['song_id'].unique()\n",
    "    rated_items = df[df['user_id'] == user_id]['song_id'].unique()\n",
    "    not_rated = [i for i in all_items if i not in rated_items]\n",
    "\n",
    "    # D·ª± ƒëo√°n rating cho c√°c item ch∆∞a ƒë√°nh gi√°\n",
    "    predictions = [model.predict(user_id, iid) for iid in not_rated]\n",
    "    top_n = sorted(predictions, key=lambda x: x.est, reverse=True)[:n]\n",
    "    return [(pred.iid, round(pred.est, 2)) for pred in top_n]\n",
    "\n",
    "# V√≠ d·ª• g·ª£i √Ω cho user 1\n",
    "print(\"\\nüéØ G·ª£i √Ω cho user 1 (user-based CF):\")\n",
    "print(recommend_top_n(user_cf, 1))\n",
    "\n",
    "print(\"\\nüéØ G·ª£i √Ω cho user 1 (item-based CF):\")\n",
    "print(recommend_top_n(item_cf, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Recommendation System.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
