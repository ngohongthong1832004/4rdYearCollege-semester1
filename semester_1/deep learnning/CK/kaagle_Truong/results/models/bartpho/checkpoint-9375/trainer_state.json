{
  "best_global_step": 9250,
  "best_metric": 4.064123630523682,
  "best_model_checkpoint": "/kaggle/working/models/bartpho/checkpoint-9250",
  "epoch": 3.0,
  "eval_steps": 50,
  "global_step": 9375,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0032,
      "grad_norm": 2.3305063247680664,
      "learning_rate": 1.9189765458422177e-06,
      "loss": 7.1099,
      "step": 10
    },
    {
      "epoch": 0.0064,
      "grad_norm": 2.384557008743286,
      "learning_rate": 4.051172707889126e-06,
      "loss": 7.0164,
      "step": 20
    },
    {
      "epoch": 0.0096,
      "grad_norm": 4.551266193389893,
      "learning_rate": 6.1833688699360345e-06,
      "loss": 7.0951,
      "step": 30
    },
    {
      "epoch": 0.0128,
      "grad_norm": 3.0064563751220703,
      "learning_rate": 8.315565031982942e-06,
      "loss": 6.9593,
      "step": 40
    },
    {
      "epoch": 0.016,
      "grad_norm": 2.4997971057891846,
      "learning_rate": 1.0447761194029851e-05,
      "loss": 6.898,
      "step": 50
    },
    {
      "epoch": 0.016,
      "eval_loss": 6.719749927520752,
      "eval_runtime": 3.7798,
      "eval_samples_per_second": 52.913,
      "eval_steps_per_second": 1.852,
      "step": 50
    },
    {
      "epoch": 0.0192,
      "grad_norm": 2.4876136779785156,
      "learning_rate": 1.257995735607676e-05,
      "loss": 6.5929,
      "step": 60
    },
    {
      "epoch": 0.0224,
      "grad_norm": 2.1913368701934814,
      "learning_rate": 1.4712153518123666e-05,
      "loss": 6.2112,
      "step": 70
    },
    {
      "epoch": 0.0256,
      "grad_norm": 3.2994163036346436,
      "learning_rate": 1.6844349680170575e-05,
      "loss": 6.1094,
      "step": 80
    },
    {
      "epoch": 0.0288,
      "grad_norm": 6.209730625152588,
      "learning_rate": 1.8976545842217487e-05,
      "loss": 5.9273,
      "step": 90
    },
    {
      "epoch": 0.032,
      "grad_norm": 4.427422046661377,
      "learning_rate": 2.1108742004264392e-05,
      "loss": 5.7757,
      "step": 100
    },
    {
      "epoch": 0.032,
      "eval_loss": 5.714476108551025,
      "eval_runtime": 3.7814,
      "eval_samples_per_second": 52.89,
      "eval_steps_per_second": 1.851,
      "step": 100
    },
    {
      "epoch": 0.0352,
      "grad_norm": 2.1034278869628906,
      "learning_rate": 2.32409381663113e-05,
      "loss": 5.6229,
      "step": 110
    },
    {
      "epoch": 0.0384,
      "grad_norm": 2.0190346240997314,
      "learning_rate": 2.537313432835821e-05,
      "loss": 5.5464,
      "step": 120
    },
    {
      "epoch": 0.0416,
      "grad_norm": 2.5387394428253174,
      "learning_rate": 2.7505330490405118e-05,
      "loss": 5.4178,
      "step": 130
    },
    {
      "epoch": 0.0448,
      "grad_norm": 2.7636499404907227,
      "learning_rate": 2.9637526652452023e-05,
      "loss": 5.4347,
      "step": 140
    },
    {
      "epoch": 0.048,
      "grad_norm": 2.471283435821533,
      "learning_rate": 3.1769722814498935e-05,
      "loss": 5.4492,
      "step": 150
    },
    {
      "epoch": 0.048,
      "eval_loss": 5.193675518035889,
      "eval_runtime": 3.7808,
      "eval_samples_per_second": 52.899,
      "eval_steps_per_second": 1.851,
      "step": 150
    },
    {
      "epoch": 0.0512,
      "grad_norm": 4.203850269317627,
      "learning_rate": 3.390191897654584e-05,
      "loss": 5.4014,
      "step": 160
    },
    {
      "epoch": 0.0544,
      "grad_norm": 9.003263473510742,
      "learning_rate": 3.603411513859275e-05,
      "loss": 5.3105,
      "step": 170
    },
    {
      "epoch": 0.0576,
      "grad_norm": 6.419952392578125,
      "learning_rate": 3.8166311300639665e-05,
      "loss": 5.2668,
      "step": 180
    },
    {
      "epoch": 0.0608,
      "grad_norm": 2.6106514930725098,
      "learning_rate": 4.029850746268657e-05,
      "loss": 5.3338,
      "step": 190
    },
    {
      "epoch": 0.064,
      "grad_norm": 2.9448864459991455,
      "learning_rate": 4.2430703624733475e-05,
      "loss": 5.2078,
      "step": 200
    },
    {
      "epoch": 0.064,
      "eval_loss": 5.030990123748779,
      "eval_runtime": 3.7781,
      "eval_samples_per_second": 52.936,
      "eval_steps_per_second": 1.853,
      "step": 200
    },
    {
      "epoch": 0.0672,
      "grad_norm": 2.849867820739746,
      "learning_rate": 4.456289978678039e-05,
      "loss": 5.2563,
      "step": 210
    },
    {
      "epoch": 0.0704,
      "grad_norm": 2.8218178749084473,
      "learning_rate": 4.669509594882729e-05,
      "loss": 5.021,
      "step": 220
    },
    {
      "epoch": 0.0736,
      "grad_norm": 4.385087966918945,
      "learning_rate": 4.88272921108742e-05,
      "loss": 5.1805,
      "step": 230
    },
    {
      "epoch": 0.0768,
      "grad_norm": 7.714895725250244,
      "learning_rate": 5.095948827292111e-05,
      "loss": 5.1206,
      "step": 240
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.620426654815674,
      "learning_rate": 5.3091684434968015e-05,
      "loss": 5.1099,
      "step": 250
    },
    {
      "epoch": 0.08,
      "eval_loss": 4.908316135406494,
      "eval_runtime": 3.7784,
      "eval_samples_per_second": 52.932,
      "eval_steps_per_second": 1.853,
      "step": 250
    },
    {
      "epoch": 0.0832,
      "grad_norm": 3.8428337574005127,
      "learning_rate": 5.5223880597014934e-05,
      "loss": 5.1466,
      "step": 260
    },
    {
      "epoch": 0.0864,
      "grad_norm": 2.6689887046813965,
      "learning_rate": 5.735607675906184e-05,
      "loss": 5.0197,
      "step": 270
    },
    {
      "epoch": 0.0896,
      "grad_norm": 8.6978120803833,
      "learning_rate": 5.9488272921108744e-05,
      "loss": 5.0059,
      "step": 280
    },
    {
      "epoch": 0.0928,
      "grad_norm": 3.1147663593292236,
      "learning_rate": 6.162046908315566e-05,
      "loss": 5.0973,
      "step": 290
    },
    {
      "epoch": 0.096,
      "grad_norm": 3.5116169452667236,
      "learning_rate": 6.375266524520256e-05,
      "loss": 5.0762,
      "step": 300
    },
    {
      "epoch": 0.096,
      "eval_loss": 4.8183064460754395,
      "eval_runtime": 3.7782,
      "eval_samples_per_second": 52.935,
      "eval_steps_per_second": 1.853,
      "step": 300
    },
    {
      "epoch": 0.0992,
      "grad_norm": 10.225580215454102,
      "learning_rate": 6.588486140724947e-05,
      "loss": 4.9487,
      "step": 310
    },
    {
      "epoch": 0.1024,
      "grad_norm": 2.6665823459625244,
      "learning_rate": 6.801705756929639e-05,
      "loss": 5.0473,
      "step": 320
    },
    {
      "epoch": 0.1056,
      "grad_norm": 2.968195915222168,
      "learning_rate": 7.014925373134329e-05,
      "loss": 5.0128,
      "step": 330
    },
    {
      "epoch": 0.1088,
      "grad_norm": 3.1178810596466064,
      "learning_rate": 7.22814498933902e-05,
      "loss": 5.0677,
      "step": 340
    },
    {
      "epoch": 0.112,
      "grad_norm": 4.873082160949707,
      "learning_rate": 7.44136460554371e-05,
      "loss": 5.0513,
      "step": 350
    },
    {
      "epoch": 0.112,
      "eval_loss": 4.715460300445557,
      "eval_runtime": 3.7789,
      "eval_samples_per_second": 52.926,
      "eval_steps_per_second": 1.852,
      "step": 350
    },
    {
      "epoch": 0.1152,
      "grad_norm": 3.111603260040283,
      "learning_rate": 7.6545842217484e-05,
      "loss": 4.9561,
      "step": 360
    },
    {
      "epoch": 0.1184,
      "grad_norm": 8.048988342285156,
      "learning_rate": 7.867803837953091e-05,
      "loss": 5.0846,
      "step": 370
    },
    {
      "epoch": 0.1216,
      "grad_norm": 2.6409523487091064,
      "learning_rate": 8.081023454157783e-05,
      "loss": 4.9595,
      "step": 380
    },
    {
      "epoch": 0.1248,
      "grad_norm": 5.606122970581055,
      "learning_rate": 8.294243070362474e-05,
      "loss": 4.9437,
      "step": 390
    },
    {
      "epoch": 0.128,
      "grad_norm": 2.425255060195923,
      "learning_rate": 8.507462686567164e-05,
      "loss": 5.0043,
      "step": 400
    },
    {
      "epoch": 0.128,
      "eval_loss": 4.740527629852295,
      "eval_runtime": 3.7794,
      "eval_samples_per_second": 52.918,
      "eval_steps_per_second": 1.852,
      "step": 400
    },
    {
      "epoch": 0.1312,
      "grad_norm": 2.79651141166687,
      "learning_rate": 8.720682302771856e-05,
      "loss": 5.0266,
      "step": 410
    },
    {
      "epoch": 0.1344,
      "grad_norm": 15.546526908874512,
      "learning_rate": 8.933901918976547e-05,
      "loss": 5.0002,
      "step": 420
    },
    {
      "epoch": 0.1376,
      "grad_norm": 4.589395523071289,
      "learning_rate": 9.147121535181237e-05,
      "loss": 4.8641,
      "step": 430
    },
    {
      "epoch": 0.1408,
      "grad_norm": 2.5910990238189697,
      "learning_rate": 9.360341151385929e-05,
      "loss": 4.8097,
      "step": 440
    },
    {
      "epoch": 0.144,
      "grad_norm": 2.51690411567688,
      "learning_rate": 9.57356076759062e-05,
      "loss": 4.9765,
      "step": 450
    },
    {
      "epoch": 0.144,
      "eval_loss": 4.669677257537842,
      "eval_runtime": 3.7792,
      "eval_samples_per_second": 52.921,
      "eval_steps_per_second": 1.852,
      "step": 450
    },
    {
      "epoch": 0.1472,
      "grad_norm": 2.872903823852539,
      "learning_rate": 9.78678038379531e-05,
      "loss": 4.9447,
      "step": 460
    },
    {
      "epoch": 0.1504,
      "grad_norm": 2.572369337081909,
      "learning_rate": 0.0001,
      "loss": 5.0498,
      "step": 470
    },
    {
      "epoch": 0.1536,
      "grad_norm": 2.56264328956604,
      "learning_rate": 0.00010213219616204692,
      "loss": 4.8957,
      "step": 480
    },
    {
      "epoch": 0.1568,
      "grad_norm": 2.4983081817626953,
      "learning_rate": 0.00010426439232409382,
      "loss": 4.8448,
      "step": 490
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.7852413654327393,
      "learning_rate": 0.00010639658848614073,
      "loss": 4.9352,
      "step": 500
    },
    {
      "epoch": 0.16,
      "eval_loss": 4.619658946990967,
      "eval_runtime": 3.7799,
      "eval_samples_per_second": 52.911,
      "eval_steps_per_second": 1.852,
      "step": 500
    },
    {
      "epoch": 0.1632,
      "grad_norm": 2.879622459411621,
      "learning_rate": 0.00010852878464818763,
      "loss": 4.936,
      "step": 510
    },
    {
      "epoch": 0.1664,
      "grad_norm": 3.6037447452545166,
      "learning_rate": 0.00011066098081023454,
      "loss": 4.9117,
      "step": 520
    },
    {
      "epoch": 0.1696,
      "grad_norm": 2.7547545433044434,
      "learning_rate": 0.00011279317697228145,
      "loss": 4.9537,
      "step": 530
    },
    {
      "epoch": 0.1728,
      "grad_norm": 2.461047649383545,
      "learning_rate": 0.00011492537313432837,
      "loss": 4.9102,
      "step": 540
    },
    {
      "epoch": 0.176,
      "grad_norm": 2.4993536472320557,
      "learning_rate": 0.00011705756929637527,
      "loss": 4.9134,
      "step": 550
    },
    {
      "epoch": 0.176,
      "eval_loss": 4.569713592529297,
      "eval_runtime": 3.7799,
      "eval_samples_per_second": 52.912,
      "eval_steps_per_second": 1.852,
      "step": 550
    },
    {
      "epoch": 0.1792,
      "grad_norm": 2.802421808242798,
      "learning_rate": 0.00011918976545842218,
      "loss": 4.8356,
      "step": 560
    },
    {
      "epoch": 0.1824,
      "grad_norm": 2.6815028190612793,
      "learning_rate": 0.0001213219616204691,
      "loss": 4.7871,
      "step": 570
    },
    {
      "epoch": 0.1856,
      "grad_norm": 2.5010855197906494,
      "learning_rate": 0.00012345415778251598,
      "loss": 4.8481,
      "step": 580
    },
    {
      "epoch": 0.1888,
      "grad_norm": 4.532298564910889,
      "learning_rate": 0.0001255863539445629,
      "loss": 4.9098,
      "step": 590
    },
    {
      "epoch": 0.192,
      "grad_norm": 2.4828884601593018,
      "learning_rate": 0.00012771855010660981,
      "loss": 4.9018,
      "step": 600
    },
    {
      "epoch": 0.192,
      "eval_loss": 4.553427219390869,
      "eval_runtime": 3.777,
      "eval_samples_per_second": 52.953,
      "eval_steps_per_second": 1.853,
      "step": 600
    },
    {
      "epoch": 0.1952,
      "grad_norm": 2.090672254562378,
      "learning_rate": 0.00012985074626865672,
      "loss": 4.9458,
      "step": 610
    },
    {
      "epoch": 0.1984,
      "grad_norm": 2.2718796730041504,
      "learning_rate": 0.00013198294243070365,
      "loss": 4.8645,
      "step": 620
    },
    {
      "epoch": 0.2016,
      "grad_norm": 2.2451224327087402,
      "learning_rate": 0.00013411513859275053,
      "loss": 4.9742,
      "step": 630
    },
    {
      "epoch": 0.2048,
      "grad_norm": 2.9229202270507812,
      "learning_rate": 0.00013624733475479746,
      "loss": 4.8912,
      "step": 640
    },
    {
      "epoch": 0.208,
      "grad_norm": 2.114880084991455,
      "learning_rate": 0.00013837953091684434,
      "loss": 4.7875,
      "step": 650
    },
    {
      "epoch": 0.208,
      "eval_loss": 4.5534539222717285,
      "eval_runtime": 3.7798,
      "eval_samples_per_second": 52.913,
      "eval_steps_per_second": 1.852,
      "step": 650
    },
    {
      "epoch": 0.2112,
      "grad_norm": 2.117882251739502,
      "learning_rate": 0.00014051172707889127,
      "loss": 4.8009,
      "step": 660
    },
    {
      "epoch": 0.2144,
      "grad_norm": 2.4962987899780273,
      "learning_rate": 0.00014264392324093818,
      "loss": 4.8394,
      "step": 670
    },
    {
      "epoch": 0.2176,
      "grad_norm": 2.407717704772949,
      "learning_rate": 0.00014477611940298508,
      "loss": 4.8464,
      "step": 680
    },
    {
      "epoch": 0.2208,
      "grad_norm": 2.0118730068206787,
      "learning_rate": 0.000146908315565032,
      "loss": 4.7953,
      "step": 690
    },
    {
      "epoch": 0.224,
      "grad_norm": 2.545541286468506,
      "learning_rate": 0.0001490405117270789,
      "loss": 4.8579,
      "step": 700
    },
    {
      "epoch": 0.224,
      "eval_loss": 4.539371967315674,
      "eval_runtime": 3.7799,
      "eval_samples_per_second": 52.912,
      "eval_steps_per_second": 1.852,
      "step": 700
    },
    {
      "epoch": 0.2272,
      "grad_norm": 2.1229984760284424,
      "learning_rate": 0.0001511727078891258,
      "loss": 4.7963,
      "step": 710
    },
    {
      "epoch": 0.2304,
      "grad_norm": 2.207573652267456,
      "learning_rate": 0.0001533049040511727,
      "loss": 4.8046,
      "step": 720
    },
    {
      "epoch": 0.2336,
      "grad_norm": 2.206327199935913,
      "learning_rate": 0.0001554371002132196,
      "loss": 4.8666,
      "step": 730
    },
    {
      "epoch": 0.2368,
      "grad_norm": 2.1881797313690186,
      "learning_rate": 0.00015756929637526654,
      "loss": 4.864,
      "step": 740
    },
    {
      "epoch": 0.24,
      "grad_norm": 3.893061637878418,
      "learning_rate": 0.00015970149253731345,
      "loss": 4.7497,
      "step": 750
    },
    {
      "epoch": 0.24,
      "eval_loss": 4.505318641662598,
      "eval_runtime": 3.7774,
      "eval_samples_per_second": 52.947,
      "eval_steps_per_second": 1.853,
      "step": 750
    },
    {
      "epoch": 0.2432,
      "grad_norm": 2.2650046348571777,
      "learning_rate": 0.00016183368869936035,
      "loss": 4.8447,
      "step": 760
    },
    {
      "epoch": 0.2464,
      "grad_norm": 2.239680051803589,
      "learning_rate": 0.00016396588486140726,
      "loss": 4.7984,
      "step": 770
    },
    {
      "epoch": 0.2496,
      "grad_norm": 2.4953787326812744,
      "learning_rate": 0.00016609808102345416,
      "loss": 4.8409,
      "step": 780
    },
    {
      "epoch": 0.2528,
      "grad_norm": 2.2596075534820557,
      "learning_rate": 0.0001682302771855011,
      "loss": 4.8925,
      "step": 790
    },
    {
      "epoch": 0.256,
      "grad_norm": 3.84053111076355,
      "learning_rate": 0.00017036247334754797,
      "loss": 4.8277,
      "step": 800
    },
    {
      "epoch": 0.256,
      "eval_loss": 4.523253917694092,
      "eval_runtime": 3.7756,
      "eval_samples_per_second": 52.972,
      "eval_steps_per_second": 1.854,
      "step": 800
    },
    {
      "epoch": 0.2592,
      "grad_norm": 2.101268768310547,
      "learning_rate": 0.0001724946695095949,
      "loss": 4.885,
      "step": 810
    },
    {
      "epoch": 0.2624,
      "grad_norm": 1.9758191108703613,
      "learning_rate": 0.00017462686567164178,
      "loss": 4.8671,
      "step": 820
    },
    {
      "epoch": 0.2656,
      "grad_norm": 1.8883551359176636,
      "learning_rate": 0.00017675906183368872,
      "loss": 4.7337,
      "step": 830
    },
    {
      "epoch": 0.2688,
      "grad_norm": 1.6293230056762695,
      "learning_rate": 0.0001788912579957356,
      "loss": 4.7266,
      "step": 840
    },
    {
      "epoch": 0.272,
      "grad_norm": 2.1278297901153564,
      "learning_rate": 0.00018102345415778253,
      "loss": 4.705,
      "step": 850
    },
    {
      "epoch": 0.272,
      "eval_loss": 4.5182013511657715,
      "eval_runtime": 3.7777,
      "eval_samples_per_second": 52.942,
      "eval_steps_per_second": 1.853,
      "step": 850
    },
    {
      "epoch": 0.2752,
      "grad_norm": 2.72540283203125,
      "learning_rate": 0.00018315565031982943,
      "loss": 4.7368,
      "step": 860
    },
    {
      "epoch": 0.2784,
      "grad_norm": 1.9255203008651733,
      "learning_rate": 0.00018528784648187634,
      "loss": 4.7433,
      "step": 870
    },
    {
      "epoch": 0.2816,
      "grad_norm": 1.8771640062332153,
      "learning_rate": 0.00018742004264392324,
      "loss": 4.6975,
      "step": 880
    },
    {
      "epoch": 0.2848,
      "grad_norm": 1.72080397605896,
      "learning_rate": 0.00018955223880597015,
      "loss": 4.7567,
      "step": 890
    },
    {
      "epoch": 0.288,
      "grad_norm": 1.6852850914001465,
      "learning_rate": 0.00019168443496801708,
      "loss": 4.7829,
      "step": 900
    },
    {
      "epoch": 0.288,
      "eval_loss": 4.473405838012695,
      "eval_runtime": 3.7749,
      "eval_samples_per_second": 52.982,
      "eval_steps_per_second": 1.854,
      "step": 900
    },
    {
      "epoch": 0.2912,
      "grad_norm": 1.694450855255127,
      "learning_rate": 0.00019381663113006398,
      "loss": 4.7351,
      "step": 910
    },
    {
      "epoch": 0.2944,
      "grad_norm": 1.8473972082138062,
      "learning_rate": 0.0001959488272921109,
      "loss": 4.8102,
      "step": 920
    },
    {
      "epoch": 0.2976,
      "grad_norm": 1.7164058685302734,
      "learning_rate": 0.0001980810234541578,
      "loss": 4.7443,
      "step": 930
    },
    {
      "epoch": 0.3008,
      "grad_norm": 1.8891407251358032,
      "learning_rate": 0.00019997629489154915,
      "loss": 4.6395,
      "step": 940
    },
    {
      "epoch": 0.304,
      "grad_norm": 1.739270567893982,
      "learning_rate": 0.00019973924380704044,
      "loss": 4.6961,
      "step": 950
    },
    {
      "epoch": 0.304,
      "eval_loss": 4.48206901550293,
      "eval_runtime": 3.778,
      "eval_samples_per_second": 52.938,
      "eval_steps_per_second": 1.853,
      "step": 950
    },
    {
      "epoch": 0.3072,
      "grad_norm": 1.7992641925811768,
      "learning_rate": 0.00019950219272253173,
      "loss": 4.7457,
      "step": 960
    },
    {
      "epoch": 0.3104,
      "grad_norm": 1.894554615020752,
      "learning_rate": 0.00019926514163802302,
      "loss": 4.7394,
      "step": 970
    },
    {
      "epoch": 0.3136,
      "grad_norm": 1.948104977607727,
      "learning_rate": 0.0001990280905535143,
      "loss": 4.7983,
      "step": 980
    },
    {
      "epoch": 0.3168,
      "grad_norm": 1.729811191558838,
      "learning_rate": 0.0001987910394690056,
      "loss": 4.6509,
      "step": 990
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.992512822151184,
      "learning_rate": 0.00019855398838449685,
      "loss": 4.7256,
      "step": 1000
    },
    {
      "epoch": 0.32,
      "eval_loss": 4.4424052238464355,
      "eval_runtime": 3.7761,
      "eval_samples_per_second": 52.965,
      "eval_steps_per_second": 1.854,
      "step": 1000
    },
    {
      "epoch": 0.3232,
      "grad_norm": 1.878456711769104,
      "learning_rate": 0.00019831693729998814,
      "loss": 4.5731,
      "step": 1010
    },
    {
      "epoch": 0.3264,
      "grad_norm": 1.7100615501403809,
      "learning_rate": 0.00019807988621547943,
      "loss": 4.7389,
      "step": 1020
    },
    {
      "epoch": 0.3296,
      "grad_norm": 1.5913286209106445,
      "learning_rate": 0.00019784283513097072,
      "loss": 4.7746,
      "step": 1030
    },
    {
      "epoch": 0.3328,
      "grad_norm": 1.7814539670944214,
      "learning_rate": 0.000197605784046462,
      "loss": 4.7166,
      "step": 1040
    },
    {
      "epoch": 0.336,
      "grad_norm": 1.8353197574615479,
      "learning_rate": 0.0001973687329619533,
      "loss": 4.7293,
      "step": 1050
    },
    {
      "epoch": 0.336,
      "eval_loss": 4.415815353393555,
      "eval_runtime": 3.7754,
      "eval_samples_per_second": 52.974,
      "eval_steps_per_second": 1.854,
      "step": 1050
    },
    {
      "epoch": 0.3392,
      "grad_norm": 1.6907926797866821,
      "learning_rate": 0.00019713168187744458,
      "loss": 4.6795,
      "step": 1060
    },
    {
      "epoch": 0.3424,
      "grad_norm": 1.7157076597213745,
      "learning_rate": 0.00019689463079293587,
      "loss": 4.7266,
      "step": 1070
    },
    {
      "epoch": 0.3456,
      "grad_norm": 1.6950732469558716,
      "learning_rate": 0.0001966575797084272,
      "loss": 4.6786,
      "step": 1080
    },
    {
      "epoch": 0.3488,
      "grad_norm": 1.6051297187805176,
      "learning_rate": 0.00019642052862391848,
      "loss": 4.7975,
      "step": 1090
    },
    {
      "epoch": 0.352,
      "grad_norm": 1.6871908903121948,
      "learning_rate": 0.00019618347753940976,
      "loss": 4.7325,
      "step": 1100
    },
    {
      "epoch": 0.352,
      "eval_loss": 4.430835723876953,
      "eval_runtime": 3.7773,
      "eval_samples_per_second": 52.948,
      "eval_steps_per_second": 1.853,
      "step": 1100
    },
    {
      "epoch": 0.3552,
      "grad_norm": 1.606567621231079,
      "learning_rate": 0.00019594642645490105,
      "loss": 4.7451,
      "step": 1110
    },
    {
      "epoch": 0.3584,
      "grad_norm": 1.7984328269958496,
      "learning_rate": 0.00019570937537039234,
      "loss": 4.6257,
      "step": 1120
    },
    {
      "epoch": 0.3616,
      "grad_norm": 1.4639137983322144,
      "learning_rate": 0.00019547232428588363,
      "loss": 4.6804,
      "step": 1130
    },
    {
      "epoch": 0.3648,
      "grad_norm": 1.657918930053711,
      "learning_rate": 0.00019523527320137492,
      "loss": 4.6241,
      "step": 1140
    },
    {
      "epoch": 0.368,
      "grad_norm": 1.5165525674819946,
      "learning_rate": 0.0001949982221168662,
      "loss": 4.712,
      "step": 1150
    },
    {
      "epoch": 0.368,
      "eval_loss": 4.413085460662842,
      "eval_runtime": 3.7781,
      "eval_samples_per_second": 52.936,
      "eval_steps_per_second": 1.853,
      "step": 1150
    },
    {
      "epoch": 0.3712,
      "grad_norm": 1.4957561492919922,
      "learning_rate": 0.0001947611710323575,
      "loss": 4.6153,
      "step": 1160
    },
    {
      "epoch": 0.3744,
      "grad_norm": 1.6204394102096558,
      "learning_rate": 0.00019452411994784876,
      "loss": 4.6698,
      "step": 1170
    },
    {
      "epoch": 0.3776,
      "grad_norm": 1.5082374811172485,
      "learning_rate": 0.00019428706886334004,
      "loss": 4.6191,
      "step": 1180
    },
    {
      "epoch": 0.3808,
      "grad_norm": 1.6604927778244019,
      "learning_rate": 0.00019405001777883133,
      "loss": 4.5508,
      "step": 1190
    },
    {
      "epoch": 0.384,
      "grad_norm": 1.9083771705627441,
      "learning_rate": 0.00019381296669432262,
      "loss": 4.7064,
      "step": 1200
    },
    {
      "epoch": 0.384,
      "eval_loss": 4.391747951507568,
      "eval_runtime": 3.7782,
      "eval_samples_per_second": 52.935,
      "eval_steps_per_second": 1.853,
      "step": 1200
    },
    {
      "epoch": 0.3872,
      "grad_norm": 1.967646598815918,
      "learning_rate": 0.0001935759156098139,
      "loss": 4.5949,
      "step": 1210
    },
    {
      "epoch": 0.3904,
      "grad_norm": 2.8199307918548584,
      "learning_rate": 0.0001933388645253052,
      "loss": 4.6473,
      "step": 1220
    },
    {
      "epoch": 0.3936,
      "grad_norm": 1.7231885194778442,
      "learning_rate": 0.00019310181344079649,
      "loss": 4.5682,
      "step": 1230
    },
    {
      "epoch": 0.3968,
      "grad_norm": 1.598905086517334,
      "learning_rate": 0.0001928647623562878,
      "loss": 4.6477,
      "step": 1240
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.7191706895828247,
      "learning_rate": 0.0001926277112717791,
      "loss": 4.5793,
      "step": 1250
    },
    {
      "epoch": 0.4,
      "eval_loss": 4.3929009437561035,
      "eval_runtime": 3.7751,
      "eval_samples_per_second": 52.979,
      "eval_steps_per_second": 1.854,
      "step": 1250
    },
    {
      "epoch": 0.4032,
      "grad_norm": 2.119028091430664,
      "learning_rate": 0.00019239066018727038,
      "loss": 4.6997,
      "step": 1260
    },
    {
      "epoch": 0.4064,
      "grad_norm": 1.4756293296813965,
      "learning_rate": 0.00019215360910276167,
      "loss": 4.645,
      "step": 1270
    },
    {
      "epoch": 0.4096,
      "grad_norm": 1.5355823040008545,
      "learning_rate": 0.00019191655801825295,
      "loss": 4.4625,
      "step": 1280
    },
    {
      "epoch": 0.4128,
      "grad_norm": 1.5208022594451904,
      "learning_rate": 0.00019167950693374424,
      "loss": 4.6523,
      "step": 1290
    },
    {
      "epoch": 0.416,
      "grad_norm": 1.7453231811523438,
      "learning_rate": 0.00019144245584923553,
      "loss": 4.663,
      "step": 1300
    },
    {
      "epoch": 0.416,
      "eval_loss": 4.375593662261963,
      "eval_runtime": 3.7762,
      "eval_samples_per_second": 52.963,
      "eval_steps_per_second": 1.854,
      "step": 1300
    },
    {
      "epoch": 0.4192,
      "grad_norm": 1.5143252611160278,
      "learning_rate": 0.00019120540476472682,
      "loss": 4.6484,
      "step": 1310
    },
    {
      "epoch": 0.4224,
      "grad_norm": 1.6694084405899048,
      "learning_rate": 0.0001909683536802181,
      "loss": 4.6586,
      "step": 1320
    },
    {
      "epoch": 0.4256,
      "grad_norm": 1.6832839250564575,
      "learning_rate": 0.0001907313025957094,
      "loss": 4.6915,
      "step": 1330
    },
    {
      "epoch": 0.4288,
      "grad_norm": 1.5651706457138062,
      "learning_rate": 0.00019049425151120068,
      "loss": 4.5406,
      "step": 1340
    },
    {
      "epoch": 0.432,
      "grad_norm": 1.7898529767990112,
      "learning_rate": 0.00019025720042669194,
      "loss": 4.5396,
      "step": 1350
    },
    {
      "epoch": 0.432,
      "eval_loss": 4.386008262634277,
      "eval_runtime": 3.7763,
      "eval_samples_per_second": 52.962,
      "eval_steps_per_second": 1.854,
      "step": 1350
    },
    {
      "epoch": 0.4352,
      "grad_norm": 1.719613790512085,
      "learning_rate": 0.00019002014934218323,
      "loss": 4.4902,
      "step": 1360
    },
    {
      "epoch": 0.4384,
      "grad_norm": 1.6539891958236694,
      "learning_rate": 0.00018978309825767452,
      "loss": 4.456,
      "step": 1370
    },
    {
      "epoch": 0.4416,
      "grad_norm": 1.5486458539962769,
      "learning_rate": 0.0001895460471731658,
      "loss": 4.5728,
      "step": 1380
    },
    {
      "epoch": 0.4448,
      "grad_norm": 1.5396485328674316,
      "learning_rate": 0.0001893089960886571,
      "loss": 4.5667,
      "step": 1390
    },
    {
      "epoch": 0.448,
      "grad_norm": 1.6614466905593872,
      "learning_rate": 0.00018907194500414839,
      "loss": 4.6627,
      "step": 1400
    },
    {
      "epoch": 0.448,
      "eval_loss": 4.362882137298584,
      "eval_runtime": 3.7757,
      "eval_samples_per_second": 52.97,
      "eval_steps_per_second": 1.854,
      "step": 1400
    },
    {
      "epoch": 0.4512,
      "grad_norm": 1.9401665925979614,
      "learning_rate": 0.0001888348939196397,
      "loss": 4.6352,
      "step": 1410
    },
    {
      "epoch": 0.4544,
      "grad_norm": 1.7553138732910156,
      "learning_rate": 0.000188597842835131,
      "loss": 4.6108,
      "step": 1420
    },
    {
      "epoch": 0.4576,
      "grad_norm": 2.488537073135376,
      "learning_rate": 0.00018836079175062228,
      "loss": 4.5398,
      "step": 1430
    },
    {
      "epoch": 0.4608,
      "grad_norm": 1.5664066076278687,
      "learning_rate": 0.00018812374066611357,
      "loss": 4.5922,
      "step": 1440
    },
    {
      "epoch": 0.464,
      "grad_norm": 1.8864243030548096,
      "learning_rate": 0.00018788668958160485,
      "loss": 4.5543,
      "step": 1450
    },
    {
      "epoch": 0.464,
      "eval_loss": 4.374101638793945,
      "eval_runtime": 3.7767,
      "eval_samples_per_second": 52.957,
      "eval_steps_per_second": 1.853,
      "step": 1450
    },
    {
      "epoch": 0.4672,
      "grad_norm": 1.7749477624893188,
      "learning_rate": 0.00018764963849709614,
      "loss": 4.5755,
      "step": 1460
    },
    {
      "epoch": 0.4704,
      "grad_norm": 1.4632810354232788,
      "learning_rate": 0.00018741258741258743,
      "loss": 4.663,
      "step": 1470
    },
    {
      "epoch": 0.4736,
      "grad_norm": 1.480730414390564,
      "learning_rate": 0.00018717553632807872,
      "loss": 4.6196,
      "step": 1480
    },
    {
      "epoch": 0.4768,
      "grad_norm": 1.7408554553985596,
      "learning_rate": 0.00018693848524357,
      "loss": 4.5263,
      "step": 1490
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.80406653881073,
      "learning_rate": 0.0001867014341590613,
      "loss": 4.68,
      "step": 1500
    },
    {
      "epoch": 0.48,
      "eval_loss": 4.372961521148682,
      "eval_runtime": 3.7799,
      "eval_samples_per_second": 52.911,
      "eval_steps_per_second": 1.852,
      "step": 1500
    },
    {
      "epoch": 0.4832,
      "grad_norm": 1.4730738401412964,
      "learning_rate": 0.00018646438307455258,
      "loss": 4.5726,
      "step": 1510
    },
    {
      "epoch": 0.4864,
      "grad_norm": 1.4338997602462769,
      "learning_rate": 0.00018622733199004387,
      "loss": 4.5964,
      "step": 1520
    },
    {
      "epoch": 0.4896,
      "grad_norm": 1.7069164514541626,
      "learning_rate": 0.00018599028090553513,
      "loss": 4.5966,
      "step": 1530
    },
    {
      "epoch": 0.4928,
      "grad_norm": 1.7008100748062134,
      "learning_rate": 0.00018575322982102642,
      "loss": 4.651,
      "step": 1540
    },
    {
      "epoch": 0.496,
      "grad_norm": 1.4839720726013184,
      "learning_rate": 0.0001855161787365177,
      "loss": 4.5495,
      "step": 1550
    },
    {
      "epoch": 0.496,
      "eval_loss": 4.362396717071533,
      "eval_runtime": 3.778,
      "eval_samples_per_second": 52.939,
      "eval_steps_per_second": 1.853,
      "step": 1550
    },
    {
      "epoch": 0.4992,
      "grad_norm": 1.4293406009674072,
      "learning_rate": 0.000185279127652009,
      "loss": 4.6705,
      "step": 1560
    },
    {
      "epoch": 0.5024,
      "grad_norm": 1.4808272123336792,
      "learning_rate": 0.0001850420765675003,
      "loss": 4.5242,
      "step": 1570
    },
    {
      "epoch": 0.5056,
      "grad_norm": 1.5535238981246948,
      "learning_rate": 0.0001848050254829916,
      "loss": 4.5576,
      "step": 1580
    },
    {
      "epoch": 0.5088,
      "grad_norm": 1.5473651885986328,
      "learning_rate": 0.0001845679743984829,
      "loss": 4.5202,
      "step": 1590
    },
    {
      "epoch": 0.512,
      "grad_norm": 1.4562351703643799,
      "learning_rate": 0.00018433092331397418,
      "loss": 4.513,
      "step": 1600
    },
    {
      "epoch": 0.512,
      "eval_loss": 4.311746120452881,
      "eval_runtime": 3.7773,
      "eval_samples_per_second": 52.948,
      "eval_steps_per_second": 1.853,
      "step": 1600
    },
    {
      "epoch": 0.5152,
      "grad_norm": 1.5081470012664795,
      "learning_rate": 0.00018409387222946547,
      "loss": 4.6227,
      "step": 1610
    },
    {
      "epoch": 0.5184,
      "grad_norm": 1.667574167251587,
      "learning_rate": 0.00018385682114495676,
      "loss": 4.6224,
      "step": 1620
    },
    {
      "epoch": 0.5216,
      "grad_norm": 1.6158251762390137,
      "learning_rate": 0.00018361977006044804,
      "loss": 4.6091,
      "step": 1630
    },
    {
      "epoch": 0.5248,
      "grad_norm": 1.5055800676345825,
      "learning_rate": 0.00018338271897593933,
      "loss": 4.6014,
      "step": 1640
    },
    {
      "epoch": 0.528,
      "grad_norm": 1.6533870697021484,
      "learning_rate": 0.00018314566789143062,
      "loss": 4.4692,
      "step": 1650
    },
    {
      "epoch": 0.528,
      "eval_loss": 4.312857627868652,
      "eval_runtime": 3.7772,
      "eval_samples_per_second": 52.95,
      "eval_steps_per_second": 1.853,
      "step": 1650
    },
    {
      "epoch": 0.5312,
      "grad_norm": 1.7250951528549194,
      "learning_rate": 0.0001829086168069219,
      "loss": 4.5023,
      "step": 1660
    },
    {
      "epoch": 0.5344,
      "grad_norm": 1.6617932319641113,
      "learning_rate": 0.0001826715657224132,
      "loss": 4.551,
      "step": 1670
    },
    {
      "epoch": 0.5376,
      "grad_norm": 1.615806221961975,
      "learning_rate": 0.00018243451463790448,
      "loss": 4.4218,
      "step": 1680
    },
    {
      "epoch": 0.5408,
      "grad_norm": 1.7465492486953735,
      "learning_rate": 0.00018219746355339577,
      "loss": 4.6391,
      "step": 1690
    },
    {
      "epoch": 0.544,
      "grad_norm": 1.77625572681427,
      "learning_rate": 0.00018196041246888706,
      "loss": 4.4589,
      "step": 1700
    },
    {
      "epoch": 0.544,
      "eval_loss": 4.339073657989502,
      "eval_runtime": 3.7763,
      "eval_samples_per_second": 52.962,
      "eval_steps_per_second": 1.854,
      "step": 1700
    },
    {
      "epoch": 0.5472,
      "grad_norm": 1.385705828666687,
      "learning_rate": 0.00018172336138437832,
      "loss": 4.5436,
      "step": 1710
    },
    {
      "epoch": 0.5504,
      "grad_norm": 1.4947726726531982,
      "learning_rate": 0.0001814863102998696,
      "loss": 4.5652,
      "step": 1720
    },
    {
      "epoch": 0.5536,
      "grad_norm": 1.6258881092071533,
      "learning_rate": 0.0001812492592153609,
      "loss": 4.4579,
      "step": 1730
    },
    {
      "epoch": 0.5568,
      "grad_norm": 1.773481011390686,
      "learning_rate": 0.00018101220813085221,
      "loss": 4.5278,
      "step": 1740
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.799072265625,
      "learning_rate": 0.0001807751570463435,
      "loss": 4.5995,
      "step": 1750
    },
    {
      "epoch": 0.56,
      "eval_loss": 4.316773891448975,
      "eval_runtime": 3.777,
      "eval_samples_per_second": 52.952,
      "eval_steps_per_second": 1.853,
      "step": 1750
    },
    {
      "epoch": 0.5632,
      "grad_norm": 1.6203327178955078,
      "learning_rate": 0.0001805381059618348,
      "loss": 4.6577,
      "step": 1760
    },
    {
      "epoch": 0.5664,
      "grad_norm": 2.0012874603271484,
      "learning_rate": 0.00018030105487732608,
      "loss": 4.5497,
      "step": 1770
    },
    {
      "epoch": 0.5696,
      "grad_norm": 1.548730492591858,
      "learning_rate": 0.00018006400379281737,
      "loss": 4.5007,
      "step": 1780
    },
    {
      "epoch": 0.5728,
      "grad_norm": 1.5475306510925293,
      "learning_rate": 0.00017982695270830866,
      "loss": 4.5478,
      "step": 1790
    },
    {
      "epoch": 0.576,
      "grad_norm": 1.6553248167037964,
      "learning_rate": 0.00017958990162379994,
      "loss": 4.4328,
      "step": 1800
    },
    {
      "epoch": 0.576,
      "eval_loss": 4.311306953430176,
      "eval_runtime": 3.7752,
      "eval_samples_per_second": 52.978,
      "eval_steps_per_second": 1.854,
      "step": 1800
    },
    {
      "epoch": 0.5792,
      "grad_norm": 1.7136286497116089,
      "learning_rate": 0.00017935285053929123,
      "loss": 4.4764,
      "step": 1810
    },
    {
      "epoch": 0.5824,
      "grad_norm": 1.4050612449645996,
      "learning_rate": 0.00017911579945478252,
      "loss": 4.5391,
      "step": 1820
    },
    {
      "epoch": 0.5856,
      "grad_norm": 2.2766153812408447,
      "learning_rate": 0.0001788787483702738,
      "loss": 4.4756,
      "step": 1830
    },
    {
      "epoch": 0.5888,
      "grad_norm": 1.79685640335083,
      "learning_rate": 0.0001786416972857651,
      "loss": 4.5459,
      "step": 1840
    },
    {
      "epoch": 0.592,
      "grad_norm": 1.637864351272583,
      "learning_rate": 0.00017840464620125639,
      "loss": 4.5119,
      "step": 1850
    },
    {
      "epoch": 0.592,
      "eval_loss": 4.317878246307373,
      "eval_runtime": 3.7792,
      "eval_samples_per_second": 52.921,
      "eval_steps_per_second": 1.852,
      "step": 1850
    },
    {
      "epoch": 0.5952,
      "grad_norm": 1.4610631465911865,
      "learning_rate": 0.00017816759511674767,
      "loss": 4.5146,
      "step": 1860
    },
    {
      "epoch": 0.5984,
      "grad_norm": 1.6378382444381714,
      "learning_rate": 0.00017793054403223896,
      "loss": 4.4624,
      "step": 1870
    },
    {
      "epoch": 0.6016,
      "grad_norm": 1.623214602470398,
      "learning_rate": 0.00017769349294773022,
      "loss": 4.5286,
      "step": 1880
    },
    {
      "epoch": 0.6048,
      "grad_norm": 1.5834416151046753,
      "learning_rate": 0.0001774564418632215,
      "loss": 4.5491,
      "step": 1890
    },
    {
      "epoch": 0.608,
      "grad_norm": 1.572445273399353,
      "learning_rate": 0.0001772193907787128,
      "loss": 4.5095,
      "step": 1900
    },
    {
      "epoch": 0.608,
      "eval_loss": 4.288805961608887,
      "eval_runtime": 3.7766,
      "eval_samples_per_second": 52.957,
      "eval_steps_per_second": 1.854,
      "step": 1900
    },
    {
      "epoch": 0.6112,
      "grad_norm": 1.701839804649353,
      "learning_rate": 0.00017698233969420412,
      "loss": 4.5242,
      "step": 1910
    },
    {
      "epoch": 0.6144,
      "grad_norm": 1.5035450458526611,
      "learning_rate": 0.0001767452886096954,
      "loss": 4.457,
      "step": 1920
    },
    {
      "epoch": 0.6176,
      "grad_norm": 1.7313843965530396,
      "learning_rate": 0.0001765082375251867,
      "loss": 4.494,
      "step": 1930
    },
    {
      "epoch": 0.6208,
      "grad_norm": 1.5634427070617676,
      "learning_rate": 0.00017627118644067798,
      "loss": 4.5462,
      "step": 1940
    },
    {
      "epoch": 0.624,
      "grad_norm": 1.4178237915039062,
      "learning_rate": 0.00017603413535616927,
      "loss": 4.402,
      "step": 1950
    },
    {
      "epoch": 0.624,
      "eval_loss": 4.2911481857299805,
      "eval_runtime": 3.7797,
      "eval_samples_per_second": 52.914,
      "eval_steps_per_second": 1.852,
      "step": 1950
    },
    {
      "epoch": 0.6272,
      "grad_norm": 3.0304274559020996,
      "learning_rate": 0.00017579708427166056,
      "loss": 4.6379,
      "step": 1960
    },
    {
      "epoch": 0.6304,
      "grad_norm": 1.6478374004364014,
      "learning_rate": 0.00017556003318715184,
      "loss": 4.4977,
      "step": 1970
    },
    {
      "epoch": 0.6336,
      "grad_norm": 1.7250127792358398,
      "learning_rate": 0.00017532298210264313,
      "loss": 4.4557,
      "step": 1980
    },
    {
      "epoch": 0.6368,
      "grad_norm": 1.2859915494918823,
      "learning_rate": 0.00017508593101813442,
      "loss": 4.4857,
      "step": 1990
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.4470245838165283,
      "learning_rate": 0.0001748488799336257,
      "loss": 4.5373,
      "step": 2000
    },
    {
      "epoch": 0.64,
      "eval_loss": 4.274167060852051,
      "eval_runtime": 3.7807,
      "eval_samples_per_second": 52.901,
      "eval_steps_per_second": 1.852,
      "step": 2000
    },
    {
      "epoch": 0.6432,
      "grad_norm": 1.699963927268982,
      "learning_rate": 0.000174611828849117,
      "loss": 4.529,
      "step": 2010
    },
    {
      "epoch": 0.6464,
      "grad_norm": 1.5788483619689941,
      "learning_rate": 0.00017437477776460829,
      "loss": 4.4623,
      "step": 2020
    },
    {
      "epoch": 0.6496,
      "grad_norm": 1.7201478481292725,
      "learning_rate": 0.00017413772668009957,
      "loss": 4.5553,
      "step": 2030
    },
    {
      "epoch": 0.6528,
      "grad_norm": 1.5545765161514282,
      "learning_rate": 0.00017390067559559086,
      "loss": 4.4764,
      "step": 2040
    },
    {
      "epoch": 0.656,
      "grad_norm": 1.4546416997909546,
      "learning_rate": 0.00017366362451108215,
      "loss": 4.5377,
      "step": 2050
    },
    {
      "epoch": 0.656,
      "eval_loss": 4.288211822509766,
      "eval_runtime": 3.7789,
      "eval_samples_per_second": 52.925,
      "eval_steps_per_second": 1.852,
      "step": 2050
    },
    {
      "epoch": 0.6592,
      "grad_norm": 1.8007639646530151,
      "learning_rate": 0.0001734265734265734,
      "loss": 4.4641,
      "step": 2060
    },
    {
      "epoch": 0.6624,
      "grad_norm": 1.7353988885879517,
      "learning_rate": 0.0001731895223420647,
      "loss": 4.3622,
      "step": 2070
    },
    {
      "epoch": 0.6656,
      "grad_norm": 1.634090781211853,
      "learning_rate": 0.00017295247125755602,
      "loss": 4.3594,
      "step": 2080
    },
    {
      "epoch": 0.6688,
      "grad_norm": 1.6670840978622437,
      "learning_rate": 0.0001727154201730473,
      "loss": 4.4318,
      "step": 2090
    },
    {
      "epoch": 0.672,
      "grad_norm": 1.4754141569137573,
      "learning_rate": 0.0001724783690885386,
      "loss": 4.5789,
      "step": 2100
    },
    {
      "epoch": 0.672,
      "eval_loss": 4.2770891189575195,
      "eval_runtime": 3.777,
      "eval_samples_per_second": 52.952,
      "eval_steps_per_second": 1.853,
      "step": 2100
    },
    {
      "epoch": 0.6752,
      "grad_norm": 1.4914754629135132,
      "learning_rate": 0.00017224131800402988,
      "loss": 4.5032,
      "step": 2110
    },
    {
      "epoch": 0.6784,
      "grad_norm": 1.5692700147628784,
      "learning_rate": 0.00017200426691952117,
      "loss": 4.3538,
      "step": 2120
    },
    {
      "epoch": 0.6816,
      "grad_norm": 1.5389504432678223,
      "learning_rate": 0.00017176721583501246,
      "loss": 4.4377,
      "step": 2130
    },
    {
      "epoch": 0.6848,
      "grad_norm": 1.4083802700042725,
      "learning_rate": 0.00017153016475050375,
      "loss": 4.5071,
      "step": 2140
    },
    {
      "epoch": 0.688,
      "grad_norm": 1.323996901512146,
      "learning_rate": 0.00017129311366599503,
      "loss": 4.3012,
      "step": 2150
    },
    {
      "epoch": 0.688,
      "eval_loss": 4.290858268737793,
      "eval_runtime": 3.7786,
      "eval_samples_per_second": 52.93,
      "eval_steps_per_second": 1.853,
      "step": 2150
    },
    {
      "epoch": 0.6912,
      "grad_norm": 1.5582811832427979,
      "learning_rate": 0.00017105606258148632,
      "loss": 4.4282,
      "step": 2160
    },
    {
      "epoch": 0.6944,
      "grad_norm": 1.6501892805099487,
      "learning_rate": 0.0001708190114969776,
      "loss": 4.5124,
      "step": 2170
    },
    {
      "epoch": 0.6976,
      "grad_norm": 1.4336045980453491,
      "learning_rate": 0.0001705819604124689,
      "loss": 4.4186,
      "step": 2180
    },
    {
      "epoch": 0.7008,
      "grad_norm": 1.67644202709198,
      "learning_rate": 0.0001703449093279602,
      "loss": 4.3818,
      "step": 2190
    },
    {
      "epoch": 0.704,
      "grad_norm": 1.551283836364746,
      "learning_rate": 0.00017010785824345148,
      "loss": 4.4782,
      "step": 2200
    },
    {
      "epoch": 0.704,
      "eval_loss": 4.281198978424072,
      "eval_runtime": 3.7746,
      "eval_samples_per_second": 52.985,
      "eval_steps_per_second": 1.854,
      "step": 2200
    },
    {
      "epoch": 0.7072,
      "grad_norm": 1.5395475625991821,
      "learning_rate": 0.00016987080715894276,
      "loss": 4.4478,
      "step": 2210
    },
    {
      "epoch": 0.7104,
      "grad_norm": 1.473624587059021,
      "learning_rate": 0.00016963375607443405,
      "loss": 4.5797,
      "step": 2220
    },
    {
      "epoch": 0.7136,
      "grad_norm": 1.5248843431472778,
      "learning_rate": 0.00016939670498992534,
      "loss": 4.5324,
      "step": 2230
    },
    {
      "epoch": 0.7168,
      "grad_norm": 1.565597414970398,
      "learning_rate": 0.00016915965390541663,
      "loss": 4.4796,
      "step": 2240
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.594321370124817,
      "learning_rate": 0.00016892260282090792,
      "loss": 4.476,
      "step": 2250
    },
    {
      "epoch": 0.72,
      "eval_loss": 4.273176193237305,
      "eval_runtime": 3.7762,
      "eval_samples_per_second": 52.963,
      "eval_steps_per_second": 1.854,
      "step": 2250
    },
    {
      "epoch": 0.7232,
      "grad_norm": 1.450732707977295,
      "learning_rate": 0.0001686855517363992,
      "loss": 4.49,
      "step": 2260
    },
    {
      "epoch": 0.7264,
      "grad_norm": 1.6306440830230713,
      "learning_rate": 0.0001684485006518905,
      "loss": 4.4403,
      "step": 2270
    },
    {
      "epoch": 0.7296,
      "grad_norm": 1.4034113883972168,
      "learning_rate": 0.00016821144956738178,
      "loss": 4.3035,
      "step": 2280
    },
    {
      "epoch": 0.7328,
      "grad_norm": 1.4851446151733398,
      "learning_rate": 0.00016797439848287307,
      "loss": 4.5035,
      "step": 2290
    },
    {
      "epoch": 0.736,
      "grad_norm": 1.5038931369781494,
      "learning_rate": 0.00016773734739836436,
      "loss": 4.5678,
      "step": 2300
    },
    {
      "epoch": 0.736,
      "eval_loss": 4.264343738555908,
      "eval_runtime": 3.7758,
      "eval_samples_per_second": 52.969,
      "eval_steps_per_second": 1.854,
      "step": 2300
    },
    {
      "epoch": 0.7392,
      "grad_norm": 1.531929612159729,
      "learning_rate": 0.00016750029631385565,
      "loss": 4.4271,
      "step": 2310
    },
    {
      "epoch": 0.7424,
      "grad_norm": 1.432819128036499,
      "learning_rate": 0.00016726324522934693,
      "loss": 4.4025,
      "step": 2320
    },
    {
      "epoch": 0.7456,
      "grad_norm": 1.6108273267745972,
      "learning_rate": 0.00016702619414483822,
      "loss": 4.4964,
      "step": 2330
    },
    {
      "epoch": 0.7488,
      "grad_norm": 1.5534197092056274,
      "learning_rate": 0.0001667891430603295,
      "loss": 4.4744,
      "step": 2340
    },
    {
      "epoch": 0.752,
      "grad_norm": 1.3895013332366943,
      "learning_rate": 0.0001665520919758208,
      "loss": 4.4765,
      "step": 2350
    },
    {
      "epoch": 0.752,
      "eval_loss": 4.264524936676025,
      "eval_runtime": 3.7758,
      "eval_samples_per_second": 52.97,
      "eval_steps_per_second": 1.854,
      "step": 2350
    },
    {
      "epoch": 0.7552,
      "grad_norm": 1.6237462759017944,
      "learning_rate": 0.0001663150408913121,
      "loss": 4.434,
      "step": 2360
    },
    {
      "epoch": 0.7584,
      "grad_norm": 1.5980867147445679,
      "learning_rate": 0.00016607798980680338,
      "loss": 4.4367,
      "step": 2370
    },
    {
      "epoch": 0.7616,
      "grad_norm": 1.4826539754867554,
      "learning_rate": 0.00016584093872229466,
      "loss": 4.5515,
      "step": 2380
    },
    {
      "epoch": 0.7648,
      "grad_norm": 1.5851082801818848,
      "learning_rate": 0.00016560388763778595,
      "loss": 4.3925,
      "step": 2390
    },
    {
      "epoch": 0.768,
      "grad_norm": 1.6354445219039917,
      "learning_rate": 0.00016536683655327724,
      "loss": 4.3251,
      "step": 2400
    },
    {
      "epoch": 0.768,
      "eval_loss": 4.274780750274658,
      "eval_runtime": 3.7753,
      "eval_samples_per_second": 52.977,
      "eval_steps_per_second": 1.854,
      "step": 2400
    },
    {
      "epoch": 0.7712,
      "grad_norm": 1.3612127304077148,
      "learning_rate": 0.00016512978546876853,
      "loss": 4.5152,
      "step": 2410
    },
    {
      "epoch": 0.7744,
      "grad_norm": 1.3837753534317017,
      "learning_rate": 0.00016489273438425982,
      "loss": 4.44,
      "step": 2420
    },
    {
      "epoch": 0.7776,
      "grad_norm": 1.4920103549957275,
      "learning_rate": 0.0001646556832997511,
      "loss": 4.4821,
      "step": 2430
    },
    {
      "epoch": 0.7808,
      "grad_norm": 1.5153756141662598,
      "learning_rate": 0.0001644186322152424,
      "loss": 4.3669,
      "step": 2440
    },
    {
      "epoch": 0.784,
      "grad_norm": 1.388290524482727,
      "learning_rate": 0.00016418158113073368,
      "loss": 4.3986,
      "step": 2450
    },
    {
      "epoch": 0.784,
      "eval_loss": 4.236523628234863,
      "eval_runtime": 3.7742,
      "eval_samples_per_second": 52.991,
      "eval_steps_per_second": 1.855,
      "step": 2450
    },
    {
      "epoch": 0.7872,
      "grad_norm": 1.4800766706466675,
      "learning_rate": 0.00016394453004622497,
      "loss": 4.4456,
      "step": 2460
    },
    {
      "epoch": 0.7904,
      "grad_norm": 1.5453561544418335,
      "learning_rate": 0.00016370747896171626,
      "loss": 4.456,
      "step": 2470
    },
    {
      "epoch": 0.7936,
      "grad_norm": 1.5485610961914062,
      "learning_rate": 0.00016347042787720755,
      "loss": 4.3837,
      "step": 2480
    },
    {
      "epoch": 0.7968,
      "grad_norm": 1.4278769493103027,
      "learning_rate": 0.00016323337679269884,
      "loss": 4.4951,
      "step": 2490
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.6176326274871826,
      "learning_rate": 0.00016299632570819012,
      "loss": 4.4129,
      "step": 2500
    },
    {
      "epoch": 0.8,
      "eval_loss": 4.239258289337158,
      "eval_runtime": 3.7779,
      "eval_samples_per_second": 52.939,
      "eval_steps_per_second": 1.853,
      "step": 2500
    },
    {
      "epoch": 0.8032,
      "grad_norm": 1.7573250532150269,
      "learning_rate": 0.0001627592746236814,
      "loss": 4.4205,
      "step": 2510
    },
    {
      "epoch": 0.8064,
      "grad_norm": 1.6617016792297363,
      "learning_rate": 0.0001625222235391727,
      "loss": 4.3093,
      "step": 2520
    },
    {
      "epoch": 0.8096,
      "grad_norm": 1.5162878036499023,
      "learning_rate": 0.000162285172454664,
      "loss": 4.5794,
      "step": 2530
    },
    {
      "epoch": 0.8128,
      "grad_norm": 1.519599437713623,
      "learning_rate": 0.00016204812137015528,
      "loss": 4.469,
      "step": 2540
    },
    {
      "epoch": 0.816,
      "grad_norm": 1.561985731124878,
      "learning_rate": 0.00016181107028564657,
      "loss": 4.4688,
      "step": 2550
    },
    {
      "epoch": 0.816,
      "eval_loss": 4.235051155090332,
      "eval_runtime": 3.7941,
      "eval_samples_per_second": 52.713,
      "eval_steps_per_second": 1.845,
      "step": 2550
    },
    {
      "epoch": 0.8192,
      "grad_norm": 1.4259084463119507,
      "learning_rate": 0.00016157401920113785,
      "loss": 4.5072,
      "step": 2560
    },
    {
      "epoch": 0.8224,
      "grad_norm": 1.513755202293396,
      "learning_rate": 0.00016133696811662914,
      "loss": 4.4094,
      "step": 2570
    },
    {
      "epoch": 0.8256,
      "grad_norm": 1.471809983253479,
      "learning_rate": 0.00016109991703212043,
      "loss": 4.3614,
      "step": 2580
    },
    {
      "epoch": 0.8288,
      "grad_norm": 1.5393455028533936,
      "learning_rate": 0.00016086286594761172,
      "loss": 4.4029,
      "step": 2590
    },
    {
      "epoch": 0.832,
      "grad_norm": 1.4409537315368652,
      "learning_rate": 0.000160625814863103,
      "loss": 4.5119,
      "step": 2600
    },
    {
      "epoch": 0.832,
      "eval_loss": 4.227539539337158,
      "eval_runtime": 3.7747,
      "eval_samples_per_second": 52.984,
      "eval_steps_per_second": 1.854,
      "step": 2600
    },
    {
      "epoch": 0.8352,
      "grad_norm": 1.5866283178329468,
      "learning_rate": 0.0001603887637785943,
      "loss": 4.5,
      "step": 2610
    },
    {
      "epoch": 0.8384,
      "grad_norm": 1.6606134176254272,
      "learning_rate": 0.00016015171269408558,
      "loss": 4.4837,
      "step": 2620
    },
    {
      "epoch": 0.8416,
      "grad_norm": 1.4361059665679932,
      "learning_rate": 0.00015991466160957687,
      "loss": 4.4145,
      "step": 2630
    },
    {
      "epoch": 0.8448,
      "grad_norm": 1.4850634336471558,
      "learning_rate": 0.00015967761052506816,
      "loss": 4.4325,
      "step": 2640
    },
    {
      "epoch": 0.848,
      "grad_norm": 1.523404836654663,
      "learning_rate": 0.00015944055944055945,
      "loss": 4.4875,
      "step": 2650
    },
    {
      "epoch": 0.848,
      "eval_loss": 4.219755172729492,
      "eval_runtime": 3.7755,
      "eval_samples_per_second": 52.973,
      "eval_steps_per_second": 1.854,
      "step": 2650
    },
    {
      "epoch": 0.8512,
      "grad_norm": 1.5285065174102783,
      "learning_rate": 0.00015920350835605074,
      "loss": 4.4747,
      "step": 2660
    },
    {
      "epoch": 0.8544,
      "grad_norm": 1.4854297637939453,
      "learning_rate": 0.00015896645727154202,
      "loss": 4.4225,
      "step": 2670
    },
    {
      "epoch": 0.8576,
      "grad_norm": 1.610011100769043,
      "learning_rate": 0.0001587294061870333,
      "loss": 4.4156,
      "step": 2680
    },
    {
      "epoch": 0.8608,
      "grad_norm": 1.4655612707138062,
      "learning_rate": 0.0001584923551025246,
      "loss": 4.4639,
      "step": 2690
    },
    {
      "epoch": 0.864,
      "grad_norm": 1.4283356666564941,
      "learning_rate": 0.0001582553040180159,
      "loss": 4.3954,
      "step": 2700
    },
    {
      "epoch": 0.864,
      "eval_loss": 4.226438999176025,
      "eval_runtime": 3.775,
      "eval_samples_per_second": 52.98,
      "eval_steps_per_second": 1.854,
      "step": 2700
    },
    {
      "epoch": 0.8672,
      "grad_norm": 1.3672759532928467,
      "learning_rate": 0.00015801825293350718,
      "loss": 4.3996,
      "step": 2710
    },
    {
      "epoch": 0.8704,
      "grad_norm": 1.5995476245880127,
      "learning_rate": 0.00015778120184899847,
      "loss": 4.321,
      "step": 2720
    },
    {
      "epoch": 0.8736,
      "grad_norm": 1.352170467376709,
      "learning_rate": 0.00015754415076448975,
      "loss": 4.3277,
      "step": 2730
    },
    {
      "epoch": 0.8768,
      "grad_norm": 1.3968782424926758,
      "learning_rate": 0.00015730709967998104,
      "loss": 4.493,
      "step": 2740
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.3984458446502686,
      "learning_rate": 0.00015707004859547233,
      "loss": 4.3895,
      "step": 2750
    },
    {
      "epoch": 0.88,
      "eval_loss": 4.226927757263184,
      "eval_runtime": 3.7755,
      "eval_samples_per_second": 52.973,
      "eval_steps_per_second": 1.854,
      "step": 2750
    },
    {
      "epoch": 0.8832,
      "grad_norm": 1.506750226020813,
      "learning_rate": 0.00015683299751096362,
      "loss": 4.5074,
      "step": 2760
    },
    {
      "epoch": 0.8864,
      "grad_norm": 1.5912259817123413,
      "learning_rate": 0.0001565959464264549,
      "loss": 4.3737,
      "step": 2770
    },
    {
      "epoch": 0.8896,
      "grad_norm": 1.7082170248031616,
      "learning_rate": 0.0001563588953419462,
      "loss": 4.4428,
      "step": 2780
    },
    {
      "epoch": 0.8928,
      "grad_norm": 1.531816005706787,
      "learning_rate": 0.00015612184425743748,
      "loss": 4.4465,
      "step": 2790
    },
    {
      "epoch": 0.896,
      "grad_norm": 1.770240068435669,
      "learning_rate": 0.00015588479317292877,
      "loss": 4.4466,
      "step": 2800
    },
    {
      "epoch": 0.896,
      "eval_loss": 4.217729568481445,
      "eval_runtime": 3.7751,
      "eval_samples_per_second": 52.979,
      "eval_steps_per_second": 1.854,
      "step": 2800
    },
    {
      "epoch": 0.8992,
      "grad_norm": 1.59366774559021,
      "learning_rate": 0.00015564774208842006,
      "loss": 4.4157,
      "step": 2810
    },
    {
      "epoch": 0.9024,
      "grad_norm": 1.4631474018096924,
      "learning_rate": 0.00015541069100391135,
      "loss": 4.5227,
      "step": 2820
    },
    {
      "epoch": 0.9056,
      "grad_norm": 1.5510170459747314,
      "learning_rate": 0.00015517363991940264,
      "loss": 4.3478,
      "step": 2830
    },
    {
      "epoch": 0.9088,
      "grad_norm": 1.5671467781066895,
      "learning_rate": 0.00015493658883489393,
      "loss": 4.2394,
      "step": 2840
    },
    {
      "epoch": 0.912,
      "grad_norm": 1.4943208694458008,
      "learning_rate": 0.00015469953775038521,
      "loss": 4.4132,
      "step": 2850
    },
    {
      "epoch": 0.912,
      "eval_loss": 4.230869293212891,
      "eval_runtime": 3.7757,
      "eval_samples_per_second": 52.971,
      "eval_steps_per_second": 1.854,
      "step": 2850
    },
    {
      "epoch": 0.9152,
      "grad_norm": 1.3407540321350098,
      "learning_rate": 0.0001544624866658765,
      "loss": 4.3206,
      "step": 2860
    },
    {
      "epoch": 0.9184,
      "grad_norm": 1.5016331672668457,
      "learning_rate": 0.0001542254355813678,
      "loss": 4.2927,
      "step": 2870
    },
    {
      "epoch": 0.9216,
      "grad_norm": 1.559128761291504,
      "learning_rate": 0.00015398838449685908,
      "loss": 4.3769,
      "step": 2880
    },
    {
      "epoch": 0.9248,
      "grad_norm": 1.4333231449127197,
      "learning_rate": 0.00015375133341235037,
      "loss": 4.383,
      "step": 2890
    },
    {
      "epoch": 0.928,
      "grad_norm": 1.3536726236343384,
      "learning_rate": 0.00015351428232784166,
      "loss": 4.401,
      "step": 2900
    },
    {
      "epoch": 0.928,
      "eval_loss": 4.209240436553955,
      "eval_runtime": 3.7758,
      "eval_samples_per_second": 52.968,
      "eval_steps_per_second": 1.854,
      "step": 2900
    },
    {
      "epoch": 0.9312,
      "grad_norm": 1.410759449005127,
      "learning_rate": 0.00015327723124333294,
      "loss": 4.4008,
      "step": 2910
    },
    {
      "epoch": 0.9344,
      "grad_norm": 1.5649927854537964,
      "learning_rate": 0.00015304018015882423,
      "loss": 4.448,
      "step": 2920
    },
    {
      "epoch": 0.9376,
      "grad_norm": 1.6862579584121704,
      "learning_rate": 0.00015280312907431552,
      "loss": 4.4337,
      "step": 2930
    },
    {
      "epoch": 0.9408,
      "grad_norm": 1.4708240032196045,
      "learning_rate": 0.0001525660779898068,
      "loss": 4.4116,
      "step": 2940
    },
    {
      "epoch": 0.944,
      "grad_norm": 1.7495956420898438,
      "learning_rate": 0.0001523290269052981,
      "loss": 4.4591,
      "step": 2950
    },
    {
      "epoch": 0.944,
      "eval_loss": 4.223700523376465,
      "eval_runtime": 3.7742,
      "eval_samples_per_second": 52.991,
      "eval_steps_per_second": 1.855,
      "step": 2950
    },
    {
      "epoch": 0.9472,
      "grad_norm": 1.4651912450790405,
      "learning_rate": 0.00015209197582078938,
      "loss": 4.4746,
      "step": 2960
    },
    {
      "epoch": 0.9504,
      "grad_norm": 1.723711371421814,
      "learning_rate": 0.00015185492473628067,
      "loss": 4.4539,
      "step": 2970
    },
    {
      "epoch": 0.9536,
      "grad_norm": 1.603918194770813,
      "learning_rate": 0.00015161787365177196,
      "loss": 4.4977,
      "step": 2980
    },
    {
      "epoch": 0.9568,
      "grad_norm": 1.4355729818344116,
      "learning_rate": 0.00015138082256726325,
      "loss": 4.3511,
      "step": 2990
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.4826512336730957,
      "learning_rate": 0.00015114377148275454,
      "loss": 4.2889,
      "step": 3000
    },
    {
      "epoch": 0.96,
      "eval_loss": 4.227823257446289,
      "eval_runtime": 3.7772,
      "eval_samples_per_second": 52.949,
      "eval_steps_per_second": 1.853,
      "step": 3000
    },
    {
      "epoch": 0.9632,
      "grad_norm": 1.4186477661132812,
      "learning_rate": 0.00015090672039824583,
      "loss": 4.4657,
      "step": 3010
    },
    {
      "epoch": 0.9664,
      "grad_norm": 1.58021080493927,
      "learning_rate": 0.00015066966931373711,
      "loss": 4.3452,
      "step": 3020
    },
    {
      "epoch": 0.9696,
      "grad_norm": 1.4203990697860718,
      "learning_rate": 0.0001504326182292284,
      "loss": 4.3634,
      "step": 3030
    },
    {
      "epoch": 0.9728,
      "grad_norm": 1.6311275959014893,
      "learning_rate": 0.0001501955671447197,
      "loss": 4.4356,
      "step": 3040
    },
    {
      "epoch": 0.976,
      "grad_norm": 1.417038917541504,
      "learning_rate": 0.00014995851606021098,
      "loss": 4.4746,
      "step": 3050
    },
    {
      "epoch": 0.976,
      "eval_loss": 4.195473670959473,
      "eval_runtime": 3.777,
      "eval_samples_per_second": 52.952,
      "eval_steps_per_second": 1.853,
      "step": 3050
    },
    {
      "epoch": 0.9792,
      "grad_norm": 1.418986201286316,
      "learning_rate": 0.00014972146497570227,
      "loss": 4.3301,
      "step": 3060
    },
    {
      "epoch": 0.9824,
      "grad_norm": 1.5632495880126953,
      "learning_rate": 0.00014948441389119356,
      "loss": 4.3855,
      "step": 3070
    },
    {
      "epoch": 0.9856,
      "grad_norm": 1.5204505920410156,
      "learning_rate": 0.00014924736280668484,
      "loss": 4.3623,
      "step": 3080
    },
    {
      "epoch": 0.9888,
      "grad_norm": 1.6002883911132812,
      "learning_rate": 0.00014901031172217613,
      "loss": 4.2833,
      "step": 3090
    },
    {
      "epoch": 0.992,
      "grad_norm": 1.6448904275894165,
      "learning_rate": 0.00014877326063766742,
      "loss": 4.3563,
      "step": 3100
    },
    {
      "epoch": 0.992,
      "eval_loss": 4.216566562652588,
      "eval_runtime": 3.7783,
      "eval_samples_per_second": 52.933,
      "eval_steps_per_second": 1.853,
      "step": 3100
    },
    {
      "epoch": 0.9952,
      "grad_norm": 1.6038874387741089,
      "learning_rate": 0.00014853620955315874,
      "loss": 4.3893,
      "step": 3110
    },
    {
      "epoch": 0.9984,
      "grad_norm": 1.4491450786590576,
      "learning_rate": 0.00014829915846865,
      "loss": 4.4558,
      "step": 3120
    },
    {
      "epoch": 1.0016,
      "grad_norm": 1.464586853981018,
      "learning_rate": 0.00014806210738414129,
      "loss": 4.3033,
      "step": 3130
    },
    {
      "epoch": 1.0048,
      "grad_norm": 1.4947962760925293,
      "learning_rate": 0.00014782505629963257,
      "loss": 4.364,
      "step": 3140
    },
    {
      "epoch": 1.008,
      "grad_norm": 1.435537576675415,
      "learning_rate": 0.00014758800521512386,
      "loss": 4.4372,
      "step": 3150
    },
    {
      "epoch": 1.008,
      "eval_loss": 4.212852954864502,
      "eval_runtime": 3.7778,
      "eval_samples_per_second": 52.941,
      "eval_steps_per_second": 1.853,
      "step": 3150
    },
    {
      "epoch": 1.0112,
      "grad_norm": 1.6518086194992065,
      "learning_rate": 0.00014735095413061515,
      "loss": 4.3183,
      "step": 3160
    },
    {
      "epoch": 1.0144,
      "grad_norm": 1.7172471284866333,
      "learning_rate": 0.00014711390304610644,
      "loss": 4.2895,
      "step": 3170
    },
    {
      "epoch": 1.0176,
      "grad_norm": 1.4697339534759521,
      "learning_rate": 0.00014687685196159773,
      "loss": 4.3619,
      "step": 3180
    },
    {
      "epoch": 1.0208,
      "grad_norm": 1.4613144397735596,
      "learning_rate": 0.00014663980087708902,
      "loss": 4.338,
      "step": 3190
    },
    {
      "epoch": 1.024,
      "grad_norm": 1.6958087682724,
      "learning_rate": 0.0001464027497925803,
      "loss": 4.4262,
      "step": 3200
    },
    {
      "epoch": 1.024,
      "eval_loss": 4.213695526123047,
      "eval_runtime": 3.7809,
      "eval_samples_per_second": 52.897,
      "eval_steps_per_second": 1.851,
      "step": 3200
    },
    {
      "epoch": 1.0272,
      "grad_norm": 1.6743173599243164,
      "learning_rate": 0.0001461656987080716,
      "loss": 4.3474,
      "step": 3210
    },
    {
      "epoch": 1.0304,
      "grad_norm": 1.6471521854400635,
      "learning_rate": 0.00014592864762356288,
      "loss": 4.3744,
      "step": 3220
    },
    {
      "epoch": 1.0336,
      "grad_norm": 1.582573652267456,
      "learning_rate": 0.00014569159653905417,
      "loss": 4.3464,
      "step": 3230
    },
    {
      "epoch": 1.0368,
      "grad_norm": 1.6961486339569092,
      "learning_rate": 0.00014545454545454546,
      "loss": 4.3384,
      "step": 3240
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.591525912284851,
      "learning_rate": 0.00014521749437003674,
      "loss": 4.236,
      "step": 3250
    },
    {
      "epoch": 1.04,
      "eval_loss": 4.21219539642334,
      "eval_runtime": 3.7763,
      "eval_samples_per_second": 52.962,
      "eval_steps_per_second": 1.854,
      "step": 3250
    },
    {
      "epoch": 1.0432,
      "grad_norm": 1.3879680633544922,
      "learning_rate": 0.00014498044328552803,
      "loss": 4.4117,
      "step": 3260
    },
    {
      "epoch": 1.0464,
      "grad_norm": 1.5148102045059204,
      "learning_rate": 0.00014474339220101932,
      "loss": 4.3593,
      "step": 3270
    },
    {
      "epoch": 1.0496,
      "grad_norm": 1.8135939836502075,
      "learning_rate": 0.00014450634111651064,
      "loss": 4.2789,
      "step": 3280
    },
    {
      "epoch": 1.0528,
      "grad_norm": 1.6305292844772339,
      "learning_rate": 0.00014426929003200193,
      "loss": 4.3829,
      "step": 3290
    },
    {
      "epoch": 1.056,
      "grad_norm": 1.439959168434143,
      "learning_rate": 0.00014403223894749319,
      "loss": 4.3489,
      "step": 3300
    },
    {
      "epoch": 1.056,
      "eval_loss": 4.19259786605835,
      "eval_runtime": 3.7764,
      "eval_samples_per_second": 52.96,
      "eval_steps_per_second": 1.854,
      "step": 3300
    },
    {
      "epoch": 1.0592,
      "grad_norm": 1.52165687084198,
      "learning_rate": 0.00014379518786298447,
      "loss": 4.3127,
      "step": 3310
    },
    {
      "epoch": 1.0624,
      "grad_norm": 1.534281849861145,
      "learning_rate": 0.00014355813677847576,
      "loss": 4.26,
      "step": 3320
    },
    {
      "epoch": 1.0656,
      "grad_norm": 1.4613245725631714,
      "learning_rate": 0.00014332108569396705,
      "loss": 4.3772,
      "step": 3330
    },
    {
      "epoch": 1.0688,
      "grad_norm": 1.4835636615753174,
      "learning_rate": 0.00014308403460945834,
      "loss": 4.3753,
      "step": 3340
    },
    {
      "epoch": 1.072,
      "grad_norm": 1.5298904180526733,
      "learning_rate": 0.00014284698352494963,
      "loss": 4.3422,
      "step": 3350
    },
    {
      "epoch": 1.072,
      "eval_loss": 4.199557304382324,
      "eval_runtime": 3.7787,
      "eval_samples_per_second": 52.928,
      "eval_steps_per_second": 1.852,
      "step": 3350
    },
    {
      "epoch": 1.0752,
      "grad_norm": 1.7913395166397095,
      "learning_rate": 0.00014260993244044092,
      "loss": 4.2493,
      "step": 3360
    },
    {
      "epoch": 1.0784,
      "grad_norm": 1.7498290538787842,
      "learning_rate": 0.0001423728813559322,
      "loss": 4.1852,
      "step": 3370
    },
    {
      "epoch": 1.0816,
      "grad_norm": 1.6250801086425781,
      "learning_rate": 0.0001421358302714235,
      "loss": 4.2734,
      "step": 3380
    },
    {
      "epoch": 1.0848,
      "grad_norm": 1.5071228742599487,
      "learning_rate": 0.00014189877918691478,
      "loss": 4.3892,
      "step": 3390
    },
    {
      "epoch": 1.088,
      "grad_norm": 1.4602982997894287,
      "learning_rate": 0.00014166172810240607,
      "loss": 4.2996,
      "step": 3400
    },
    {
      "epoch": 1.088,
      "eval_loss": 4.18937873840332,
      "eval_runtime": 3.7771,
      "eval_samples_per_second": 52.95,
      "eval_steps_per_second": 1.853,
      "step": 3400
    },
    {
      "epoch": 1.0912,
      "grad_norm": 1.656146764755249,
      "learning_rate": 0.00014142467701789736,
      "loss": 4.3866,
      "step": 3410
    },
    {
      "epoch": 1.0944,
      "grad_norm": 1.8424313068389893,
      "learning_rate": 0.00014118762593338865,
      "loss": 4.3672,
      "step": 3420
    },
    {
      "epoch": 1.0976,
      "grad_norm": 1.4958717823028564,
      "learning_rate": 0.00014095057484887993,
      "loss": 4.3122,
      "step": 3430
    },
    {
      "epoch": 1.1008,
      "grad_norm": 1.4892714023590088,
      "learning_rate": 0.00014071352376437122,
      "loss": 4.362,
      "step": 3440
    },
    {
      "epoch": 1.104,
      "grad_norm": 1.738419532775879,
      "learning_rate": 0.00014047647267986254,
      "loss": 4.2953,
      "step": 3450
    },
    {
      "epoch": 1.104,
      "eval_loss": 4.193152904510498,
      "eval_runtime": 3.7794,
      "eval_samples_per_second": 52.919,
      "eval_steps_per_second": 1.852,
      "step": 3450
    },
    {
      "epoch": 1.1072,
      "grad_norm": 1.3850282430648804,
      "learning_rate": 0.00014023942159535383,
      "loss": 4.3722,
      "step": 3460
    },
    {
      "epoch": 1.1104,
      "grad_norm": 1.4672880172729492,
      "learning_rate": 0.00014000237051084511,
      "loss": 4.3381,
      "step": 3470
    },
    {
      "epoch": 1.1136,
      "grad_norm": 1.3965638875961304,
      "learning_rate": 0.00013976531942633638,
      "loss": 4.274,
      "step": 3480
    },
    {
      "epoch": 1.1168,
      "grad_norm": 1.6584064960479736,
      "learning_rate": 0.00013952826834182766,
      "loss": 4.2328,
      "step": 3490
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.5579372644424438,
      "learning_rate": 0.00013929121725731895,
      "loss": 4.4191,
      "step": 3500
    },
    {
      "epoch": 1.12,
      "eval_loss": 4.17665958404541,
      "eval_runtime": 3.7775,
      "eval_samples_per_second": 52.945,
      "eval_steps_per_second": 1.853,
      "step": 3500
    },
    {
      "epoch": 1.1232,
      "grad_norm": 1.4814845323562622,
      "learning_rate": 0.00013905416617281024,
      "loss": 4.329,
      "step": 3510
    },
    {
      "epoch": 1.1264,
      "grad_norm": 1.464732050895691,
      "learning_rate": 0.00013881711508830153,
      "loss": 4.3414,
      "step": 3520
    },
    {
      "epoch": 1.1296,
      "grad_norm": 1.5181843042373657,
      "learning_rate": 0.00013858006400379282,
      "loss": 4.28,
      "step": 3530
    },
    {
      "epoch": 1.1328,
      "grad_norm": 1.6491657495498657,
      "learning_rate": 0.0001383430129192841,
      "loss": 4.3048,
      "step": 3540
    },
    {
      "epoch": 1.1360000000000001,
      "grad_norm": 1.6759525537490845,
      "learning_rate": 0.0001381059618347754,
      "loss": 4.2887,
      "step": 3550
    },
    {
      "epoch": 1.1360000000000001,
      "eval_loss": 4.193525314331055,
      "eval_runtime": 3.7791,
      "eval_samples_per_second": 52.923,
      "eval_steps_per_second": 1.852,
      "step": 3550
    },
    {
      "epoch": 1.1392,
      "grad_norm": 1.6200473308563232,
      "learning_rate": 0.00013786891075026668,
      "loss": 4.3203,
      "step": 3560
    },
    {
      "epoch": 1.1424,
      "grad_norm": 1.5785630941390991,
      "learning_rate": 0.00013763185966575797,
      "loss": 4.2458,
      "step": 3570
    },
    {
      "epoch": 1.1456,
      "grad_norm": 1.5567911863327026,
      "learning_rate": 0.00013739480858124926,
      "loss": 4.3287,
      "step": 3580
    },
    {
      "epoch": 1.1488,
      "grad_norm": 1.588516116142273,
      "learning_rate": 0.00013715775749674055,
      "loss": 4.3899,
      "step": 3590
    },
    {
      "epoch": 1.152,
      "grad_norm": 1.7283071279525757,
      "learning_rate": 0.00013692070641223183,
      "loss": 4.2819,
      "step": 3600
    },
    {
      "epoch": 1.152,
      "eval_loss": 4.201023578643799,
      "eval_runtime": 3.7803,
      "eval_samples_per_second": 52.906,
      "eval_steps_per_second": 1.852,
      "step": 3600
    },
    {
      "epoch": 1.1552,
      "grad_norm": 1.4977518320083618,
      "learning_rate": 0.00013668365532772315,
      "loss": 4.2793,
      "step": 3610
    },
    {
      "epoch": 1.1584,
      "grad_norm": 1.6137558221817017,
      "learning_rate": 0.00013644660424321444,
      "loss": 4.3019,
      "step": 3620
    },
    {
      "epoch": 1.1616,
      "grad_norm": 1.5867091417312622,
      "learning_rate": 0.00013620955315870573,
      "loss": 4.3452,
      "step": 3630
    },
    {
      "epoch": 1.1648,
      "grad_norm": 1.6706643104553223,
      "learning_rate": 0.00013597250207419701,
      "loss": 4.3319,
      "step": 3640
    },
    {
      "epoch": 1.168,
      "grad_norm": 1.5202302932739258,
      "learning_rate": 0.0001357354509896883,
      "loss": 4.4228,
      "step": 3650
    },
    {
      "epoch": 1.168,
      "eval_loss": 4.176705837249756,
      "eval_runtime": 3.779,
      "eval_samples_per_second": 52.924,
      "eval_steps_per_second": 1.852,
      "step": 3650
    },
    {
      "epoch": 1.1712,
      "grad_norm": 1.5966923236846924,
      "learning_rate": 0.00013549839990517956,
      "loss": 4.2307,
      "step": 3660
    },
    {
      "epoch": 1.1743999999999999,
      "grad_norm": 1.5099800825119019,
      "learning_rate": 0.00013526134882067085,
      "loss": 4.3572,
      "step": 3670
    },
    {
      "epoch": 1.1776,
      "grad_norm": 1.408969759941101,
      "learning_rate": 0.00013502429773616214,
      "loss": 4.3301,
      "step": 3680
    },
    {
      "epoch": 1.1808,
      "grad_norm": 1.638070821762085,
      "learning_rate": 0.00013478724665165343,
      "loss": 4.3975,
      "step": 3690
    },
    {
      "epoch": 1.184,
      "grad_norm": 1.5399518013000488,
      "learning_rate": 0.00013455019556714472,
      "loss": 4.2589,
      "step": 3700
    },
    {
      "epoch": 1.184,
      "eval_loss": 4.176966667175293,
      "eval_runtime": 3.7766,
      "eval_samples_per_second": 52.957,
      "eval_steps_per_second": 1.853,
      "step": 3700
    },
    {
      "epoch": 1.1872,
      "grad_norm": 1.5280570983886719,
      "learning_rate": 0.000134313144482636,
      "loss": 4.3797,
      "step": 3710
    },
    {
      "epoch": 1.1904,
      "grad_norm": 1.6123368740081787,
      "learning_rate": 0.0001340760933981273,
      "loss": 4.3679,
      "step": 3720
    },
    {
      "epoch": 1.1936,
      "grad_norm": 1.4621365070343018,
      "learning_rate": 0.00013383904231361858,
      "loss": 4.3347,
      "step": 3730
    },
    {
      "epoch": 1.1968,
      "grad_norm": 1.6578900814056396,
      "learning_rate": 0.00013360199122910987,
      "loss": 4.2035,
      "step": 3740
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.6221739053726196,
      "learning_rate": 0.00013336494014460116,
      "loss": 4.3428,
      "step": 3750
    },
    {
      "epoch": 1.2,
      "eval_loss": 4.1699442863464355,
      "eval_runtime": 3.777,
      "eval_samples_per_second": 52.952,
      "eval_steps_per_second": 1.853,
      "step": 3750
    },
    {
      "epoch": 1.2032,
      "grad_norm": 1.7612379789352417,
      "learning_rate": 0.00013312788906009245,
      "loss": 4.3367,
      "step": 3760
    },
    {
      "epoch": 1.2064,
      "grad_norm": 1.519525170326233,
      "learning_rate": 0.00013289083797558374,
      "loss": 4.3113,
      "step": 3770
    },
    {
      "epoch": 1.2096,
      "grad_norm": 1.5622352361679077,
      "learning_rate": 0.00013265378689107505,
      "loss": 4.3913,
      "step": 3780
    },
    {
      "epoch": 1.2128,
      "grad_norm": 1.3932582139968872,
      "learning_rate": 0.00013241673580656634,
      "loss": 4.2068,
      "step": 3790
    },
    {
      "epoch": 1.216,
      "grad_norm": 1.5356111526489258,
      "learning_rate": 0.00013217968472205763,
      "loss": 4.3165,
      "step": 3800
    },
    {
      "epoch": 1.216,
      "eval_loss": 4.160808563232422,
      "eval_runtime": 3.7774,
      "eval_samples_per_second": 52.947,
      "eval_steps_per_second": 1.853,
      "step": 3800
    },
    {
      "epoch": 1.2192,
      "grad_norm": 1.6123558282852173,
      "learning_rate": 0.00013194263363754892,
      "loss": 4.2759,
      "step": 3810
    },
    {
      "epoch": 1.2224,
      "grad_norm": 1.6378257274627686,
      "learning_rate": 0.0001317055825530402,
      "loss": 4.2023,
      "step": 3820
    },
    {
      "epoch": 1.2256,
      "grad_norm": 1.7259641885757446,
      "learning_rate": 0.00013146853146853147,
      "loss": 4.3229,
      "step": 3830
    },
    {
      "epoch": 1.2288000000000001,
      "grad_norm": 1.4916279315948486,
      "learning_rate": 0.00013123148038402275,
      "loss": 4.3196,
      "step": 3840
    },
    {
      "epoch": 1.232,
      "grad_norm": 1.614194631576538,
      "learning_rate": 0.00013099442929951404,
      "loss": 4.2816,
      "step": 3850
    },
    {
      "epoch": 1.232,
      "eval_loss": 4.179419040679932,
      "eval_runtime": 3.7764,
      "eval_samples_per_second": 52.961,
      "eval_steps_per_second": 1.854,
      "step": 3850
    },
    {
      "epoch": 1.2352,
      "grad_norm": 1.6186872720718384,
      "learning_rate": 0.00013075737821500533,
      "loss": 4.301,
      "step": 3860
    },
    {
      "epoch": 1.2384,
      "grad_norm": 1.4540119171142578,
      "learning_rate": 0.00013052032713049662,
      "loss": 4.2459,
      "step": 3870
    },
    {
      "epoch": 1.2416,
      "grad_norm": 1.5501614809036255,
      "learning_rate": 0.0001302832760459879,
      "loss": 4.2689,
      "step": 3880
    },
    {
      "epoch": 1.2448,
      "grad_norm": 1.6891847848892212,
      "learning_rate": 0.0001300462249614792,
      "loss": 4.2518,
      "step": 3890
    },
    {
      "epoch": 1.248,
      "grad_norm": 1.6886646747589111,
      "learning_rate": 0.00012980917387697048,
      "loss": 4.4252,
      "step": 3900
    },
    {
      "epoch": 1.248,
      "eval_loss": 4.156154155731201,
      "eval_runtime": 3.78,
      "eval_samples_per_second": 52.91,
      "eval_steps_per_second": 1.852,
      "step": 3900
    },
    {
      "epoch": 1.2511999999999999,
      "grad_norm": 1.63853120803833,
      "learning_rate": 0.00012957212279246177,
      "loss": 4.3258,
      "step": 3910
    },
    {
      "epoch": 1.2544,
      "grad_norm": 1.662053108215332,
      "learning_rate": 0.00012933507170795306,
      "loss": 4.3432,
      "step": 3920
    },
    {
      "epoch": 1.2576,
      "grad_norm": 1.7575979232788086,
      "learning_rate": 0.00012909802062344435,
      "loss": 4.2967,
      "step": 3930
    },
    {
      "epoch": 1.2608,
      "grad_norm": 1.47152578830719,
      "learning_rate": 0.00012886096953893564,
      "loss": 4.1945,
      "step": 3940
    },
    {
      "epoch": 1.264,
      "grad_norm": 1.564624547958374,
      "learning_rate": 0.00012862391845442695,
      "loss": 4.3061,
      "step": 3950
    },
    {
      "epoch": 1.264,
      "eval_loss": 4.1846699714660645,
      "eval_runtime": 3.7767,
      "eval_samples_per_second": 52.957,
      "eval_steps_per_second": 1.853,
      "step": 3950
    },
    {
      "epoch": 1.2671999999999999,
      "grad_norm": 1.7347759008407593,
      "learning_rate": 0.00012838686736991824,
      "loss": 4.369,
      "step": 3960
    },
    {
      "epoch": 1.2704,
      "grad_norm": 1.6503329277038574,
      "learning_rate": 0.00012814981628540953,
      "loss": 4.337,
      "step": 3970
    },
    {
      "epoch": 1.2736,
      "grad_norm": 1.5658587217330933,
      "learning_rate": 0.00012791276520090082,
      "loss": 4.3332,
      "step": 3980
    },
    {
      "epoch": 1.2768,
      "grad_norm": 1.5384478569030762,
      "learning_rate": 0.0001276757141163921,
      "loss": 4.2582,
      "step": 3990
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.6351771354675293,
      "learning_rate": 0.0001274386630318834,
      "loss": 4.3957,
      "step": 4000
    },
    {
      "epoch": 1.28,
      "eval_loss": 4.1731719970703125,
      "eval_runtime": 3.7769,
      "eval_samples_per_second": 52.954,
      "eval_steps_per_second": 1.853,
      "step": 4000
    },
    {
      "epoch": 1.2832,
      "grad_norm": 1.44794499874115,
      "learning_rate": 0.00012720161194737465,
      "loss": 4.3754,
      "step": 4010
    },
    {
      "epoch": 1.2864,
      "grad_norm": 1.5017966032028198,
      "learning_rate": 0.00012696456086286594,
      "loss": 4.2929,
      "step": 4020
    },
    {
      "epoch": 1.2896,
      "grad_norm": 1.5188934803009033,
      "learning_rate": 0.00012672750977835723,
      "loss": 4.4259,
      "step": 4030
    },
    {
      "epoch": 1.2928,
      "grad_norm": 1.5070911645889282,
      "learning_rate": 0.00012649045869384852,
      "loss": 4.3177,
      "step": 4040
    },
    {
      "epoch": 1.296,
      "grad_norm": 1.3842846155166626,
      "learning_rate": 0.0001262534076093398,
      "loss": 4.3026,
      "step": 4050
    },
    {
      "epoch": 1.296,
      "eval_loss": 4.1600847244262695,
      "eval_runtime": 3.7805,
      "eval_samples_per_second": 52.903,
      "eval_steps_per_second": 1.852,
      "step": 4050
    },
    {
      "epoch": 1.2992,
      "grad_norm": 1.4787142276763916,
      "learning_rate": 0.0001260163565248311,
      "loss": 4.3401,
      "step": 4060
    },
    {
      "epoch": 1.3024,
      "grad_norm": 1.5130982398986816,
      "learning_rate": 0.00012577930544032238,
      "loss": 4.44,
      "step": 4070
    },
    {
      "epoch": 1.3056,
      "grad_norm": 1.3963648080825806,
      "learning_rate": 0.00012554225435581367,
      "loss": 4.3326,
      "step": 4080
    },
    {
      "epoch": 1.3088,
      "grad_norm": 1.7146681547164917,
      "learning_rate": 0.00012530520327130496,
      "loss": 4.1977,
      "step": 4090
    },
    {
      "epoch": 1.312,
      "grad_norm": 1.6177364587783813,
      "learning_rate": 0.00012506815218679625,
      "loss": 4.3563,
      "step": 4100
    },
    {
      "epoch": 1.312,
      "eval_loss": 4.171626091003418,
      "eval_runtime": 3.7776,
      "eval_samples_per_second": 52.943,
      "eval_steps_per_second": 1.853,
      "step": 4100
    },
    {
      "epoch": 1.3152,
      "grad_norm": 1.6122747659683228,
      "learning_rate": 0.00012483110110228756,
      "loss": 4.2823,
      "step": 4110
    },
    {
      "epoch": 1.3184,
      "grad_norm": 1.6173235177993774,
      "learning_rate": 0.00012459405001777885,
      "loss": 4.275,
      "step": 4120
    },
    {
      "epoch": 1.3216,
      "grad_norm": 1.6486281156539917,
      "learning_rate": 0.00012435699893327014,
      "loss": 4.4287,
      "step": 4130
    },
    {
      "epoch": 1.3248,
      "grad_norm": 1.664785623550415,
      "learning_rate": 0.00012411994784876143,
      "loss": 4.3061,
      "step": 4140
    },
    {
      "epoch": 1.328,
      "grad_norm": 1.6681519746780396,
      "learning_rate": 0.00012388289676425272,
      "loss": 4.303,
      "step": 4150
    },
    {
      "epoch": 1.328,
      "eval_loss": 4.1763410568237305,
      "eval_runtime": 3.7795,
      "eval_samples_per_second": 52.917,
      "eval_steps_per_second": 1.852,
      "step": 4150
    },
    {
      "epoch": 1.3312,
      "grad_norm": 1.6334683895111084,
      "learning_rate": 0.000123645845679744,
      "loss": 4.2858,
      "step": 4160
    },
    {
      "epoch": 1.3344,
      "grad_norm": 1.5761680603027344,
      "learning_rate": 0.0001234087945952353,
      "loss": 4.379,
      "step": 4170
    },
    {
      "epoch": 1.3376000000000001,
      "grad_norm": 1.56515371799469,
      "learning_rate": 0.00012317174351072658,
      "loss": 4.2818,
      "step": 4180
    },
    {
      "epoch": 1.3408,
      "grad_norm": 1.854190707206726,
      "learning_rate": 0.00012293469242621784,
      "loss": 4.3567,
      "step": 4190
    },
    {
      "epoch": 1.3439999999999999,
      "grad_norm": 1.6275619268417358,
      "learning_rate": 0.00012269764134170913,
      "loss": 4.2728,
      "step": 4200
    },
    {
      "epoch": 1.3439999999999999,
      "eval_loss": 4.155273914337158,
      "eval_runtime": 3.7781,
      "eval_samples_per_second": 52.936,
      "eval_steps_per_second": 1.853,
      "step": 4200
    },
    {
      "epoch": 1.3472,
      "grad_norm": 1.4554299116134644,
      "learning_rate": 0.00012246059025720042,
      "loss": 4.3245,
      "step": 4210
    },
    {
      "epoch": 1.3504,
      "grad_norm": 1.6407263278961182,
      "learning_rate": 0.0001222235391726917,
      "loss": 4.2719,
      "step": 4220
    },
    {
      "epoch": 1.3536000000000001,
      "grad_norm": 1.6921919584274292,
      "learning_rate": 0.00012198648808818301,
      "loss": 4.2556,
      "step": 4230
    },
    {
      "epoch": 1.3568,
      "grad_norm": 1.579992413520813,
      "learning_rate": 0.0001217494370036743,
      "loss": 4.189,
      "step": 4240
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 1.5047543048858643,
      "learning_rate": 0.00012151238591916559,
      "loss": 4.4134,
      "step": 4250
    },
    {
      "epoch": 1.3599999999999999,
      "eval_loss": 4.146798610687256,
      "eval_runtime": 3.7781,
      "eval_samples_per_second": 52.937,
      "eval_steps_per_second": 1.853,
      "step": 4250
    },
    {
      "epoch": 1.3632,
      "grad_norm": 1.6099050045013428,
      "learning_rate": 0.00012127533483465687,
      "loss": 4.3105,
      "step": 4260
    },
    {
      "epoch": 1.3664,
      "grad_norm": 1.4394025802612305,
      "learning_rate": 0.00012103828375014816,
      "loss": 4.3039,
      "step": 4270
    },
    {
      "epoch": 1.3696,
      "grad_norm": 1.5278706550598145,
      "learning_rate": 0.00012080123266563945,
      "loss": 4.2983,
      "step": 4280
    },
    {
      "epoch": 1.3728,
      "grad_norm": 1.791908860206604,
      "learning_rate": 0.00012056418158113074,
      "loss": 4.2121,
      "step": 4290
    },
    {
      "epoch": 1.376,
      "grad_norm": 1.6485722064971924,
      "learning_rate": 0.00012032713049662203,
      "loss": 4.2857,
      "step": 4300
    },
    {
      "epoch": 1.376,
      "eval_loss": 4.148431777954102,
      "eval_runtime": 3.778,
      "eval_samples_per_second": 52.937,
      "eval_steps_per_second": 1.853,
      "step": 4300
    },
    {
      "epoch": 1.3792,
      "grad_norm": 1.6085739135742188,
      "learning_rate": 0.00012009007941211332,
      "loss": 4.2446,
      "step": 4310
    },
    {
      "epoch": 1.3824,
      "grad_norm": 1.8175076246261597,
      "learning_rate": 0.0001198530283276046,
      "loss": 4.172,
      "step": 4320
    },
    {
      "epoch": 1.3856,
      "grad_norm": 1.7272018194198608,
      "learning_rate": 0.0001196159772430959,
      "loss": 4.2385,
      "step": 4330
    },
    {
      "epoch": 1.3888,
      "grad_norm": 1.69225013256073,
      "learning_rate": 0.0001193789261585872,
      "loss": 4.4032,
      "step": 4340
    },
    {
      "epoch": 1.392,
      "grad_norm": 1.6624022722244263,
      "learning_rate": 0.00011914187507407848,
      "loss": 4.2593,
      "step": 4350
    },
    {
      "epoch": 1.392,
      "eval_loss": 4.151304244995117,
      "eval_runtime": 3.7775,
      "eval_samples_per_second": 52.945,
      "eval_steps_per_second": 1.853,
      "step": 4350
    },
    {
      "epoch": 1.3952,
      "grad_norm": 1.626563310623169,
      "learning_rate": 0.00011890482398956974,
      "loss": 4.3125,
      "step": 4360
    },
    {
      "epoch": 1.3984,
      "grad_norm": 1.8278663158416748,
      "learning_rate": 0.00011866777290506103,
      "loss": 4.2383,
      "step": 4370
    },
    {
      "epoch": 1.4016,
      "grad_norm": 1.7118022441864014,
      "learning_rate": 0.00011843072182055232,
      "loss": 4.2526,
      "step": 4380
    },
    {
      "epoch": 1.4048,
      "grad_norm": 1.4420452117919922,
      "learning_rate": 0.00011819367073604362,
      "loss": 4.3372,
      "step": 4390
    },
    {
      "epoch": 1.408,
      "grad_norm": 1.85258948802948,
      "learning_rate": 0.00011795661965153491,
      "loss": 4.2643,
      "step": 4400
    },
    {
      "epoch": 1.408,
      "eval_loss": 4.160367012023926,
      "eval_runtime": 3.7783,
      "eval_samples_per_second": 52.933,
      "eval_steps_per_second": 1.853,
      "step": 4400
    },
    {
      "epoch": 1.4112,
      "grad_norm": 1.5485275983810425,
      "learning_rate": 0.0001177195685670262,
      "loss": 4.2442,
      "step": 4410
    },
    {
      "epoch": 1.4144,
      "grad_norm": 1.435004711151123,
      "learning_rate": 0.00011748251748251749,
      "loss": 4.3497,
      "step": 4420
    },
    {
      "epoch": 1.4176,
      "grad_norm": 1.859649419784546,
      "learning_rate": 0.00011724546639800878,
      "loss": 4.3259,
      "step": 4430
    },
    {
      "epoch": 1.4208,
      "grad_norm": 1.5762985944747925,
      "learning_rate": 0.00011700841531350006,
      "loss": 4.2177,
      "step": 4440
    },
    {
      "epoch": 1.424,
      "grad_norm": 1.6485892534255981,
      "learning_rate": 0.00011677136422899135,
      "loss": 4.1965,
      "step": 4450
    },
    {
      "epoch": 1.424,
      "eval_loss": 4.15589714050293,
      "eval_runtime": 3.7771,
      "eval_samples_per_second": 52.951,
      "eval_steps_per_second": 1.853,
      "step": 4450
    },
    {
      "epoch": 1.4272,
      "grad_norm": 1.5008213520050049,
      "learning_rate": 0.00011653431314448264,
      "loss": 4.2721,
      "step": 4460
    },
    {
      "epoch": 1.4304000000000001,
      "grad_norm": 1.4398342370986938,
      "learning_rate": 0.00011629726205997393,
      "loss": 4.2791,
      "step": 4470
    },
    {
      "epoch": 1.4336,
      "grad_norm": 1.5080575942993164,
      "learning_rate": 0.00011606021097546522,
      "loss": 4.2676,
      "step": 4480
    },
    {
      "epoch": 1.4368,
      "grad_norm": 1.493407964706421,
      "learning_rate": 0.0001158231598909565,
      "loss": 4.4315,
      "step": 4490
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.6546200513839722,
      "learning_rate": 0.00011558610880644781,
      "loss": 4.1912,
      "step": 4500
    },
    {
      "epoch": 1.44,
      "eval_loss": 4.1508097648620605,
      "eval_runtime": 3.7793,
      "eval_samples_per_second": 52.92,
      "eval_steps_per_second": 1.852,
      "step": 4500
    },
    {
      "epoch": 1.4432,
      "grad_norm": 1.599121332168579,
      "learning_rate": 0.0001153490577219391,
      "loss": 4.2592,
      "step": 4510
    },
    {
      "epoch": 1.4464000000000001,
      "grad_norm": 1.5633889436721802,
      "learning_rate": 0.00011511200663743038,
      "loss": 4.2494,
      "step": 4520
    },
    {
      "epoch": 1.4496,
      "grad_norm": 1.772156000137329,
      "learning_rate": 0.00011487495555292167,
      "loss": 4.2744,
      "step": 4530
    },
    {
      "epoch": 1.4527999999999999,
      "grad_norm": 1.655559778213501,
      "learning_rate": 0.00011463790446841293,
      "loss": 4.3537,
      "step": 4540
    },
    {
      "epoch": 1.456,
      "grad_norm": 1.4612610340118408,
      "learning_rate": 0.00011440085338390422,
      "loss": 4.3714,
      "step": 4550
    },
    {
      "epoch": 1.456,
      "eval_loss": 4.134843349456787,
      "eval_runtime": 3.777,
      "eval_samples_per_second": 52.951,
      "eval_steps_per_second": 1.853,
      "step": 4550
    },
    {
      "epoch": 1.4592,
      "grad_norm": 1.619716763496399,
      "learning_rate": 0.00011416380229939552,
      "loss": 4.2931,
      "step": 4560
    },
    {
      "epoch": 1.4624,
      "grad_norm": 1.6014142036437988,
      "learning_rate": 0.00011392675121488681,
      "loss": 4.2801,
      "step": 4570
    },
    {
      "epoch": 1.4656,
      "grad_norm": 1.8790769577026367,
      "learning_rate": 0.0001136897001303781,
      "loss": 4.1504,
      "step": 4580
    },
    {
      "epoch": 1.4687999999999999,
      "grad_norm": 1.4324607849121094,
      "learning_rate": 0.00011345264904586939,
      "loss": 4.2958,
      "step": 4590
    },
    {
      "epoch": 1.472,
      "grad_norm": 1.5339690446853638,
      "learning_rate": 0.00011321559796136068,
      "loss": 4.1743,
      "step": 4600
    },
    {
      "epoch": 1.472,
      "eval_loss": 4.152394771575928,
      "eval_runtime": 3.7779,
      "eval_samples_per_second": 52.94,
      "eval_steps_per_second": 1.853,
      "step": 4600
    },
    {
      "epoch": 1.4752,
      "grad_norm": 1.8211356401443481,
      "learning_rate": 0.00011297854687685196,
      "loss": 4.2728,
      "step": 4610
    },
    {
      "epoch": 1.4784,
      "grad_norm": 1.600215196609497,
      "learning_rate": 0.00011274149579234325,
      "loss": 4.3212,
      "step": 4620
    },
    {
      "epoch": 1.4816,
      "grad_norm": 1.6286121606826782,
      "learning_rate": 0.00011250444470783454,
      "loss": 4.2984,
      "step": 4630
    },
    {
      "epoch": 1.4848,
      "grad_norm": 1.5764942169189453,
      "learning_rate": 0.00011226739362332583,
      "loss": 4.3187,
      "step": 4640
    },
    {
      "epoch": 1.488,
      "grad_norm": 1.4572103023529053,
      "learning_rate": 0.00011203034253881712,
      "loss": 4.4028,
      "step": 4650
    },
    {
      "epoch": 1.488,
      "eval_loss": 4.136463165283203,
      "eval_runtime": 3.7775,
      "eval_samples_per_second": 52.946,
      "eval_steps_per_second": 1.853,
      "step": 4650
    },
    {
      "epoch": 1.4912,
      "grad_norm": 1.6159851551055908,
      "learning_rate": 0.00011179329145430842,
      "loss": 4.2408,
      "step": 4660
    },
    {
      "epoch": 1.4944,
      "grad_norm": 1.689099907875061,
      "learning_rate": 0.00011155624036979971,
      "loss": 4.2732,
      "step": 4670
    },
    {
      "epoch": 1.4976,
      "grad_norm": 1.5784952640533447,
      "learning_rate": 0.000111319189285291,
      "loss": 4.1707,
      "step": 4680
    },
    {
      "epoch": 1.5008,
      "grad_norm": 1.4892199039459229,
      "learning_rate": 0.00011108213820078228,
      "loss": 4.3592,
      "step": 4690
    },
    {
      "epoch": 1.504,
      "grad_norm": 1.640909194946289,
      "learning_rate": 0.00011084508711627357,
      "loss": 4.3128,
      "step": 4700
    },
    {
      "epoch": 1.504,
      "eval_loss": 4.1334309577941895,
      "eval_runtime": 3.7811,
      "eval_samples_per_second": 52.894,
      "eval_steps_per_second": 1.851,
      "step": 4700
    },
    {
      "epoch": 1.5072,
      "grad_norm": 1.6847481727600098,
      "learning_rate": 0.00011060803603176486,
      "loss": 4.2459,
      "step": 4710
    },
    {
      "epoch": 1.5104,
      "grad_norm": 1.6149404048919678,
      "learning_rate": 0.00011037098494725612,
      "loss": 4.3037,
      "step": 4720
    },
    {
      "epoch": 1.5135999999999998,
      "grad_norm": 1.681792974472046,
      "learning_rate": 0.00011013393386274742,
      "loss": 4.312,
      "step": 4730
    },
    {
      "epoch": 1.5168,
      "grad_norm": 1.6663891077041626,
      "learning_rate": 0.00010989688277823871,
      "loss": 4.2993,
      "step": 4740
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.5943913459777832,
      "learning_rate": 0.00010965983169373,
      "loss": 4.2585,
      "step": 4750
    },
    {
      "epoch": 1.52,
      "eval_loss": 4.1353840827941895,
      "eval_runtime": 3.7804,
      "eval_samples_per_second": 52.905,
      "eval_steps_per_second": 1.852,
      "step": 4750
    },
    {
      "epoch": 1.5232,
      "grad_norm": 1.7076725959777832,
      "learning_rate": 0.00010942278060922129,
      "loss": 4.2139,
      "step": 4760
    },
    {
      "epoch": 1.5264,
      "grad_norm": 1.665618896484375,
      "learning_rate": 0.00010918572952471258,
      "loss": 4.2025,
      "step": 4770
    },
    {
      "epoch": 1.5295999999999998,
      "grad_norm": 1.577144742012024,
      "learning_rate": 0.00010894867844020387,
      "loss": 4.2581,
      "step": 4780
    },
    {
      "epoch": 1.5328,
      "grad_norm": 1.7495274543762207,
      "learning_rate": 0.00010871162735569515,
      "loss": 4.2531,
      "step": 4790
    },
    {
      "epoch": 1.536,
      "grad_norm": 1.7066762447357178,
      "learning_rate": 0.00010847457627118644,
      "loss": 4.2816,
      "step": 4800
    },
    {
      "epoch": 1.536,
      "eval_loss": 4.138350963592529,
      "eval_runtime": 3.7774,
      "eval_samples_per_second": 52.947,
      "eval_steps_per_second": 1.853,
      "step": 4800
    },
    {
      "epoch": 1.5392000000000001,
      "grad_norm": 1.6516679525375366,
      "learning_rate": 0.00010823752518667773,
      "loss": 4.2374,
      "step": 4810
    },
    {
      "epoch": 1.5424,
      "grad_norm": 1.735249638557434,
      "learning_rate": 0.00010800047410216902,
      "loss": 4.2623,
      "step": 4820
    },
    {
      "epoch": 1.5455999999999999,
      "grad_norm": 1.5325111150741577,
      "learning_rate": 0.00010776342301766032,
      "loss": 4.274,
      "step": 4830
    },
    {
      "epoch": 1.5488,
      "grad_norm": 1.6809128522872925,
      "learning_rate": 0.00010752637193315161,
      "loss": 4.1244,
      "step": 4840
    },
    {
      "epoch": 1.552,
      "grad_norm": 1.7207190990447998,
      "learning_rate": 0.0001072893208486429,
      "loss": 4.3244,
      "step": 4850
    },
    {
      "epoch": 1.552,
      "eval_loss": 4.134176254272461,
      "eval_runtime": 3.7783,
      "eval_samples_per_second": 52.935,
      "eval_steps_per_second": 1.853,
      "step": 4850
    },
    {
      "epoch": 1.5552000000000001,
      "grad_norm": 1.7872834205627441,
      "learning_rate": 0.00010705226976413419,
      "loss": 4.2429,
      "step": 4860
    },
    {
      "epoch": 1.5584,
      "grad_norm": 1.5980993509292603,
      "learning_rate": 0.00010681521867962547,
      "loss": 4.207,
      "step": 4870
    },
    {
      "epoch": 1.5615999999999999,
      "grad_norm": 1.691666603088379,
      "learning_rate": 0.00010657816759511676,
      "loss": 4.2344,
      "step": 4880
    },
    {
      "epoch": 1.5648,
      "grad_norm": 1.6279345750808716,
      "learning_rate": 0.00010634111651060805,
      "loss": 4.2387,
      "step": 4890
    },
    {
      "epoch": 1.568,
      "grad_norm": 1.5565855503082275,
      "learning_rate": 0.00010610406542609932,
      "loss": 4.2498,
      "step": 4900
    },
    {
      "epoch": 1.568,
      "eval_loss": 4.141090393066406,
      "eval_runtime": 3.7782,
      "eval_samples_per_second": 52.935,
      "eval_steps_per_second": 1.853,
      "step": 4900
    },
    {
      "epoch": 1.5712000000000002,
      "grad_norm": 1.5418809652328491,
      "learning_rate": 0.00010586701434159061,
      "loss": 4.2805,
      "step": 4910
    },
    {
      "epoch": 1.5744,
      "grad_norm": 1.7072830200195312,
      "learning_rate": 0.0001056299632570819,
      "loss": 4.3054,
      "step": 4920
    },
    {
      "epoch": 1.5776,
      "grad_norm": 1.623311161994934,
      "learning_rate": 0.00010539291217257319,
      "loss": 4.1926,
      "step": 4930
    },
    {
      "epoch": 1.5808,
      "grad_norm": 1.8141794204711914,
      "learning_rate": 0.00010515586108806448,
      "loss": 4.1896,
      "step": 4940
    },
    {
      "epoch": 1.584,
      "grad_norm": 1.6437686681747437,
      "learning_rate": 0.00010491881000355577,
      "loss": 4.3436,
      "step": 4950
    },
    {
      "epoch": 1.584,
      "eval_loss": 4.129861354827881,
      "eval_runtime": 3.778,
      "eval_samples_per_second": 52.938,
      "eval_steps_per_second": 1.853,
      "step": 4950
    },
    {
      "epoch": 1.5872000000000002,
      "grad_norm": 1.701220989227295,
      "learning_rate": 0.00010468175891904705,
      "loss": 4.1651,
      "step": 4960
    },
    {
      "epoch": 1.5904,
      "grad_norm": 1.5052361488342285,
      "learning_rate": 0.00010444470783453834,
      "loss": 4.3292,
      "step": 4970
    },
    {
      "epoch": 1.5936,
      "grad_norm": 1.6692508459091187,
      "learning_rate": 0.00010420765675002963,
      "loss": 4.303,
      "step": 4980
    },
    {
      "epoch": 1.5968,
      "grad_norm": 1.6423742771148682,
      "learning_rate": 0.00010397060566552092,
      "loss": 4.2308,
      "step": 4990
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.4641834497451782,
      "learning_rate": 0.00010373355458101222,
      "loss": 4.185,
      "step": 5000
    },
    {
      "epoch": 1.6,
      "eval_loss": 4.123706817626953,
      "eval_runtime": 3.7772,
      "eval_samples_per_second": 52.95,
      "eval_steps_per_second": 1.853,
      "step": 5000
    },
    {
      "epoch": 1.6032,
      "grad_norm": 1.4687801599502563,
      "learning_rate": 0.00010349650349650351,
      "loss": 4.2009,
      "step": 5010
    },
    {
      "epoch": 1.6064,
      "grad_norm": 1.6557124853134155,
      "learning_rate": 0.0001032594524119948,
      "loss": 4.3249,
      "step": 5020
    },
    {
      "epoch": 1.6096,
      "grad_norm": 1.6482665538787842,
      "learning_rate": 0.00010302240132748609,
      "loss": 4.2348,
      "step": 5030
    },
    {
      "epoch": 1.6128,
      "grad_norm": 1.5533288717269897,
      "learning_rate": 0.00010278535024297737,
      "loss": 4.2675,
      "step": 5040
    },
    {
      "epoch": 1.616,
      "grad_norm": 1.5195177793502808,
      "learning_rate": 0.00010254829915846866,
      "loss": 4.3789,
      "step": 5050
    },
    {
      "epoch": 1.616,
      "eval_loss": 4.12429141998291,
      "eval_runtime": 3.7765,
      "eval_samples_per_second": 52.959,
      "eval_steps_per_second": 1.854,
      "step": 5050
    },
    {
      "epoch": 1.6192,
      "grad_norm": 1.6259431838989258,
      "learning_rate": 0.00010231124807395995,
      "loss": 4.2889,
      "step": 5060
    },
    {
      "epoch": 1.6223999999999998,
      "grad_norm": 1.5458762645721436,
      "learning_rate": 0.00010207419698945123,
      "loss": 4.2979,
      "step": 5070
    },
    {
      "epoch": 1.6256,
      "grad_norm": 1.5954610109329224,
      "learning_rate": 0.00010183714590494251,
      "loss": 4.2644,
      "step": 5080
    },
    {
      "epoch": 1.6288,
      "grad_norm": 1.62152099609375,
      "learning_rate": 0.0001016000948204338,
      "loss": 4.2976,
      "step": 5090
    },
    {
      "epoch": 1.6320000000000001,
      "grad_norm": 1.673673152923584,
      "learning_rate": 0.00010136304373592509,
      "loss": 4.306,
      "step": 5100
    },
    {
      "epoch": 1.6320000000000001,
      "eval_loss": 4.1386399269104,
      "eval_runtime": 3.7769,
      "eval_samples_per_second": 52.954,
      "eval_steps_per_second": 1.853,
      "step": 5100
    },
    {
      "epoch": 1.6352,
      "grad_norm": 1.5008456707000732,
      "learning_rate": 0.00010112599265141638,
      "loss": 4.2805,
      "step": 5110
    },
    {
      "epoch": 1.6383999999999999,
      "grad_norm": 1.572455644607544,
      "learning_rate": 0.00010088894156690767,
      "loss": 4.2697,
      "step": 5120
    },
    {
      "epoch": 1.6416,
      "grad_norm": 1.6243491172790527,
      "learning_rate": 0.00010065189048239896,
      "loss": 4.2988,
      "step": 5130
    },
    {
      "epoch": 1.6448,
      "grad_norm": 1.459722638130188,
      "learning_rate": 0.00010041483939789024,
      "loss": 4.3251,
      "step": 5140
    },
    {
      "epoch": 1.6480000000000001,
      "grad_norm": 1.6231058835983276,
      "learning_rate": 0.00010017778831338153,
      "loss": 4.2242,
      "step": 5150
    },
    {
      "epoch": 1.6480000000000001,
      "eval_loss": 4.1279473304748535,
      "eval_runtime": 3.7782,
      "eval_samples_per_second": 52.935,
      "eval_steps_per_second": 1.853,
      "step": 5150
    },
    {
      "epoch": 1.6512,
      "grad_norm": 1.5541701316833496,
      "learning_rate": 9.994073722887283e-05,
      "loss": 4.1975,
      "step": 5160
    },
    {
      "epoch": 1.6543999999999999,
      "grad_norm": 1.5204635858535767,
      "learning_rate": 9.970368614436412e-05,
      "loss": 4.2259,
      "step": 5170
    },
    {
      "epoch": 1.6576,
      "grad_norm": 1.797673225402832,
      "learning_rate": 9.946663505985541e-05,
      "loss": 4.2706,
      "step": 5180
    },
    {
      "epoch": 1.6608,
      "grad_norm": 1.6586263179779053,
      "learning_rate": 9.92295839753467e-05,
      "loss": 4.2485,
      "step": 5190
    },
    {
      "epoch": 1.6640000000000001,
      "grad_norm": 1.701501727104187,
      "learning_rate": 9.899253289083799e-05,
      "loss": 4.2803,
      "step": 5200
    },
    {
      "epoch": 1.6640000000000001,
      "eval_loss": 4.1283650398254395,
      "eval_runtime": 3.7776,
      "eval_samples_per_second": 52.944,
      "eval_steps_per_second": 1.853,
      "step": 5200
    },
    {
      "epoch": 1.6672,
      "grad_norm": 1.8400697708129883,
      "learning_rate": 9.875548180632926e-05,
      "loss": 4.197,
      "step": 5210
    },
    {
      "epoch": 1.6703999999999999,
      "grad_norm": 1.8027679920196533,
      "learning_rate": 9.851843072182055e-05,
      "loss": 4.2132,
      "step": 5220
    },
    {
      "epoch": 1.6736,
      "grad_norm": 1.5728044509887695,
      "learning_rate": 9.828137963731184e-05,
      "loss": 4.2305,
      "step": 5230
    },
    {
      "epoch": 1.6768,
      "grad_norm": 1.7043089866638184,
      "learning_rate": 9.804432855280313e-05,
      "loss": 4.2029,
      "step": 5240
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 1.7067327499389648,
      "learning_rate": 9.780727746829443e-05,
      "loss": 4.2164,
      "step": 5250
    },
    {
      "epoch": 1.6800000000000002,
      "eval_loss": 4.119865894317627,
      "eval_runtime": 3.7773,
      "eval_samples_per_second": 52.948,
      "eval_steps_per_second": 1.853,
      "step": 5250
    },
    {
      "epoch": 1.6832,
      "grad_norm": 1.4562060832977295,
      "learning_rate": 9.757022638378572e-05,
      "loss": 4.2429,
      "step": 5260
    },
    {
      "epoch": 1.6864,
      "grad_norm": 1.8893464803695679,
      "learning_rate": 9.7333175299277e-05,
      "loss": 4.1955,
      "step": 5270
    },
    {
      "epoch": 1.6896,
      "grad_norm": 1.593169927597046,
      "learning_rate": 9.709612421476829e-05,
      "loss": 4.2514,
      "step": 5280
    },
    {
      "epoch": 1.6928,
      "grad_norm": 1.7446459531784058,
      "learning_rate": 9.685907313025958e-05,
      "loss": 4.2477,
      "step": 5290
    },
    {
      "epoch": 1.696,
      "grad_norm": 1.4792507886886597,
      "learning_rate": 9.662202204575086e-05,
      "loss": 4.334,
      "step": 5300
    },
    {
      "epoch": 1.696,
      "eval_loss": 4.136923789978027,
      "eval_runtime": 3.7761,
      "eval_samples_per_second": 52.965,
      "eval_steps_per_second": 1.854,
      "step": 5300
    },
    {
      "epoch": 1.6992,
      "grad_norm": 1.6744866371154785,
      "learning_rate": 9.638497096124214e-05,
      "loss": 4.1304,
      "step": 5310
    },
    {
      "epoch": 1.7024,
      "grad_norm": 1.6652476787567139,
      "learning_rate": 9.614791987673343e-05,
      "loss": 4.2566,
      "step": 5320
    },
    {
      "epoch": 1.7056,
      "grad_norm": 1.5469799041748047,
      "learning_rate": 9.591086879222473e-05,
      "loss": 4.3574,
      "step": 5330
    },
    {
      "epoch": 1.7088,
      "grad_norm": 1.8817424774169922,
      "learning_rate": 9.567381770771602e-05,
      "loss": 4.2384,
      "step": 5340
    },
    {
      "epoch": 1.712,
      "grad_norm": 1.5996499061584473,
      "learning_rate": 9.543676662320731e-05,
      "loss": 4.3246,
      "step": 5350
    },
    {
      "epoch": 1.712,
      "eval_loss": 4.136679649353027,
      "eval_runtime": 3.7773,
      "eval_samples_per_second": 52.947,
      "eval_steps_per_second": 1.853,
      "step": 5350
    },
    {
      "epoch": 1.7151999999999998,
      "grad_norm": 1.6163033246994019,
      "learning_rate": 9.51997155386986e-05,
      "loss": 4.2232,
      "step": 5360
    },
    {
      "epoch": 1.7184,
      "grad_norm": 1.7878516912460327,
      "learning_rate": 9.496266445418989e-05,
      "loss": 4.3112,
      "step": 5370
    },
    {
      "epoch": 1.7216,
      "grad_norm": 1.7212501764297485,
      "learning_rate": 9.472561336968116e-05,
      "loss": 4.2547,
      "step": 5380
    },
    {
      "epoch": 1.7248,
      "grad_norm": 1.4882789850234985,
      "learning_rate": 9.448856228517245e-05,
      "loss": 4.1644,
      "step": 5390
    },
    {
      "epoch": 1.728,
      "grad_norm": 1.6711310148239136,
      "learning_rate": 9.425151120066374e-05,
      "loss": 4.2545,
      "step": 5400
    },
    {
      "epoch": 1.728,
      "eval_loss": 4.1440534591674805,
      "eval_runtime": 3.7765,
      "eval_samples_per_second": 52.959,
      "eval_steps_per_second": 1.854,
      "step": 5400
    },
    {
      "epoch": 1.7311999999999999,
      "grad_norm": 1.7035876512527466,
      "learning_rate": 9.401446011615504e-05,
      "loss": 4.3003,
      "step": 5410
    },
    {
      "epoch": 1.7344,
      "grad_norm": 1.4516711235046387,
      "learning_rate": 9.377740903164633e-05,
      "loss": 4.212,
      "step": 5420
    },
    {
      "epoch": 1.7376,
      "grad_norm": 1.3526475429534912,
      "learning_rate": 9.354035794713762e-05,
      "loss": 4.2865,
      "step": 5430
    },
    {
      "epoch": 1.7408000000000001,
      "grad_norm": 1.6678017377853394,
      "learning_rate": 9.33033068626289e-05,
      "loss": 4.3105,
      "step": 5440
    },
    {
      "epoch": 1.744,
      "grad_norm": 1.5320340394973755,
      "learning_rate": 9.30662557781202e-05,
      "loss": 4.2025,
      "step": 5450
    },
    {
      "epoch": 1.744,
      "eval_loss": 4.140052318572998,
      "eval_runtime": 3.7764,
      "eval_samples_per_second": 52.961,
      "eval_steps_per_second": 1.854,
      "step": 5450
    },
    {
      "epoch": 1.7471999999999999,
      "grad_norm": 1.663624882698059,
      "learning_rate": 9.282920469361148e-05,
      "loss": 4.2627,
      "step": 5460
    },
    {
      "epoch": 1.7504,
      "grad_norm": 1.8368520736694336,
      "learning_rate": 9.259215360910276e-05,
      "loss": 4.1503,
      "step": 5470
    },
    {
      "epoch": 1.7536,
      "grad_norm": 1.5970649719238281,
      "learning_rate": 9.235510252459405e-05,
      "loss": 4.2565,
      "step": 5480
    },
    {
      "epoch": 1.7568000000000001,
      "grad_norm": 1.6719021797180176,
      "learning_rate": 9.211805144008533e-05,
      "loss": 4.3366,
      "step": 5490
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.5782523155212402,
      "learning_rate": 9.188100035557664e-05,
      "loss": 4.1915,
      "step": 5500
    },
    {
      "epoch": 1.76,
      "eval_loss": 4.14377498626709,
      "eval_runtime": 3.7767,
      "eval_samples_per_second": 52.956,
      "eval_steps_per_second": 1.853,
      "step": 5500
    },
    {
      "epoch": 1.7631999999999999,
      "grad_norm": 1.4676296710968018,
      "learning_rate": 9.164394927106792e-05,
      "loss": 4.2986,
      "step": 5510
    },
    {
      "epoch": 1.7664,
      "grad_norm": 1.7176942825317383,
      "learning_rate": 9.140689818655921e-05,
      "loss": 4.2832,
      "step": 5520
    },
    {
      "epoch": 1.7696,
      "grad_norm": 1.815408706665039,
      "learning_rate": 9.11698471020505e-05,
      "loss": 4.1745,
      "step": 5530
    },
    {
      "epoch": 1.7728000000000002,
      "grad_norm": 1.581562876701355,
      "learning_rate": 9.093279601754179e-05,
      "loss": 4.1338,
      "step": 5540
    },
    {
      "epoch": 1.776,
      "grad_norm": 1.92793869972229,
      "learning_rate": 9.069574493303308e-05,
      "loss": 4.3366,
      "step": 5550
    },
    {
      "epoch": 1.776,
      "eval_loss": 4.134478569030762,
      "eval_runtime": 3.7764,
      "eval_samples_per_second": 52.96,
      "eval_steps_per_second": 1.854,
      "step": 5550
    },
    {
      "epoch": 1.7792,
      "grad_norm": 1.4583944082260132,
      "learning_rate": 9.045869384852435e-05,
      "loss": 4.3684,
      "step": 5560
    },
    {
      "epoch": 1.7824,
      "grad_norm": 1.5295593738555908,
      "learning_rate": 9.022164276401564e-05,
      "loss": 4.1879,
      "step": 5570
    },
    {
      "epoch": 1.7856,
      "grad_norm": 1.590969443321228,
      "learning_rate": 8.998459167950694e-05,
      "loss": 4.226,
      "step": 5580
    },
    {
      "epoch": 1.7888,
      "grad_norm": 1.5105828046798706,
      "learning_rate": 8.974754059499823e-05,
      "loss": 4.288,
      "step": 5590
    },
    {
      "epoch": 1.792,
      "grad_norm": 1.4867119789123535,
      "learning_rate": 8.951048951048952e-05,
      "loss": 4.2539,
      "step": 5600
    },
    {
      "epoch": 1.792,
      "eval_loss": 4.138604640960693,
      "eval_runtime": 3.7777,
      "eval_samples_per_second": 52.942,
      "eval_steps_per_second": 1.853,
      "step": 5600
    },
    {
      "epoch": 1.7952,
      "grad_norm": 1.6415815353393555,
      "learning_rate": 8.92734384259808e-05,
      "loss": 4.2454,
      "step": 5610
    },
    {
      "epoch": 1.7984,
      "grad_norm": 1.8616969585418701,
      "learning_rate": 8.90363873414721e-05,
      "loss": 4.1251,
      "step": 5620
    },
    {
      "epoch": 1.8016,
      "grad_norm": 1.5461958646774292,
      "learning_rate": 8.879933625696338e-05,
      "loss": 4.3558,
      "step": 5630
    },
    {
      "epoch": 1.8048,
      "grad_norm": 1.801463007926941,
      "learning_rate": 8.856228517245467e-05,
      "loss": 4.0962,
      "step": 5640
    },
    {
      "epoch": 1.808,
      "grad_norm": 1.515602707862854,
      "learning_rate": 8.832523408794595e-05,
      "loss": 4.1526,
      "step": 5650
    },
    {
      "epoch": 1.808,
      "eval_loss": 4.132864475250244,
      "eval_runtime": 3.7759,
      "eval_samples_per_second": 52.968,
      "eval_steps_per_second": 1.854,
      "step": 5650
    },
    {
      "epoch": 1.8112,
      "grad_norm": 1.6774605512619019,
      "learning_rate": 8.808818300343725e-05,
      "loss": 4.1917,
      "step": 5660
    },
    {
      "epoch": 1.8144,
      "grad_norm": 1.5951387882232666,
      "learning_rate": 8.785113191892854e-05,
      "loss": 4.2918,
      "step": 5670
    },
    {
      "epoch": 1.8176,
      "grad_norm": 1.6257433891296387,
      "learning_rate": 8.761408083441982e-05,
      "loss": 4.2865,
      "step": 5680
    },
    {
      "epoch": 1.8208,
      "grad_norm": 1.7341545820236206,
      "learning_rate": 8.737702974991111e-05,
      "loss": 4.1567,
      "step": 5690
    },
    {
      "epoch": 1.8239999999999998,
      "grad_norm": 1.4292341470718384,
      "learning_rate": 8.71399786654024e-05,
      "loss": 4.1297,
      "step": 5700
    },
    {
      "epoch": 1.8239999999999998,
      "eval_loss": 4.126590728759766,
      "eval_runtime": 3.7778,
      "eval_samples_per_second": 52.942,
      "eval_steps_per_second": 1.853,
      "step": 5700
    },
    {
      "epoch": 1.8272,
      "grad_norm": 1.5352191925048828,
      "learning_rate": 8.690292758089369e-05,
      "loss": 4.1785,
      "step": 5710
    },
    {
      "epoch": 1.8304,
      "grad_norm": 1.696300745010376,
      "learning_rate": 8.666587649638498e-05,
      "loss": 4.308,
      "step": 5720
    },
    {
      "epoch": 1.8336000000000001,
      "grad_norm": 1.6126091480255127,
      "learning_rate": 8.642882541187627e-05,
      "loss": 4.1462,
      "step": 5730
    },
    {
      "epoch": 1.8368,
      "grad_norm": 1.5110687017440796,
      "learning_rate": 8.619177432736754e-05,
      "loss": 4.2245,
      "step": 5740
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 1.5915766954421997,
      "learning_rate": 8.595472324285884e-05,
      "loss": 4.244,
      "step": 5750
    },
    {
      "epoch": 1.8399999999999999,
      "eval_loss": 4.124703884124756,
      "eval_runtime": 3.7763,
      "eval_samples_per_second": 52.963,
      "eval_steps_per_second": 1.854,
      "step": 5750
    },
    {
      "epoch": 1.8432,
      "grad_norm": 1.5240318775177002,
      "learning_rate": 8.571767215835013e-05,
      "loss": 4.043,
      "step": 5760
    },
    {
      "epoch": 1.8464,
      "grad_norm": 1.7004108428955078,
      "learning_rate": 8.548062107384142e-05,
      "loss": 4.2575,
      "step": 5770
    },
    {
      "epoch": 1.8496000000000001,
      "grad_norm": 1.4568818807601929,
      "learning_rate": 8.524356998933271e-05,
      "loss": 4.3436,
      "step": 5780
    },
    {
      "epoch": 1.8528,
      "grad_norm": 1.9407645463943481,
      "learning_rate": 8.5006518904824e-05,
      "loss": 4.1988,
      "step": 5790
    },
    {
      "epoch": 1.8559999999999999,
      "grad_norm": 1.7549856901168823,
      "learning_rate": 8.476946782031528e-05,
      "loss": 4.2445,
      "step": 5800
    },
    {
      "epoch": 1.8559999999999999,
      "eval_loss": 4.128378868103027,
      "eval_runtime": 3.7784,
      "eval_samples_per_second": 52.932,
      "eval_steps_per_second": 1.853,
      "step": 5800
    },
    {
      "epoch": 1.8592,
      "grad_norm": 1.62299382686615,
      "learning_rate": 8.453241673580657e-05,
      "loss": 4.2435,
      "step": 5810
    },
    {
      "epoch": 1.8624,
      "grad_norm": 1.7370854616165161,
      "learning_rate": 8.429536565129786e-05,
      "loss": 4.2222,
      "step": 5820
    },
    {
      "epoch": 1.8656000000000001,
      "grad_norm": 1.576121211051941,
      "learning_rate": 8.405831456678915e-05,
      "loss": 4.3004,
      "step": 5830
    },
    {
      "epoch": 1.8688,
      "grad_norm": 1.4764171838760376,
      "learning_rate": 8.382126348228044e-05,
      "loss": 4.2483,
      "step": 5840
    },
    {
      "epoch": 1.8719999999999999,
      "grad_norm": 1.5729490518569946,
      "learning_rate": 8.358421239777173e-05,
      "loss": 4.224,
      "step": 5850
    },
    {
      "epoch": 1.8719999999999999,
      "eval_loss": 4.121720790863037,
      "eval_runtime": 3.7771,
      "eval_samples_per_second": 52.951,
      "eval_steps_per_second": 1.853,
      "step": 5850
    },
    {
      "epoch": 1.8752,
      "grad_norm": 1.5752981901168823,
      "learning_rate": 8.334716131326301e-05,
      "loss": 4.2253,
      "step": 5860
    },
    {
      "epoch": 1.8784,
      "grad_norm": 1.8169881105422974,
      "learning_rate": 8.31101102287543e-05,
      "loss": 4.1357,
      "step": 5870
    },
    {
      "epoch": 1.8816000000000002,
      "grad_norm": 1.7856757640838623,
      "learning_rate": 8.287305914424559e-05,
      "loss": 4.3097,
      "step": 5880
    },
    {
      "epoch": 1.8848,
      "grad_norm": 1.7419620752334595,
      "learning_rate": 8.263600805973688e-05,
      "loss": 4.239,
      "step": 5890
    },
    {
      "epoch": 1.888,
      "grad_norm": 1.4253202676773071,
      "learning_rate": 8.239895697522817e-05,
      "loss": 4.1365,
      "step": 5900
    },
    {
      "epoch": 1.888,
      "eval_loss": 4.113503932952881,
      "eval_runtime": 3.7763,
      "eval_samples_per_second": 52.962,
      "eval_steps_per_second": 1.854,
      "step": 5900
    },
    {
      "epoch": 1.8912,
      "grad_norm": 1.5309147834777832,
      "learning_rate": 8.216190589071945e-05,
      "loss": 4.1421,
      "step": 5910
    },
    {
      "epoch": 1.8944,
      "grad_norm": 1.5997236967086792,
      "learning_rate": 8.192485480621074e-05,
      "loss": 4.2464,
      "step": 5920
    },
    {
      "epoch": 1.8976,
      "grad_norm": 1.8107666969299316,
      "learning_rate": 8.168780372170203e-05,
      "loss": 4.2811,
      "step": 5930
    },
    {
      "epoch": 1.9008,
      "grad_norm": 1.6085702180862427,
      "learning_rate": 8.145075263719332e-05,
      "loss": 4.1918,
      "step": 5940
    },
    {
      "epoch": 1.904,
      "grad_norm": 1.676788091659546,
      "learning_rate": 8.121370155268461e-05,
      "loss": 4.2097,
      "step": 5950
    },
    {
      "epoch": 1.904,
      "eval_loss": 4.114072799682617,
      "eval_runtime": 3.7752,
      "eval_samples_per_second": 52.977,
      "eval_steps_per_second": 1.854,
      "step": 5950
    },
    {
      "epoch": 1.9072,
      "grad_norm": 1.3639854192733765,
      "learning_rate": 8.09766504681759e-05,
      "loss": 4.2179,
      "step": 5960
    },
    {
      "epoch": 1.9104,
      "grad_norm": 1.5263333320617676,
      "learning_rate": 8.073959938366718e-05,
      "loss": 4.1538,
      "step": 5970
    },
    {
      "epoch": 1.9136,
      "grad_norm": 1.6660726070404053,
      "learning_rate": 8.050254829915847e-05,
      "loss": 4.2909,
      "step": 5980
    },
    {
      "epoch": 1.9167999999999998,
      "grad_norm": 1.630763292312622,
      "learning_rate": 8.026549721464976e-05,
      "loss": 4.1437,
      "step": 5990
    },
    {
      "epoch": 1.92,
      "grad_norm": 1.8232849836349487,
      "learning_rate": 8.002844613014105e-05,
      "loss": 4.2516,
      "step": 6000
    },
    {
      "epoch": 1.92,
      "eval_loss": 4.1052727699279785,
      "eval_runtime": 3.7763,
      "eval_samples_per_second": 52.962,
      "eval_steps_per_second": 1.854,
      "step": 6000
    },
    {
      "epoch": 1.9232,
      "grad_norm": 1.81525719165802,
      "learning_rate": 7.979139504563234e-05,
      "loss": 4.1965,
      "step": 6010
    },
    {
      "epoch": 1.9264000000000001,
      "grad_norm": 1.6489765644073486,
      "learning_rate": 7.955434396112363e-05,
      "loss": 4.0917,
      "step": 6020
    },
    {
      "epoch": 1.9296,
      "grad_norm": 1.7537877559661865,
      "learning_rate": 7.931729287661491e-05,
      "loss": 4.1948,
      "step": 6030
    },
    {
      "epoch": 1.9327999999999999,
      "grad_norm": 1.6765170097351074,
      "learning_rate": 7.90802417921062e-05,
      "loss": 4.2264,
      "step": 6040
    },
    {
      "epoch": 1.936,
      "grad_norm": 1.7895960807800293,
      "learning_rate": 7.884319070759749e-05,
      "loss": 4.2586,
      "step": 6050
    },
    {
      "epoch": 1.936,
      "eval_loss": 4.120710372924805,
      "eval_runtime": 3.7783,
      "eval_samples_per_second": 52.933,
      "eval_steps_per_second": 1.853,
      "step": 6050
    },
    {
      "epoch": 1.9392,
      "grad_norm": 1.72645103931427,
      "learning_rate": 7.860613962308878e-05,
      "loss": 4.1575,
      "step": 6060
    },
    {
      "epoch": 1.9424000000000001,
      "grad_norm": 1.6458420753479004,
      "learning_rate": 7.836908853858007e-05,
      "loss": 4.2292,
      "step": 6070
    },
    {
      "epoch": 1.9456,
      "grad_norm": 1.8293169736862183,
      "learning_rate": 7.813203745407136e-05,
      "loss": 4.1854,
      "step": 6080
    },
    {
      "epoch": 1.9487999999999999,
      "grad_norm": 1.7117509841918945,
      "learning_rate": 7.789498636956264e-05,
      "loss": 4.2064,
      "step": 6090
    },
    {
      "epoch": 1.952,
      "grad_norm": 1.6116513013839722,
      "learning_rate": 7.765793528505393e-05,
      "loss": 4.2527,
      "step": 6100
    },
    {
      "epoch": 1.952,
      "eval_loss": 4.110508441925049,
      "eval_runtime": 3.7776,
      "eval_samples_per_second": 52.943,
      "eval_steps_per_second": 1.853,
      "step": 6100
    },
    {
      "epoch": 1.9552,
      "grad_norm": 1.6459378004074097,
      "learning_rate": 7.742088420054522e-05,
      "loss": 4.2028,
      "step": 6110
    },
    {
      "epoch": 1.9584000000000001,
      "grad_norm": 1.6188573837280273,
      "learning_rate": 7.718383311603651e-05,
      "loss": 4.2749,
      "step": 6120
    },
    {
      "epoch": 1.9616,
      "grad_norm": 1.663346290588379,
      "learning_rate": 7.69467820315278e-05,
      "loss": 4.2878,
      "step": 6130
    },
    {
      "epoch": 1.9647999999999999,
      "grad_norm": 1.484494924545288,
      "learning_rate": 7.670973094701909e-05,
      "loss": 4.2328,
      "step": 6140
    },
    {
      "epoch": 1.968,
      "grad_norm": 1.7112998962402344,
      "learning_rate": 7.647267986251037e-05,
      "loss": 4.3068,
      "step": 6150
    },
    {
      "epoch": 1.968,
      "eval_loss": 4.113199234008789,
      "eval_runtime": 3.7781,
      "eval_samples_per_second": 52.936,
      "eval_steps_per_second": 1.853,
      "step": 6150
    },
    {
      "epoch": 1.9712,
      "grad_norm": 1.393651008605957,
      "learning_rate": 7.623562877800166e-05,
      "loss": 4.2758,
      "step": 6160
    },
    {
      "epoch": 1.9744000000000002,
      "grad_norm": 1.447311520576477,
      "learning_rate": 7.599857769349295e-05,
      "loss": 4.2581,
      "step": 6170
    },
    {
      "epoch": 1.9776,
      "grad_norm": 1.574211597442627,
      "learning_rate": 7.576152660898424e-05,
      "loss": 4.1556,
      "step": 6180
    },
    {
      "epoch": 1.9808,
      "grad_norm": 1.4596105813980103,
      "learning_rate": 7.552447552447553e-05,
      "loss": 4.121,
      "step": 6190
    },
    {
      "epoch": 1.984,
      "grad_norm": 1.6877999305725098,
      "learning_rate": 7.528742443996681e-05,
      "loss": 4.27,
      "step": 6200
    },
    {
      "epoch": 1.984,
      "eval_loss": 4.106625556945801,
      "eval_runtime": 3.7759,
      "eval_samples_per_second": 52.968,
      "eval_steps_per_second": 1.854,
      "step": 6200
    },
    {
      "epoch": 1.9872,
      "grad_norm": 1.665261149406433,
      "learning_rate": 7.50503733554581e-05,
      "loss": 4.152,
      "step": 6210
    },
    {
      "epoch": 1.9904,
      "grad_norm": 1.8960776329040527,
      "learning_rate": 7.481332227094939e-05,
      "loss": 4.1855,
      "step": 6220
    },
    {
      "epoch": 1.9936,
      "grad_norm": 1.5124810934066772,
      "learning_rate": 7.457627118644068e-05,
      "loss": 4.2964,
      "step": 6230
    },
    {
      "epoch": 1.9968,
      "grad_norm": 1.6019283533096313,
      "learning_rate": 7.433922010193197e-05,
      "loss": 4.2073,
      "step": 6240
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.8009291887283325,
      "learning_rate": 7.410216901742326e-05,
      "loss": 4.093,
      "step": 6250
    },
    {
      "epoch": 2.0,
      "eval_loss": 4.112117290496826,
      "eval_runtime": 3.7784,
      "eval_samples_per_second": 52.932,
      "eval_steps_per_second": 1.853,
      "step": 6250
    },
    {
      "epoch": 2.0032,
      "grad_norm": 1.6968727111816406,
      "learning_rate": 7.386511793291456e-05,
      "loss": 4.1388,
      "step": 6260
    },
    {
      "epoch": 2.0064,
      "grad_norm": 1.6955610513687134,
      "learning_rate": 7.362806684840583e-05,
      "loss": 4.2168,
      "step": 6270
    },
    {
      "epoch": 2.0096,
      "grad_norm": 1.655462384223938,
      "learning_rate": 7.339101576389712e-05,
      "loss": 4.1602,
      "step": 6280
    },
    {
      "epoch": 2.0128,
      "grad_norm": 1.5317410230636597,
      "learning_rate": 7.315396467938841e-05,
      "loss": 4.1064,
      "step": 6290
    },
    {
      "epoch": 2.016,
      "grad_norm": 1.581583023071289,
      "learning_rate": 7.29169135948797e-05,
      "loss": 4.133,
      "step": 6300
    },
    {
      "epoch": 2.016,
      "eval_loss": 4.118225574493408,
      "eval_runtime": 3.777,
      "eval_samples_per_second": 52.952,
      "eval_steps_per_second": 1.853,
      "step": 6300
    },
    {
      "epoch": 2.0192,
      "grad_norm": 1.606581211090088,
      "learning_rate": 7.267986251037099e-05,
      "loss": 4.3311,
      "step": 6310
    },
    {
      "epoch": 2.0224,
      "grad_norm": 1.7657958269119263,
      "learning_rate": 7.244281142586227e-05,
      "loss": 4.16,
      "step": 6320
    },
    {
      "epoch": 2.0256,
      "grad_norm": 1.6697889566421509,
      "learning_rate": 7.220576034135356e-05,
      "loss": 4.1916,
      "step": 6330
    },
    {
      "epoch": 2.0288,
      "grad_norm": 1.739501714706421,
      "learning_rate": 7.196870925684485e-05,
      "loss": 4.2234,
      "step": 6340
    },
    {
      "epoch": 2.032,
      "grad_norm": 1.650692343711853,
      "learning_rate": 7.173165817233615e-05,
      "loss": 4.0796,
      "step": 6350
    },
    {
      "epoch": 2.032,
      "eval_loss": 4.107368469238281,
      "eval_runtime": 3.7789,
      "eval_samples_per_second": 52.925,
      "eval_steps_per_second": 1.852,
      "step": 6350
    },
    {
      "epoch": 2.0352,
      "grad_norm": 1.5035139322280884,
      "learning_rate": 7.149460708782743e-05,
      "loss": 4.2349,
      "step": 6360
    },
    {
      "epoch": 2.0384,
      "grad_norm": 1.5514634847640991,
      "learning_rate": 7.125755600331872e-05,
      "loss": 4.1483,
      "step": 6370
    },
    {
      "epoch": 2.0416,
      "grad_norm": 1.8185174465179443,
      "learning_rate": 7.102050491881e-05,
      "loss": 4.1855,
      "step": 6380
    },
    {
      "epoch": 2.0448,
      "grad_norm": 1.4861456155776978,
      "learning_rate": 7.078345383430129e-05,
      "loss": 4.1256,
      "step": 6390
    },
    {
      "epoch": 2.048,
      "grad_norm": 1.8416668176651,
      "learning_rate": 7.054640274979258e-05,
      "loss": 4.1195,
      "step": 6400
    },
    {
      "epoch": 2.048,
      "eval_loss": 4.101480007171631,
      "eval_runtime": 3.78,
      "eval_samples_per_second": 52.91,
      "eval_steps_per_second": 1.852,
      "step": 6400
    },
    {
      "epoch": 2.0512,
      "grad_norm": 1.7747607231140137,
      "learning_rate": 7.030935166528387e-05,
      "loss": 4.1381,
      "step": 6410
    },
    {
      "epoch": 2.0544,
      "grad_norm": 1.586657166481018,
      "learning_rate": 7.007230058077516e-05,
      "loss": 4.1474,
      "step": 6420
    },
    {
      "epoch": 2.0576,
      "grad_norm": 1.730919361114502,
      "learning_rate": 6.983524949626646e-05,
      "loss": 4.2411,
      "step": 6430
    },
    {
      "epoch": 2.0608,
      "grad_norm": 1.593557357788086,
      "learning_rate": 6.959819841175775e-05,
      "loss": 4.1498,
      "step": 6440
    },
    {
      "epoch": 2.064,
      "grad_norm": 1.532488465309143,
      "learning_rate": 6.936114732724902e-05,
      "loss": 4.1657,
      "step": 6450
    },
    {
      "epoch": 2.064,
      "eval_loss": 4.09882926940918,
      "eval_runtime": 3.7772,
      "eval_samples_per_second": 52.95,
      "eval_steps_per_second": 1.853,
      "step": 6450
    },
    {
      "epoch": 2.0672,
      "grad_norm": 1.6805164813995361,
      "learning_rate": 6.912409624274031e-05,
      "loss": 4.2578,
      "step": 6460
    },
    {
      "epoch": 2.0704,
      "grad_norm": 1.6974118947982788,
      "learning_rate": 6.88870451582316e-05,
      "loss": 4.2822,
      "step": 6470
    },
    {
      "epoch": 2.0736,
      "grad_norm": 1.6552913188934326,
      "learning_rate": 6.864999407372289e-05,
      "loss": 4.1741,
      "step": 6480
    },
    {
      "epoch": 2.0768,
      "grad_norm": 1.6778044700622559,
      "learning_rate": 6.841294298921418e-05,
      "loss": 4.1804,
      "step": 6490
    },
    {
      "epoch": 2.08,
      "grad_norm": 1.676163673400879,
      "learning_rate": 6.817589190470546e-05,
      "loss": 4.1329,
      "step": 6500
    },
    {
      "epoch": 2.08,
      "eval_loss": 4.101343154907227,
      "eval_runtime": 3.7781,
      "eval_samples_per_second": 52.937,
      "eval_steps_per_second": 1.853,
      "step": 6500
    },
    {
      "epoch": 2.0832,
      "grad_norm": 1.8355153799057007,
      "learning_rate": 6.793884082019677e-05,
      "loss": 4.1438,
      "step": 6510
    },
    {
      "epoch": 2.0864,
      "grad_norm": 1.640201449394226,
      "learning_rate": 6.770178973568805e-05,
      "loss": 4.1572,
      "step": 6520
    },
    {
      "epoch": 2.0896,
      "grad_norm": 1.6665680408477783,
      "learning_rate": 6.746473865117934e-05,
      "loss": 4.2151,
      "step": 6530
    },
    {
      "epoch": 2.0928,
      "grad_norm": 1.9103453159332275,
      "learning_rate": 6.722768756667062e-05,
      "loss": 4.2204,
      "step": 6540
    },
    {
      "epoch": 2.096,
      "grad_norm": 1.465765118598938,
      "learning_rate": 6.69906364821619e-05,
      "loss": 4.2078,
      "step": 6550
    },
    {
      "epoch": 2.096,
      "eval_loss": 4.10062313079834,
      "eval_runtime": 3.7788,
      "eval_samples_per_second": 52.926,
      "eval_steps_per_second": 1.852,
      "step": 6550
    },
    {
      "epoch": 2.0992,
      "grad_norm": 1.7228997945785522,
      "learning_rate": 6.675358539765319e-05,
      "loss": 4.193,
      "step": 6560
    },
    {
      "epoch": 2.1024,
      "grad_norm": 1.8249722719192505,
      "learning_rate": 6.651653431314448e-05,
      "loss": 4.1783,
      "step": 6570
    },
    {
      "epoch": 2.1056,
      "grad_norm": 1.8442142009735107,
      "learning_rate": 6.627948322863577e-05,
      "loss": 4.1825,
      "step": 6580
    },
    {
      "epoch": 2.1088,
      "grad_norm": 1.6403167247772217,
      "learning_rate": 6.604243214412706e-05,
      "loss": 4.0656,
      "step": 6590
    },
    {
      "epoch": 2.112,
      "grad_norm": 1.8043402433395386,
      "learning_rate": 6.580538105961836e-05,
      "loss": 4.1539,
      "step": 6600
    },
    {
      "epoch": 2.112,
      "eval_loss": 4.104201793670654,
      "eval_runtime": 3.7774,
      "eval_samples_per_second": 52.947,
      "eval_steps_per_second": 1.853,
      "step": 6600
    },
    {
      "epoch": 2.1152,
      "grad_norm": 1.6806704998016357,
      "learning_rate": 6.556832997510965e-05,
      "loss": 4.2689,
      "step": 6610
    },
    {
      "epoch": 2.1184,
      "grad_norm": 1.7326750755310059,
      "learning_rate": 6.533127889060092e-05,
      "loss": 4.2643,
      "step": 6620
    },
    {
      "epoch": 2.1216,
      "grad_norm": 1.6514853239059448,
      "learning_rate": 6.509422780609221e-05,
      "loss": 4.1443,
      "step": 6630
    },
    {
      "epoch": 2.1248,
      "grad_norm": 1.765305995941162,
      "learning_rate": 6.48571767215835e-05,
      "loss": 4.1706,
      "step": 6640
    },
    {
      "epoch": 2.128,
      "grad_norm": 1.9468554258346558,
      "learning_rate": 6.462012563707479e-05,
      "loss": 4.2288,
      "step": 6650
    },
    {
      "epoch": 2.128,
      "eval_loss": 4.095258712768555,
      "eval_runtime": 3.7777,
      "eval_samples_per_second": 52.942,
      "eval_steps_per_second": 1.853,
      "step": 6650
    },
    {
      "epoch": 2.1312,
      "grad_norm": 1.629223346710205,
      "learning_rate": 6.438307455256608e-05,
      "loss": 4.1887,
      "step": 6660
    },
    {
      "epoch": 2.1344,
      "grad_norm": 1.5723737478256226,
      "learning_rate": 6.414602346805736e-05,
      "loss": 4.2648,
      "step": 6670
    },
    {
      "epoch": 2.1376,
      "grad_norm": 1.7420086860656738,
      "learning_rate": 6.390897238354867e-05,
      "loss": 4.1814,
      "step": 6680
    },
    {
      "epoch": 2.1408,
      "grad_norm": 1.7013630867004395,
      "learning_rate": 6.367192129903995e-05,
      "loss": 4.242,
      "step": 6690
    },
    {
      "epoch": 2.144,
      "grad_norm": 1.636027455329895,
      "learning_rate": 6.343487021453124e-05,
      "loss": 4.2074,
      "step": 6700
    },
    {
      "epoch": 2.144,
      "eval_loss": 4.0954155921936035,
      "eval_runtime": 3.7805,
      "eval_samples_per_second": 52.903,
      "eval_steps_per_second": 1.852,
      "step": 6700
    },
    {
      "epoch": 2.1471999999999998,
      "grad_norm": 1.648451566696167,
      "learning_rate": 6.319781913002252e-05,
      "loss": 4.0905,
      "step": 6710
    },
    {
      "epoch": 2.1504,
      "grad_norm": 1.7924761772155762,
      "learning_rate": 6.29607680455138e-05,
      "loss": 4.2674,
      "step": 6720
    },
    {
      "epoch": 2.1536,
      "grad_norm": 1.827809453010559,
      "learning_rate": 6.27237169610051e-05,
      "loss": 4.1278,
      "step": 6730
    },
    {
      "epoch": 2.1568,
      "grad_norm": 1.6138834953308105,
      "learning_rate": 6.248666587649638e-05,
      "loss": 4.0658,
      "step": 6740
    },
    {
      "epoch": 2.16,
      "grad_norm": 1.7643957138061523,
      "learning_rate": 6.224961479198767e-05,
      "loss": 4.248,
      "step": 6750
    },
    {
      "epoch": 2.16,
      "eval_loss": 4.102404594421387,
      "eval_runtime": 3.7794,
      "eval_samples_per_second": 52.919,
      "eval_steps_per_second": 1.852,
      "step": 6750
    },
    {
      "epoch": 2.1632,
      "grad_norm": 1.6031430959701538,
      "learning_rate": 6.201256370747897e-05,
      "loss": 4.1565,
      "step": 6760
    },
    {
      "epoch": 2.1664,
      "grad_norm": 1.8622410297393799,
      "learning_rate": 6.177551262297026e-05,
      "loss": 4.0391,
      "step": 6770
    },
    {
      "epoch": 2.1696,
      "grad_norm": 1.5932238101959229,
      "learning_rate": 6.153846153846155e-05,
      "loss": 4.1732,
      "step": 6780
    },
    {
      "epoch": 2.1728,
      "grad_norm": 1.760189175605774,
      "learning_rate": 6.130141045395284e-05,
      "loss": 4.2512,
      "step": 6790
    },
    {
      "epoch": 2.176,
      "grad_norm": 2.002953290939331,
      "learning_rate": 6.106435936944411e-05,
      "loss": 4.1637,
      "step": 6800
    },
    {
      "epoch": 2.176,
      "eval_loss": 4.104340076446533,
      "eval_runtime": 3.7779,
      "eval_samples_per_second": 52.94,
      "eval_steps_per_second": 1.853,
      "step": 6800
    },
    {
      "epoch": 2.1792,
      "grad_norm": 1.8094574213027954,
      "learning_rate": 6.08273082849354e-05,
      "loss": 4.1815,
      "step": 6810
    },
    {
      "epoch": 2.1824,
      "grad_norm": 1.5291564464569092,
      "learning_rate": 6.0590257200426695e-05,
      "loss": 4.2244,
      "step": 6820
    },
    {
      "epoch": 2.1856,
      "grad_norm": 1.6723264455795288,
      "learning_rate": 6.035320611591798e-05,
      "loss": 4.2557,
      "step": 6830
    },
    {
      "epoch": 2.1888,
      "grad_norm": 1.5563161373138428,
      "learning_rate": 6.011615503140927e-05,
      "loss": 4.2005,
      "step": 6840
    },
    {
      "epoch": 2.192,
      "grad_norm": 1.7384979724884033,
      "learning_rate": 5.987910394690056e-05,
      "loss": 4.206,
      "step": 6850
    },
    {
      "epoch": 2.192,
      "eval_loss": 4.110751152038574,
      "eval_runtime": 3.7778,
      "eval_samples_per_second": 52.941,
      "eval_steps_per_second": 1.853,
      "step": 6850
    },
    {
      "epoch": 2.1952,
      "grad_norm": 1.7679874897003174,
      "learning_rate": 5.964205286239185e-05,
      "loss": 4.1222,
      "step": 6860
    },
    {
      "epoch": 2.1984,
      "grad_norm": 1.5956612825393677,
      "learning_rate": 5.940500177788314e-05,
      "loss": 4.1676,
      "step": 6870
    },
    {
      "epoch": 2.2016,
      "grad_norm": 1.7291635274887085,
      "learning_rate": 5.916795069337443e-05,
      "loss": 4.1833,
      "step": 6880
    },
    {
      "epoch": 2.2048,
      "grad_norm": 1.7871145009994507,
      "learning_rate": 5.8930899608865706e-05,
      "loss": 4.1769,
      "step": 6890
    },
    {
      "epoch": 2.208,
      "grad_norm": 1.8400614261627197,
      "learning_rate": 5.8693848524357e-05,
      "loss": 4.0569,
      "step": 6900
    },
    {
      "epoch": 2.208,
      "eval_loss": 4.097471714019775,
      "eval_runtime": 3.7789,
      "eval_samples_per_second": 52.925,
      "eval_steps_per_second": 1.852,
      "step": 6900
    },
    {
      "epoch": 2.2112,
      "grad_norm": 1.8190481662750244,
      "learning_rate": 5.845679743984829e-05,
      "loss": 4.2003,
      "step": 6910
    },
    {
      "epoch": 2.2144,
      "grad_norm": 1.7369186878204346,
      "learning_rate": 5.821974635533958e-05,
      "loss": 4.1509,
      "step": 6920
    },
    {
      "epoch": 2.2176,
      "grad_norm": 2.3527674674987793,
      "learning_rate": 5.7982695270830866e-05,
      "loss": 4.1783,
      "step": 6930
    },
    {
      "epoch": 2.2208,
      "grad_norm": 1.7905033826828003,
      "learning_rate": 5.7745644186322154e-05,
      "loss": 4.1138,
      "step": 6940
    },
    {
      "epoch": 2.224,
      "grad_norm": 1.7570456266403198,
      "learning_rate": 5.750859310181344e-05,
      "loss": 4.1207,
      "step": 6950
    },
    {
      "epoch": 2.224,
      "eval_loss": 4.099615097045898,
      "eval_runtime": 3.7814,
      "eval_samples_per_second": 52.89,
      "eval_steps_per_second": 1.851,
      "step": 6950
    },
    {
      "epoch": 2.2272,
      "grad_norm": 1.6685112714767456,
      "learning_rate": 5.727154201730474e-05,
      "loss": 4.0574,
      "step": 6960
    },
    {
      "epoch": 2.2304,
      "grad_norm": 1.5423222780227661,
      "learning_rate": 5.7034490932796026e-05,
      "loss": 4.1128,
      "step": 6970
    },
    {
      "epoch": 2.2336,
      "grad_norm": 1.842096209526062,
      "learning_rate": 5.67974398482873e-05,
      "loss": 4.1369,
      "step": 6980
    },
    {
      "epoch": 2.2368,
      "grad_norm": 1.921919584274292,
      "learning_rate": 5.6560388763778596e-05,
      "loss": 4.1719,
      "step": 6990
    },
    {
      "epoch": 2.24,
      "grad_norm": 1.6906815767288208,
      "learning_rate": 5.6323337679269884e-05,
      "loss": 3.9915,
      "step": 7000
    },
    {
      "epoch": 2.24,
      "eval_loss": 4.098210334777832,
      "eval_runtime": 3.7777,
      "eval_samples_per_second": 52.942,
      "eval_steps_per_second": 1.853,
      "step": 7000
    },
    {
      "epoch": 2.2432,
      "grad_norm": 1.8624098300933838,
      "learning_rate": 5.608628659476117e-05,
      "loss": 4.1624,
      "step": 7010
    },
    {
      "epoch": 2.2464,
      "grad_norm": 1.5211385488510132,
      "learning_rate": 5.584923551025246e-05,
      "loss": 4.0361,
      "step": 7020
    },
    {
      "epoch": 2.2496,
      "grad_norm": 1.787275791168213,
      "learning_rate": 5.561218442574375e-05,
      "loss": 4.1187,
      "step": 7030
    },
    {
      "epoch": 2.2528,
      "grad_norm": 1.9692292213439941,
      "learning_rate": 5.5375133341235044e-05,
      "loss": 4.0786,
      "step": 7040
    },
    {
      "epoch": 2.2560000000000002,
      "grad_norm": 1.6791545152664185,
      "learning_rate": 5.513808225672633e-05,
      "loss": 4.1495,
      "step": 7050
    },
    {
      "epoch": 2.2560000000000002,
      "eval_loss": 4.1007280349731445,
      "eval_runtime": 3.7818,
      "eval_samples_per_second": 52.885,
      "eval_steps_per_second": 1.851,
      "step": 7050
    },
    {
      "epoch": 2.2592,
      "grad_norm": 1.664133906364441,
      "learning_rate": 5.490103117221762e-05,
      "loss": 4.107,
      "step": 7060
    },
    {
      "epoch": 2.2624,
      "grad_norm": 1.5557670593261719,
      "learning_rate": 5.46639800877089e-05,
      "loss": 4.1882,
      "step": 7070
    },
    {
      "epoch": 2.2656,
      "grad_norm": 1.617568016052246,
      "learning_rate": 5.442692900320019e-05,
      "loss": 4.1335,
      "step": 7080
    },
    {
      "epoch": 2.2688,
      "grad_norm": 2.4298408031463623,
      "learning_rate": 5.418987791869148e-05,
      "loss": 4.2503,
      "step": 7090
    },
    {
      "epoch": 2.2720000000000002,
      "grad_norm": 1.5312204360961914,
      "learning_rate": 5.395282683418277e-05,
      "loss": 4.2687,
      "step": 7100
    },
    {
      "epoch": 2.2720000000000002,
      "eval_loss": 4.103374004364014,
      "eval_runtime": 3.7802,
      "eval_samples_per_second": 52.907,
      "eval_steps_per_second": 1.852,
      "step": 7100
    },
    {
      "epoch": 2.2752,
      "grad_norm": 1.8247077465057373,
      "learning_rate": 5.3715775749674055e-05,
      "loss": 4.2324,
      "step": 7110
    },
    {
      "epoch": 2.2784,
      "grad_norm": 1.7967472076416016,
      "learning_rate": 5.347872466516535e-05,
      "loss": 4.1361,
      "step": 7120
    },
    {
      "epoch": 2.2816,
      "grad_norm": 1.7282944917678833,
      "learning_rate": 5.324167358065664e-05,
      "loss": 4.1322,
      "step": 7130
    },
    {
      "epoch": 2.2848,
      "grad_norm": 1.7251285314559937,
      "learning_rate": 5.300462249614793e-05,
      "loss": 4.2141,
      "step": 7140
    },
    {
      "epoch": 2.288,
      "grad_norm": 1.7205497026443481,
      "learning_rate": 5.2767571411639215e-05,
      "loss": 4.0747,
      "step": 7150
    },
    {
      "epoch": 2.288,
      "eval_loss": 4.104036331176758,
      "eval_runtime": 3.7775,
      "eval_samples_per_second": 52.945,
      "eval_steps_per_second": 1.853,
      "step": 7150
    },
    {
      "epoch": 2.2912,
      "grad_norm": 1.625531554222107,
      "learning_rate": 5.2530520327130497e-05,
      "loss": 4.0628,
      "step": 7160
    },
    {
      "epoch": 2.2944,
      "grad_norm": 1.8593655824661255,
      "learning_rate": 5.2293469242621785e-05,
      "loss": 4.1966,
      "step": 7170
    },
    {
      "epoch": 2.2976,
      "grad_norm": 1.6208029985427856,
      "learning_rate": 5.205641815811307e-05,
      "loss": 3.9893,
      "step": 7180
    },
    {
      "epoch": 2.3008,
      "grad_norm": 2.031576633453369,
      "learning_rate": 5.181936707360436e-05,
      "loss": 4.2178,
      "step": 7190
    },
    {
      "epoch": 2.304,
      "grad_norm": 1.4638534784317017,
      "learning_rate": 5.158231598909565e-05,
      "loss": 4.1937,
      "step": 7200
    },
    {
      "epoch": 2.304,
      "eval_loss": 4.0999345779418945,
      "eval_runtime": 3.7792,
      "eval_samples_per_second": 52.922,
      "eval_steps_per_second": 1.852,
      "step": 7200
    },
    {
      "epoch": 2.3072,
      "grad_norm": 1.8291999101638794,
      "learning_rate": 5.1345264904586945e-05,
      "loss": 4.1743,
      "step": 7210
    },
    {
      "epoch": 2.3104,
      "grad_norm": 1.8123244047164917,
      "learning_rate": 5.110821382007823e-05,
      "loss": 4.1578,
      "step": 7220
    },
    {
      "epoch": 2.3136,
      "grad_norm": 1.6054290533065796,
      "learning_rate": 5.087116273556952e-05,
      "loss": 4.228,
      "step": 7230
    },
    {
      "epoch": 2.3168,
      "grad_norm": 1.736838459968567,
      "learning_rate": 5.063411165106081e-05,
      "loss": 4.1227,
      "step": 7240
    },
    {
      "epoch": 2.32,
      "grad_norm": 1.875077724456787,
      "learning_rate": 5.039706056655209e-05,
      "loss": 4.1534,
      "step": 7250
    },
    {
      "epoch": 2.32,
      "eval_loss": 4.09287166595459,
      "eval_runtime": 3.779,
      "eval_samples_per_second": 52.924,
      "eval_steps_per_second": 1.852,
      "step": 7250
    },
    {
      "epoch": 2.3232,
      "grad_norm": 1.7064648866653442,
      "learning_rate": 5.016000948204338e-05,
      "loss": 4.1988,
      "step": 7260
    },
    {
      "epoch": 2.3264,
      "grad_norm": 1.6941406726837158,
      "learning_rate": 4.992295839753467e-05,
      "loss": 4.2206,
      "step": 7270
    },
    {
      "epoch": 2.3296,
      "grad_norm": 1.709779143333435,
      "learning_rate": 4.9685907313025956e-05,
      "loss": 4.243,
      "step": 7280
    },
    {
      "epoch": 2.3327999999999998,
      "grad_norm": 1.6772187948226929,
      "learning_rate": 4.944885622851725e-05,
      "loss": 4.2162,
      "step": 7290
    },
    {
      "epoch": 2.336,
      "grad_norm": 1.7586830854415894,
      "learning_rate": 4.921180514400854e-05,
      "loss": 4.1451,
      "step": 7300
    },
    {
      "epoch": 2.336,
      "eval_loss": 4.097158908843994,
      "eval_runtime": 3.7788,
      "eval_samples_per_second": 52.928,
      "eval_steps_per_second": 1.852,
      "step": 7300
    },
    {
      "epoch": 2.3392,
      "grad_norm": 1.6297967433929443,
      "learning_rate": 4.897475405949982e-05,
      "loss": 4.1809,
      "step": 7310
    },
    {
      "epoch": 2.3424,
      "grad_norm": 1.6644489765167236,
      "learning_rate": 4.873770297499111e-05,
      "loss": 4.0974,
      "step": 7320
    },
    {
      "epoch": 2.3456,
      "grad_norm": 1.798865795135498,
      "learning_rate": 4.8500651890482404e-05,
      "loss": 4.1383,
      "step": 7330
    },
    {
      "epoch": 2.3487999999999998,
      "grad_norm": 1.6494642496109009,
      "learning_rate": 4.826360080597369e-05,
      "loss": 4.1943,
      "step": 7340
    },
    {
      "epoch": 2.352,
      "grad_norm": 1.5932981967926025,
      "learning_rate": 4.802654972146498e-05,
      "loss": 4.1942,
      "step": 7350
    },
    {
      "epoch": 2.352,
      "eval_loss": 4.092909336090088,
      "eval_runtime": 3.7774,
      "eval_samples_per_second": 52.947,
      "eval_steps_per_second": 1.853,
      "step": 7350
    },
    {
      "epoch": 2.3552,
      "grad_norm": 1.8307361602783203,
      "learning_rate": 4.778949863695626e-05,
      "loss": 4.0791,
      "step": 7360
    },
    {
      "epoch": 2.3584,
      "grad_norm": 1.708054542541504,
      "learning_rate": 4.755244755244756e-05,
      "loss": 4.2219,
      "step": 7370
    },
    {
      "epoch": 2.3616,
      "grad_norm": 1.888534665107727,
      "learning_rate": 4.7315396467938846e-05,
      "loss": 4.1378,
      "step": 7380
    },
    {
      "epoch": 2.3648,
      "grad_norm": 1.7667486667633057,
      "learning_rate": 4.7078345383430134e-05,
      "loss": 4.2217,
      "step": 7390
    },
    {
      "epoch": 2.368,
      "grad_norm": 1.7169628143310547,
      "learning_rate": 4.6841294298921415e-05,
      "loss": 4.1036,
      "step": 7400
    },
    {
      "epoch": 2.368,
      "eval_loss": 4.085747241973877,
      "eval_runtime": 3.7782,
      "eval_samples_per_second": 52.935,
      "eval_steps_per_second": 1.853,
      "step": 7400
    },
    {
      "epoch": 2.3712,
      "grad_norm": 1.6986112594604492,
      "learning_rate": 4.660424321441271e-05,
      "loss": 4.2299,
      "step": 7410
    },
    {
      "epoch": 2.3744,
      "grad_norm": 1.752700924873352,
      "learning_rate": 4.6367192129904e-05,
      "loss": 4.005,
      "step": 7420
    },
    {
      "epoch": 2.3776,
      "grad_norm": 1.7808687686920166,
      "learning_rate": 4.613014104539529e-05,
      "loss": 3.9897,
      "step": 7430
    },
    {
      "epoch": 2.3808,
      "grad_norm": 1.8057491779327393,
      "learning_rate": 4.589308996088657e-05,
      "loss": 4.1281,
      "step": 7440
    },
    {
      "epoch": 2.384,
      "grad_norm": 1.8818061351776123,
      "learning_rate": 4.5656038876377864e-05,
      "loss": 4.1588,
      "step": 7450
    },
    {
      "epoch": 2.384,
      "eval_loss": 4.089113235473633,
      "eval_runtime": 3.7783,
      "eval_samples_per_second": 52.934,
      "eval_steps_per_second": 1.853,
      "step": 7450
    },
    {
      "epoch": 2.3872,
      "grad_norm": 1.6807303428649902,
      "learning_rate": 4.541898779186915e-05,
      "loss": 4.1382,
      "step": 7460
    },
    {
      "epoch": 2.3904,
      "grad_norm": 1.9040406942367554,
      "learning_rate": 4.518193670736044e-05,
      "loss": 4.1458,
      "step": 7470
    },
    {
      "epoch": 2.3936,
      "grad_norm": 1.8377985954284668,
      "learning_rate": 4.494488562285173e-05,
      "loss": 4.0266,
      "step": 7480
    },
    {
      "epoch": 2.3968,
      "grad_norm": 1.7738333940505981,
      "learning_rate": 4.470783453834301e-05,
      "loss": 4.0642,
      "step": 7490
    },
    {
      "epoch": 2.4,
      "grad_norm": 1.6418899297714233,
      "learning_rate": 4.4470783453834305e-05,
      "loss": 4.1792,
      "step": 7500
    },
    {
      "epoch": 2.4,
      "eval_loss": 4.079310894012451,
      "eval_runtime": 3.7777,
      "eval_samples_per_second": 52.942,
      "eval_steps_per_second": 1.853,
      "step": 7500
    },
    {
      "epoch": 2.4032,
      "grad_norm": 1.8833674192428589,
      "learning_rate": 4.423373236932559e-05,
      "loss": 4.2258,
      "step": 7510
    },
    {
      "epoch": 2.4064,
      "grad_norm": 2.1906237602233887,
      "learning_rate": 4.399668128481688e-05,
      "loss": 4.1454,
      "step": 7520
    },
    {
      "epoch": 2.4096,
      "grad_norm": 1.5816978216171265,
      "learning_rate": 4.375963020030816e-05,
      "loss": 4.0869,
      "step": 7530
    },
    {
      "epoch": 2.4128,
      "grad_norm": 1.6707795858383179,
      "learning_rate": 4.352257911579946e-05,
      "loss": 4.1309,
      "step": 7540
    },
    {
      "epoch": 2.416,
      "grad_norm": 1.7348405122756958,
      "learning_rate": 4.3285528031290746e-05,
      "loss": 4.0565,
      "step": 7550
    },
    {
      "epoch": 2.416,
      "eval_loss": 4.0801897048950195,
      "eval_runtime": 3.7782,
      "eval_samples_per_second": 52.936,
      "eval_steps_per_second": 1.853,
      "step": 7550
    },
    {
      "epoch": 2.4192,
      "grad_norm": 1.6822494268417358,
      "learning_rate": 4.3048476946782035e-05,
      "loss": 4.1981,
      "step": 7560
    },
    {
      "epoch": 2.4224,
      "grad_norm": 1.7129789590835571,
      "learning_rate": 4.281142586227332e-05,
      "loss": 4.1196,
      "step": 7570
    },
    {
      "epoch": 2.4256,
      "grad_norm": 1.829100251197815,
      "learning_rate": 4.257437477776461e-05,
      "loss": 4.1306,
      "step": 7580
    },
    {
      "epoch": 2.4288,
      "grad_norm": 1.5014175176620483,
      "learning_rate": 4.23373236932559e-05,
      "loss": 4.2279,
      "step": 7590
    },
    {
      "epoch": 2.432,
      "grad_norm": 1.7978296279907227,
      "learning_rate": 4.210027260874719e-05,
      "loss": 4.1112,
      "step": 7600
    },
    {
      "epoch": 2.432,
      "eval_loss": 4.087003707885742,
      "eval_runtime": 3.7784,
      "eval_samples_per_second": 52.933,
      "eval_steps_per_second": 1.853,
      "step": 7600
    },
    {
      "epoch": 2.4352,
      "grad_norm": 1.686574935913086,
      "learning_rate": 4.1863221524238476e-05,
      "loss": 4.153,
      "step": 7610
    },
    {
      "epoch": 2.4384,
      "grad_norm": 1.645859956741333,
      "learning_rate": 4.1626170439729764e-05,
      "loss": 4.2543,
      "step": 7620
    },
    {
      "epoch": 2.4416,
      "grad_norm": 1.738085389137268,
      "learning_rate": 4.138911935522105e-05,
      "loss": 4.0567,
      "step": 7630
    },
    {
      "epoch": 2.4448,
      "grad_norm": 1.9379328489303589,
      "learning_rate": 4.115206827071234e-05,
      "loss": 4.1993,
      "step": 7640
    },
    {
      "epoch": 2.448,
      "grad_norm": 1.9357826709747314,
      "learning_rate": 4.091501718620363e-05,
      "loss": 4.1766,
      "step": 7650
    },
    {
      "epoch": 2.448,
      "eval_loss": 4.078380584716797,
      "eval_runtime": 3.779,
      "eval_samples_per_second": 52.924,
      "eval_steps_per_second": 1.852,
      "step": 7650
    },
    {
      "epoch": 2.4512,
      "grad_norm": 1.642257809638977,
      "learning_rate": 4.067796610169492e-05,
      "loss": 4.249,
      "step": 7660
    },
    {
      "epoch": 2.4544,
      "grad_norm": 1.8367514610290527,
      "learning_rate": 4.0440915017186206e-05,
      "loss": 4.115,
      "step": 7670
    },
    {
      "epoch": 2.4576000000000002,
      "grad_norm": 1.6939482688903809,
      "learning_rate": 4.0203863932677494e-05,
      "loss": 3.965,
      "step": 7680
    },
    {
      "epoch": 2.4608,
      "grad_norm": 1.8370137214660645,
      "learning_rate": 3.996681284816878e-05,
      "loss": 4.1922,
      "step": 7690
    },
    {
      "epoch": 2.464,
      "grad_norm": 1.5791006088256836,
      "learning_rate": 3.972976176366007e-05,
      "loss": 4.1946,
      "step": 7700
    },
    {
      "epoch": 2.464,
      "eval_loss": 4.082366943359375,
      "eval_runtime": 3.7788,
      "eval_samples_per_second": 52.927,
      "eval_steps_per_second": 1.852,
      "step": 7700
    },
    {
      "epoch": 2.4672,
      "grad_norm": 1.6268126964569092,
      "learning_rate": 3.949271067915136e-05,
      "loss": 4.1522,
      "step": 7710
    },
    {
      "epoch": 2.4704,
      "grad_norm": 1.7991405725479126,
      "learning_rate": 3.925565959464265e-05,
      "loss": 4.2072,
      "step": 7720
    },
    {
      "epoch": 2.4736000000000002,
      "grad_norm": 1.8163107633590698,
      "learning_rate": 3.9018608510133935e-05,
      "loss": 4.166,
      "step": 7730
    },
    {
      "epoch": 2.4768,
      "grad_norm": 1.5466046333312988,
      "learning_rate": 3.8781557425625224e-05,
      "loss": 4.0767,
      "step": 7740
    },
    {
      "epoch": 2.48,
      "grad_norm": 1.6619501113891602,
      "learning_rate": 3.854450634111651e-05,
      "loss": 4.1697,
      "step": 7750
    },
    {
      "epoch": 2.48,
      "eval_loss": 4.079033374786377,
      "eval_runtime": 3.7783,
      "eval_samples_per_second": 52.934,
      "eval_steps_per_second": 1.853,
      "step": 7750
    },
    {
      "epoch": 2.4832,
      "grad_norm": 1.695089340209961,
      "learning_rate": 3.83074552566078e-05,
      "loss": 4.123,
      "step": 7760
    },
    {
      "epoch": 2.4864,
      "grad_norm": 1.6652754545211792,
      "learning_rate": 3.807040417209909e-05,
      "loss": 4.1472,
      "step": 7770
    },
    {
      "epoch": 2.4896,
      "grad_norm": 1.70193350315094,
      "learning_rate": 3.783335308759038e-05,
      "loss": 4.1944,
      "step": 7780
    },
    {
      "epoch": 2.4928,
      "grad_norm": 1.6796077489852905,
      "learning_rate": 3.7596302003081665e-05,
      "loss": 4.235,
      "step": 7790
    },
    {
      "epoch": 2.496,
      "grad_norm": 1.6715190410614014,
      "learning_rate": 3.735925091857295e-05,
      "loss": 4.1432,
      "step": 7800
    },
    {
      "epoch": 2.496,
      "eval_loss": 4.078528881072998,
      "eval_runtime": 3.7789,
      "eval_samples_per_second": 52.925,
      "eval_steps_per_second": 1.852,
      "step": 7800
    },
    {
      "epoch": 2.4992,
      "grad_norm": 1.9952480792999268,
      "learning_rate": 3.712219983406424e-05,
      "loss": 4.1046,
      "step": 7810
    },
    {
      "epoch": 2.5023999999999997,
      "grad_norm": 1.7698253393173218,
      "learning_rate": 3.688514874955553e-05,
      "loss": 4.2474,
      "step": 7820
    },
    {
      "epoch": 2.5056000000000003,
      "grad_norm": 1.74915611743927,
      "learning_rate": 3.664809766504682e-05,
      "loss": 3.9636,
      "step": 7830
    },
    {
      "epoch": 2.5088,
      "grad_norm": 1.641111135482788,
      "learning_rate": 3.6411046580538106e-05,
      "loss": 4.0664,
      "step": 7840
    },
    {
      "epoch": 2.512,
      "grad_norm": 1.6507891416549683,
      "learning_rate": 3.6173995496029395e-05,
      "loss": 4.135,
      "step": 7850
    },
    {
      "epoch": 2.512,
      "eval_loss": 4.077568054199219,
      "eval_runtime": 3.7807,
      "eval_samples_per_second": 52.901,
      "eval_steps_per_second": 1.852,
      "step": 7850
    },
    {
      "epoch": 2.5152,
      "grad_norm": 1.6983143091201782,
      "learning_rate": 3.593694441152068e-05,
      "loss": 4.3026,
      "step": 7860
    },
    {
      "epoch": 2.5183999999999997,
      "grad_norm": 1.9386941194534302,
      "learning_rate": 3.569989332701197e-05,
      "loss": 4.2792,
      "step": 7870
    },
    {
      "epoch": 2.5216,
      "grad_norm": 1.6842819452285767,
      "learning_rate": 3.5462842242503266e-05,
      "loss": 4.1124,
      "step": 7880
    },
    {
      "epoch": 2.5248,
      "grad_norm": 1.689164400100708,
      "learning_rate": 3.522579115799455e-05,
      "loss": 4.1902,
      "step": 7890
    },
    {
      "epoch": 2.528,
      "grad_norm": 1.8453681468963623,
      "learning_rate": 3.4988740073485836e-05,
      "loss": 4.07,
      "step": 7900
    },
    {
      "epoch": 2.528,
      "eval_loss": 4.075640678405762,
      "eval_runtime": 3.7807,
      "eval_samples_per_second": 52.9,
      "eval_steps_per_second": 1.851,
      "step": 7900
    },
    {
      "epoch": 2.5312,
      "grad_norm": 1.848673701286316,
      "learning_rate": 3.4751688988977124e-05,
      "loss": 4.1959,
      "step": 7910
    },
    {
      "epoch": 2.5343999999999998,
      "grad_norm": 1.6368846893310547,
      "learning_rate": 3.451463790446842e-05,
      "loss": 4.0826,
      "step": 7920
    },
    {
      "epoch": 2.5376,
      "grad_norm": 1.7555739879608154,
      "learning_rate": 3.42775868199597e-05,
      "loss": 4.1197,
      "step": 7930
    },
    {
      "epoch": 2.5408,
      "grad_norm": 1.8475348949432373,
      "learning_rate": 3.404053573545099e-05,
      "loss": 4.2038,
      "step": 7940
    },
    {
      "epoch": 2.544,
      "grad_norm": 1.6499971151351929,
      "learning_rate": 3.380348465094228e-05,
      "loss": 4.0974,
      "step": 7950
    },
    {
      "epoch": 2.544,
      "eval_loss": 4.086129665374756,
      "eval_runtime": 3.7795,
      "eval_samples_per_second": 52.917,
      "eval_steps_per_second": 1.852,
      "step": 7950
    },
    {
      "epoch": 2.5472,
      "grad_norm": 1.5449750423431396,
      "learning_rate": 3.356643356643357e-05,
      "loss": 4.1788,
      "step": 7960
    },
    {
      "epoch": 2.5504,
      "grad_norm": 1.681462287902832,
      "learning_rate": 3.332938248192486e-05,
      "loss": 4.1322,
      "step": 7970
    },
    {
      "epoch": 2.5536,
      "grad_norm": 1.9000767469406128,
      "learning_rate": 3.309233139741614e-05,
      "loss": 4.1749,
      "step": 7980
    },
    {
      "epoch": 2.5568,
      "grad_norm": 1.526650071144104,
      "learning_rate": 3.285528031290743e-05,
      "loss": 4.1771,
      "step": 7990
    },
    {
      "epoch": 2.56,
      "grad_norm": 1.8268814086914062,
      "learning_rate": 3.261822922839872e-05,
      "loss": 4.1131,
      "step": 8000
    },
    {
      "epoch": 2.56,
      "eval_loss": 4.071206569671631,
      "eval_runtime": 3.779,
      "eval_samples_per_second": 52.924,
      "eval_steps_per_second": 1.852,
      "step": 8000
    },
    {
      "epoch": 2.5632,
      "grad_norm": 1.7995818853378296,
      "learning_rate": 3.2381178143890014e-05,
      "loss": 4.1116,
      "step": 8010
    },
    {
      "epoch": 2.5664,
      "grad_norm": 1.7140841484069824,
      "learning_rate": 3.2144127059381296e-05,
      "loss": 4.0745,
      "step": 8020
    },
    {
      "epoch": 2.5696,
      "grad_norm": 1.8253382444381714,
      "learning_rate": 3.1907075974872584e-05,
      "loss": 4.0716,
      "step": 8030
    },
    {
      "epoch": 2.5728,
      "grad_norm": 1.9032098054885864,
      "learning_rate": 3.167002489036387e-05,
      "loss": 4.1908,
      "step": 8040
    },
    {
      "epoch": 2.576,
      "grad_norm": 2.036639451980591,
      "learning_rate": 3.143297380585517e-05,
      "loss": 4.1118,
      "step": 8050
    },
    {
      "epoch": 2.576,
      "eval_loss": 4.084523677825928,
      "eval_runtime": 3.7794,
      "eval_samples_per_second": 52.918,
      "eval_steps_per_second": 1.852,
      "step": 8050
    },
    {
      "epoch": 2.5792,
      "grad_norm": 1.6429413557052612,
      "learning_rate": 3.119592272134645e-05,
      "loss": 4.2499,
      "step": 8060
    },
    {
      "epoch": 2.5824,
      "grad_norm": 1.6821672916412354,
      "learning_rate": 3.095887163683774e-05,
      "loss": 4.1954,
      "step": 8070
    },
    {
      "epoch": 2.5856,
      "grad_norm": 1.7564630508422852,
      "learning_rate": 3.0721820552329025e-05,
      "loss": 4.2303,
      "step": 8080
    },
    {
      "epoch": 2.5888,
      "grad_norm": 1.84837806224823,
      "learning_rate": 3.0484769467820317e-05,
      "loss": 4.1319,
      "step": 8090
    },
    {
      "epoch": 2.592,
      "grad_norm": 1.5575319528579712,
      "learning_rate": 3.024771838331161e-05,
      "loss": 4.1572,
      "step": 8100
    },
    {
      "epoch": 2.592,
      "eval_loss": 4.082096576690674,
      "eval_runtime": 3.7776,
      "eval_samples_per_second": 52.943,
      "eval_steps_per_second": 1.853,
      "step": 8100
    },
    {
      "epoch": 2.5952,
      "grad_norm": 1.8511556386947632,
      "learning_rate": 3.001066729880289e-05,
      "loss": 3.9839,
      "step": 8110
    },
    {
      "epoch": 2.5984,
      "grad_norm": 2.1147468090057373,
      "learning_rate": 2.9773616214294182e-05,
      "loss": 4.0626,
      "step": 8120
    },
    {
      "epoch": 2.6016,
      "grad_norm": 1.9895187616348267,
      "learning_rate": 2.953656512978547e-05,
      "loss": 4.1173,
      "step": 8130
    },
    {
      "epoch": 2.6048,
      "grad_norm": 1.727811336517334,
      "learning_rate": 2.9299514045276762e-05,
      "loss": 4.0416,
      "step": 8140
    },
    {
      "epoch": 2.608,
      "grad_norm": 1.8900690078735352,
      "learning_rate": 2.9062462960768043e-05,
      "loss": 4.1911,
      "step": 8150
    },
    {
      "epoch": 2.608,
      "eval_loss": 4.074606895446777,
      "eval_runtime": 3.78,
      "eval_samples_per_second": 52.909,
      "eval_steps_per_second": 1.852,
      "step": 8150
    },
    {
      "epoch": 2.6112,
      "grad_norm": 1.8280340433120728,
      "learning_rate": 2.8825411876259335e-05,
      "loss": 4.2183,
      "step": 8160
    },
    {
      "epoch": 2.6144,
      "grad_norm": 1.6846044063568115,
      "learning_rate": 2.8588360791750623e-05,
      "loss": 4.1338,
      "step": 8170
    },
    {
      "epoch": 2.6176,
      "grad_norm": 1.8734265565872192,
      "learning_rate": 2.8351309707241915e-05,
      "loss": 4.1284,
      "step": 8180
    },
    {
      "epoch": 2.6208,
      "grad_norm": 1.6263827085494995,
      "learning_rate": 2.8114258622733203e-05,
      "loss": 4.0704,
      "step": 8190
    },
    {
      "epoch": 2.624,
      "grad_norm": 2.0143892765045166,
      "learning_rate": 2.7877207538224488e-05,
      "loss": 4.1384,
      "step": 8200
    },
    {
      "epoch": 2.624,
      "eval_loss": 4.076687812805176,
      "eval_runtime": 3.7774,
      "eval_samples_per_second": 52.946,
      "eval_steps_per_second": 1.853,
      "step": 8200
    },
    {
      "epoch": 2.6272,
      "grad_norm": 1.801462173461914,
      "learning_rate": 2.7640156453715776e-05,
      "loss": 3.9077,
      "step": 8210
    },
    {
      "epoch": 2.6304,
      "grad_norm": 1.5374631881713867,
      "learning_rate": 2.7403105369207065e-05,
      "loss": 4.0358,
      "step": 8220
    },
    {
      "epoch": 2.6336,
      "grad_norm": 1.636486530303955,
      "learning_rate": 2.7166054284698356e-05,
      "loss": 4.1528,
      "step": 8230
    },
    {
      "epoch": 2.6368,
      "grad_norm": 1.725569248199463,
      "learning_rate": 2.692900320018964e-05,
      "loss": 4.1925,
      "step": 8240
    },
    {
      "epoch": 2.64,
      "grad_norm": 1.8046528100967407,
      "learning_rate": 2.669195211568093e-05,
      "loss": 4.2013,
      "step": 8250
    },
    {
      "epoch": 2.64,
      "eval_loss": 4.069084644317627,
      "eval_runtime": 3.7757,
      "eval_samples_per_second": 52.971,
      "eval_steps_per_second": 1.854,
      "step": 8250
    },
    {
      "epoch": 2.6432,
      "grad_norm": 1.6979585886001587,
      "learning_rate": 2.6454901031172218e-05,
      "loss": 4.2212,
      "step": 8260
    },
    {
      "epoch": 2.6464,
      "grad_norm": 1.5712165832519531,
      "learning_rate": 2.621784994666351e-05,
      "loss": 4.1642,
      "step": 8270
    },
    {
      "epoch": 2.6496,
      "grad_norm": 1.6144306659698486,
      "learning_rate": 2.5980798862154798e-05,
      "loss": 4.18,
      "step": 8280
    },
    {
      "epoch": 2.6528,
      "grad_norm": 1.731237530708313,
      "learning_rate": 2.5743747777646083e-05,
      "loss": 4.2011,
      "step": 8290
    },
    {
      "epoch": 2.656,
      "grad_norm": 1.7802586555480957,
      "learning_rate": 2.550669669313737e-05,
      "loss": 4.0634,
      "step": 8300
    },
    {
      "epoch": 2.656,
      "eval_loss": 4.072884559631348,
      "eval_runtime": 3.7743,
      "eval_samples_per_second": 52.989,
      "eval_steps_per_second": 1.855,
      "step": 8300
    },
    {
      "epoch": 2.6592000000000002,
      "grad_norm": 1.7972136735916138,
      "learning_rate": 2.5269645608628662e-05,
      "loss": 4.2583,
      "step": 8310
    },
    {
      "epoch": 2.6624,
      "grad_norm": 1.8843110799789429,
      "learning_rate": 2.503259452411995e-05,
      "loss": 4.1229,
      "step": 8320
    },
    {
      "epoch": 2.6656,
      "grad_norm": 1.7354609966278076,
      "learning_rate": 2.479554343961124e-05,
      "loss": 4.1669,
      "step": 8330
    },
    {
      "epoch": 2.6688,
      "grad_norm": 1.6537644863128662,
      "learning_rate": 2.4558492355102524e-05,
      "loss": 4.1324,
      "step": 8340
    },
    {
      "epoch": 2.672,
      "grad_norm": 1.8260716199874878,
      "learning_rate": 2.4321441270593816e-05,
      "loss": 4.2056,
      "step": 8350
    },
    {
      "epoch": 2.672,
      "eval_loss": 4.0732221603393555,
      "eval_runtime": 3.7776,
      "eval_samples_per_second": 52.944,
      "eval_steps_per_second": 1.853,
      "step": 8350
    },
    {
      "epoch": 2.6752000000000002,
      "grad_norm": 1.6993898153305054,
      "learning_rate": 2.40843901860851e-05,
      "loss": 4.1921,
      "step": 8360
    },
    {
      "epoch": 2.6784,
      "grad_norm": 2.014533281326294,
      "learning_rate": 2.3847339101576392e-05,
      "loss": 4.0942,
      "step": 8370
    },
    {
      "epoch": 2.6816,
      "grad_norm": 1.8743534088134766,
      "learning_rate": 2.361028801706768e-05,
      "loss": 4.1229,
      "step": 8380
    },
    {
      "epoch": 2.6848,
      "grad_norm": 1.8489253520965576,
      "learning_rate": 2.337323693255897e-05,
      "loss": 4.1321,
      "step": 8390
    },
    {
      "epoch": 2.6879999999999997,
      "grad_norm": 1.6407370567321777,
      "learning_rate": 2.3136185848050257e-05,
      "loss": 4.1979,
      "step": 8400
    },
    {
      "epoch": 2.6879999999999997,
      "eval_loss": 4.067867279052734,
      "eval_runtime": 3.7757,
      "eval_samples_per_second": 52.97,
      "eval_steps_per_second": 1.854,
      "step": 8400
    },
    {
      "epoch": 2.6912000000000003,
      "grad_norm": 1.9235268831253052,
      "learning_rate": 2.2899134763541545e-05,
      "loss": 4.0991,
      "step": 8410
    },
    {
      "epoch": 2.6944,
      "grad_norm": 1.8604884147644043,
      "learning_rate": 2.2662083679032834e-05,
      "loss": 4.2372,
      "step": 8420
    },
    {
      "epoch": 2.6976,
      "grad_norm": 1.7490417957305908,
      "learning_rate": 2.2425032594524122e-05,
      "loss": 4.1331,
      "step": 8430
    },
    {
      "epoch": 2.7008,
      "grad_norm": 1.8467581272125244,
      "learning_rate": 2.218798151001541e-05,
      "loss": 4.1971,
      "step": 8440
    },
    {
      "epoch": 2.7039999999999997,
      "grad_norm": 1.7736611366271973,
      "learning_rate": 2.1950930425506695e-05,
      "loss": 4.1004,
      "step": 8450
    },
    {
      "epoch": 2.7039999999999997,
      "eval_loss": 4.067510604858398,
      "eval_runtime": 3.7748,
      "eval_samples_per_second": 52.983,
      "eval_steps_per_second": 1.854,
      "step": 8450
    },
    {
      "epoch": 2.7072000000000003,
      "grad_norm": 1.7852438688278198,
      "learning_rate": 2.1713879340997987e-05,
      "loss": 4.1832,
      "step": 8460
    },
    {
      "epoch": 2.7104,
      "grad_norm": 1.7254106998443604,
      "learning_rate": 2.147682825648927e-05,
      "loss": 4.184,
      "step": 8470
    },
    {
      "epoch": 2.7136,
      "grad_norm": 1.649915337562561,
      "learning_rate": 2.1239777171980563e-05,
      "loss": 4.257,
      "step": 8480
    },
    {
      "epoch": 2.7168,
      "grad_norm": 1.796303153038025,
      "learning_rate": 2.100272608747185e-05,
      "loss": 4.1047,
      "step": 8490
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 1.8285497426986694,
      "learning_rate": 2.076567500296314e-05,
      "loss": 4.2038,
      "step": 8500
    },
    {
      "epoch": 2.7199999999999998,
      "eval_loss": 4.070791721343994,
      "eval_runtime": 3.7751,
      "eval_samples_per_second": 52.978,
      "eval_steps_per_second": 1.854,
      "step": 8500
    },
    {
      "epoch": 2.7232,
      "grad_norm": 1.883621096611023,
      "learning_rate": 2.0528623918454428e-05,
      "loss": 4.1045,
      "step": 8510
    },
    {
      "epoch": 2.7264,
      "grad_norm": 1.6705068349838257,
      "learning_rate": 2.0291572833945716e-05,
      "loss": 4.0675,
      "step": 8520
    },
    {
      "epoch": 2.7296,
      "grad_norm": 1.7343891859054565,
      "learning_rate": 2.0054521749437005e-05,
      "loss": 4.1804,
      "step": 8530
    },
    {
      "epoch": 2.7328,
      "grad_norm": 1.7430394887924194,
      "learning_rate": 1.9817470664928293e-05,
      "loss": 4.1245,
      "step": 8540
    },
    {
      "epoch": 2.7359999999999998,
      "grad_norm": 1.6778767108917236,
      "learning_rate": 1.958041958041958e-05,
      "loss": 4.198,
      "step": 8550
    },
    {
      "epoch": 2.7359999999999998,
      "eval_loss": 4.070033550262451,
      "eval_runtime": 3.7757,
      "eval_samples_per_second": 52.97,
      "eval_steps_per_second": 1.854,
      "step": 8550
    },
    {
      "epoch": 2.7392,
      "grad_norm": 1.6357426643371582,
      "learning_rate": 1.934336849591087e-05,
      "loss": 4.1096,
      "step": 8560
    },
    {
      "epoch": 2.7424,
      "grad_norm": 1.9834206104278564,
      "learning_rate": 1.9106317411402158e-05,
      "loss": 4.1471,
      "step": 8570
    },
    {
      "epoch": 2.7456,
      "grad_norm": 1.769018292427063,
      "learning_rate": 1.886926632689345e-05,
      "loss": 4.1719,
      "step": 8580
    },
    {
      "epoch": 2.7488,
      "grad_norm": 2.032193660736084,
      "learning_rate": 1.8632215242384734e-05,
      "loss": 4.1258,
      "step": 8590
    },
    {
      "epoch": 2.752,
      "grad_norm": 1.9981268644332886,
      "learning_rate": 1.8395164157876023e-05,
      "loss": 4.1358,
      "step": 8600
    },
    {
      "epoch": 2.752,
      "eval_loss": 4.069312572479248,
      "eval_runtime": 3.7737,
      "eval_samples_per_second": 52.998,
      "eval_steps_per_second": 1.855,
      "step": 8600
    },
    {
      "epoch": 2.7552,
      "grad_norm": 1.5294194221496582,
      "learning_rate": 1.815811307336731e-05,
      "loss": 4.1496,
      "step": 8610
    },
    {
      "epoch": 2.7584,
      "grad_norm": 1.8921730518341064,
      "learning_rate": 1.79210619888586e-05,
      "loss": 4.1742,
      "step": 8620
    },
    {
      "epoch": 2.7616,
      "grad_norm": 1.9582023620605469,
      "learning_rate": 1.7684010904349887e-05,
      "loss": 4.0816,
      "step": 8630
    },
    {
      "epoch": 2.7648,
      "grad_norm": 1.56421959400177,
      "learning_rate": 1.7446959819841176e-05,
      "loss": 4.139,
      "step": 8640
    },
    {
      "epoch": 2.768,
      "grad_norm": 1.636325716972351,
      "learning_rate": 1.7209908735332464e-05,
      "loss": 4.2357,
      "step": 8650
    },
    {
      "epoch": 2.768,
      "eval_loss": 4.067967414855957,
      "eval_runtime": 3.78,
      "eval_samples_per_second": 52.91,
      "eval_steps_per_second": 1.852,
      "step": 8650
    },
    {
      "epoch": 2.7712,
      "grad_norm": 1.6389694213867188,
      "learning_rate": 1.6972857650823752e-05,
      "loss": 4.1034,
      "step": 8660
    },
    {
      "epoch": 2.7744,
      "grad_norm": 2.0037693977355957,
      "learning_rate": 1.673580656631504e-05,
      "loss": 4.0813,
      "step": 8670
    },
    {
      "epoch": 2.7776,
      "grad_norm": 1.8558454513549805,
      "learning_rate": 1.649875548180633e-05,
      "loss": 4.1823,
      "step": 8680
    },
    {
      "epoch": 2.7808,
      "grad_norm": 1.723434329032898,
      "learning_rate": 1.626170439729762e-05,
      "loss": 4.1635,
      "step": 8690
    },
    {
      "epoch": 2.784,
      "grad_norm": 1.8965948820114136,
      "learning_rate": 1.6024653312788905e-05,
      "loss": 4.2404,
      "step": 8700
    },
    {
      "epoch": 2.784,
      "eval_loss": 4.066669464111328,
      "eval_runtime": 3.7791,
      "eval_samples_per_second": 52.923,
      "eval_steps_per_second": 1.852,
      "step": 8700
    },
    {
      "epoch": 2.7872,
      "grad_norm": 1.6998467445373535,
      "learning_rate": 1.5787602228280197e-05,
      "loss": 4.1259,
      "step": 8710
    },
    {
      "epoch": 2.7904,
      "grad_norm": 1.7381926774978638,
      "learning_rate": 1.5550551143771482e-05,
      "loss": 4.1016,
      "step": 8720
    },
    {
      "epoch": 2.7936,
      "grad_norm": 1.7572624683380127,
      "learning_rate": 1.5313500059262774e-05,
      "loss": 4.1649,
      "step": 8730
    },
    {
      "epoch": 2.7968,
      "grad_norm": 1.794353723526001,
      "learning_rate": 1.5076448974754059e-05,
      "loss": 4.1319,
      "step": 8740
    },
    {
      "epoch": 2.8,
      "grad_norm": 1.8404892683029175,
      "learning_rate": 1.4839397890245349e-05,
      "loss": 4.1295,
      "step": 8750
    },
    {
      "epoch": 2.8,
      "eval_loss": 4.0679030418396,
      "eval_runtime": 3.7802,
      "eval_samples_per_second": 52.907,
      "eval_steps_per_second": 1.852,
      "step": 8750
    },
    {
      "epoch": 2.8032,
      "grad_norm": 1.6673128604888916,
      "learning_rate": 1.4602346805736635e-05,
      "loss": 4.0621,
      "step": 8760
    },
    {
      "epoch": 2.8064,
      "grad_norm": 1.811320185661316,
      "learning_rate": 1.4365295721227925e-05,
      "loss": 4.0885,
      "step": 8770
    },
    {
      "epoch": 2.8096,
      "grad_norm": 1.7035729885101318,
      "learning_rate": 1.4128244636719215e-05,
      "loss": 4.1705,
      "step": 8780
    },
    {
      "epoch": 2.8128,
      "grad_norm": 1.8244231939315796,
      "learning_rate": 1.3891193552210502e-05,
      "loss": 4.0878,
      "step": 8790
    },
    {
      "epoch": 2.816,
      "grad_norm": 1.9940687417984009,
      "learning_rate": 1.3654142467701792e-05,
      "loss": 4.1671,
      "step": 8800
    },
    {
      "epoch": 2.816,
      "eval_loss": 4.070422172546387,
      "eval_runtime": 3.7781,
      "eval_samples_per_second": 52.937,
      "eval_steps_per_second": 1.853,
      "step": 8800
    },
    {
      "epoch": 2.8192,
      "grad_norm": 1.6351100206375122,
      "learning_rate": 1.3417091383193078e-05,
      "loss": 4.127,
      "step": 8810
    },
    {
      "epoch": 2.8224,
      "grad_norm": 1.7733876705169678,
      "learning_rate": 1.3180040298684368e-05,
      "loss": 4.0743,
      "step": 8820
    },
    {
      "epoch": 2.8256,
      "grad_norm": 1.5678579807281494,
      "learning_rate": 1.2942989214175655e-05,
      "loss": 4.1004,
      "step": 8830
    },
    {
      "epoch": 2.8288,
      "grad_norm": 1.8356895446777344,
      "learning_rate": 1.2705938129666945e-05,
      "loss": 4.0579,
      "step": 8840
    },
    {
      "epoch": 2.832,
      "grad_norm": 1.622290015220642,
      "learning_rate": 1.2468887045158233e-05,
      "loss": 4.2643,
      "step": 8850
    },
    {
      "epoch": 2.832,
      "eval_loss": 4.068686008453369,
      "eval_runtime": 3.7787,
      "eval_samples_per_second": 52.928,
      "eval_steps_per_second": 1.852,
      "step": 8850
    },
    {
      "epoch": 2.8352,
      "grad_norm": 1.6388238668441772,
      "learning_rate": 1.2231835960649521e-05,
      "loss": 4.1427,
      "step": 8860
    },
    {
      "epoch": 2.8384,
      "grad_norm": 1.8283299207687378,
      "learning_rate": 1.199478487614081e-05,
      "loss": 4.1623,
      "step": 8870
    },
    {
      "epoch": 2.8416,
      "grad_norm": 1.7160379886627197,
      "learning_rate": 1.1757733791632098e-05,
      "loss": 4.0811,
      "step": 8880
    },
    {
      "epoch": 2.8448,
      "grad_norm": 2.0273005962371826,
      "learning_rate": 1.1520682707123386e-05,
      "loss": 4.139,
      "step": 8890
    },
    {
      "epoch": 2.848,
      "grad_norm": 1.66848886013031,
      "learning_rate": 1.1283631622614674e-05,
      "loss": 4.1635,
      "step": 8900
    },
    {
      "epoch": 2.848,
      "eval_loss": 4.069969177246094,
      "eval_runtime": 3.7773,
      "eval_samples_per_second": 52.948,
      "eval_steps_per_second": 1.853,
      "step": 8900
    },
    {
      "epoch": 2.8512,
      "grad_norm": 1.7005642652511597,
      "learning_rate": 1.1046580538105963e-05,
      "loss": 4.1246,
      "step": 8910
    },
    {
      "epoch": 2.8544,
      "grad_norm": 1.6699237823486328,
      "learning_rate": 1.0809529453597251e-05,
      "loss": 4.1488,
      "step": 8920
    },
    {
      "epoch": 2.8576,
      "grad_norm": 1.5086969137191772,
      "learning_rate": 1.057247836908854e-05,
      "loss": 4.0388,
      "step": 8930
    },
    {
      "epoch": 2.8608000000000002,
      "grad_norm": 1.7127832174301147,
      "learning_rate": 1.0335427284579828e-05,
      "loss": 4.122,
      "step": 8940
    },
    {
      "epoch": 2.864,
      "grad_norm": 1.796231985092163,
      "learning_rate": 1.0098376200071116e-05,
      "loss": 4.1031,
      "step": 8950
    },
    {
      "epoch": 2.864,
      "eval_loss": 4.072583198547363,
      "eval_runtime": 3.7761,
      "eval_samples_per_second": 52.965,
      "eval_steps_per_second": 1.854,
      "step": 8950
    },
    {
      "epoch": 2.8672,
      "grad_norm": 1.5708801746368408,
      "learning_rate": 9.861325115562404e-06,
      "loss": 4.1747,
      "step": 8960
    },
    {
      "epoch": 2.8704,
      "grad_norm": 1.7097100019454956,
      "learning_rate": 9.624274031053692e-06,
      "loss": 4.0288,
      "step": 8970
    },
    {
      "epoch": 2.8736,
      "grad_norm": 1.8913401365280151,
      "learning_rate": 9.38722294654498e-06,
      "loss": 4.1134,
      "step": 8980
    },
    {
      "epoch": 2.8768000000000002,
      "grad_norm": 1.989813208580017,
      "learning_rate": 9.150171862036269e-06,
      "loss": 4.0095,
      "step": 8990
    },
    {
      "epoch": 2.88,
      "grad_norm": 1.7700189352035522,
      "learning_rate": 8.913120777527557e-06,
      "loss": 4.1288,
      "step": 9000
    },
    {
      "epoch": 2.88,
      "eval_loss": 4.073902130126953,
      "eval_runtime": 3.7758,
      "eval_samples_per_second": 52.968,
      "eval_steps_per_second": 1.854,
      "step": 9000
    },
    {
      "epoch": 2.8832,
      "grad_norm": 1.6836146116256714,
      "learning_rate": 8.676069693018846e-06,
      "loss": 4.2246,
      "step": 9010
    },
    {
      "epoch": 2.8864,
      "grad_norm": 1.8404823541641235,
      "learning_rate": 8.439018608510134e-06,
      "loss": 4.1179,
      "step": 9020
    },
    {
      "epoch": 2.8895999999999997,
      "grad_norm": 1.7237106561660767,
      "learning_rate": 8.201967524001422e-06,
      "loss": 4.2049,
      "step": 9030
    },
    {
      "epoch": 2.8928000000000003,
      "grad_norm": 1.8139606714248657,
      "learning_rate": 7.964916439492712e-06,
      "loss": 4.116,
      "step": 9040
    },
    {
      "epoch": 2.896,
      "grad_norm": 1.7822012901306152,
      "learning_rate": 7.727865354984e-06,
      "loss": 4.2303,
      "step": 9050
    },
    {
      "epoch": 2.896,
      "eval_loss": 4.065125942230225,
      "eval_runtime": 3.7773,
      "eval_samples_per_second": 52.948,
      "eval_steps_per_second": 1.853,
      "step": 9050
    },
    {
      "epoch": 2.8992,
      "grad_norm": 1.7210216522216797,
      "learning_rate": 7.490814270475288e-06,
      "loss": 4.1133,
      "step": 9060
    },
    {
      "epoch": 2.9024,
      "grad_norm": 1.632992148399353,
      "learning_rate": 7.253763185966576e-06,
      "loss": 4.2038,
      "step": 9070
    },
    {
      "epoch": 2.9055999999999997,
      "grad_norm": 1.7681814432144165,
      "learning_rate": 7.016712101457864e-06,
      "loss": 4.1887,
      "step": 9080
    },
    {
      "epoch": 2.9088000000000003,
      "grad_norm": 1.827370524406433,
      "learning_rate": 6.779661016949153e-06,
      "loss": 4.146,
      "step": 9090
    },
    {
      "epoch": 2.912,
      "grad_norm": 1.611536979675293,
      "learning_rate": 6.542609932440441e-06,
      "loss": 4.2484,
      "step": 9100
    },
    {
      "epoch": 2.912,
      "eval_loss": 4.0672173500061035,
      "eval_runtime": 3.7782,
      "eval_samples_per_second": 52.936,
      "eval_steps_per_second": 1.853,
      "step": 9100
    },
    {
      "epoch": 2.9152,
      "grad_norm": 1.8131779432296753,
      "learning_rate": 6.305558847931729e-06,
      "loss": 4.0967,
      "step": 9110
    },
    {
      "epoch": 2.9184,
      "grad_norm": 1.6761711835861206,
      "learning_rate": 6.068507763423018e-06,
      "loss": 4.0287,
      "step": 9120
    },
    {
      "epoch": 2.9215999999999998,
      "grad_norm": 1.7464066743850708,
      "learning_rate": 5.831456678914307e-06,
      "loss": 4.094,
      "step": 9130
    },
    {
      "epoch": 2.9248,
      "grad_norm": 1.8074678182601929,
      "learning_rate": 5.594405594405595e-06,
      "loss": 4.1245,
      "step": 9140
    },
    {
      "epoch": 2.928,
      "grad_norm": 1.6765350103378296,
      "learning_rate": 5.357354509896883e-06,
      "loss": 4.1151,
      "step": 9150
    },
    {
      "epoch": 2.928,
      "eval_loss": 4.066868782043457,
      "eval_runtime": 3.7787,
      "eval_samples_per_second": 52.928,
      "eval_steps_per_second": 1.852,
      "step": 9150
    },
    {
      "epoch": 2.9312,
      "grad_norm": 1.779050588607788,
      "learning_rate": 5.1203034253881714e-06,
      "loss": 4.164,
      "step": 9160
    },
    {
      "epoch": 2.9344,
      "grad_norm": 1.9456990957260132,
      "learning_rate": 4.88325234087946e-06,
      "loss": 4.1377,
      "step": 9170
    },
    {
      "epoch": 2.9375999999999998,
      "grad_norm": 1.6473292112350464,
      "learning_rate": 4.646201256370748e-06,
      "loss": 4.1533,
      "step": 9180
    },
    {
      "epoch": 2.9408,
      "grad_norm": 1.8317981958389282,
      "learning_rate": 4.409150171862036e-06,
      "loss": 4.204,
      "step": 9190
    },
    {
      "epoch": 2.944,
      "grad_norm": 1.817662000656128,
      "learning_rate": 4.1720990873533246e-06,
      "loss": 4.1112,
      "step": 9200
    },
    {
      "epoch": 2.944,
      "eval_loss": 4.0682268142700195,
      "eval_runtime": 3.7839,
      "eval_samples_per_second": 52.855,
      "eval_steps_per_second": 1.85,
      "step": 9200
    },
    {
      "epoch": 2.9472,
      "grad_norm": 1.618864893913269,
      "learning_rate": 3.935048002844613e-06,
      "loss": 4.2003,
      "step": 9210
    },
    {
      "epoch": 2.9504,
      "grad_norm": 1.8160065412521362,
      "learning_rate": 3.697996918335902e-06,
      "loss": 4.1164,
      "step": 9220
    },
    {
      "epoch": 2.9536,
      "grad_norm": 1.8698701858520508,
      "learning_rate": 3.4609458338271903e-06,
      "loss": 4.0838,
      "step": 9230
    },
    {
      "epoch": 2.9568,
      "grad_norm": 1.8080865144729614,
      "learning_rate": 3.223894749318478e-06,
      "loss": 4.0813,
      "step": 9240
    },
    {
      "epoch": 2.96,
      "grad_norm": 1.796438455581665,
      "learning_rate": 2.9868436648097664e-06,
      "loss": 4.0846,
      "step": 9250
    },
    {
      "epoch": 2.96,
      "eval_loss": 4.064123630523682,
      "eval_runtime": 3.7819,
      "eval_samples_per_second": 52.883,
      "eval_steps_per_second": 1.851,
      "step": 9250
    },
    {
      "epoch": 2.9632,
      "grad_norm": 1.7231857776641846,
      "learning_rate": 2.749792580301055e-06,
      "loss": 4.2313,
      "step": 9260
    },
    {
      "epoch": 2.9664,
      "grad_norm": 1.6117546558380127,
      "learning_rate": 2.5127414957923434e-06,
      "loss": 4.1595,
      "step": 9270
    },
    {
      "epoch": 2.9696,
      "grad_norm": 1.7924697399139404,
      "learning_rate": 2.2756904112836317e-06,
      "loss": 4.1233,
      "step": 9280
    },
    {
      "epoch": 2.9728,
      "grad_norm": 1.6109980344772339,
      "learning_rate": 2.03863932677492e-06,
      "loss": 4.1181,
      "step": 9290
    },
    {
      "epoch": 2.976,
      "grad_norm": 1.765953779220581,
      "learning_rate": 1.8015882422662084e-06,
      "loss": 4.1886,
      "step": 9300
    },
    {
      "epoch": 2.976,
      "eval_loss": 4.0662055015563965,
      "eval_runtime": 3.7798,
      "eval_samples_per_second": 52.912,
      "eval_steps_per_second": 1.852,
      "step": 9300
    },
    {
      "epoch": 2.9792,
      "grad_norm": 1.9464945793151855,
      "learning_rate": 1.564537157757497e-06,
      "loss": 4.1532,
      "step": 9310
    },
    {
      "epoch": 2.9824,
      "grad_norm": 1.6470036506652832,
      "learning_rate": 1.3274860732487852e-06,
      "loss": 4.0591,
      "step": 9320
    },
    {
      "epoch": 2.9856,
      "grad_norm": 1.565771222114563,
      "learning_rate": 1.0904349887400735e-06,
      "loss": 4.1097,
      "step": 9330
    },
    {
      "epoch": 2.9888,
      "grad_norm": 1.9843437671661377,
      "learning_rate": 8.53383904231362e-07,
      "loss": 4.1657,
      "step": 9340
    },
    {
      "epoch": 2.992,
      "grad_norm": 1.7488415241241455,
      "learning_rate": 6.163328197226503e-07,
      "loss": 4.1398,
      "step": 9350
    },
    {
      "epoch": 2.992,
      "eval_loss": 4.064945220947266,
      "eval_runtime": 3.7818,
      "eval_samples_per_second": 52.885,
      "eval_steps_per_second": 1.851,
      "step": 9350
    },
    {
      "epoch": 2.9952,
      "grad_norm": 1.715699553489685,
      "learning_rate": 3.7928173521393864e-07,
      "loss": 4.1551,
      "step": 9360
    },
    {
      "epoch": 2.9984,
      "grad_norm": 1.6933743953704834,
      "learning_rate": 1.4223065070522698e-07,
      "loss": 4.1077,
      "step": 9370
    }
  ],
  "logging_steps": 10,
  "max_steps": 9375,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 8.32604995584e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
