{
  "best_global_step": 8500,
  "best_metric": 1.0613770484924316,
  "best_model_checkpoint": "/kaggle/working/models/vit5-base/checkpoint-8500",
  "epoch": 3.0,
  "eval_steps": 50,
  "global_step": 9375,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0032,
      "grad_norm": 69.19813537597656,
      "learning_rate": 1.9189765458422177e-06,
      "loss": 31.0395,
      "step": 10
    },
    {
      "epoch": 0.0064,
      "grad_norm": 73.5982437133789,
      "learning_rate": 4.051172707889126e-06,
      "loss": 29.7596,
      "step": 20
    },
    {
      "epoch": 0.0096,
      "grad_norm": 72.94176483154297,
      "learning_rate": 6.1833688699360345e-06,
      "loss": 25.6516,
      "step": 30
    },
    {
      "epoch": 0.0128,
      "grad_norm": 65.88688659667969,
      "learning_rate": 8.315565031982942e-06,
      "loss": 19.6095,
      "step": 40
    },
    {
      "epoch": 0.016,
      "grad_norm": 41.52111053466797,
      "learning_rate": 1.0447761194029851e-05,
      "loss": 12.7077,
      "step": 50
    },
    {
      "epoch": 0.016,
      "eval_loss": 7.699410438537598,
      "eval_runtime": 2.3366,
      "eval_samples_per_second": 85.595,
      "eval_steps_per_second": 1.712,
      "step": 50
    },
    {
      "epoch": 0.0192,
      "grad_norm": 17.65923500061035,
      "learning_rate": 1.257995735607676e-05,
      "loss": 6.7514,
      "step": 60
    },
    {
      "epoch": 0.0224,
      "grad_norm": 3.4906973838806152,
      "learning_rate": 1.4712153518123666e-05,
      "loss": 3.5373,
      "step": 70
    },
    {
      "epoch": 0.0256,
      "grad_norm": 2.566615343093872,
      "learning_rate": 1.6844349680170575e-05,
      "loss": 2.5202,
      "step": 80
    },
    {
      "epoch": 0.0288,
      "grad_norm": 1.661171555519104,
      "learning_rate": 1.8976545842217487e-05,
      "loss": 2.1491,
      "step": 90
    },
    {
      "epoch": 0.032,
      "grad_norm": 1.2595651149749756,
      "learning_rate": 2.1108742004264392e-05,
      "loss": 1.842,
      "step": 100
    },
    {
      "epoch": 0.032,
      "eval_loss": 1.690676212310791,
      "eval_runtime": 2.3374,
      "eval_samples_per_second": 85.565,
      "eval_steps_per_second": 1.711,
      "step": 100
    },
    {
      "epoch": 0.0352,
      "grad_norm": 0.9197786450386047,
      "learning_rate": 2.32409381663113e-05,
      "loss": 1.7211,
      "step": 110
    },
    {
      "epoch": 0.0384,
      "grad_norm": 0.9764770269393921,
      "learning_rate": 2.537313432835821e-05,
      "loss": 1.594,
      "step": 120
    },
    {
      "epoch": 0.0416,
      "grad_norm": 0.6084533929824829,
      "learning_rate": 2.7505330490405118e-05,
      "loss": 1.4736,
      "step": 130
    },
    {
      "epoch": 0.0448,
      "grad_norm": 0.5629391074180603,
      "learning_rate": 2.9637526652452023e-05,
      "loss": 1.4598,
      "step": 140
    },
    {
      "epoch": 0.048,
      "grad_norm": 0.5336785316467285,
      "learning_rate": 3.1769722814498935e-05,
      "loss": 1.3513,
      "step": 150
    },
    {
      "epoch": 0.048,
      "eval_loss": 1.450751781463623,
      "eval_runtime": 2.3372,
      "eval_samples_per_second": 85.573,
      "eval_steps_per_second": 1.711,
      "step": 150
    },
    {
      "epoch": 0.0512,
      "grad_norm": 0.6016176342964172,
      "learning_rate": 3.390191897654584e-05,
      "loss": 1.5133,
      "step": 160
    },
    {
      "epoch": 0.0544,
      "grad_norm": 0.6322293877601624,
      "learning_rate": 3.603411513859275e-05,
      "loss": 1.246,
      "step": 170
    },
    {
      "epoch": 0.0576,
      "grad_norm": 0.5602941513061523,
      "learning_rate": 3.8166311300639665e-05,
      "loss": 1.3373,
      "step": 180
    },
    {
      "epoch": 0.0608,
      "grad_norm": 0.6704506278038025,
      "learning_rate": 4.029850746268657e-05,
      "loss": 1.3836,
      "step": 190
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.5271943211555481,
      "learning_rate": 4.2430703624733475e-05,
      "loss": 1.3317,
      "step": 200
    },
    {
      "epoch": 0.064,
      "eval_loss": 1.3339303731918335,
      "eval_runtime": 2.3371,
      "eval_samples_per_second": 85.577,
      "eval_steps_per_second": 1.712,
      "step": 200
    },
    {
      "epoch": 0.0672,
      "grad_norm": 0.6080327033996582,
      "learning_rate": 4.456289978678039e-05,
      "loss": 1.3577,
      "step": 210
    },
    {
      "epoch": 0.0704,
      "grad_norm": 0.7114837765693665,
      "learning_rate": 4.669509594882729e-05,
      "loss": 1.1873,
      "step": 220
    },
    {
      "epoch": 0.0736,
      "grad_norm": 0.5619970560073853,
      "learning_rate": 4.88272921108742e-05,
      "loss": 1.1935,
      "step": 230
    },
    {
      "epoch": 0.0768,
      "grad_norm": 0.6104201674461365,
      "learning_rate": 5.095948827292111e-05,
      "loss": 1.2366,
      "step": 240
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5473642349243164,
      "learning_rate": 5.3091684434968015e-05,
      "loss": 1.1667,
      "step": 250
    },
    {
      "epoch": 0.08,
      "eval_loss": 1.2047066688537598,
      "eval_runtime": 2.3385,
      "eval_samples_per_second": 85.525,
      "eval_steps_per_second": 1.711,
      "step": 250
    },
    {
      "epoch": 0.0832,
      "grad_norm": 0.4966389536857605,
      "learning_rate": 5.5223880597014934e-05,
      "loss": 1.2427,
      "step": 260
    },
    {
      "epoch": 0.0864,
      "grad_norm": 0.529354453086853,
      "learning_rate": 5.735607675906184e-05,
      "loss": 1.1268,
      "step": 270
    },
    {
      "epoch": 0.0896,
      "grad_norm": 0.49294593930244446,
      "learning_rate": 5.9488272921108744e-05,
      "loss": 1.0543,
      "step": 280
    },
    {
      "epoch": 0.0928,
      "grad_norm": 0.5727434754371643,
      "learning_rate": 6.162046908315566e-05,
      "loss": 1.0986,
      "step": 290
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.4833747446537018,
      "learning_rate": 6.375266524520256e-05,
      "loss": 1.1191,
      "step": 300
    },
    {
      "epoch": 0.096,
      "eval_loss": 1.186323881149292,
      "eval_runtime": 2.3378,
      "eval_samples_per_second": 85.55,
      "eval_steps_per_second": 1.711,
      "step": 300
    },
    {
      "epoch": 0.0992,
      "grad_norm": 0.435518741607666,
      "learning_rate": 6.588486140724947e-05,
      "loss": 1.0565,
      "step": 310
    },
    {
      "epoch": 0.1024,
      "grad_norm": 0.5579683780670166,
      "learning_rate": 6.801705756929639e-05,
      "loss": 1.124,
      "step": 320
    },
    {
      "epoch": 0.1056,
      "grad_norm": 0.5086454749107361,
      "learning_rate": 7.014925373134329e-05,
      "loss": 1.1122,
      "step": 330
    },
    {
      "epoch": 0.1088,
      "grad_norm": 0.4455872178077698,
      "learning_rate": 7.22814498933902e-05,
      "loss": 1.1431,
      "step": 340
    },
    {
      "epoch": 0.112,
      "grad_norm": 0.5835546851158142,
      "learning_rate": 7.44136460554371e-05,
      "loss": 1.1607,
      "step": 350
    },
    {
      "epoch": 0.112,
      "eval_loss": 1.1721889972686768,
      "eval_runtime": 2.3372,
      "eval_samples_per_second": 85.573,
      "eval_steps_per_second": 1.711,
      "step": 350
    },
    {
      "epoch": 0.1152,
      "grad_norm": 0.4632447063922882,
      "learning_rate": 7.6545842217484e-05,
      "loss": 1.0722,
      "step": 360
    },
    {
      "epoch": 0.1184,
      "grad_norm": 0.5371463298797607,
      "learning_rate": 7.867803837953091e-05,
      "loss": 1.1405,
      "step": 370
    },
    {
      "epoch": 0.1216,
      "grad_norm": 0.5482791066169739,
      "learning_rate": 8.081023454157783e-05,
      "loss": 1.0788,
      "step": 380
    },
    {
      "epoch": 0.1248,
      "grad_norm": 0.4542990028858185,
      "learning_rate": 8.294243070362474e-05,
      "loss": 1.1273,
      "step": 390
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.5655798316001892,
      "learning_rate": 8.507462686567164e-05,
      "loss": 1.1846,
      "step": 400
    },
    {
      "epoch": 0.128,
      "eval_loss": 1.1636639833450317,
      "eval_runtime": 2.3393,
      "eval_samples_per_second": 85.495,
      "eval_steps_per_second": 1.71,
      "step": 400
    },
    {
      "epoch": 0.1312,
      "grad_norm": 0.5229615569114685,
      "learning_rate": 8.720682302771856e-05,
      "loss": 1.1821,
      "step": 410
    },
    {
      "epoch": 0.1344,
      "grad_norm": 0.42894652485847473,
      "learning_rate": 8.933901918976547e-05,
      "loss": 1.1864,
      "step": 420
    },
    {
      "epoch": 0.1376,
      "grad_norm": 0.48203253746032715,
      "learning_rate": 9.147121535181237e-05,
      "loss": 1.0926,
      "step": 430
    },
    {
      "epoch": 0.1408,
      "grad_norm": 0.5778676271438599,
      "learning_rate": 9.360341151385929e-05,
      "loss": 1.0286,
      "step": 440
    },
    {
      "epoch": 0.144,
      "grad_norm": 0.4658922851085663,
      "learning_rate": 9.57356076759062e-05,
      "loss": 1.1281,
      "step": 450
    },
    {
      "epoch": 0.144,
      "eval_loss": 1.1613062620162964,
      "eval_runtime": 2.3375,
      "eval_samples_per_second": 85.561,
      "eval_steps_per_second": 1.711,
      "step": 450
    },
    {
      "epoch": 0.1472,
      "grad_norm": 0.41557008028030396,
      "learning_rate": 9.78678038379531e-05,
      "loss": 1.1442,
      "step": 460
    },
    {
      "epoch": 0.1504,
      "grad_norm": 0.4765915870666504,
      "learning_rate": 0.0001,
      "loss": 1.1542,
      "step": 470
    },
    {
      "epoch": 0.1536,
      "grad_norm": 0.5220112204551697,
      "learning_rate": 0.00010213219616204692,
      "loss": 1.1181,
      "step": 480
    },
    {
      "epoch": 0.1568,
      "grad_norm": 0.49832719564437866,
      "learning_rate": 0.00010426439232409382,
      "loss": 1.08,
      "step": 490
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4643652141094208,
      "learning_rate": 0.00010639658848614073,
      "loss": 1.1658,
      "step": 500
    },
    {
      "epoch": 0.16,
      "eval_loss": 1.148858904838562,
      "eval_runtime": 2.34,
      "eval_samples_per_second": 85.469,
      "eval_steps_per_second": 1.709,
      "step": 500
    },
    {
      "epoch": 0.1632,
      "grad_norm": 0.4659041464328766,
      "learning_rate": 0.00010852878464818763,
      "loss": 1.1104,
      "step": 510
    },
    {
      "epoch": 0.1664,
      "grad_norm": 0.3923422396183014,
      "learning_rate": 0.00011066098081023454,
      "loss": 1.0871,
      "step": 520
    },
    {
      "epoch": 0.1696,
      "grad_norm": 0.47849971055984497,
      "learning_rate": 0.00011279317697228145,
      "loss": 1.0665,
      "step": 530
    },
    {
      "epoch": 0.1728,
      "grad_norm": 0.476181298494339,
      "learning_rate": 0.00011492537313432837,
      "loss": 1.1166,
      "step": 540
    },
    {
      "epoch": 0.176,
      "grad_norm": 0.39915090799331665,
      "learning_rate": 0.00011705756929637527,
      "loss": 1.1453,
      "step": 550
    },
    {
      "epoch": 0.176,
      "eval_loss": 1.147416591644287,
      "eval_runtime": 2.338,
      "eval_samples_per_second": 85.543,
      "eval_steps_per_second": 1.711,
      "step": 550
    },
    {
      "epoch": 0.1792,
      "grad_norm": 0.3968147933483124,
      "learning_rate": 0.00011918976545842218,
      "loss": 1.0797,
      "step": 560
    },
    {
      "epoch": 0.1824,
      "grad_norm": 0.4505676329135895,
      "learning_rate": 0.0001213219616204691,
      "loss": 1.0633,
      "step": 570
    },
    {
      "epoch": 0.1856,
      "grad_norm": 0.5884152054786682,
      "learning_rate": 0.00012345415778251598,
      "loss": 1.0842,
      "step": 580
    },
    {
      "epoch": 0.1888,
      "grad_norm": 0.48683178424835205,
      "learning_rate": 0.0001255863539445629,
      "loss": 1.0314,
      "step": 590
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.5812621712684631,
      "learning_rate": 0.00012771855010660981,
      "loss": 1.1266,
      "step": 600
    },
    {
      "epoch": 0.192,
      "eval_loss": 1.141809105873108,
      "eval_runtime": 2.34,
      "eval_samples_per_second": 85.471,
      "eval_steps_per_second": 1.709,
      "step": 600
    },
    {
      "epoch": 0.1952,
      "grad_norm": 0.4714082181453705,
      "learning_rate": 0.00012985074626865672,
      "loss": 1.0881,
      "step": 610
    },
    {
      "epoch": 0.1984,
      "grad_norm": 0.5757817029953003,
      "learning_rate": 0.00013198294243070365,
      "loss": 1.1195,
      "step": 620
    },
    {
      "epoch": 0.2016,
      "grad_norm": 0.49408289790153503,
      "learning_rate": 0.00013411513859275053,
      "loss": 1.084,
      "step": 630
    },
    {
      "epoch": 0.2048,
      "grad_norm": 0.41487327218055725,
      "learning_rate": 0.00013624733475479746,
      "loss": 1.0841,
      "step": 640
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.4166930317878723,
      "learning_rate": 0.00013837953091684434,
      "loss": 1.1086,
      "step": 650
    },
    {
      "epoch": 0.208,
      "eval_loss": 1.1407999992370605,
      "eval_runtime": 2.3376,
      "eval_samples_per_second": 85.556,
      "eval_steps_per_second": 1.711,
      "step": 650
    },
    {
      "epoch": 0.2112,
      "grad_norm": 0.42784202098846436,
      "learning_rate": 0.00014051172707889127,
      "loss": 1.1117,
      "step": 660
    },
    {
      "epoch": 0.2144,
      "grad_norm": 0.37095212936401367,
      "learning_rate": 0.00014264392324093818,
      "loss": 1.0671,
      "step": 670
    },
    {
      "epoch": 0.2176,
      "grad_norm": 0.401797354221344,
      "learning_rate": 0.00014477611940298508,
      "loss": 1.0944,
      "step": 680
    },
    {
      "epoch": 0.2208,
      "grad_norm": 0.39006271958351135,
      "learning_rate": 0.000146908315565032,
      "loss": 1.1542,
      "step": 690
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.3564833700656891,
      "learning_rate": 0.0001490405117270789,
      "loss": 1.0701,
      "step": 700
    },
    {
      "epoch": 0.224,
      "eval_loss": 1.1341663599014282,
      "eval_runtime": 2.3406,
      "eval_samples_per_second": 85.449,
      "eval_steps_per_second": 1.709,
      "step": 700
    },
    {
      "epoch": 0.2272,
      "grad_norm": 0.3794569671154022,
      "learning_rate": 0.0001511727078891258,
      "loss": 1.0286,
      "step": 710
    },
    {
      "epoch": 0.2304,
      "grad_norm": 0.44763803482055664,
      "learning_rate": 0.0001533049040511727,
      "loss": 1.0546,
      "step": 720
    },
    {
      "epoch": 0.2336,
      "grad_norm": 0.3856862783432007,
      "learning_rate": 0.0001554371002132196,
      "loss": 1.0905,
      "step": 730
    },
    {
      "epoch": 0.2368,
      "grad_norm": 0.37703442573547363,
      "learning_rate": 0.00015756929637526654,
      "loss": 1.1009,
      "step": 740
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.3488914668560028,
      "learning_rate": 0.00015970149253731345,
      "loss": 1.0256,
      "step": 750
    },
    {
      "epoch": 0.24,
      "eval_loss": 1.1287742853164673,
      "eval_runtime": 2.3411,
      "eval_samples_per_second": 85.431,
      "eval_steps_per_second": 1.709,
      "step": 750
    },
    {
      "epoch": 0.2432,
      "grad_norm": 0.3748317360877991,
      "learning_rate": 0.00016183368869936035,
      "loss": 1.0607,
      "step": 760
    },
    {
      "epoch": 0.2464,
      "grad_norm": 0.34306883811950684,
      "learning_rate": 0.00016396588486140726,
      "loss": 0.942,
      "step": 770
    },
    {
      "epoch": 0.2496,
      "grad_norm": 0.41213560104370117,
      "learning_rate": 0.00016609808102345416,
      "loss": 1.1705,
      "step": 780
    },
    {
      "epoch": 0.2528,
      "grad_norm": 0.38441184163093567,
      "learning_rate": 0.0001682302771855011,
      "loss": 1.0627,
      "step": 790
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.417404443025589,
      "learning_rate": 0.00017036247334754797,
      "loss": 1.109,
      "step": 800
    },
    {
      "epoch": 0.256,
      "eval_loss": 1.1313884258270264,
      "eval_runtime": 2.3405,
      "eval_samples_per_second": 85.453,
      "eval_steps_per_second": 1.709,
      "step": 800
    },
    {
      "epoch": 0.2592,
      "grad_norm": 0.4139849543571472,
      "learning_rate": 0.0001724946695095949,
      "loss": 1.0921,
      "step": 810
    },
    {
      "epoch": 0.2624,
      "grad_norm": 0.4481484889984131,
      "learning_rate": 0.00017462686567164178,
      "loss": 1.0748,
      "step": 820
    },
    {
      "epoch": 0.2656,
      "grad_norm": 0.39680784940719604,
      "learning_rate": 0.00017675906183368872,
      "loss": 1.0575,
      "step": 830
    },
    {
      "epoch": 0.2688,
      "grad_norm": 0.4139363467693329,
      "learning_rate": 0.0001788912579957356,
      "loss": 1.0796,
      "step": 840
    },
    {
      "epoch": 0.272,
      "grad_norm": 0.3725064694881439,
      "learning_rate": 0.00018102345415778253,
      "loss": 0.9813,
      "step": 850
    },
    {
      "epoch": 0.272,
      "eval_loss": 1.1244359016418457,
      "eval_runtime": 2.3403,
      "eval_samples_per_second": 85.459,
      "eval_steps_per_second": 1.709,
      "step": 850
    },
    {
      "epoch": 0.2752,
      "grad_norm": 0.31681132316589355,
      "learning_rate": 0.00018315565031982943,
      "loss": 1.0285,
      "step": 860
    },
    {
      "epoch": 0.2784,
      "grad_norm": 0.3602568209171295,
      "learning_rate": 0.00018528784648187634,
      "loss": 1.0937,
      "step": 870
    },
    {
      "epoch": 0.2816,
      "grad_norm": 0.373654305934906,
      "learning_rate": 0.00018742004264392324,
      "loss": 0.9816,
      "step": 880
    },
    {
      "epoch": 0.2848,
      "grad_norm": 0.4258483648300171,
      "learning_rate": 0.00018955223880597015,
      "loss": 1.1278,
      "step": 890
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.35293981432914734,
      "learning_rate": 0.00019168443496801708,
      "loss": 1.0539,
      "step": 900
    },
    {
      "epoch": 0.288,
      "eval_loss": 1.1241949796676636,
      "eval_runtime": 2.3391,
      "eval_samples_per_second": 85.505,
      "eval_steps_per_second": 1.71,
      "step": 900
    },
    {
      "epoch": 0.2912,
      "grad_norm": 0.498153418302536,
      "learning_rate": 0.00019381663113006398,
      "loss": 1.1587,
      "step": 910
    },
    {
      "epoch": 0.2944,
      "grad_norm": 0.35440853238105774,
      "learning_rate": 0.0001959488272921109,
      "loss": 1.1038,
      "step": 920
    },
    {
      "epoch": 0.2976,
      "grad_norm": 0.369735985994339,
      "learning_rate": 0.0001980810234541578,
      "loss": 1.0467,
      "step": 930
    },
    {
      "epoch": 0.3008,
      "grad_norm": 0.3457324206829071,
      "learning_rate": 0.00019997629489154915,
      "loss": 0.9976,
      "step": 940
    },
    {
      "epoch": 0.304,
      "grad_norm": 0.41923558712005615,
      "learning_rate": 0.00019973924380704044,
      "loss": 1.0299,
      "step": 950
    },
    {
      "epoch": 0.304,
      "eval_loss": 1.1269376277923584,
      "eval_runtime": 2.3399,
      "eval_samples_per_second": 85.475,
      "eval_steps_per_second": 1.709,
      "step": 950
    },
    {
      "epoch": 0.3072,
      "grad_norm": 0.31867292523384094,
      "learning_rate": 0.00019950219272253173,
      "loss": 0.9795,
      "step": 960
    },
    {
      "epoch": 0.3104,
      "grad_norm": 0.29760438203811646,
      "learning_rate": 0.00019926514163802302,
      "loss": 1.0873,
      "step": 970
    },
    {
      "epoch": 0.3136,
      "grad_norm": 0.3280469477176666,
      "learning_rate": 0.0001990280905535143,
      "loss": 1.0891,
      "step": 980
    },
    {
      "epoch": 0.3168,
      "grad_norm": 0.385209858417511,
      "learning_rate": 0.0001987910394690056,
      "loss": 1.0699,
      "step": 990
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3557678759098053,
      "learning_rate": 0.00019855398838449685,
      "loss": 1.1089,
      "step": 1000
    },
    {
      "epoch": 0.32,
      "eval_loss": 1.124455213546753,
      "eval_runtime": 2.3408,
      "eval_samples_per_second": 85.44,
      "eval_steps_per_second": 1.709,
      "step": 1000
    },
    {
      "epoch": 0.3232,
      "grad_norm": 0.3203548491001129,
      "learning_rate": 0.00019831693729998814,
      "loss": 1.031,
      "step": 1010
    },
    {
      "epoch": 0.3264,
      "grad_norm": 0.3489174544811249,
      "learning_rate": 0.00019807988621547943,
      "loss": 1.0893,
      "step": 1020
    },
    {
      "epoch": 0.3296,
      "grad_norm": 0.36694809794425964,
      "learning_rate": 0.00019784283513097072,
      "loss": 1.0917,
      "step": 1030
    },
    {
      "epoch": 0.3328,
      "grad_norm": 0.3142153024673462,
      "learning_rate": 0.000197605784046462,
      "loss": 0.9841,
      "step": 1040
    },
    {
      "epoch": 0.336,
      "grad_norm": 0.3139495849609375,
      "learning_rate": 0.0001973687329619533,
      "loss": 1.0384,
      "step": 1050
    },
    {
      "epoch": 0.336,
      "eval_loss": 1.123436450958252,
      "eval_runtime": 2.3396,
      "eval_samples_per_second": 85.484,
      "eval_steps_per_second": 1.71,
      "step": 1050
    },
    {
      "epoch": 0.3392,
      "grad_norm": 0.29377272725105286,
      "learning_rate": 0.00019713168187744458,
      "loss": 1.0178,
      "step": 1060
    },
    {
      "epoch": 0.3424,
      "grad_norm": 0.32394516468048096,
      "learning_rate": 0.00019689463079293587,
      "loss": 1.088,
      "step": 1070
    },
    {
      "epoch": 0.3456,
      "grad_norm": 0.37995678186416626,
      "learning_rate": 0.0001966575797084272,
      "loss": 1.0379,
      "step": 1080
    },
    {
      "epoch": 0.3488,
      "grad_norm": 0.3709198832511902,
      "learning_rate": 0.00019642052862391848,
      "loss": 0.9924,
      "step": 1090
    },
    {
      "epoch": 0.352,
      "grad_norm": 0.3037886917591095,
      "learning_rate": 0.00019618347753940976,
      "loss": 1.0324,
      "step": 1100
    },
    {
      "epoch": 0.352,
      "eval_loss": 1.1191326379776,
      "eval_runtime": 2.3408,
      "eval_samples_per_second": 85.442,
      "eval_steps_per_second": 1.709,
      "step": 1100
    },
    {
      "epoch": 0.3552,
      "grad_norm": 0.32164710760116577,
      "learning_rate": 0.00019594642645490105,
      "loss": 1.0553,
      "step": 1110
    },
    {
      "epoch": 0.3584,
      "grad_norm": 0.31437185406684875,
      "learning_rate": 0.00019570937537039234,
      "loss": 1.0215,
      "step": 1120
    },
    {
      "epoch": 0.3616,
      "grad_norm": 0.38973358273506165,
      "learning_rate": 0.00019547232428588363,
      "loss": 1.0422,
      "step": 1130
    },
    {
      "epoch": 0.3648,
      "grad_norm": 0.2963048219680786,
      "learning_rate": 0.00019523527320137492,
      "loss": 0.9676,
      "step": 1140
    },
    {
      "epoch": 0.368,
      "grad_norm": 0.3294295072555542,
      "learning_rate": 0.0001949982221168662,
      "loss": 1.071,
      "step": 1150
    },
    {
      "epoch": 0.368,
      "eval_loss": 1.1136982440948486,
      "eval_runtime": 2.3441,
      "eval_samples_per_second": 85.321,
      "eval_steps_per_second": 1.706,
      "step": 1150
    },
    {
      "epoch": 0.3712,
      "grad_norm": 0.40461447834968567,
      "learning_rate": 0.0001947611710323575,
      "loss": 1.068,
      "step": 1160
    },
    {
      "epoch": 0.3744,
      "grad_norm": 0.3091374337673187,
      "learning_rate": 0.00019452411994784876,
      "loss": 1.035,
      "step": 1170
    },
    {
      "epoch": 0.3776,
      "grad_norm": 0.32680225372314453,
      "learning_rate": 0.00019428706886334004,
      "loss": 1.0071,
      "step": 1180
    },
    {
      "epoch": 0.3808,
      "grad_norm": 0.33049261569976807,
      "learning_rate": 0.00019405001777883133,
      "loss": 1.0391,
      "step": 1190
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.35889989137649536,
      "learning_rate": 0.00019381296669432262,
      "loss": 1.1254,
      "step": 1200
    },
    {
      "epoch": 0.384,
      "eval_loss": 1.1103092432022095,
      "eval_runtime": 2.3441,
      "eval_samples_per_second": 85.32,
      "eval_steps_per_second": 1.706,
      "step": 1200
    },
    {
      "epoch": 0.3872,
      "grad_norm": 0.27639293670654297,
      "learning_rate": 0.0001935759156098139,
      "loss": 0.9893,
      "step": 1210
    },
    {
      "epoch": 0.3904,
      "grad_norm": 0.3131595253944397,
      "learning_rate": 0.0001933388645253052,
      "loss": 1.0837,
      "step": 1220
    },
    {
      "epoch": 0.3936,
      "grad_norm": 0.2845284640789032,
      "learning_rate": 0.00019310181344079649,
      "loss": 1.0349,
      "step": 1230
    },
    {
      "epoch": 0.3968,
      "grad_norm": 0.32541075348854065,
      "learning_rate": 0.0001928647623562878,
      "loss": 1.0575,
      "step": 1240
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.29553836584091187,
      "learning_rate": 0.0001926277112717791,
      "loss": 1.0532,
      "step": 1250
    },
    {
      "epoch": 0.4,
      "eval_loss": 1.1146457195281982,
      "eval_runtime": 2.342,
      "eval_samples_per_second": 85.395,
      "eval_steps_per_second": 1.708,
      "step": 1250
    },
    {
      "epoch": 0.4032,
      "grad_norm": 0.3482978940010071,
      "learning_rate": 0.00019239066018727038,
      "loss": 1.1189,
      "step": 1260
    },
    {
      "epoch": 0.4064,
      "grad_norm": 0.33173346519470215,
      "learning_rate": 0.00019215360910276167,
      "loss": 1.042,
      "step": 1270
    },
    {
      "epoch": 0.4096,
      "grad_norm": 0.3638879060745239,
      "learning_rate": 0.00019191655801825295,
      "loss": 1.0096,
      "step": 1280
    },
    {
      "epoch": 0.4128,
      "grad_norm": 0.3318054676055908,
      "learning_rate": 0.00019167950693374424,
      "loss": 1.1681,
      "step": 1290
    },
    {
      "epoch": 0.416,
      "grad_norm": 0.3385430872440338,
      "learning_rate": 0.00019144245584923553,
      "loss": 1.0145,
      "step": 1300
    },
    {
      "epoch": 0.416,
      "eval_loss": 1.1179285049438477,
      "eval_runtime": 2.3438,
      "eval_samples_per_second": 85.332,
      "eval_steps_per_second": 1.707,
      "step": 1300
    },
    {
      "epoch": 0.4192,
      "grad_norm": 0.3335341215133667,
      "learning_rate": 0.00019120540476472682,
      "loss": 1.1264,
      "step": 1310
    },
    {
      "epoch": 0.4224,
      "grad_norm": 0.3230504095554352,
      "learning_rate": 0.0001909683536802181,
      "loss": 1.1019,
      "step": 1320
    },
    {
      "epoch": 0.4256,
      "grad_norm": 0.2974932789802551,
      "learning_rate": 0.0001907313025957094,
      "loss": 1.1184,
      "step": 1330
    },
    {
      "epoch": 0.4288,
      "grad_norm": 0.31565073132514954,
      "learning_rate": 0.00019049425151120068,
      "loss": 1.0037,
      "step": 1340
    },
    {
      "epoch": 0.432,
      "grad_norm": 0.3127445876598358,
      "learning_rate": 0.00019025720042669194,
      "loss": 1.0334,
      "step": 1350
    },
    {
      "epoch": 0.432,
      "eval_loss": 1.1115851402282715,
      "eval_runtime": 2.3424,
      "eval_samples_per_second": 85.382,
      "eval_steps_per_second": 1.708,
      "step": 1350
    },
    {
      "epoch": 0.4352,
      "grad_norm": 0.30397894978523254,
      "learning_rate": 0.00019002014934218323,
      "loss": 1.0014,
      "step": 1360
    },
    {
      "epoch": 0.4384,
      "grad_norm": 0.3109806776046753,
      "learning_rate": 0.00018978309825767452,
      "loss": 0.9842,
      "step": 1370
    },
    {
      "epoch": 0.4416,
      "grad_norm": 0.31346604228019714,
      "learning_rate": 0.0001895460471731658,
      "loss": 1.0514,
      "step": 1380
    },
    {
      "epoch": 0.4448,
      "grad_norm": 0.3307856619358063,
      "learning_rate": 0.0001893089960886571,
      "loss": 1.0452,
      "step": 1390
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.2918831706047058,
      "learning_rate": 0.00018907194500414839,
      "loss": 1.0541,
      "step": 1400
    },
    {
      "epoch": 0.448,
      "eval_loss": 1.1159802675247192,
      "eval_runtime": 2.3444,
      "eval_samples_per_second": 85.31,
      "eval_steps_per_second": 1.706,
      "step": 1400
    },
    {
      "epoch": 0.4512,
      "grad_norm": 0.30100253224372864,
      "learning_rate": 0.0001888348939196397,
      "loss": 1.0364,
      "step": 1410
    },
    {
      "epoch": 0.4544,
      "grad_norm": 0.3335064649581909,
      "learning_rate": 0.000188597842835131,
      "loss": 1.062,
      "step": 1420
    },
    {
      "epoch": 0.4576,
      "grad_norm": 0.28637805581092834,
      "learning_rate": 0.00018836079175062228,
      "loss": 0.9725,
      "step": 1430
    },
    {
      "epoch": 0.4608,
      "grad_norm": 0.34320196509361267,
      "learning_rate": 0.00018812374066611357,
      "loss": 1.0508,
      "step": 1440
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.34171462059020996,
      "learning_rate": 0.00018788668958160485,
      "loss": 1.0429,
      "step": 1450
    },
    {
      "epoch": 0.464,
      "eval_loss": 1.112156867980957,
      "eval_runtime": 2.3436,
      "eval_samples_per_second": 85.339,
      "eval_steps_per_second": 1.707,
      "step": 1450
    },
    {
      "epoch": 0.4672,
      "grad_norm": 0.3214649558067322,
      "learning_rate": 0.00018764963849709614,
      "loss": 1.0571,
      "step": 1460
    },
    {
      "epoch": 0.4704,
      "grad_norm": 0.31026390194892883,
      "learning_rate": 0.00018741258741258743,
      "loss": 1.1278,
      "step": 1470
    },
    {
      "epoch": 0.4736,
      "grad_norm": 0.304178386926651,
      "learning_rate": 0.00018717553632807872,
      "loss": 1.024,
      "step": 1480
    },
    {
      "epoch": 0.4768,
      "grad_norm": 0.269637793302536,
      "learning_rate": 0.00018693848524357,
      "loss": 0.9838,
      "step": 1490
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3546998202800751,
      "learning_rate": 0.0001867014341590613,
      "loss": 1.1127,
      "step": 1500
    },
    {
      "epoch": 0.48,
      "eval_loss": 1.1099724769592285,
      "eval_runtime": 2.3426,
      "eval_samples_per_second": 85.375,
      "eval_steps_per_second": 1.708,
      "step": 1500
    },
    {
      "epoch": 0.4832,
      "grad_norm": 0.345430463552475,
      "learning_rate": 0.00018646438307455258,
      "loss": 1.0261,
      "step": 1510
    },
    {
      "epoch": 0.4864,
      "grad_norm": 0.3130015432834625,
      "learning_rate": 0.00018622733199004387,
      "loss": 1.0387,
      "step": 1520
    },
    {
      "epoch": 0.4896,
      "grad_norm": 0.2975163161754608,
      "learning_rate": 0.00018599028090553513,
      "loss": 1.0306,
      "step": 1530
    },
    {
      "epoch": 0.4928,
      "grad_norm": 0.2613213360309601,
      "learning_rate": 0.00018575322982102642,
      "loss": 0.9713,
      "step": 1540
    },
    {
      "epoch": 0.496,
      "grad_norm": 0.3213407099246979,
      "learning_rate": 0.0001855161787365177,
      "loss": 1.0568,
      "step": 1550
    },
    {
      "epoch": 0.496,
      "eval_loss": 1.1130414009094238,
      "eval_runtime": 2.3435,
      "eval_samples_per_second": 85.343,
      "eval_steps_per_second": 1.707,
      "step": 1550
    },
    {
      "epoch": 0.4992,
      "grad_norm": 0.3053322732448578,
      "learning_rate": 0.000185279127652009,
      "loss": 1.1262,
      "step": 1560
    },
    {
      "epoch": 0.5024,
      "grad_norm": 0.33825913071632385,
      "learning_rate": 0.0001850420765675003,
      "loss": 1.0521,
      "step": 1570
    },
    {
      "epoch": 0.5056,
      "grad_norm": 0.30941006541252136,
      "learning_rate": 0.0001848050254829916,
      "loss": 1.0837,
      "step": 1580
    },
    {
      "epoch": 0.5088,
      "grad_norm": 0.3287462890148163,
      "learning_rate": 0.0001845679743984829,
      "loss": 1.0619,
      "step": 1590
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.32540038228034973,
      "learning_rate": 0.00018433092331397418,
      "loss": 0.9892,
      "step": 1600
    },
    {
      "epoch": 0.512,
      "eval_loss": 1.1046782732009888,
      "eval_runtime": 2.3437,
      "eval_samples_per_second": 85.335,
      "eval_steps_per_second": 1.707,
      "step": 1600
    },
    {
      "epoch": 0.5152,
      "grad_norm": 0.31781795620918274,
      "learning_rate": 0.00018409387222946547,
      "loss": 1.0242,
      "step": 1610
    },
    {
      "epoch": 0.5184,
      "grad_norm": 0.2858683168888092,
      "learning_rate": 0.00018385682114495676,
      "loss": 1.0793,
      "step": 1620
    },
    {
      "epoch": 0.5216,
      "grad_norm": 0.30847594141960144,
      "learning_rate": 0.00018361977006044804,
      "loss": 1.0723,
      "step": 1630
    },
    {
      "epoch": 0.5248,
      "grad_norm": 0.3067674934864044,
      "learning_rate": 0.00018338271897593933,
      "loss": 1.0381,
      "step": 1640
    },
    {
      "epoch": 0.528,
      "grad_norm": 0.30376043915748596,
      "learning_rate": 0.00018314566789143062,
      "loss": 0.9581,
      "step": 1650
    },
    {
      "epoch": 0.528,
      "eval_loss": 1.108433485031128,
      "eval_runtime": 2.344,
      "eval_samples_per_second": 85.326,
      "eval_steps_per_second": 1.707,
      "step": 1650
    },
    {
      "epoch": 0.5312,
      "grad_norm": 0.2982756793498993,
      "learning_rate": 0.0001829086168069219,
      "loss": 1.0757,
      "step": 1660
    },
    {
      "epoch": 0.5344,
      "grad_norm": 0.294243723154068,
      "learning_rate": 0.0001826715657224132,
      "loss": 1.0433,
      "step": 1670
    },
    {
      "epoch": 0.5376,
      "grad_norm": 0.35092172026634216,
      "learning_rate": 0.00018243451463790448,
      "loss": 1.0188,
      "step": 1680
    },
    {
      "epoch": 0.5408,
      "grad_norm": 0.2990056276321411,
      "learning_rate": 0.00018219746355339577,
      "loss": 1.0556,
      "step": 1690
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.38906463980674744,
      "learning_rate": 0.00018196041246888706,
      "loss": 1.0282,
      "step": 1700
    },
    {
      "epoch": 0.544,
      "eval_loss": 1.110258936882019,
      "eval_runtime": 2.3452,
      "eval_samples_per_second": 85.281,
      "eval_steps_per_second": 1.706,
      "step": 1700
    },
    {
      "epoch": 0.5472,
      "grad_norm": 0.3976582884788513,
      "learning_rate": 0.00018172336138437832,
      "loss": 1.0544,
      "step": 1710
    },
    {
      "epoch": 0.5504,
      "grad_norm": 0.32325583696365356,
      "learning_rate": 0.0001814863102998696,
      "loss": 1.063,
      "step": 1720
    },
    {
      "epoch": 0.5536,
      "grad_norm": 0.26183563470840454,
      "learning_rate": 0.0001812492592153609,
      "loss": 0.9879,
      "step": 1730
    },
    {
      "epoch": 0.5568,
      "grad_norm": 0.340267539024353,
      "learning_rate": 0.00018101220813085221,
      "loss": 1.0517,
      "step": 1740
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.2856338322162628,
      "learning_rate": 0.0001807751570463435,
      "loss": 0.9978,
      "step": 1750
    },
    {
      "epoch": 0.56,
      "eval_loss": 1.1069073677062988,
      "eval_runtime": 2.3439,
      "eval_samples_per_second": 85.329,
      "eval_steps_per_second": 1.707,
      "step": 1750
    },
    {
      "epoch": 0.5632,
      "grad_norm": 0.3177449107170105,
      "learning_rate": 0.0001805381059618348,
      "loss": 1.082,
      "step": 1760
    },
    {
      "epoch": 0.5664,
      "grad_norm": 0.28642433881759644,
      "learning_rate": 0.00018030105487732608,
      "loss": 1.0608,
      "step": 1770
    },
    {
      "epoch": 0.5696,
      "grad_norm": 0.42618077993392944,
      "learning_rate": 0.00018006400379281737,
      "loss": 1.0665,
      "step": 1780
    },
    {
      "epoch": 0.5728,
      "grad_norm": 0.3554815649986267,
      "learning_rate": 0.00017982695270830866,
      "loss": 0.9978,
      "step": 1790
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.3019552528858185,
      "learning_rate": 0.00017958990162379994,
      "loss": 1.0082,
      "step": 1800
    },
    {
      "epoch": 0.576,
      "eval_loss": 1.1028515100479126,
      "eval_runtime": 2.343,
      "eval_samples_per_second": 85.362,
      "eval_steps_per_second": 1.707,
      "step": 1800
    },
    {
      "epoch": 0.5792,
      "grad_norm": 0.2774515151977539,
      "learning_rate": 0.00017935285053929123,
      "loss": 1.0162,
      "step": 1810
    },
    {
      "epoch": 0.5824,
      "grad_norm": 0.305418998003006,
      "learning_rate": 0.00017911579945478252,
      "loss": 0.9831,
      "step": 1820
    },
    {
      "epoch": 0.5856,
      "grad_norm": 0.33986642956733704,
      "learning_rate": 0.0001788787483702738,
      "loss": 1.0039,
      "step": 1830
    },
    {
      "epoch": 0.5888,
      "grad_norm": 0.2942125201225281,
      "learning_rate": 0.0001786416972857651,
      "loss": 1.0711,
      "step": 1840
    },
    {
      "epoch": 0.592,
      "grad_norm": 0.3003416657447815,
      "learning_rate": 0.00017840464620125639,
      "loss": 1.0644,
      "step": 1850
    },
    {
      "epoch": 0.592,
      "eval_loss": 1.1034915447235107,
      "eval_runtime": 2.3424,
      "eval_samples_per_second": 85.384,
      "eval_steps_per_second": 1.708,
      "step": 1850
    },
    {
      "epoch": 0.5952,
      "grad_norm": 0.3183422088623047,
      "learning_rate": 0.00017816759511674767,
      "loss": 1.0195,
      "step": 1860
    },
    {
      "epoch": 0.5984,
      "grad_norm": 0.2867245078086853,
      "learning_rate": 0.00017793054403223896,
      "loss": 0.9887,
      "step": 1870
    },
    {
      "epoch": 0.6016,
      "grad_norm": 0.312039852142334,
      "learning_rate": 0.00017769349294773022,
      "loss": 1.1004,
      "step": 1880
    },
    {
      "epoch": 0.6048,
      "grad_norm": 0.3226386606693268,
      "learning_rate": 0.0001774564418632215,
      "loss": 1.0704,
      "step": 1890
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.2878372371196747,
      "learning_rate": 0.0001772193907787128,
      "loss": 1.0157,
      "step": 1900
    },
    {
      "epoch": 0.608,
      "eval_loss": 1.1008256673812866,
      "eval_runtime": 2.3437,
      "eval_samples_per_second": 85.334,
      "eval_steps_per_second": 1.707,
      "step": 1900
    },
    {
      "epoch": 0.6112,
      "grad_norm": 0.27973049879074097,
      "learning_rate": 0.00017698233969420412,
      "loss": 0.992,
      "step": 1910
    },
    {
      "epoch": 0.6144,
      "grad_norm": 0.32673487067222595,
      "learning_rate": 0.0001767452886096954,
      "loss": 1.0329,
      "step": 1920
    },
    {
      "epoch": 0.6176,
      "grad_norm": 0.2656446695327759,
      "learning_rate": 0.0001765082375251867,
      "loss": 0.9897,
      "step": 1930
    },
    {
      "epoch": 0.6208,
      "grad_norm": 0.3044833838939667,
      "learning_rate": 0.00017627118644067798,
      "loss": 1.0726,
      "step": 1940
    },
    {
      "epoch": 0.624,
      "grad_norm": 0.31305885314941406,
      "learning_rate": 0.00017603413535616927,
      "loss": 1.0504,
      "step": 1950
    },
    {
      "epoch": 0.624,
      "eval_loss": 1.1035542488098145,
      "eval_runtime": 2.3432,
      "eval_samples_per_second": 85.352,
      "eval_steps_per_second": 1.707,
      "step": 1950
    },
    {
      "epoch": 0.6272,
      "grad_norm": 0.30412545800209045,
      "learning_rate": 0.00017579708427166056,
      "loss": 1.1114,
      "step": 1960
    },
    {
      "epoch": 0.6304,
      "grad_norm": 0.3353184163570404,
      "learning_rate": 0.00017556003318715184,
      "loss": 0.9991,
      "step": 1970
    },
    {
      "epoch": 0.6336,
      "grad_norm": 0.239022895693779,
      "learning_rate": 0.00017532298210264313,
      "loss": 0.9762,
      "step": 1980
    },
    {
      "epoch": 0.6368,
      "grad_norm": 0.362257182598114,
      "learning_rate": 0.00017508593101813442,
      "loss": 1.0508,
      "step": 1990
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.37342092394828796,
      "learning_rate": 0.0001748488799336257,
      "loss": 1.0666,
      "step": 2000
    },
    {
      "epoch": 0.64,
      "eval_loss": 1.104735255241394,
      "eval_runtime": 2.3434,
      "eval_samples_per_second": 85.346,
      "eval_steps_per_second": 1.707,
      "step": 2000
    },
    {
      "epoch": 0.6432,
      "grad_norm": 0.3058416247367859,
      "learning_rate": 0.000174611828849117,
      "loss": 0.9984,
      "step": 2010
    },
    {
      "epoch": 0.6464,
      "grad_norm": 0.27544742822647095,
      "learning_rate": 0.00017437477776460829,
      "loss": 0.969,
      "step": 2020
    },
    {
      "epoch": 0.6496,
      "grad_norm": 0.2838221490383148,
      "learning_rate": 0.00017413772668009957,
      "loss": 1.0215,
      "step": 2030
    },
    {
      "epoch": 0.6528,
      "grad_norm": 0.32649484276771545,
      "learning_rate": 0.00017390067559559086,
      "loss": 1.0648,
      "step": 2040
    },
    {
      "epoch": 0.656,
      "grad_norm": 0.313267320394516,
      "learning_rate": 0.00017366362451108215,
      "loss": 1.1207,
      "step": 2050
    },
    {
      "epoch": 0.656,
      "eval_loss": 1.1037673950195312,
      "eval_runtime": 2.3455,
      "eval_samples_per_second": 85.268,
      "eval_steps_per_second": 1.705,
      "step": 2050
    },
    {
      "epoch": 0.6592,
      "grad_norm": 0.38967612385749817,
      "learning_rate": 0.0001734265734265734,
      "loss": 1.0695,
      "step": 2060
    },
    {
      "epoch": 0.6624,
      "grad_norm": 0.3378832936286926,
      "learning_rate": 0.0001731895223420647,
      "loss": 1.0037,
      "step": 2070
    },
    {
      "epoch": 0.6656,
      "grad_norm": 0.2492017298936844,
      "learning_rate": 0.00017295247125755602,
      "loss": 0.9814,
      "step": 2080
    },
    {
      "epoch": 0.6688,
      "grad_norm": 0.31709614396095276,
      "learning_rate": 0.0001727154201730473,
      "loss": 1.037,
      "step": 2090
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.3492889404296875,
      "learning_rate": 0.0001724783690885386,
      "loss": 1.026,
      "step": 2100
    },
    {
      "epoch": 0.672,
      "eval_loss": 1.1000781059265137,
      "eval_runtime": 2.3438,
      "eval_samples_per_second": 85.33,
      "eval_steps_per_second": 1.707,
      "step": 2100
    },
    {
      "epoch": 0.6752,
      "grad_norm": 0.3549972474575043,
      "learning_rate": 0.00017224131800402988,
      "loss": 1.0087,
      "step": 2110
    },
    {
      "epoch": 0.6784,
      "grad_norm": 0.3727273941040039,
      "learning_rate": 0.00017200426691952117,
      "loss": 1.0258,
      "step": 2120
    },
    {
      "epoch": 0.6816,
      "grad_norm": 0.28005489706993103,
      "learning_rate": 0.00017176721583501246,
      "loss": 0.9982,
      "step": 2130
    },
    {
      "epoch": 0.6848,
      "grad_norm": 0.32509830594062805,
      "learning_rate": 0.00017153016475050375,
      "loss": 1.0831,
      "step": 2140
    },
    {
      "epoch": 0.688,
      "grad_norm": 0.3556949496269226,
      "learning_rate": 0.00017129311366599503,
      "loss": 0.9582,
      "step": 2150
    },
    {
      "epoch": 0.688,
      "eval_loss": 1.1037036180496216,
      "eval_runtime": 2.3442,
      "eval_samples_per_second": 85.318,
      "eval_steps_per_second": 1.706,
      "step": 2150
    },
    {
      "epoch": 0.6912,
      "grad_norm": 0.2858780026435852,
      "learning_rate": 0.00017105606258148632,
      "loss": 1.0779,
      "step": 2160
    },
    {
      "epoch": 0.6944,
      "grad_norm": 0.27903318405151367,
      "learning_rate": 0.0001708190114969776,
      "loss": 0.9741,
      "step": 2170
    },
    {
      "epoch": 0.6976,
      "grad_norm": 0.3803861737251282,
      "learning_rate": 0.0001705819604124689,
      "loss": 1.0162,
      "step": 2180
    },
    {
      "epoch": 0.7008,
      "grad_norm": 0.31766781210899353,
      "learning_rate": 0.0001703449093279602,
      "loss": 1.0066,
      "step": 2190
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.29973652958869934,
      "learning_rate": 0.00017010785824345148,
      "loss": 1.0175,
      "step": 2200
    },
    {
      "epoch": 0.704,
      "eval_loss": 1.1042664051055908,
      "eval_runtime": 2.3437,
      "eval_samples_per_second": 85.335,
      "eval_steps_per_second": 1.707,
      "step": 2200
    },
    {
      "epoch": 0.7072,
      "grad_norm": 0.3053847551345825,
      "learning_rate": 0.00016987080715894276,
      "loss": 1.009,
      "step": 2210
    },
    {
      "epoch": 0.7104,
      "grad_norm": 0.3329838812351227,
      "learning_rate": 0.00016963375607443405,
      "loss": 1.0917,
      "step": 2220
    },
    {
      "epoch": 0.7136,
      "grad_norm": 0.333345890045166,
      "learning_rate": 0.00016939670498992534,
      "loss": 1.0526,
      "step": 2230
    },
    {
      "epoch": 0.7168,
      "grad_norm": 0.33137258887290955,
      "learning_rate": 0.00016915965390541663,
      "loss": 1.0523,
      "step": 2240
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.31364110112190247,
      "learning_rate": 0.00016892260282090792,
      "loss": 0.9882,
      "step": 2250
    },
    {
      "epoch": 0.72,
      "eval_loss": 1.0925942659378052,
      "eval_runtime": 2.3453,
      "eval_samples_per_second": 85.277,
      "eval_steps_per_second": 1.706,
      "step": 2250
    },
    {
      "epoch": 0.7232,
      "grad_norm": 0.3024023771286011,
      "learning_rate": 0.0001686855517363992,
      "loss": 1.0702,
      "step": 2260
    },
    {
      "epoch": 0.7264,
      "grad_norm": 0.31909945607185364,
      "learning_rate": 0.0001684485006518905,
      "loss": 1.0153,
      "step": 2270
    },
    {
      "epoch": 0.7296,
      "grad_norm": 0.3424145579338074,
      "learning_rate": 0.00016821144956738178,
      "loss": 1.069,
      "step": 2280
    },
    {
      "epoch": 0.7328,
      "grad_norm": 0.3031844198703766,
      "learning_rate": 0.00016797439848287307,
      "loss": 1.074,
      "step": 2290
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.2972222864627838,
      "learning_rate": 0.00016773734739836436,
      "loss": 1.0522,
      "step": 2300
    },
    {
      "epoch": 0.736,
      "eval_loss": 1.0917026996612549,
      "eval_runtime": 2.3435,
      "eval_samples_per_second": 85.344,
      "eval_steps_per_second": 1.707,
      "step": 2300
    },
    {
      "epoch": 0.7392,
      "grad_norm": 0.3645426332950592,
      "learning_rate": 0.00016750029631385565,
      "loss": 0.9884,
      "step": 2310
    },
    {
      "epoch": 0.7424,
      "grad_norm": 0.34186238050460815,
      "learning_rate": 0.00016726324522934693,
      "loss": 1.0549,
      "step": 2320
    },
    {
      "epoch": 0.7456,
      "grad_norm": 0.35841062664985657,
      "learning_rate": 0.00016702619414483822,
      "loss": 1.0518,
      "step": 2330
    },
    {
      "epoch": 0.7488,
      "grad_norm": 0.2952232360839844,
      "learning_rate": 0.0001667891430603295,
      "loss": 0.9834,
      "step": 2340
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.3193212151527405,
      "learning_rate": 0.0001665520919758208,
      "loss": 1.1471,
      "step": 2350
    },
    {
      "epoch": 0.752,
      "eval_loss": 1.093415379524231,
      "eval_runtime": 2.3439,
      "eval_samples_per_second": 85.328,
      "eval_steps_per_second": 1.707,
      "step": 2350
    },
    {
      "epoch": 0.7552,
      "grad_norm": 0.35006746649742126,
      "learning_rate": 0.0001663150408913121,
      "loss": 1.054,
      "step": 2360
    },
    {
      "epoch": 0.7584,
      "grad_norm": 0.32794928550720215,
      "learning_rate": 0.00016607798980680338,
      "loss": 1.0396,
      "step": 2370
    },
    {
      "epoch": 0.7616,
      "grad_norm": 0.3091373145580292,
      "learning_rate": 0.00016584093872229466,
      "loss": 1.1468,
      "step": 2380
    },
    {
      "epoch": 0.7648,
      "grad_norm": 0.2914148271083832,
      "learning_rate": 0.00016560388763778595,
      "loss": 0.9575,
      "step": 2390
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.3145657479763031,
      "learning_rate": 0.00016536683655327724,
      "loss": 1.0174,
      "step": 2400
    },
    {
      "epoch": 0.768,
      "eval_loss": 1.1027966737747192,
      "eval_runtime": 2.3435,
      "eval_samples_per_second": 85.342,
      "eval_steps_per_second": 1.707,
      "step": 2400
    },
    {
      "epoch": 0.7712,
      "grad_norm": 0.33365997672080994,
      "learning_rate": 0.00016512978546876853,
      "loss": 1.0839,
      "step": 2410
    },
    {
      "epoch": 0.7744,
      "grad_norm": 0.3712870180606842,
      "learning_rate": 0.00016489273438425982,
      "loss": 1.0197,
      "step": 2420
    },
    {
      "epoch": 0.7776,
      "grad_norm": 0.2925910949707031,
      "learning_rate": 0.0001646556832997511,
      "loss": 1.1312,
      "step": 2430
    },
    {
      "epoch": 0.7808,
      "grad_norm": 0.3126431703567505,
      "learning_rate": 0.0001644186322152424,
      "loss": 1.0351,
      "step": 2440
    },
    {
      "epoch": 0.784,
      "grad_norm": 0.37208735942840576,
      "learning_rate": 0.00016418158113073368,
      "loss": 1.0876,
      "step": 2450
    },
    {
      "epoch": 0.784,
      "eval_loss": 1.0918899774551392,
      "eval_runtime": 2.3424,
      "eval_samples_per_second": 85.381,
      "eval_steps_per_second": 1.708,
      "step": 2450
    },
    {
      "epoch": 0.7872,
      "grad_norm": 0.31524813175201416,
      "learning_rate": 0.00016394453004622497,
      "loss": 1.0319,
      "step": 2460
    },
    {
      "epoch": 0.7904,
      "grad_norm": 0.28988566994667053,
      "learning_rate": 0.00016370747896171626,
      "loss": 0.9842,
      "step": 2470
    },
    {
      "epoch": 0.7936,
      "grad_norm": 0.3283516764640808,
      "learning_rate": 0.00016347042787720755,
      "loss": 1.0355,
      "step": 2480
    },
    {
      "epoch": 0.7968,
      "grad_norm": 0.3308250904083252,
      "learning_rate": 0.00016323337679269884,
      "loss": 1.079,
      "step": 2490
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.2780984938144684,
      "learning_rate": 0.00016299632570819012,
      "loss": 0.9835,
      "step": 2500
    },
    {
      "epoch": 0.8,
      "eval_loss": 1.0908863544464111,
      "eval_runtime": 2.3446,
      "eval_samples_per_second": 85.304,
      "eval_steps_per_second": 1.706,
      "step": 2500
    },
    {
      "epoch": 0.8032,
      "grad_norm": 0.28530803322792053,
      "learning_rate": 0.0001627592746236814,
      "loss": 0.9898,
      "step": 2510
    },
    {
      "epoch": 0.8064,
      "grad_norm": 0.3194611072540283,
      "learning_rate": 0.0001625222235391727,
      "loss": 0.9868,
      "step": 2520
    },
    {
      "epoch": 0.8096,
      "grad_norm": 0.3004322946071625,
      "learning_rate": 0.000162285172454664,
      "loss": 1.0664,
      "step": 2530
    },
    {
      "epoch": 0.8128,
      "grad_norm": 0.2560170590877533,
      "learning_rate": 0.00016204812137015528,
      "loss": 0.9677,
      "step": 2540
    },
    {
      "epoch": 0.816,
      "grad_norm": 0.31944382190704346,
      "learning_rate": 0.00016181107028564657,
      "loss": 1.0343,
      "step": 2550
    },
    {
      "epoch": 0.816,
      "eval_loss": 1.0919560194015503,
      "eval_runtime": 2.3446,
      "eval_samples_per_second": 85.302,
      "eval_steps_per_second": 1.706,
      "step": 2550
    },
    {
      "epoch": 0.8192,
      "grad_norm": 0.3276301622390747,
      "learning_rate": 0.00016157401920113785,
      "loss": 1.0627,
      "step": 2560
    },
    {
      "epoch": 0.8224,
      "grad_norm": 0.2877168655395508,
      "learning_rate": 0.00016133696811662914,
      "loss": 1.014,
      "step": 2570
    },
    {
      "epoch": 0.8256,
      "grad_norm": 0.30812203884124756,
      "learning_rate": 0.00016109991703212043,
      "loss": 1.0156,
      "step": 2580
    },
    {
      "epoch": 0.8288,
      "grad_norm": 0.2887223958969116,
      "learning_rate": 0.00016086286594761172,
      "loss": 1.0504,
      "step": 2590
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.29519984126091003,
      "learning_rate": 0.000160625814863103,
      "loss": 1.0575,
      "step": 2600
    },
    {
      "epoch": 0.832,
      "eval_loss": 1.0922746658325195,
      "eval_runtime": 2.3426,
      "eval_samples_per_second": 85.374,
      "eval_steps_per_second": 1.707,
      "step": 2600
    },
    {
      "epoch": 0.8352,
      "grad_norm": 0.3415023982524872,
      "learning_rate": 0.0001603887637785943,
      "loss": 1.0606,
      "step": 2610
    },
    {
      "epoch": 0.8384,
      "grad_norm": 0.2628939747810364,
      "learning_rate": 0.00016015171269408558,
      "loss": 0.9876,
      "step": 2620
    },
    {
      "epoch": 0.8416,
      "grad_norm": 0.3374202847480774,
      "learning_rate": 0.00015991466160957687,
      "loss": 1.0542,
      "step": 2630
    },
    {
      "epoch": 0.8448,
      "grad_norm": 0.3216615617275238,
      "learning_rate": 0.00015967761052506816,
      "loss": 1.0377,
      "step": 2640
    },
    {
      "epoch": 0.848,
      "grad_norm": 0.3198525905609131,
      "learning_rate": 0.00015944055944055945,
      "loss": 1.0771,
      "step": 2650
    },
    {
      "epoch": 0.848,
      "eval_loss": 1.0895382165908813,
      "eval_runtime": 2.3445,
      "eval_samples_per_second": 85.306,
      "eval_steps_per_second": 1.706,
      "step": 2650
    },
    {
      "epoch": 0.8512,
      "grad_norm": 0.2900403141975403,
      "learning_rate": 0.00015920350835605074,
      "loss": 1.07,
      "step": 2660
    },
    {
      "epoch": 0.8544,
      "grad_norm": 0.3571614921092987,
      "learning_rate": 0.00015896645727154202,
      "loss": 1.0302,
      "step": 2670
    },
    {
      "epoch": 0.8576,
      "grad_norm": 0.37170472741127014,
      "learning_rate": 0.0001587294061870333,
      "loss": 0.9851,
      "step": 2680
    },
    {
      "epoch": 0.8608,
      "grad_norm": 0.27125799655914307,
      "learning_rate": 0.0001584923551025246,
      "loss": 1.0629,
      "step": 2690
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.30196547508239746,
      "learning_rate": 0.0001582553040180159,
      "loss": 1.0288,
      "step": 2700
    },
    {
      "epoch": 0.864,
      "eval_loss": 1.0941646099090576,
      "eval_runtime": 2.3445,
      "eval_samples_per_second": 85.306,
      "eval_steps_per_second": 1.706,
      "step": 2700
    },
    {
      "epoch": 0.8672,
      "grad_norm": 0.31894680857658386,
      "learning_rate": 0.00015801825293350718,
      "loss": 1.0864,
      "step": 2710
    },
    {
      "epoch": 0.8704,
      "grad_norm": 0.2872570753097534,
      "learning_rate": 0.00015778120184899847,
      "loss": 0.9685,
      "step": 2720
    },
    {
      "epoch": 0.8736,
      "grad_norm": 0.3711136281490326,
      "learning_rate": 0.00015754415076448975,
      "loss": 1.0513,
      "step": 2730
    },
    {
      "epoch": 0.8768,
      "grad_norm": 0.36960649490356445,
      "learning_rate": 0.00015730709967998104,
      "loss": 1.0326,
      "step": 2740
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.34970033168792725,
      "learning_rate": 0.00015707004859547233,
      "loss": 1.0815,
      "step": 2750
    },
    {
      "epoch": 0.88,
      "eval_loss": 1.089913249015808,
      "eval_runtime": 2.343,
      "eval_samples_per_second": 85.362,
      "eval_steps_per_second": 1.707,
      "step": 2750
    },
    {
      "epoch": 0.8832,
      "grad_norm": 0.2601395845413208,
      "learning_rate": 0.00015683299751096362,
      "loss": 1.0823,
      "step": 2760
    },
    {
      "epoch": 0.8864,
      "grad_norm": 0.3081558048725128,
      "learning_rate": 0.0001565959464264549,
      "loss": 0.978,
      "step": 2770
    },
    {
      "epoch": 0.8896,
      "grad_norm": 0.2960692048072815,
      "learning_rate": 0.0001563588953419462,
      "loss": 1.053,
      "step": 2780
    },
    {
      "epoch": 0.8928,
      "grad_norm": 0.3745322823524475,
      "learning_rate": 0.00015612184425743748,
      "loss": 1.0206,
      "step": 2790
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.29164648056030273,
      "learning_rate": 0.00015588479317292877,
      "loss": 1.0211,
      "step": 2800
    },
    {
      "epoch": 0.896,
      "eval_loss": 1.0907856225967407,
      "eval_runtime": 2.3433,
      "eval_samples_per_second": 85.351,
      "eval_steps_per_second": 1.707,
      "step": 2800
    },
    {
      "epoch": 0.8992,
      "grad_norm": 0.3500390350818634,
      "learning_rate": 0.00015564774208842006,
      "loss": 1.0702,
      "step": 2810
    },
    {
      "epoch": 0.9024,
      "grad_norm": 0.3039954602718353,
      "learning_rate": 0.00015541069100391135,
      "loss": 1.0904,
      "step": 2820
    },
    {
      "epoch": 0.9056,
      "grad_norm": 0.3090730607509613,
      "learning_rate": 0.00015517363991940264,
      "loss": 0.9743,
      "step": 2830
    },
    {
      "epoch": 0.9088,
      "grad_norm": 0.40450477600097656,
      "learning_rate": 0.00015493658883489393,
      "loss": 0.9375,
      "step": 2840
    },
    {
      "epoch": 0.912,
      "grad_norm": 0.3019392490386963,
      "learning_rate": 0.00015469953775038521,
      "loss": 0.9829,
      "step": 2850
    },
    {
      "epoch": 0.912,
      "eval_loss": 1.088897705078125,
      "eval_runtime": 2.3427,
      "eval_samples_per_second": 85.373,
      "eval_steps_per_second": 1.707,
      "step": 2850
    },
    {
      "epoch": 0.9152,
      "grad_norm": 0.33704686164855957,
      "learning_rate": 0.0001544624866658765,
      "loss": 0.9935,
      "step": 2860
    },
    {
      "epoch": 0.9184,
      "grad_norm": 0.29519128799438477,
      "learning_rate": 0.0001542254355813678,
      "loss": 0.9866,
      "step": 2870
    },
    {
      "epoch": 0.9216,
      "grad_norm": 0.24065737426280975,
      "learning_rate": 0.00015398838449685908,
      "loss": 0.9482,
      "step": 2880
    },
    {
      "epoch": 0.9248,
      "grad_norm": 0.34407466650009155,
      "learning_rate": 0.00015375133341235037,
      "loss": 1.0154,
      "step": 2890
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.3084923028945923,
      "learning_rate": 0.00015351428232784166,
      "loss": 1.0448,
      "step": 2900
    },
    {
      "epoch": 0.928,
      "eval_loss": 1.0839965343475342,
      "eval_runtime": 2.3439,
      "eval_samples_per_second": 85.329,
      "eval_steps_per_second": 1.707,
      "step": 2900
    },
    {
      "epoch": 0.9312,
      "grad_norm": 0.35105037689208984,
      "learning_rate": 0.00015327723124333294,
      "loss": 1.0113,
      "step": 2910
    },
    {
      "epoch": 0.9344,
      "grad_norm": 0.28465914726257324,
      "learning_rate": 0.00015304018015882423,
      "loss": 1.035,
      "step": 2920
    },
    {
      "epoch": 0.9376,
      "grad_norm": 0.2689414918422699,
      "learning_rate": 0.00015280312907431552,
      "loss": 0.9572,
      "step": 2930
    },
    {
      "epoch": 0.9408,
      "grad_norm": 0.299722820520401,
      "learning_rate": 0.0001525660779898068,
      "loss": 0.9696,
      "step": 2940
    },
    {
      "epoch": 0.944,
      "grad_norm": 0.25833427906036377,
      "learning_rate": 0.0001523290269052981,
      "loss": 1.0734,
      "step": 2950
    },
    {
      "epoch": 0.944,
      "eval_loss": 1.090000033378601,
      "eval_runtime": 2.3447,
      "eval_samples_per_second": 85.298,
      "eval_steps_per_second": 1.706,
      "step": 2950
    },
    {
      "epoch": 0.9472,
      "grad_norm": 0.2695189118385315,
      "learning_rate": 0.00015209197582078938,
      "loss": 1.0195,
      "step": 2960
    },
    {
      "epoch": 0.9504,
      "grad_norm": 0.26639094948768616,
      "learning_rate": 0.00015185492473628067,
      "loss": 0.9319,
      "step": 2970
    },
    {
      "epoch": 0.9536,
      "grad_norm": 0.3124673366546631,
      "learning_rate": 0.00015161787365177196,
      "loss": 1.0291,
      "step": 2980
    },
    {
      "epoch": 0.9568,
      "grad_norm": 0.3358478546142578,
      "learning_rate": 0.00015138082256726325,
      "loss": 0.9777,
      "step": 2990
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.2838078439235687,
      "learning_rate": 0.00015114377148275454,
      "loss": 1.0051,
      "step": 3000
    },
    {
      "epoch": 0.96,
      "eval_loss": 1.0855896472930908,
      "eval_runtime": 2.3443,
      "eval_samples_per_second": 85.314,
      "eval_steps_per_second": 1.706,
      "step": 3000
    },
    {
      "epoch": 0.9632,
      "grad_norm": 0.35537269711494446,
      "learning_rate": 0.00015090672039824583,
      "loss": 0.9607,
      "step": 3010
    },
    {
      "epoch": 0.9664,
      "grad_norm": 0.3043953776359558,
      "learning_rate": 0.00015066966931373711,
      "loss": 0.9657,
      "step": 3020
    },
    {
      "epoch": 0.9696,
      "grad_norm": 0.3127087652683258,
      "learning_rate": 0.0001504326182292284,
      "loss": 1.0435,
      "step": 3030
    },
    {
      "epoch": 0.9728,
      "grad_norm": 0.3715147376060486,
      "learning_rate": 0.0001501955671447197,
      "loss": 1.1027,
      "step": 3040
    },
    {
      "epoch": 0.976,
      "grad_norm": 0.330807089805603,
      "learning_rate": 0.00014995851606021098,
      "loss": 1.0374,
      "step": 3050
    },
    {
      "epoch": 0.976,
      "eval_loss": 1.0856330394744873,
      "eval_runtime": 2.3442,
      "eval_samples_per_second": 85.316,
      "eval_steps_per_second": 1.706,
      "step": 3050
    },
    {
      "epoch": 0.9792,
      "grad_norm": 0.33334505558013916,
      "learning_rate": 0.00014972146497570227,
      "loss": 1.0631,
      "step": 3060
    },
    {
      "epoch": 0.9824,
      "grad_norm": 0.31060123443603516,
      "learning_rate": 0.00014948441389119356,
      "loss": 0.9802,
      "step": 3070
    },
    {
      "epoch": 0.9856,
      "grad_norm": 0.29521429538726807,
      "learning_rate": 0.00014924736280668484,
      "loss": 0.9773,
      "step": 3080
    },
    {
      "epoch": 0.9888,
      "grad_norm": 0.25461095571517944,
      "learning_rate": 0.00014901031172217613,
      "loss": 0.9405,
      "step": 3090
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.27680638432502747,
      "learning_rate": 0.00014877326063766742,
      "loss": 1.0281,
      "step": 3100
    },
    {
      "epoch": 0.992,
      "eval_loss": 1.0878896713256836,
      "eval_runtime": 2.3441,
      "eval_samples_per_second": 85.32,
      "eval_steps_per_second": 1.706,
      "step": 3100
    },
    {
      "epoch": 0.9952,
      "grad_norm": 0.287458211183548,
      "learning_rate": 0.00014853620955315874,
      "loss": 1.0351,
      "step": 3110
    },
    {
      "epoch": 0.9984,
      "grad_norm": 0.30479738116264343,
      "learning_rate": 0.00014829915846865,
      "loss": 1.0823,
      "step": 3120
    },
    {
      "epoch": 1.0016,
      "grad_norm": 0.38314399123191833,
      "learning_rate": 0.00014806210738414129,
      "loss": 1.0612,
      "step": 3130
    },
    {
      "epoch": 1.0048,
      "grad_norm": 0.33641692996025085,
      "learning_rate": 0.00014782505629963257,
      "loss": 0.9708,
      "step": 3140
    },
    {
      "epoch": 1.008,
      "grad_norm": 0.3505186438560486,
      "learning_rate": 0.00014758800521512386,
      "loss": 1.043,
      "step": 3150
    },
    {
      "epoch": 1.008,
      "eval_loss": 1.0934083461761475,
      "eval_runtime": 2.3433,
      "eval_samples_per_second": 85.35,
      "eval_steps_per_second": 1.707,
      "step": 3150
    },
    {
      "epoch": 1.0112,
      "grad_norm": 0.3060447871685028,
      "learning_rate": 0.00014735095413061515,
      "loss": 0.9212,
      "step": 3160
    },
    {
      "epoch": 1.0144,
      "grad_norm": 0.2887829840183258,
      "learning_rate": 0.00014711390304610644,
      "loss": 0.9272,
      "step": 3170
    },
    {
      "epoch": 1.0176,
      "grad_norm": 0.3247167468070984,
      "learning_rate": 0.00014687685196159773,
      "loss": 1.0829,
      "step": 3180
    },
    {
      "epoch": 1.0208,
      "grad_norm": 0.3439936339855194,
      "learning_rate": 0.00014663980087708902,
      "loss": 1.0103,
      "step": 3190
    },
    {
      "epoch": 1.024,
      "grad_norm": 0.2974855601787567,
      "learning_rate": 0.0001464027497925803,
      "loss": 1.1011,
      "step": 3200
    },
    {
      "epoch": 1.024,
      "eval_loss": 1.0882928371429443,
      "eval_runtime": 2.3428,
      "eval_samples_per_second": 85.368,
      "eval_steps_per_second": 1.707,
      "step": 3200
    },
    {
      "epoch": 1.0272,
      "grad_norm": 0.35363033413887024,
      "learning_rate": 0.0001461656987080716,
      "loss": 1.0899,
      "step": 3210
    },
    {
      "epoch": 1.0304,
      "grad_norm": 0.29969650506973267,
      "learning_rate": 0.00014592864762356288,
      "loss": 1.0189,
      "step": 3220
    },
    {
      "epoch": 1.0336,
      "grad_norm": 0.313018262386322,
      "learning_rate": 0.00014569159653905417,
      "loss": 1.0667,
      "step": 3230
    },
    {
      "epoch": 1.0368,
      "grad_norm": 0.31495577096939087,
      "learning_rate": 0.00014545454545454546,
      "loss": 0.9288,
      "step": 3240
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.329807847738266,
      "learning_rate": 0.00014521749437003674,
      "loss": 1.0166,
      "step": 3250
    },
    {
      "epoch": 1.04,
      "eval_loss": 1.086982250213623,
      "eval_runtime": 2.3429,
      "eval_samples_per_second": 85.366,
      "eval_steps_per_second": 1.707,
      "step": 3250
    },
    {
      "epoch": 1.0432,
      "grad_norm": 0.3288309574127197,
      "learning_rate": 0.00014498044328552803,
      "loss": 0.9885,
      "step": 3260
    },
    {
      "epoch": 1.0464,
      "grad_norm": 0.3100098669528961,
      "learning_rate": 0.00014474339220101932,
      "loss": 0.9613,
      "step": 3270
    },
    {
      "epoch": 1.0496,
      "grad_norm": 0.2870435118675232,
      "learning_rate": 0.00014450634111651064,
      "loss": 0.9337,
      "step": 3280
    },
    {
      "epoch": 1.0528,
      "grad_norm": 0.31587404012680054,
      "learning_rate": 0.00014426929003200193,
      "loss": 1.0078,
      "step": 3290
    },
    {
      "epoch": 1.056,
      "grad_norm": 0.3335217237472534,
      "learning_rate": 0.00014403223894749319,
      "loss": 1.1132,
      "step": 3300
    },
    {
      "epoch": 1.056,
      "eval_loss": 1.0857092142105103,
      "eval_runtime": 2.3415,
      "eval_samples_per_second": 85.416,
      "eval_steps_per_second": 1.708,
      "step": 3300
    },
    {
      "epoch": 1.0592,
      "grad_norm": 0.3400859534740448,
      "learning_rate": 0.00014379518786298447,
      "loss": 1.0008,
      "step": 3310
    },
    {
      "epoch": 1.0624,
      "grad_norm": 0.33581316471099854,
      "learning_rate": 0.00014355813677847576,
      "loss": 0.97,
      "step": 3320
    },
    {
      "epoch": 1.0656,
      "grad_norm": 0.3015975058078766,
      "learning_rate": 0.00014332108569396705,
      "loss": 1.0595,
      "step": 3330
    },
    {
      "epoch": 1.0688,
      "grad_norm": 0.3459121286869049,
      "learning_rate": 0.00014308403460945834,
      "loss": 1.1242,
      "step": 3340
    },
    {
      "epoch": 1.072,
      "grad_norm": 0.3256866931915283,
      "learning_rate": 0.00014284698352494963,
      "loss": 1.0472,
      "step": 3350
    },
    {
      "epoch": 1.072,
      "eval_loss": 1.0831564664840698,
      "eval_runtime": 2.3462,
      "eval_samples_per_second": 85.246,
      "eval_steps_per_second": 1.705,
      "step": 3350
    },
    {
      "epoch": 1.0752,
      "grad_norm": 0.311859667301178,
      "learning_rate": 0.00014260993244044092,
      "loss": 0.9694,
      "step": 3360
    },
    {
      "epoch": 1.0784,
      "grad_norm": 0.3791596293449402,
      "learning_rate": 0.0001423728813559322,
      "loss": 0.9383,
      "step": 3370
    },
    {
      "epoch": 1.0816,
      "grad_norm": 0.2973175644874573,
      "learning_rate": 0.0001421358302714235,
      "loss": 0.9891,
      "step": 3380
    },
    {
      "epoch": 1.0848,
      "grad_norm": 0.33513522148132324,
      "learning_rate": 0.00014189877918691478,
      "loss": 1.0064,
      "step": 3390
    },
    {
      "epoch": 1.088,
      "grad_norm": 0.3505959212779999,
      "learning_rate": 0.00014166172810240607,
      "loss": 1.0146,
      "step": 3400
    },
    {
      "epoch": 1.088,
      "eval_loss": 1.081950068473816,
      "eval_runtime": 2.3432,
      "eval_samples_per_second": 85.355,
      "eval_steps_per_second": 1.707,
      "step": 3400
    },
    {
      "epoch": 1.0912,
      "grad_norm": 0.39185479283332825,
      "learning_rate": 0.00014142467701789736,
      "loss": 1.017,
      "step": 3410
    },
    {
      "epoch": 1.0944,
      "grad_norm": 0.3228633403778076,
      "learning_rate": 0.00014118762593338865,
      "loss": 1.0801,
      "step": 3420
    },
    {
      "epoch": 1.0976,
      "grad_norm": 0.3896462619304657,
      "learning_rate": 0.00014095057484887993,
      "loss": 1.0022,
      "step": 3430
    },
    {
      "epoch": 1.1008,
      "grad_norm": 0.3263871967792511,
      "learning_rate": 0.00014071352376437122,
      "loss": 1.0108,
      "step": 3440
    },
    {
      "epoch": 1.104,
      "grad_norm": 0.25298815965652466,
      "learning_rate": 0.00014047647267986254,
      "loss": 0.9805,
      "step": 3450
    },
    {
      "epoch": 1.104,
      "eval_loss": 1.0841988325119019,
      "eval_runtime": 2.3434,
      "eval_samples_per_second": 85.346,
      "eval_steps_per_second": 1.707,
      "step": 3450
    },
    {
      "epoch": 1.1072,
      "grad_norm": 0.3238350450992584,
      "learning_rate": 0.00014023942159535383,
      "loss": 1.0663,
      "step": 3460
    },
    {
      "epoch": 1.1104,
      "grad_norm": 0.32209908962249756,
      "learning_rate": 0.00014000237051084511,
      "loss": 1.0132,
      "step": 3470
    },
    {
      "epoch": 1.1136,
      "grad_norm": 0.3147783577442169,
      "learning_rate": 0.00013976531942633638,
      "loss": 0.9363,
      "step": 3480
    },
    {
      "epoch": 1.1168,
      "grad_norm": 0.30943116545677185,
      "learning_rate": 0.00013952826834182766,
      "loss": 0.904,
      "step": 3490
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.3261316418647766,
      "learning_rate": 0.00013929121725731895,
      "loss": 1.0211,
      "step": 3500
    },
    {
      "epoch": 1.12,
      "eval_loss": 1.0845621824264526,
      "eval_runtime": 2.3432,
      "eval_samples_per_second": 85.355,
      "eval_steps_per_second": 1.707,
      "step": 3500
    },
    {
      "epoch": 1.1232,
      "grad_norm": 0.31535378098487854,
      "learning_rate": 0.00013905416617281024,
      "loss": 1.0359,
      "step": 3510
    },
    {
      "epoch": 1.1264,
      "grad_norm": 0.36069101095199585,
      "learning_rate": 0.00013881711508830153,
      "loss": 1.0275,
      "step": 3520
    },
    {
      "epoch": 1.1296,
      "grad_norm": 0.29959625005722046,
      "learning_rate": 0.00013858006400379282,
      "loss": 0.9921,
      "step": 3530
    },
    {
      "epoch": 1.1328,
      "grad_norm": 0.3083610534667969,
      "learning_rate": 0.0001383430129192841,
      "loss": 1.0157,
      "step": 3540
    },
    {
      "epoch": 1.1360000000000001,
      "grad_norm": 0.2883806526660919,
      "learning_rate": 0.0001381059618347754,
      "loss": 1.029,
      "step": 3550
    },
    {
      "epoch": 1.1360000000000001,
      "eval_loss": 1.0833773612976074,
      "eval_runtime": 2.3431,
      "eval_samples_per_second": 85.359,
      "eval_steps_per_second": 1.707,
      "step": 3550
    },
    {
      "epoch": 1.1392,
      "grad_norm": 0.29317936301231384,
      "learning_rate": 0.00013786891075026668,
      "loss": 0.9775,
      "step": 3560
    },
    {
      "epoch": 1.1424,
      "grad_norm": 0.31559309363365173,
      "learning_rate": 0.00013763185966575797,
      "loss": 0.9763,
      "step": 3570
    },
    {
      "epoch": 1.1456,
      "grad_norm": 0.32588836550712585,
      "learning_rate": 0.00013739480858124926,
      "loss": 1.0402,
      "step": 3580
    },
    {
      "epoch": 1.1488,
      "grad_norm": 0.2925276458263397,
      "learning_rate": 0.00013715775749674055,
      "loss": 1.061,
      "step": 3590
    },
    {
      "epoch": 1.152,
      "grad_norm": 0.3236440122127533,
      "learning_rate": 0.00013692070641223183,
      "loss": 0.9839,
      "step": 3600
    },
    {
      "epoch": 1.152,
      "eval_loss": 1.0878899097442627,
      "eval_runtime": 2.3441,
      "eval_samples_per_second": 85.321,
      "eval_steps_per_second": 1.706,
      "step": 3600
    },
    {
      "epoch": 1.1552,
      "grad_norm": 0.3253190219402313,
      "learning_rate": 0.00013668365532772315,
      "loss": 0.9562,
      "step": 3610
    },
    {
      "epoch": 1.1584,
      "grad_norm": 0.3200978636741638,
      "learning_rate": 0.00013644660424321444,
      "loss": 1.0112,
      "step": 3620
    },
    {
      "epoch": 1.1616,
      "grad_norm": 0.32051339745521545,
      "learning_rate": 0.00013620955315870573,
      "loss": 1.0711,
      "step": 3630
    },
    {
      "epoch": 1.1648,
      "grad_norm": 0.3111787438392639,
      "learning_rate": 0.00013597250207419701,
      "loss": 0.944,
      "step": 3640
    },
    {
      "epoch": 1.168,
      "grad_norm": 0.32172510027885437,
      "learning_rate": 0.0001357354509896883,
      "loss": 0.9776,
      "step": 3650
    },
    {
      "epoch": 1.168,
      "eval_loss": 1.0837106704711914,
      "eval_runtime": 2.3438,
      "eval_samples_per_second": 85.332,
      "eval_steps_per_second": 1.707,
      "step": 3650
    },
    {
      "epoch": 1.1712,
      "grad_norm": 0.4061947166919708,
      "learning_rate": 0.00013549839990517956,
      "loss": 0.9167,
      "step": 3660
    },
    {
      "epoch": 1.1743999999999999,
      "grad_norm": 0.29393187165260315,
      "learning_rate": 0.00013526134882067085,
      "loss": 0.9931,
      "step": 3670
    },
    {
      "epoch": 1.1776,
      "grad_norm": 0.33405953645706177,
      "learning_rate": 0.00013502429773616214,
      "loss": 0.9888,
      "step": 3680
    },
    {
      "epoch": 1.1808,
      "grad_norm": 0.2796107828617096,
      "learning_rate": 0.00013478724665165343,
      "loss": 0.9982,
      "step": 3690
    },
    {
      "epoch": 1.184,
      "grad_norm": 0.3160462975502014,
      "learning_rate": 0.00013455019556714472,
      "loss": 0.9375,
      "step": 3700
    },
    {
      "epoch": 1.184,
      "eval_loss": 1.0868831872940063,
      "eval_runtime": 2.3433,
      "eval_samples_per_second": 85.348,
      "eval_steps_per_second": 1.707,
      "step": 3700
    },
    {
      "epoch": 1.1872,
      "grad_norm": 0.3566291928291321,
      "learning_rate": 0.000134313144482636,
      "loss": 1.083,
      "step": 3710
    },
    {
      "epoch": 1.1904,
      "grad_norm": 0.3343086242675781,
      "learning_rate": 0.0001340760933981273,
      "loss": 1.0363,
      "step": 3720
    },
    {
      "epoch": 1.1936,
      "grad_norm": 0.3445229232311249,
      "learning_rate": 0.00013383904231361858,
      "loss": 1.0148,
      "step": 3730
    },
    {
      "epoch": 1.1968,
      "grad_norm": 0.29364097118377686,
      "learning_rate": 0.00013360199122910987,
      "loss": 1.0244,
      "step": 3740
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.3298615515232086,
      "learning_rate": 0.00013336494014460116,
      "loss": 0.9905,
      "step": 3750
    },
    {
      "epoch": 1.2,
      "eval_loss": 1.0817878246307373,
      "eval_runtime": 2.343,
      "eval_samples_per_second": 85.362,
      "eval_steps_per_second": 1.707,
      "step": 3750
    },
    {
      "epoch": 1.2032,
      "grad_norm": 0.2911440134048462,
      "learning_rate": 0.00013312788906009245,
      "loss": 0.9972,
      "step": 3760
    },
    {
      "epoch": 1.2064,
      "grad_norm": 0.3139112591743469,
      "learning_rate": 0.00013289083797558374,
      "loss": 1.0386,
      "step": 3770
    },
    {
      "epoch": 1.2096,
      "grad_norm": 0.32416918873786926,
      "learning_rate": 0.00013265378689107505,
      "loss": 1.0251,
      "step": 3780
    },
    {
      "epoch": 1.2128,
      "grad_norm": 0.3743906319141388,
      "learning_rate": 0.00013241673580656634,
      "loss": 0.9489,
      "step": 3790
    },
    {
      "epoch": 1.216,
      "grad_norm": 0.3396950662136078,
      "learning_rate": 0.00013217968472205763,
      "loss": 0.9925,
      "step": 3800
    },
    {
      "epoch": 1.216,
      "eval_loss": 1.0803892612457275,
      "eval_runtime": 2.3422,
      "eval_samples_per_second": 85.39,
      "eval_steps_per_second": 1.708,
      "step": 3800
    },
    {
      "epoch": 1.2192,
      "grad_norm": 0.3047478497028351,
      "learning_rate": 0.00013194263363754892,
      "loss": 1.0643,
      "step": 3810
    },
    {
      "epoch": 1.2224,
      "grad_norm": 0.3321841061115265,
      "learning_rate": 0.0001317055825530402,
      "loss": 0.9657,
      "step": 3820
    },
    {
      "epoch": 1.2256,
      "grad_norm": 0.47803568840026855,
      "learning_rate": 0.00013146853146853147,
      "loss": 0.9892,
      "step": 3830
    },
    {
      "epoch": 1.2288000000000001,
      "grad_norm": 0.3547998368740082,
      "learning_rate": 0.00013123148038402275,
      "loss": 1.045,
      "step": 3840
    },
    {
      "epoch": 1.232,
      "grad_norm": 0.30749788880348206,
      "learning_rate": 0.00013099442929951404,
      "loss": 0.9873,
      "step": 3850
    },
    {
      "epoch": 1.232,
      "eval_loss": 1.0808465480804443,
      "eval_runtime": 2.3437,
      "eval_samples_per_second": 85.335,
      "eval_steps_per_second": 1.707,
      "step": 3850
    },
    {
      "epoch": 1.2352,
      "grad_norm": 0.36479923129081726,
      "learning_rate": 0.00013075737821500533,
      "loss": 1.087,
      "step": 3860
    },
    {
      "epoch": 1.2384,
      "grad_norm": 0.3463206887245178,
      "learning_rate": 0.00013052032713049662,
      "loss": 1.0601,
      "step": 3870
    },
    {
      "epoch": 1.2416,
      "grad_norm": 0.3338014781475067,
      "learning_rate": 0.0001302832760459879,
      "loss": 0.936,
      "step": 3880
    },
    {
      "epoch": 1.2448,
      "grad_norm": 0.3752516806125641,
      "learning_rate": 0.0001300462249614792,
      "loss": 1.0205,
      "step": 3890
    },
    {
      "epoch": 1.248,
      "grad_norm": 0.3000361919403076,
      "learning_rate": 0.00012980917387697048,
      "loss": 1.0328,
      "step": 3900
    },
    {
      "epoch": 1.248,
      "eval_loss": 1.077368140220642,
      "eval_runtime": 2.3425,
      "eval_samples_per_second": 85.378,
      "eval_steps_per_second": 1.708,
      "step": 3900
    },
    {
      "epoch": 1.2511999999999999,
      "grad_norm": 0.31132200360298157,
      "learning_rate": 0.00012957212279246177,
      "loss": 0.9529,
      "step": 3910
    },
    {
      "epoch": 1.2544,
      "grad_norm": 0.2688433527946472,
      "learning_rate": 0.00012933507170795306,
      "loss": 0.987,
      "step": 3920
    },
    {
      "epoch": 1.2576,
      "grad_norm": 0.31693631410598755,
      "learning_rate": 0.00012909802062344435,
      "loss": 1.0453,
      "step": 3930
    },
    {
      "epoch": 1.2608,
      "grad_norm": 0.3593270778656006,
      "learning_rate": 0.00012886096953893564,
      "loss": 1.0047,
      "step": 3940
    },
    {
      "epoch": 1.264,
      "grad_norm": 0.3430202007293701,
      "learning_rate": 0.00012862391845442695,
      "loss": 1.0473,
      "step": 3950
    },
    {
      "epoch": 1.264,
      "eval_loss": 1.0810633897781372,
      "eval_runtime": 2.3425,
      "eval_samples_per_second": 85.378,
      "eval_steps_per_second": 1.708,
      "step": 3950
    },
    {
      "epoch": 1.2671999999999999,
      "grad_norm": 0.335671067237854,
      "learning_rate": 0.00012838686736991824,
      "loss": 0.9663,
      "step": 3960
    },
    {
      "epoch": 1.2704,
      "grad_norm": 0.3085883855819702,
      "learning_rate": 0.00012814981628540953,
      "loss": 0.9927,
      "step": 3970
    },
    {
      "epoch": 1.2736,
      "grad_norm": 0.3085428774356842,
      "learning_rate": 0.00012791276520090082,
      "loss": 1.0234,
      "step": 3980
    },
    {
      "epoch": 1.2768,
      "grad_norm": 0.3328905403614044,
      "learning_rate": 0.0001276757141163921,
      "loss": 1.0125,
      "step": 3990
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.33679842948913574,
      "learning_rate": 0.0001274386630318834,
      "loss": 1.0165,
      "step": 4000
    },
    {
      "epoch": 1.28,
      "eval_loss": 1.086693525314331,
      "eval_runtime": 2.3426,
      "eval_samples_per_second": 85.375,
      "eval_steps_per_second": 1.708,
      "step": 4000
    },
    {
      "epoch": 1.2832,
      "grad_norm": 0.3485104441642761,
      "learning_rate": 0.00012720161194737465,
      "loss": 1.0176,
      "step": 4010
    },
    {
      "epoch": 1.2864,
      "grad_norm": 0.34093427658081055,
      "learning_rate": 0.00012696456086286594,
      "loss": 1.0288,
      "step": 4020
    },
    {
      "epoch": 1.2896,
      "grad_norm": 0.37998610734939575,
      "learning_rate": 0.00012672750977835723,
      "loss": 1.1486,
      "step": 4030
    },
    {
      "epoch": 1.2928,
      "grad_norm": 0.324509859085083,
      "learning_rate": 0.00012649045869384852,
      "loss": 1.0877,
      "step": 4040
    },
    {
      "epoch": 1.296,
      "grad_norm": 0.3687029778957367,
      "learning_rate": 0.0001262534076093398,
      "loss": 1.0841,
      "step": 4050
    },
    {
      "epoch": 1.296,
      "eval_loss": 1.0777161121368408,
      "eval_runtime": 2.3419,
      "eval_samples_per_second": 85.399,
      "eval_steps_per_second": 1.708,
      "step": 4050
    },
    {
      "epoch": 1.2992,
      "grad_norm": 0.29313910007476807,
      "learning_rate": 0.0001260163565248311,
      "loss": 0.9797,
      "step": 4060
    },
    {
      "epoch": 1.3024,
      "grad_norm": 0.31330230832099915,
      "learning_rate": 0.00012577930544032238,
      "loss": 0.9996,
      "step": 4070
    },
    {
      "epoch": 1.3056,
      "grad_norm": 0.3504100441932678,
      "learning_rate": 0.00012554225435581367,
      "loss": 1.0414,
      "step": 4080
    },
    {
      "epoch": 1.3088,
      "grad_norm": 0.294560045003891,
      "learning_rate": 0.00012530520327130496,
      "loss": 0.9913,
      "step": 4090
    },
    {
      "epoch": 1.312,
      "grad_norm": 0.3229443430900574,
      "learning_rate": 0.00012506815218679625,
      "loss": 1.014,
      "step": 4100
    },
    {
      "epoch": 1.312,
      "eval_loss": 1.0826603174209595,
      "eval_runtime": 2.3426,
      "eval_samples_per_second": 85.375,
      "eval_steps_per_second": 1.707,
      "step": 4100
    },
    {
      "epoch": 1.3152,
      "grad_norm": 0.3551630973815918,
      "learning_rate": 0.00012483110110228756,
      "loss": 1.0209,
      "step": 4110
    },
    {
      "epoch": 1.3184,
      "grad_norm": 0.373546302318573,
      "learning_rate": 0.00012459405001777885,
      "loss": 0.9751,
      "step": 4120
    },
    {
      "epoch": 1.3216,
      "grad_norm": 0.32600119709968567,
      "learning_rate": 0.00012435699893327014,
      "loss": 1.0516,
      "step": 4130
    },
    {
      "epoch": 1.3248,
      "grad_norm": 0.3724333345890045,
      "learning_rate": 0.00012411994784876143,
      "loss": 1.0117,
      "step": 4140
    },
    {
      "epoch": 1.328,
      "grad_norm": 0.3151647448539734,
      "learning_rate": 0.00012388289676425272,
      "loss": 0.9621,
      "step": 4150
    },
    {
      "epoch": 1.328,
      "eval_loss": 1.0814040899276733,
      "eval_runtime": 2.3438,
      "eval_samples_per_second": 85.331,
      "eval_steps_per_second": 1.707,
      "step": 4150
    },
    {
      "epoch": 1.3312,
      "grad_norm": 0.3651774525642395,
      "learning_rate": 0.000123645845679744,
      "loss": 0.9635,
      "step": 4160
    },
    {
      "epoch": 1.3344,
      "grad_norm": 0.3998226225376129,
      "learning_rate": 0.0001234087945952353,
      "loss": 0.9821,
      "step": 4170
    },
    {
      "epoch": 1.3376000000000001,
      "grad_norm": 0.3002847731113434,
      "learning_rate": 0.00012317174351072658,
      "loss": 0.9521,
      "step": 4180
    },
    {
      "epoch": 1.3408,
      "grad_norm": 0.2937813103199005,
      "learning_rate": 0.00012293469242621784,
      "loss": 1.0452,
      "step": 4190
    },
    {
      "epoch": 1.3439999999999999,
      "grad_norm": 0.32620489597320557,
      "learning_rate": 0.00012269764134170913,
      "loss": 1.132,
      "step": 4200
    },
    {
      "epoch": 1.3439999999999999,
      "eval_loss": 1.0766003131866455,
      "eval_runtime": 2.3435,
      "eval_samples_per_second": 85.343,
      "eval_steps_per_second": 1.707,
      "step": 4200
    },
    {
      "epoch": 1.3472,
      "grad_norm": 0.40294697880744934,
      "learning_rate": 0.00012246059025720042,
      "loss": 0.9953,
      "step": 4210
    },
    {
      "epoch": 1.3504,
      "grad_norm": 0.3202175199985504,
      "learning_rate": 0.0001222235391726917,
      "loss": 1.056,
      "step": 4220
    },
    {
      "epoch": 1.3536000000000001,
      "grad_norm": 0.2562634348869324,
      "learning_rate": 0.00012198648808818301,
      "loss": 0.9904,
      "step": 4230
    },
    {
      "epoch": 1.3568,
      "grad_norm": 0.33337414264678955,
      "learning_rate": 0.0001217494370036743,
      "loss": 0.9356,
      "step": 4240
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.32961681485176086,
      "learning_rate": 0.00012151238591916559,
      "loss": 1.0812,
      "step": 4250
    },
    {
      "epoch": 1.3599999999999999,
      "eval_loss": 1.076757550239563,
      "eval_runtime": 2.3433,
      "eval_samples_per_second": 85.349,
      "eval_steps_per_second": 1.707,
      "step": 4250
    },
    {
      "epoch": 1.3632,
      "grad_norm": 0.2580643594264984,
      "learning_rate": 0.00012127533483465687,
      "loss": 0.9786,
      "step": 4260
    },
    {
      "epoch": 1.3664,
      "grad_norm": 0.3467097580432892,
      "learning_rate": 0.00012103828375014816,
      "loss": 0.9365,
      "step": 4270
    },
    {
      "epoch": 1.3696,
      "grad_norm": 0.2967299520969391,
      "learning_rate": 0.00012080123266563945,
      "loss": 1.0376,
      "step": 4280
    },
    {
      "epoch": 1.3728,
      "grad_norm": 0.25765109062194824,
      "learning_rate": 0.00012056418158113074,
      "loss": 0.9153,
      "step": 4290
    },
    {
      "epoch": 1.376,
      "grad_norm": 0.3054943084716797,
      "learning_rate": 0.00012032713049662203,
      "loss": 0.9138,
      "step": 4300
    },
    {
      "epoch": 1.376,
      "eval_loss": 1.0744856595993042,
      "eval_runtime": 2.3428,
      "eval_samples_per_second": 85.368,
      "eval_steps_per_second": 1.707,
      "step": 4300
    },
    {
      "epoch": 1.3792,
      "grad_norm": 0.3393315076828003,
      "learning_rate": 0.00012009007941211332,
      "loss": 1.0223,
      "step": 4310
    },
    {
      "epoch": 1.3824,
      "grad_norm": 0.2811967730522156,
      "learning_rate": 0.0001198530283276046,
      "loss": 0.9555,
      "step": 4320
    },
    {
      "epoch": 1.3856,
      "grad_norm": 0.3136320114135742,
      "learning_rate": 0.0001196159772430959,
      "loss": 0.9116,
      "step": 4330
    },
    {
      "epoch": 1.3888,
      "grad_norm": 0.34208396077156067,
      "learning_rate": 0.0001193789261585872,
      "loss": 1.028,
      "step": 4340
    },
    {
      "epoch": 1.392,
      "grad_norm": 0.29344409704208374,
      "learning_rate": 0.00011914187507407848,
      "loss": 1.0014,
      "step": 4350
    },
    {
      "epoch": 1.392,
      "eval_loss": 1.0762161016464233,
      "eval_runtime": 2.344,
      "eval_samples_per_second": 85.323,
      "eval_steps_per_second": 1.706,
      "step": 4350
    },
    {
      "epoch": 1.3952,
      "grad_norm": 0.3179834485054016,
      "learning_rate": 0.00011890482398956974,
      "loss": 0.9657,
      "step": 4360
    },
    {
      "epoch": 1.3984,
      "grad_norm": 0.3083842694759369,
      "learning_rate": 0.00011866777290506103,
      "loss": 0.9795,
      "step": 4370
    },
    {
      "epoch": 1.4016,
      "grad_norm": 0.3111231029033661,
      "learning_rate": 0.00011843072182055232,
      "loss": 1.0072,
      "step": 4380
    },
    {
      "epoch": 1.4048,
      "grad_norm": 0.331010639667511,
      "learning_rate": 0.00011819367073604362,
      "loss": 1.156,
      "step": 4390
    },
    {
      "epoch": 1.408,
      "grad_norm": 0.28845569491386414,
      "learning_rate": 0.00011795661965153491,
      "loss": 1.0538,
      "step": 4400
    },
    {
      "epoch": 1.408,
      "eval_loss": 1.0754685401916504,
      "eval_runtime": 2.344,
      "eval_samples_per_second": 85.326,
      "eval_steps_per_second": 1.707,
      "step": 4400
    },
    {
      "epoch": 1.4112,
      "grad_norm": 0.3233027458190918,
      "learning_rate": 0.0001177195685670262,
      "loss": 0.9481,
      "step": 4410
    },
    {
      "epoch": 1.4144,
      "grad_norm": 0.3275045156478882,
      "learning_rate": 0.00011748251748251749,
      "loss": 1.0204,
      "step": 4420
    },
    {
      "epoch": 1.4176,
      "grad_norm": 0.23644711077213287,
      "learning_rate": 0.00011724546639800878,
      "loss": 1.0195,
      "step": 4430
    },
    {
      "epoch": 1.4208,
      "grad_norm": 0.3019431531429291,
      "learning_rate": 0.00011700841531350006,
      "loss": 0.9315,
      "step": 4440
    },
    {
      "epoch": 1.424,
      "grad_norm": 0.32865777611732483,
      "learning_rate": 0.00011677136422899135,
      "loss": 0.9135,
      "step": 4450
    },
    {
      "epoch": 1.424,
      "eval_loss": 1.077019453048706,
      "eval_runtime": 2.3437,
      "eval_samples_per_second": 85.336,
      "eval_steps_per_second": 1.707,
      "step": 4450
    },
    {
      "epoch": 1.4272,
      "grad_norm": 0.28611963987350464,
      "learning_rate": 0.00011653431314448264,
      "loss": 0.933,
      "step": 4460
    },
    {
      "epoch": 1.4304000000000001,
      "grad_norm": 0.3008212149143219,
      "learning_rate": 0.00011629726205997393,
      "loss": 0.9897,
      "step": 4470
    },
    {
      "epoch": 1.4336,
      "grad_norm": 0.34904760122299194,
      "learning_rate": 0.00011606021097546522,
      "loss": 1.0165,
      "step": 4480
    },
    {
      "epoch": 1.4368,
      "grad_norm": 0.3723328113555908,
      "learning_rate": 0.0001158231598909565,
      "loss": 1.1322,
      "step": 4490
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.30401402711868286,
      "learning_rate": 0.00011558610880644781,
      "loss": 1.0061,
      "step": 4500
    },
    {
      "epoch": 1.44,
      "eval_loss": 1.0757925510406494,
      "eval_runtime": 2.3407,
      "eval_samples_per_second": 85.444,
      "eval_steps_per_second": 1.709,
      "step": 4500
    },
    {
      "epoch": 1.4432,
      "grad_norm": 0.34116223454475403,
      "learning_rate": 0.0001153490577219391,
      "loss": 0.9472,
      "step": 4510
    },
    {
      "epoch": 1.4464000000000001,
      "grad_norm": 0.34166911244392395,
      "learning_rate": 0.00011511200663743038,
      "loss": 1.0416,
      "step": 4520
    },
    {
      "epoch": 1.4496,
      "grad_norm": 0.2740556001663208,
      "learning_rate": 0.00011487495555292167,
      "loss": 0.9341,
      "step": 4530
    },
    {
      "epoch": 1.4527999999999999,
      "grad_norm": 0.2946156859397888,
      "learning_rate": 0.00011463790446841293,
      "loss": 1.0141,
      "step": 4540
    },
    {
      "epoch": 1.456,
      "grad_norm": 0.36930254101753235,
      "learning_rate": 0.00011440085338390422,
      "loss": 1.0129,
      "step": 4550
    },
    {
      "epoch": 1.456,
      "eval_loss": 1.0742807388305664,
      "eval_runtime": 2.3423,
      "eval_samples_per_second": 85.387,
      "eval_steps_per_second": 1.708,
      "step": 4550
    },
    {
      "epoch": 1.4592,
      "grad_norm": 0.3097628355026245,
      "learning_rate": 0.00011416380229939552,
      "loss": 0.9487,
      "step": 4560
    },
    {
      "epoch": 1.4624,
      "grad_norm": 0.27883967757225037,
      "learning_rate": 0.00011392675121488681,
      "loss": 0.9773,
      "step": 4570
    },
    {
      "epoch": 1.4656,
      "grad_norm": 0.3017379939556122,
      "learning_rate": 0.0001136897001303781,
      "loss": 0.9667,
      "step": 4580
    },
    {
      "epoch": 1.4687999999999999,
      "grad_norm": 0.35619208216667175,
      "learning_rate": 0.00011345264904586939,
      "loss": 1.0367,
      "step": 4590
    },
    {
      "epoch": 1.472,
      "grad_norm": 0.3310113251209259,
      "learning_rate": 0.00011321559796136068,
      "loss": 0.9335,
      "step": 4600
    },
    {
      "epoch": 1.472,
      "eval_loss": 1.076780080795288,
      "eval_runtime": 2.3402,
      "eval_samples_per_second": 85.462,
      "eval_steps_per_second": 1.709,
      "step": 4600
    },
    {
      "epoch": 1.4752,
      "grad_norm": 0.2865200638771057,
      "learning_rate": 0.00011297854687685196,
      "loss": 0.9552,
      "step": 4610
    },
    {
      "epoch": 1.4784,
      "grad_norm": 0.28933340311050415,
      "learning_rate": 0.00011274149579234325,
      "loss": 1.0003,
      "step": 4620
    },
    {
      "epoch": 1.4816,
      "grad_norm": 0.3010045886039734,
      "learning_rate": 0.00011250444470783454,
      "loss": 0.9767,
      "step": 4630
    },
    {
      "epoch": 1.4848,
      "grad_norm": 0.29122740030288696,
      "learning_rate": 0.00011226739362332583,
      "loss": 0.9539,
      "step": 4640
    },
    {
      "epoch": 1.488,
      "grad_norm": 0.2942207157611847,
      "learning_rate": 0.00011203034253881712,
      "loss": 1.0661,
      "step": 4650
    },
    {
      "epoch": 1.488,
      "eval_loss": 1.072221040725708,
      "eval_runtime": 2.3428,
      "eval_samples_per_second": 85.369,
      "eval_steps_per_second": 1.707,
      "step": 4650
    },
    {
      "epoch": 1.4912,
      "grad_norm": 0.31075239181518555,
      "learning_rate": 0.00011179329145430842,
      "loss": 0.9779,
      "step": 4660
    },
    {
      "epoch": 1.4944,
      "grad_norm": 0.2938491404056549,
      "learning_rate": 0.00011155624036979971,
      "loss": 1.0107,
      "step": 4670
    },
    {
      "epoch": 1.4976,
      "grad_norm": 0.29341012239456177,
      "learning_rate": 0.000111319189285291,
      "loss": 0.9351,
      "step": 4680
    },
    {
      "epoch": 1.5008,
      "grad_norm": 0.32719460129737854,
      "learning_rate": 0.00011108213820078228,
      "loss": 1.0007,
      "step": 4690
    },
    {
      "epoch": 1.504,
      "grad_norm": 0.31796127557754517,
      "learning_rate": 0.00011084508711627357,
      "loss": 1.0395,
      "step": 4700
    },
    {
      "epoch": 1.504,
      "eval_loss": 1.073117971420288,
      "eval_runtime": 2.3427,
      "eval_samples_per_second": 85.37,
      "eval_steps_per_second": 1.707,
      "step": 4700
    },
    {
      "epoch": 1.5072,
      "grad_norm": 0.33982405066490173,
      "learning_rate": 0.00011060803603176486,
      "loss": 0.9809,
      "step": 4710
    },
    {
      "epoch": 1.5104,
      "grad_norm": 0.33270806074142456,
      "learning_rate": 0.00011037098494725612,
      "loss": 0.9333,
      "step": 4720
    },
    {
      "epoch": 1.5135999999999998,
      "grad_norm": 0.32259008288383484,
      "learning_rate": 0.00011013393386274742,
      "loss": 1.0002,
      "step": 4730
    },
    {
      "epoch": 1.5168,
      "grad_norm": 0.3415911793708801,
      "learning_rate": 0.00010989688277823871,
      "loss": 0.9475,
      "step": 4740
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.30103057622909546,
      "learning_rate": 0.00010965983169373,
      "loss": 0.9733,
      "step": 4750
    },
    {
      "epoch": 1.52,
      "eval_loss": 1.074703574180603,
      "eval_runtime": 2.3438,
      "eval_samples_per_second": 85.332,
      "eval_steps_per_second": 1.707,
      "step": 4750
    },
    {
      "epoch": 1.5232,
      "grad_norm": 0.26783889532089233,
      "learning_rate": 0.00010942278060922129,
      "loss": 0.9588,
      "step": 4760
    },
    {
      "epoch": 1.5264,
      "grad_norm": 0.2981029152870178,
      "learning_rate": 0.00010918572952471258,
      "loss": 0.9455,
      "step": 4770
    },
    {
      "epoch": 1.5295999999999998,
      "grad_norm": 0.314497172832489,
      "learning_rate": 0.00010894867844020387,
      "loss": 1.073,
      "step": 4780
    },
    {
      "epoch": 1.5328,
      "grad_norm": 0.29874488711357117,
      "learning_rate": 0.00010871162735569515,
      "loss": 1.0336,
      "step": 4790
    },
    {
      "epoch": 1.536,
      "grad_norm": 0.3126256465911865,
      "learning_rate": 0.00010847457627118644,
      "loss": 1.0244,
      "step": 4800
    },
    {
      "epoch": 1.536,
      "eval_loss": 1.0730094909667969,
      "eval_runtime": 2.3426,
      "eval_samples_per_second": 85.375,
      "eval_steps_per_second": 1.707,
      "step": 4800
    },
    {
      "epoch": 1.5392000000000001,
      "grad_norm": 0.30628541111946106,
      "learning_rate": 0.00010823752518667773,
      "loss": 0.9889,
      "step": 4810
    },
    {
      "epoch": 1.5424,
      "grad_norm": 0.29276326298713684,
      "learning_rate": 0.00010800047410216902,
      "loss": 1.0048,
      "step": 4820
    },
    {
      "epoch": 1.5455999999999999,
      "grad_norm": 0.29667937755584717,
      "learning_rate": 0.00010776342301766032,
      "loss": 1.0019,
      "step": 4830
    },
    {
      "epoch": 1.5488,
      "grad_norm": 0.3021296560764313,
      "learning_rate": 0.00010752637193315161,
      "loss": 0.899,
      "step": 4840
    },
    {
      "epoch": 1.552,
      "grad_norm": 0.31112900376319885,
      "learning_rate": 0.0001072893208486429,
      "loss": 0.9981,
      "step": 4850
    },
    {
      "epoch": 1.552,
      "eval_loss": 1.0757309198379517,
      "eval_runtime": 2.3433,
      "eval_samples_per_second": 85.349,
      "eval_steps_per_second": 1.707,
      "step": 4850
    },
    {
      "epoch": 1.5552000000000001,
      "grad_norm": 0.27843475341796875,
      "learning_rate": 0.00010705226976413419,
      "loss": 0.927,
      "step": 4860
    },
    {
      "epoch": 1.5584,
      "grad_norm": 0.2988830506801605,
      "learning_rate": 0.00010681521867962547,
      "loss": 1.0276,
      "step": 4870
    },
    {
      "epoch": 1.5615999999999999,
      "grad_norm": 0.302724152803421,
      "learning_rate": 0.00010657816759511676,
      "loss": 0.9805,
      "step": 4880
    },
    {
      "epoch": 1.5648,
      "grad_norm": 0.38502004742622375,
      "learning_rate": 0.00010634111651060805,
      "loss": 1.0051,
      "step": 4890
    },
    {
      "epoch": 1.568,
      "grad_norm": 0.34193938970565796,
      "learning_rate": 0.00010610406542609932,
      "loss": 1.0476,
      "step": 4900
    },
    {
      "epoch": 1.568,
      "eval_loss": 1.074998378753662,
      "eval_runtime": 2.3434,
      "eval_samples_per_second": 85.347,
      "eval_steps_per_second": 1.707,
      "step": 4900
    },
    {
      "epoch": 1.5712000000000002,
      "grad_norm": 0.2875919044017792,
      "learning_rate": 0.00010586701434159061,
      "loss": 0.9355,
      "step": 4910
    },
    {
      "epoch": 1.5744,
      "grad_norm": 0.3203675150871277,
      "learning_rate": 0.0001056299632570819,
      "loss": 0.9786,
      "step": 4920
    },
    {
      "epoch": 1.5776,
      "grad_norm": 0.29081693291664124,
      "learning_rate": 0.00010539291217257319,
      "loss": 0.9333,
      "step": 4930
    },
    {
      "epoch": 1.5808,
      "grad_norm": 0.281471312046051,
      "learning_rate": 0.00010515586108806448,
      "loss": 0.9411,
      "step": 4940
    },
    {
      "epoch": 1.584,
      "grad_norm": 0.3095707297325134,
      "learning_rate": 0.00010491881000355577,
      "loss": 0.9733,
      "step": 4950
    },
    {
      "epoch": 1.584,
      "eval_loss": 1.0790661573410034,
      "eval_runtime": 2.343,
      "eval_samples_per_second": 85.362,
      "eval_steps_per_second": 1.707,
      "step": 4950
    },
    {
      "epoch": 1.5872000000000002,
      "grad_norm": 0.31664445996284485,
      "learning_rate": 0.00010468175891904705,
      "loss": 0.95,
      "step": 4960
    },
    {
      "epoch": 1.5904,
      "grad_norm": 0.35103920102119446,
      "learning_rate": 0.00010444470783453834,
      "loss": 1.0541,
      "step": 4970
    },
    {
      "epoch": 1.5936,
      "grad_norm": 0.3002666234970093,
      "learning_rate": 0.00010420765675002963,
      "loss": 1.0485,
      "step": 4980
    },
    {
      "epoch": 1.5968,
      "grad_norm": 0.34252551198005676,
      "learning_rate": 0.00010397060566552092,
      "loss": 0.9992,
      "step": 4990
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.38347792625427246,
      "learning_rate": 0.00010373355458101222,
      "loss": 0.9098,
      "step": 5000
    },
    {
      "epoch": 1.6,
      "eval_loss": 1.0741602182388306,
      "eval_runtime": 2.3422,
      "eval_samples_per_second": 85.39,
      "eval_steps_per_second": 1.708,
      "step": 5000
    },
    {
      "epoch": 1.6032,
      "grad_norm": 0.32334133982658386,
      "learning_rate": 0.00010349650349650351,
      "loss": 0.9682,
      "step": 5010
    },
    {
      "epoch": 1.6064,
      "grad_norm": 0.3106594383716583,
      "learning_rate": 0.0001032594524119948,
      "loss": 0.978,
      "step": 5020
    },
    {
      "epoch": 1.6096,
      "grad_norm": 0.30300459265708923,
      "learning_rate": 0.00010302240132748609,
      "loss": 0.9876,
      "step": 5030
    },
    {
      "epoch": 1.6128,
      "grad_norm": 0.31065160036087036,
      "learning_rate": 0.00010278535024297737,
      "loss": 1.0469,
      "step": 5040
    },
    {
      "epoch": 1.616,
      "grad_norm": 0.36514151096343994,
      "learning_rate": 0.00010254829915846866,
      "loss": 1.0327,
      "step": 5050
    },
    {
      "epoch": 1.616,
      "eval_loss": 1.0741891860961914,
      "eval_runtime": 2.3426,
      "eval_samples_per_second": 85.374,
      "eval_steps_per_second": 1.707,
      "step": 5050
    },
    {
      "epoch": 1.6192,
      "grad_norm": 0.34044620394706726,
      "learning_rate": 0.00010231124807395995,
      "loss": 0.9707,
      "step": 5060
    },
    {
      "epoch": 1.6223999999999998,
      "grad_norm": 0.30702030658721924,
      "learning_rate": 0.00010207419698945123,
      "loss": 0.9837,
      "step": 5070
    },
    {
      "epoch": 1.6256,
      "grad_norm": 0.36463257670402527,
      "learning_rate": 0.00010183714590494251,
      "loss": 1.0657,
      "step": 5080
    },
    {
      "epoch": 1.6288,
      "grad_norm": 0.26166465878486633,
      "learning_rate": 0.0001016000948204338,
      "loss": 1.0254,
      "step": 5090
    },
    {
      "epoch": 1.6320000000000001,
      "grad_norm": 0.274872362613678,
      "learning_rate": 0.00010136304373592509,
      "loss": 0.9905,
      "step": 5100
    },
    {
      "epoch": 1.6320000000000001,
      "eval_loss": 1.074416160583496,
      "eval_runtime": 2.3419,
      "eval_samples_per_second": 85.402,
      "eval_steps_per_second": 1.708,
      "step": 5100
    },
    {
      "epoch": 1.6352,
      "grad_norm": 0.35862496495246887,
      "learning_rate": 0.00010112599265141638,
      "loss": 1.0276,
      "step": 5110
    },
    {
      "epoch": 1.6383999999999999,
      "grad_norm": 0.3299334645271301,
      "learning_rate": 0.00010088894156690767,
      "loss": 1.0119,
      "step": 5120
    },
    {
      "epoch": 1.6416,
      "grad_norm": 0.3321704566478729,
      "learning_rate": 0.00010065189048239896,
      "loss": 1.0428,
      "step": 5130
    },
    {
      "epoch": 1.6448,
      "grad_norm": 0.34324193000793457,
      "learning_rate": 0.00010041483939789024,
      "loss": 0.9654,
      "step": 5140
    },
    {
      "epoch": 1.6480000000000001,
      "grad_norm": 0.3354801833629608,
      "learning_rate": 0.00010017778831338153,
      "loss": 0.9333,
      "step": 5150
    },
    {
      "epoch": 1.6480000000000001,
      "eval_loss": 1.0758888721466064,
      "eval_runtime": 2.3429,
      "eval_samples_per_second": 85.364,
      "eval_steps_per_second": 1.707,
      "step": 5150
    },
    {
      "epoch": 1.6512,
      "grad_norm": 0.32939547300338745,
      "learning_rate": 9.994073722887283e-05,
      "loss": 1.022,
      "step": 5160
    },
    {
      "epoch": 1.6543999999999999,
      "grad_norm": 0.36635419726371765,
      "learning_rate": 9.970368614436412e-05,
      "loss": 0.9701,
      "step": 5170
    },
    {
      "epoch": 1.6576,
      "grad_norm": 0.2922433018684387,
      "learning_rate": 9.946663505985541e-05,
      "loss": 0.9819,
      "step": 5180
    },
    {
      "epoch": 1.6608,
      "grad_norm": 0.2684725821018219,
      "learning_rate": 9.92295839753467e-05,
      "loss": 0.9713,
      "step": 5190
    },
    {
      "epoch": 1.6640000000000001,
      "grad_norm": 0.3089757561683655,
      "learning_rate": 9.899253289083799e-05,
      "loss": 1.0597,
      "step": 5200
    },
    {
      "epoch": 1.6640000000000001,
      "eval_loss": 1.079443097114563,
      "eval_runtime": 2.3412,
      "eval_samples_per_second": 85.425,
      "eval_steps_per_second": 1.708,
      "step": 5200
    },
    {
      "epoch": 1.6672,
      "grad_norm": 0.32418447732925415,
      "learning_rate": 9.875548180632926e-05,
      "loss": 0.9482,
      "step": 5210
    },
    {
      "epoch": 1.6703999999999999,
      "grad_norm": 0.2967921495437622,
      "learning_rate": 9.851843072182055e-05,
      "loss": 0.939,
      "step": 5220
    },
    {
      "epoch": 1.6736,
      "grad_norm": 0.36710596084594727,
      "learning_rate": 9.828137963731184e-05,
      "loss": 0.9565,
      "step": 5230
    },
    {
      "epoch": 1.6768,
      "grad_norm": 0.3389960825443268,
      "learning_rate": 9.804432855280313e-05,
      "loss": 0.9737,
      "step": 5240
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 0.36335110664367676,
      "learning_rate": 9.780727746829443e-05,
      "loss": 0.8948,
      "step": 5250
    },
    {
      "epoch": 1.6800000000000002,
      "eval_loss": 1.0781000852584839,
      "eval_runtime": 2.341,
      "eval_samples_per_second": 85.435,
      "eval_steps_per_second": 1.709,
      "step": 5250
    },
    {
      "epoch": 1.6832,
      "grad_norm": 0.3540968894958496,
      "learning_rate": 9.757022638378572e-05,
      "loss": 1.0103,
      "step": 5260
    },
    {
      "epoch": 1.6864,
      "grad_norm": 0.3267228305339813,
      "learning_rate": 9.7333175299277e-05,
      "loss": 0.9961,
      "step": 5270
    },
    {
      "epoch": 1.6896,
      "grad_norm": 0.32143136858940125,
      "learning_rate": 9.709612421476829e-05,
      "loss": 0.99,
      "step": 5280
    },
    {
      "epoch": 1.6928,
      "grad_norm": 0.29876700043678284,
      "learning_rate": 9.685907313025958e-05,
      "loss": 0.9969,
      "step": 5290
    },
    {
      "epoch": 1.696,
      "grad_norm": 0.4044468402862549,
      "learning_rate": 9.662202204575086e-05,
      "loss": 1.0078,
      "step": 5300
    },
    {
      "epoch": 1.696,
      "eval_loss": 1.078303337097168,
      "eval_runtime": 2.341,
      "eval_samples_per_second": 85.432,
      "eval_steps_per_second": 1.709,
      "step": 5300
    },
    {
      "epoch": 1.6992,
      "grad_norm": 0.34095045924186707,
      "learning_rate": 9.638497096124214e-05,
      "loss": 0.938,
      "step": 5310
    },
    {
      "epoch": 1.7024,
      "grad_norm": 0.3328860402107239,
      "learning_rate": 9.614791987673343e-05,
      "loss": 1.017,
      "step": 5320
    },
    {
      "epoch": 1.7056,
      "grad_norm": 0.3138197064399719,
      "learning_rate": 9.591086879222473e-05,
      "loss": 1.0336,
      "step": 5330
    },
    {
      "epoch": 1.7088,
      "grad_norm": 0.3164541721343994,
      "learning_rate": 9.567381770771602e-05,
      "loss": 1.0382,
      "step": 5340
    },
    {
      "epoch": 1.712,
      "grad_norm": 0.3474998474121094,
      "learning_rate": 9.543676662320731e-05,
      "loss": 1.0404,
      "step": 5350
    },
    {
      "epoch": 1.712,
      "eval_loss": 1.074273705482483,
      "eval_runtime": 2.3436,
      "eval_samples_per_second": 85.338,
      "eval_steps_per_second": 1.707,
      "step": 5350
    },
    {
      "epoch": 1.7151999999999998,
      "grad_norm": 0.34126150608062744,
      "learning_rate": 9.51997155386986e-05,
      "loss": 0.9791,
      "step": 5360
    },
    {
      "epoch": 1.7184,
      "grad_norm": 0.2867182493209839,
      "learning_rate": 9.496266445418989e-05,
      "loss": 0.936,
      "step": 5370
    },
    {
      "epoch": 1.7216,
      "grad_norm": 0.2772234380245209,
      "learning_rate": 9.472561336968116e-05,
      "loss": 0.941,
      "step": 5380
    },
    {
      "epoch": 1.7248,
      "grad_norm": 0.3094072937965393,
      "learning_rate": 9.448856228517245e-05,
      "loss": 0.9885,
      "step": 5390
    },
    {
      "epoch": 1.728,
      "grad_norm": 0.3111499547958374,
      "learning_rate": 9.425151120066374e-05,
      "loss": 0.9194,
      "step": 5400
    },
    {
      "epoch": 1.728,
      "eval_loss": 1.0714040994644165,
      "eval_runtime": 2.3441,
      "eval_samples_per_second": 85.319,
      "eval_steps_per_second": 1.706,
      "step": 5400
    },
    {
      "epoch": 1.7311999999999999,
      "grad_norm": 0.3156129717826843,
      "learning_rate": 9.401446011615504e-05,
      "loss": 0.9924,
      "step": 5410
    },
    {
      "epoch": 1.7344,
      "grad_norm": 0.3217965364456177,
      "learning_rate": 9.377740903164633e-05,
      "loss": 0.9671,
      "step": 5420
    },
    {
      "epoch": 1.7376,
      "grad_norm": 0.37332814931869507,
      "learning_rate": 9.354035794713762e-05,
      "loss": 1.0308,
      "step": 5430
    },
    {
      "epoch": 1.7408000000000001,
      "grad_norm": 0.30950602889060974,
      "learning_rate": 9.33033068626289e-05,
      "loss": 1.0384,
      "step": 5440
    },
    {
      "epoch": 1.744,
      "grad_norm": 0.31163614988327026,
      "learning_rate": 9.30662557781202e-05,
      "loss": 0.9939,
      "step": 5450
    },
    {
      "epoch": 1.744,
      "eval_loss": 1.0727753639221191,
      "eval_runtime": 2.3422,
      "eval_samples_per_second": 85.391,
      "eval_steps_per_second": 1.708,
      "step": 5450
    },
    {
      "epoch": 1.7471999999999999,
      "grad_norm": 0.34081366658210754,
      "learning_rate": 9.282920469361148e-05,
      "loss": 0.9667,
      "step": 5460
    },
    {
      "epoch": 1.7504,
      "grad_norm": 0.28043583035469055,
      "learning_rate": 9.259215360910276e-05,
      "loss": 0.8875,
      "step": 5470
    },
    {
      "epoch": 1.7536,
      "grad_norm": 0.3138010501861572,
      "learning_rate": 9.235510252459405e-05,
      "loss": 1.0123,
      "step": 5480
    },
    {
      "epoch": 1.7568000000000001,
      "grad_norm": 0.32844823598861694,
      "learning_rate": 9.211805144008533e-05,
      "loss": 1.0157,
      "step": 5490
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.385755330324173,
      "learning_rate": 9.188100035557664e-05,
      "loss": 0.9996,
      "step": 5500
    },
    {
      "epoch": 1.76,
      "eval_loss": 1.0725897550582886,
      "eval_runtime": 2.3429,
      "eval_samples_per_second": 85.363,
      "eval_steps_per_second": 1.707,
      "step": 5500
    },
    {
      "epoch": 1.7631999999999999,
      "grad_norm": 0.3417265713214874,
      "learning_rate": 9.164394927106792e-05,
      "loss": 1.0489,
      "step": 5510
    },
    {
      "epoch": 1.7664,
      "grad_norm": 0.4405023753643036,
      "learning_rate": 9.140689818655921e-05,
      "loss": 1.0196,
      "step": 5520
    },
    {
      "epoch": 1.7696,
      "grad_norm": 0.2588212192058563,
      "learning_rate": 9.11698471020505e-05,
      "loss": 0.9054,
      "step": 5530
    },
    {
      "epoch": 1.7728000000000002,
      "grad_norm": 0.31751248240470886,
      "learning_rate": 9.093279601754179e-05,
      "loss": 0.993,
      "step": 5540
    },
    {
      "epoch": 1.776,
      "grad_norm": 0.29030314087867737,
      "learning_rate": 9.069574493303308e-05,
      "loss": 1.0643,
      "step": 5550
    },
    {
      "epoch": 1.776,
      "eval_loss": 1.0723655223846436,
      "eval_runtime": 2.3432,
      "eval_samples_per_second": 85.352,
      "eval_steps_per_second": 1.707,
      "step": 5550
    },
    {
      "epoch": 1.7792,
      "grad_norm": 0.33534470200538635,
      "learning_rate": 9.045869384852435e-05,
      "loss": 0.9706,
      "step": 5560
    },
    {
      "epoch": 1.7824,
      "grad_norm": 0.3228890597820282,
      "learning_rate": 9.022164276401564e-05,
      "loss": 0.9585,
      "step": 5570
    },
    {
      "epoch": 1.7856,
      "grad_norm": 0.3028300106525421,
      "learning_rate": 8.998459167950694e-05,
      "loss": 0.9474,
      "step": 5580
    },
    {
      "epoch": 1.7888,
      "grad_norm": 0.321642130613327,
      "learning_rate": 8.974754059499823e-05,
      "loss": 1.0189,
      "step": 5590
    },
    {
      "epoch": 1.792,
      "grad_norm": 0.33875253796577454,
      "learning_rate": 8.951048951048952e-05,
      "loss": 0.9627,
      "step": 5600
    },
    {
      "epoch": 1.792,
      "eval_loss": 1.0714712142944336,
      "eval_runtime": 2.3428,
      "eval_samples_per_second": 85.368,
      "eval_steps_per_second": 1.707,
      "step": 5600
    },
    {
      "epoch": 1.7952,
      "grad_norm": 0.27646979689598083,
      "learning_rate": 8.92734384259808e-05,
      "loss": 0.9745,
      "step": 5610
    },
    {
      "epoch": 1.7984,
      "grad_norm": 0.30938035249710083,
      "learning_rate": 8.90363873414721e-05,
      "loss": 0.8794,
      "step": 5620
    },
    {
      "epoch": 1.8016,
      "grad_norm": 0.35901013016700745,
      "learning_rate": 8.879933625696338e-05,
      "loss": 0.9779,
      "step": 5630
    },
    {
      "epoch": 1.8048,
      "grad_norm": 0.2923409938812256,
      "learning_rate": 8.856228517245467e-05,
      "loss": 0.9162,
      "step": 5640
    },
    {
      "epoch": 1.808,
      "grad_norm": 0.3107796907424927,
      "learning_rate": 8.832523408794595e-05,
      "loss": 1.0029,
      "step": 5650
    },
    {
      "epoch": 1.808,
      "eval_loss": 1.0711638927459717,
      "eval_runtime": 2.3417,
      "eval_samples_per_second": 85.409,
      "eval_steps_per_second": 1.708,
      "step": 5650
    },
    {
      "epoch": 1.8112,
      "grad_norm": 0.3086012899875641,
      "learning_rate": 8.808818300343725e-05,
      "loss": 0.9601,
      "step": 5660
    },
    {
      "epoch": 1.8144,
      "grad_norm": 0.30964311957359314,
      "learning_rate": 8.785113191892854e-05,
      "loss": 0.9818,
      "step": 5670
    },
    {
      "epoch": 1.8176,
      "grad_norm": 0.30693331360816956,
      "learning_rate": 8.761408083441982e-05,
      "loss": 1.0395,
      "step": 5680
    },
    {
      "epoch": 1.8208,
      "grad_norm": 0.3373135030269623,
      "learning_rate": 8.737702974991111e-05,
      "loss": 0.9564,
      "step": 5690
    },
    {
      "epoch": 1.8239999999999998,
      "grad_norm": 0.3405170142650604,
      "learning_rate": 8.71399786654024e-05,
      "loss": 0.9781,
      "step": 5700
    },
    {
      "epoch": 1.8239999999999998,
      "eval_loss": 1.071352481842041,
      "eval_runtime": 2.3437,
      "eval_samples_per_second": 85.336,
      "eval_steps_per_second": 1.707,
      "step": 5700
    },
    {
      "epoch": 1.8272,
      "grad_norm": 0.29885199666023254,
      "learning_rate": 8.690292758089369e-05,
      "loss": 1.0072,
      "step": 5710
    },
    {
      "epoch": 1.8304,
      "grad_norm": 0.34125611186027527,
      "learning_rate": 8.666587649638498e-05,
      "loss": 1.0806,
      "step": 5720
    },
    {
      "epoch": 1.8336000000000001,
      "grad_norm": 0.30638664960861206,
      "learning_rate": 8.642882541187627e-05,
      "loss": 0.8916,
      "step": 5730
    },
    {
      "epoch": 1.8368,
      "grad_norm": 0.32176026701927185,
      "learning_rate": 8.619177432736754e-05,
      "loss": 0.9721,
      "step": 5740
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 0.45421457290649414,
      "learning_rate": 8.595472324285884e-05,
      "loss": 1.0355,
      "step": 5750
    },
    {
      "epoch": 1.8399999999999999,
      "eval_loss": 1.070460557937622,
      "eval_runtime": 2.3438,
      "eval_samples_per_second": 85.333,
      "eval_steps_per_second": 1.707,
      "step": 5750
    },
    {
      "epoch": 1.8432,
      "grad_norm": 0.29107239842414856,
      "learning_rate": 8.571767215835013e-05,
      "loss": 0.928,
      "step": 5760
    },
    {
      "epoch": 1.8464,
      "grad_norm": 0.3310083746910095,
      "learning_rate": 8.548062107384142e-05,
      "loss": 1.0023,
      "step": 5770
    },
    {
      "epoch": 1.8496000000000001,
      "grad_norm": 0.35118168592453003,
      "learning_rate": 8.524356998933271e-05,
      "loss": 1.0273,
      "step": 5780
    },
    {
      "epoch": 1.8528,
      "grad_norm": 0.2796842157840729,
      "learning_rate": 8.5006518904824e-05,
      "loss": 0.9909,
      "step": 5790
    },
    {
      "epoch": 1.8559999999999999,
      "grad_norm": 0.3329971134662628,
      "learning_rate": 8.476946782031528e-05,
      "loss": 0.9268,
      "step": 5800
    },
    {
      "epoch": 1.8559999999999999,
      "eval_loss": 1.0732998847961426,
      "eval_runtime": 2.3405,
      "eval_samples_per_second": 85.451,
      "eval_steps_per_second": 1.709,
      "step": 5800
    },
    {
      "epoch": 1.8592,
      "grad_norm": 0.32215815782546997,
      "learning_rate": 8.453241673580657e-05,
      "loss": 1.0066,
      "step": 5810
    },
    {
      "epoch": 1.8624,
      "grad_norm": 0.28294140100479126,
      "learning_rate": 8.429536565129786e-05,
      "loss": 0.9938,
      "step": 5820
    },
    {
      "epoch": 1.8656000000000001,
      "grad_norm": 0.3409128189086914,
      "learning_rate": 8.405831456678915e-05,
      "loss": 0.9784,
      "step": 5830
    },
    {
      "epoch": 1.8688,
      "grad_norm": 0.3675197660923004,
      "learning_rate": 8.382126348228044e-05,
      "loss": 1.0168,
      "step": 5840
    },
    {
      "epoch": 1.8719999999999999,
      "grad_norm": 0.3248993456363678,
      "learning_rate": 8.358421239777173e-05,
      "loss": 1.0236,
      "step": 5850
    },
    {
      "epoch": 1.8719999999999999,
      "eval_loss": 1.0724382400512695,
      "eval_runtime": 2.341,
      "eval_samples_per_second": 85.433,
      "eval_steps_per_second": 1.709,
      "step": 5850
    },
    {
      "epoch": 1.8752,
      "grad_norm": 0.33669787645339966,
      "learning_rate": 8.334716131326301e-05,
      "loss": 1.0139,
      "step": 5860
    },
    {
      "epoch": 1.8784,
      "grad_norm": 0.2953921854496002,
      "learning_rate": 8.31101102287543e-05,
      "loss": 0.9649,
      "step": 5870
    },
    {
      "epoch": 1.8816000000000002,
      "grad_norm": 0.30307215452194214,
      "learning_rate": 8.287305914424559e-05,
      "loss": 0.9877,
      "step": 5880
    },
    {
      "epoch": 1.8848,
      "grad_norm": 0.30811607837677,
      "learning_rate": 8.263600805973688e-05,
      "loss": 0.9967,
      "step": 5890
    },
    {
      "epoch": 1.888,
      "grad_norm": 0.33569836616516113,
      "learning_rate": 8.239895697522817e-05,
      "loss": 0.9494,
      "step": 5900
    },
    {
      "epoch": 1.888,
      "eval_loss": 1.072950005531311,
      "eval_runtime": 2.3405,
      "eval_samples_per_second": 85.453,
      "eval_steps_per_second": 1.709,
      "step": 5900
    },
    {
      "epoch": 1.8912,
      "grad_norm": 0.3191186785697937,
      "learning_rate": 8.216190589071945e-05,
      "loss": 0.9365,
      "step": 5910
    },
    {
      "epoch": 1.8944,
      "grad_norm": 0.3310295045375824,
      "learning_rate": 8.192485480621074e-05,
      "loss": 1.0122,
      "step": 5920
    },
    {
      "epoch": 1.8976,
      "grad_norm": 0.29922014474868774,
      "learning_rate": 8.168780372170203e-05,
      "loss": 1.0171,
      "step": 5930
    },
    {
      "epoch": 1.9008,
      "grad_norm": 0.29868146777153015,
      "learning_rate": 8.145075263719332e-05,
      "loss": 0.9937,
      "step": 5940
    },
    {
      "epoch": 1.904,
      "grad_norm": 0.3396550118923187,
      "learning_rate": 8.121370155268461e-05,
      "loss": 0.9761,
      "step": 5950
    },
    {
      "epoch": 1.904,
      "eval_loss": 1.0713688135147095,
      "eval_runtime": 2.3407,
      "eval_samples_per_second": 85.445,
      "eval_steps_per_second": 1.709,
      "step": 5950
    },
    {
      "epoch": 1.9072,
      "grad_norm": 0.3706649839878082,
      "learning_rate": 8.09766504681759e-05,
      "loss": 1.0568,
      "step": 5960
    },
    {
      "epoch": 1.9104,
      "grad_norm": 0.2989679276943207,
      "learning_rate": 8.073959938366718e-05,
      "loss": 0.9632,
      "step": 5970
    },
    {
      "epoch": 1.9136,
      "grad_norm": 0.3709696829319,
      "learning_rate": 8.050254829915847e-05,
      "loss": 1.0216,
      "step": 5980
    },
    {
      "epoch": 1.9167999999999998,
      "grad_norm": 0.30102211236953735,
      "learning_rate": 8.026549721464976e-05,
      "loss": 0.9075,
      "step": 5990
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.28930234909057617,
      "learning_rate": 8.002844613014105e-05,
      "loss": 1.0441,
      "step": 6000
    },
    {
      "epoch": 1.92,
      "eval_loss": 1.0698007345199585,
      "eval_runtime": 2.3419,
      "eval_samples_per_second": 85.4,
      "eval_steps_per_second": 1.708,
      "step": 6000
    },
    {
      "epoch": 1.9232,
      "grad_norm": 0.3127020001411438,
      "learning_rate": 7.979139504563234e-05,
      "loss": 0.9212,
      "step": 6010
    },
    {
      "epoch": 1.9264000000000001,
      "grad_norm": 0.2878767251968384,
      "learning_rate": 7.955434396112363e-05,
      "loss": 0.9325,
      "step": 6020
    },
    {
      "epoch": 1.9296,
      "grad_norm": 0.32819685339927673,
      "learning_rate": 7.931729287661491e-05,
      "loss": 1.0304,
      "step": 6030
    },
    {
      "epoch": 1.9327999999999999,
      "grad_norm": 0.31096670031547546,
      "learning_rate": 7.90802417921062e-05,
      "loss": 0.9761,
      "step": 6040
    },
    {
      "epoch": 1.936,
      "grad_norm": 0.30861896276474,
      "learning_rate": 7.884319070759749e-05,
      "loss": 0.9523,
      "step": 6050
    },
    {
      "epoch": 1.936,
      "eval_loss": 1.0723209381103516,
      "eval_runtime": 2.3399,
      "eval_samples_per_second": 85.473,
      "eval_steps_per_second": 1.709,
      "step": 6050
    },
    {
      "epoch": 1.9392,
      "grad_norm": 0.36495769023895264,
      "learning_rate": 7.860613962308878e-05,
      "loss": 0.959,
      "step": 6060
    },
    {
      "epoch": 1.9424000000000001,
      "grad_norm": 0.31856563687324524,
      "learning_rate": 7.836908853858007e-05,
      "loss": 0.9846,
      "step": 6070
    },
    {
      "epoch": 1.9456,
      "grad_norm": 0.3183017075061798,
      "learning_rate": 7.813203745407136e-05,
      "loss": 0.9246,
      "step": 6080
    },
    {
      "epoch": 1.9487999999999999,
      "grad_norm": 0.35947927832603455,
      "learning_rate": 7.789498636956264e-05,
      "loss": 0.925,
      "step": 6090
    },
    {
      "epoch": 1.952,
      "grad_norm": 0.35415616631507874,
      "learning_rate": 7.765793528505393e-05,
      "loss": 0.9982,
      "step": 6100
    },
    {
      "epoch": 1.952,
      "eval_loss": 1.0703243017196655,
      "eval_runtime": 2.3399,
      "eval_samples_per_second": 85.475,
      "eval_steps_per_second": 1.71,
      "step": 6100
    },
    {
      "epoch": 1.9552,
      "grad_norm": 0.2964349389076233,
      "learning_rate": 7.742088420054522e-05,
      "loss": 0.9896,
      "step": 6110
    },
    {
      "epoch": 1.9584000000000001,
      "grad_norm": 0.3328509032726288,
      "learning_rate": 7.718383311603651e-05,
      "loss": 0.9482,
      "step": 6120
    },
    {
      "epoch": 1.9616,
      "grad_norm": 0.33828938007354736,
      "learning_rate": 7.69467820315278e-05,
      "loss": 1.0147,
      "step": 6130
    },
    {
      "epoch": 1.9647999999999999,
      "grad_norm": 0.3032509386539459,
      "learning_rate": 7.670973094701909e-05,
      "loss": 0.9768,
      "step": 6140
    },
    {
      "epoch": 1.968,
      "grad_norm": 0.28736600279808044,
      "learning_rate": 7.647267986251037e-05,
      "loss": 1.0093,
      "step": 6150
    },
    {
      "epoch": 1.968,
      "eval_loss": 1.0724540948867798,
      "eval_runtime": 2.3397,
      "eval_samples_per_second": 85.482,
      "eval_steps_per_second": 1.71,
      "step": 6150
    },
    {
      "epoch": 1.9712,
      "grad_norm": 0.4117024540901184,
      "learning_rate": 7.623562877800166e-05,
      "loss": 0.9775,
      "step": 6160
    },
    {
      "epoch": 1.9744000000000002,
      "grad_norm": 0.34639352560043335,
      "learning_rate": 7.599857769349295e-05,
      "loss": 0.9749,
      "step": 6170
    },
    {
      "epoch": 1.9776,
      "grad_norm": 0.3292696475982666,
      "learning_rate": 7.576152660898424e-05,
      "loss": 0.9475,
      "step": 6180
    },
    {
      "epoch": 1.9808,
      "grad_norm": 0.35012632608413696,
      "learning_rate": 7.552447552447553e-05,
      "loss": 1.015,
      "step": 6190
    },
    {
      "epoch": 1.984,
      "grad_norm": 0.3479633033275604,
      "learning_rate": 7.528742443996681e-05,
      "loss": 1.0012,
      "step": 6200
    },
    {
      "epoch": 1.984,
      "eval_loss": 1.0718684196472168,
      "eval_runtime": 2.3404,
      "eval_samples_per_second": 85.456,
      "eval_steps_per_second": 1.709,
      "step": 6200
    },
    {
      "epoch": 1.9872,
      "grad_norm": 0.29099568724632263,
      "learning_rate": 7.50503733554581e-05,
      "loss": 1.0099,
      "step": 6210
    },
    {
      "epoch": 1.9904,
      "grad_norm": 0.27459457516670227,
      "learning_rate": 7.481332227094939e-05,
      "loss": 0.9455,
      "step": 6220
    },
    {
      "epoch": 1.9936,
      "grad_norm": 0.3441794216632843,
      "learning_rate": 7.457627118644068e-05,
      "loss": 0.9989,
      "step": 6230
    },
    {
      "epoch": 1.9968,
      "grad_norm": 0.3158603608608246,
      "learning_rate": 7.433922010193197e-05,
      "loss": 0.9418,
      "step": 6240
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.28948336839675903,
      "learning_rate": 7.410216901742326e-05,
      "loss": 0.905,
      "step": 6250
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.0738133192062378,
      "eval_runtime": 2.3402,
      "eval_samples_per_second": 85.463,
      "eval_steps_per_second": 1.709,
      "step": 6250
    },
    {
      "epoch": 2.0032,
      "grad_norm": 0.33280742168426514,
      "learning_rate": 7.386511793291456e-05,
      "loss": 0.9766,
      "step": 6260
    },
    {
      "epoch": 2.0064,
      "grad_norm": 0.3105956017971039,
      "learning_rate": 7.362806684840583e-05,
      "loss": 0.916,
      "step": 6270
    },
    {
      "epoch": 2.0096,
      "grad_norm": 0.3048095703125,
      "learning_rate": 7.339101576389712e-05,
      "loss": 0.9472,
      "step": 6280
    },
    {
      "epoch": 2.0128,
      "grad_norm": 0.3121451735496521,
      "learning_rate": 7.315396467938841e-05,
      "loss": 0.9672,
      "step": 6290
    },
    {
      "epoch": 2.016,
      "grad_norm": 0.3451061248779297,
      "learning_rate": 7.29169135948797e-05,
      "loss": 1.0133,
      "step": 6300
    },
    {
      "epoch": 2.016,
      "eval_loss": 1.0764145851135254,
      "eval_runtime": 2.3393,
      "eval_samples_per_second": 85.495,
      "eval_steps_per_second": 1.71,
      "step": 6300
    },
    {
      "epoch": 2.0192,
      "grad_norm": 0.40722838044166565,
      "learning_rate": 7.267986251037099e-05,
      "loss": 1.1028,
      "step": 6310
    },
    {
      "epoch": 2.0224,
      "grad_norm": 0.286448210477829,
      "learning_rate": 7.244281142586227e-05,
      "loss": 0.9936,
      "step": 6320
    },
    {
      "epoch": 2.0256,
      "grad_norm": 0.3103068768978119,
      "learning_rate": 7.220576034135356e-05,
      "loss": 0.9724,
      "step": 6330
    },
    {
      "epoch": 2.0288,
      "grad_norm": 0.32056087255477905,
      "learning_rate": 7.196870925684485e-05,
      "loss": 1.0018,
      "step": 6340
    },
    {
      "epoch": 2.032,
      "grad_norm": 0.3672875761985779,
      "learning_rate": 7.173165817233615e-05,
      "loss": 0.8802,
      "step": 6350
    },
    {
      "epoch": 2.032,
      "eval_loss": 1.0722053050994873,
      "eval_runtime": 2.3411,
      "eval_samples_per_second": 85.429,
      "eval_steps_per_second": 1.709,
      "step": 6350
    },
    {
      "epoch": 2.0352,
      "grad_norm": 0.3783678710460663,
      "learning_rate": 7.149460708782743e-05,
      "loss": 1.0311,
      "step": 6360
    },
    {
      "epoch": 2.0384,
      "grad_norm": 0.35119861364364624,
      "learning_rate": 7.125755600331872e-05,
      "loss": 1.0033,
      "step": 6370
    },
    {
      "epoch": 2.0416,
      "grad_norm": 0.31143516302108765,
      "learning_rate": 7.102050491881e-05,
      "loss": 0.9786,
      "step": 6380
    },
    {
      "epoch": 2.0448,
      "grad_norm": 0.3367307782173157,
      "learning_rate": 7.078345383430129e-05,
      "loss": 0.9593,
      "step": 6390
    },
    {
      "epoch": 2.048,
      "grad_norm": 0.3894195854663849,
      "learning_rate": 7.054640274979258e-05,
      "loss": 0.9946,
      "step": 6400
    },
    {
      "epoch": 2.048,
      "eval_loss": 1.0714644193649292,
      "eval_runtime": 2.3402,
      "eval_samples_per_second": 85.463,
      "eval_steps_per_second": 1.709,
      "step": 6400
    },
    {
      "epoch": 2.0512,
      "grad_norm": 0.3219103515148163,
      "learning_rate": 7.030935166528387e-05,
      "loss": 0.9264,
      "step": 6410
    },
    {
      "epoch": 2.0544,
      "grad_norm": 0.35747870802879333,
      "learning_rate": 7.007230058077516e-05,
      "loss": 0.9781,
      "step": 6420
    },
    {
      "epoch": 2.0576,
      "grad_norm": 0.33157646656036377,
      "learning_rate": 6.983524949626646e-05,
      "loss": 1.0116,
      "step": 6430
    },
    {
      "epoch": 2.0608,
      "grad_norm": 0.294281005859375,
      "learning_rate": 6.959819841175775e-05,
      "loss": 0.9875,
      "step": 6440
    },
    {
      "epoch": 2.064,
      "grad_norm": 0.36521679162979126,
      "learning_rate": 6.936114732724902e-05,
      "loss": 0.9996,
      "step": 6450
    },
    {
      "epoch": 2.064,
      "eval_loss": 1.0722731351852417,
      "eval_runtime": 2.3417,
      "eval_samples_per_second": 85.408,
      "eval_steps_per_second": 1.708,
      "step": 6450
    },
    {
      "epoch": 2.0672,
      "grad_norm": 0.3672275245189667,
      "learning_rate": 6.912409624274031e-05,
      "loss": 0.9479,
      "step": 6460
    },
    {
      "epoch": 2.0704,
      "grad_norm": 0.3884342610836029,
      "learning_rate": 6.88870451582316e-05,
      "loss": 1.0511,
      "step": 6470
    },
    {
      "epoch": 2.0736,
      "grad_norm": 0.35907524824142456,
      "learning_rate": 6.864999407372289e-05,
      "loss": 0.9639,
      "step": 6480
    },
    {
      "epoch": 2.0768,
      "grad_norm": 0.365988552570343,
      "learning_rate": 6.841294298921418e-05,
      "loss": 1.019,
      "step": 6490
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.34814712405204773,
      "learning_rate": 6.817589190470546e-05,
      "loss": 1.0253,
      "step": 6500
    },
    {
      "epoch": 2.08,
      "eval_loss": 1.0721666812896729,
      "eval_runtime": 2.3403,
      "eval_samples_per_second": 85.458,
      "eval_steps_per_second": 1.709,
      "step": 6500
    },
    {
      "epoch": 2.0832,
      "grad_norm": 0.29152652621269226,
      "learning_rate": 6.793884082019677e-05,
      "loss": 0.9562,
      "step": 6510
    },
    {
      "epoch": 2.0864,
      "grad_norm": 0.3315017819404602,
      "learning_rate": 6.770178973568805e-05,
      "loss": 1.0013,
      "step": 6520
    },
    {
      "epoch": 2.0896,
      "grad_norm": 0.39563992619514465,
      "learning_rate": 6.746473865117934e-05,
      "loss": 1.0142,
      "step": 6530
    },
    {
      "epoch": 2.0928,
      "grad_norm": 0.2727348208427429,
      "learning_rate": 6.722768756667062e-05,
      "loss": 0.951,
      "step": 6540
    },
    {
      "epoch": 2.096,
      "grad_norm": 0.3230901062488556,
      "learning_rate": 6.69906364821619e-05,
      "loss": 0.9926,
      "step": 6550
    },
    {
      "epoch": 2.096,
      "eval_loss": 1.0743050575256348,
      "eval_runtime": 2.3419,
      "eval_samples_per_second": 85.4,
      "eval_steps_per_second": 1.708,
      "step": 6550
    },
    {
      "epoch": 2.0992,
      "grad_norm": 0.36114129424095154,
      "learning_rate": 6.675358539765319e-05,
      "loss": 0.9526,
      "step": 6560
    },
    {
      "epoch": 2.1024,
      "grad_norm": 0.293741911649704,
      "learning_rate": 6.651653431314448e-05,
      "loss": 0.9511,
      "step": 6570
    },
    {
      "epoch": 2.1056,
      "grad_norm": 0.33204761147499084,
      "learning_rate": 6.627948322863577e-05,
      "loss": 0.9944,
      "step": 6580
    },
    {
      "epoch": 2.1088,
      "grad_norm": 0.2727949619293213,
      "learning_rate": 6.604243214412706e-05,
      "loss": 0.9594,
      "step": 6590
    },
    {
      "epoch": 2.112,
      "grad_norm": 0.3032010495662689,
      "learning_rate": 6.580538105961836e-05,
      "loss": 1.012,
      "step": 6600
    },
    {
      "epoch": 2.112,
      "eval_loss": 1.0750460624694824,
      "eval_runtime": 2.3412,
      "eval_samples_per_second": 85.427,
      "eval_steps_per_second": 1.709,
      "step": 6600
    },
    {
      "epoch": 2.1152,
      "grad_norm": 0.3283332288265228,
      "learning_rate": 6.556832997510965e-05,
      "loss": 1.0376,
      "step": 6610
    },
    {
      "epoch": 2.1184,
      "grad_norm": 0.2927992343902588,
      "learning_rate": 6.533127889060092e-05,
      "loss": 0.9881,
      "step": 6620
    },
    {
      "epoch": 2.1216,
      "grad_norm": 0.40566474199295044,
      "learning_rate": 6.509422780609221e-05,
      "loss": 0.968,
      "step": 6630
    },
    {
      "epoch": 2.1248,
      "grad_norm": 0.3643237054347992,
      "learning_rate": 6.48571767215835e-05,
      "loss": 1.0705,
      "step": 6640
    },
    {
      "epoch": 2.128,
      "grad_norm": 0.3265420198440552,
      "learning_rate": 6.462012563707479e-05,
      "loss": 0.9589,
      "step": 6650
    },
    {
      "epoch": 2.128,
      "eval_loss": 1.0749175548553467,
      "eval_runtime": 2.3409,
      "eval_samples_per_second": 85.438,
      "eval_steps_per_second": 1.709,
      "step": 6650
    },
    {
      "epoch": 2.1312,
      "grad_norm": 0.3351059556007385,
      "learning_rate": 6.438307455256608e-05,
      "loss": 0.963,
      "step": 6660
    },
    {
      "epoch": 2.1344,
      "grad_norm": 0.3354058861732483,
      "learning_rate": 6.414602346805736e-05,
      "loss": 1.0016,
      "step": 6670
    },
    {
      "epoch": 2.1376,
      "grad_norm": 0.3259466886520386,
      "learning_rate": 6.390897238354867e-05,
      "loss": 0.9058,
      "step": 6680
    },
    {
      "epoch": 2.1408,
      "grad_norm": 0.33937230706214905,
      "learning_rate": 6.367192129903995e-05,
      "loss": 0.9972,
      "step": 6690
    },
    {
      "epoch": 2.144,
      "grad_norm": 0.3298225998878479,
      "learning_rate": 6.343487021453124e-05,
      "loss": 0.9389,
      "step": 6700
    },
    {
      "epoch": 2.144,
      "eval_loss": 1.0759766101837158,
      "eval_runtime": 2.3403,
      "eval_samples_per_second": 85.458,
      "eval_steps_per_second": 1.709,
      "step": 6700
    },
    {
      "epoch": 2.1471999999999998,
      "grad_norm": 0.3088163137435913,
      "learning_rate": 6.319781913002252e-05,
      "loss": 0.9475,
      "step": 6710
    },
    {
      "epoch": 2.1504,
      "grad_norm": 0.3653947114944458,
      "learning_rate": 6.29607680455138e-05,
      "loss": 0.9685,
      "step": 6720
    },
    {
      "epoch": 2.1536,
      "grad_norm": 0.32582271099090576,
      "learning_rate": 6.27237169610051e-05,
      "loss": 0.9235,
      "step": 6730
    },
    {
      "epoch": 2.1568,
      "grad_norm": 0.4983645975589752,
      "learning_rate": 6.248666587649638e-05,
      "loss": 0.9003,
      "step": 6740
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.3295983672142029,
      "learning_rate": 6.224961479198767e-05,
      "loss": 1.0305,
      "step": 6750
    },
    {
      "epoch": 2.16,
      "eval_loss": 1.074292778968811,
      "eval_runtime": 2.3405,
      "eval_samples_per_second": 85.453,
      "eval_steps_per_second": 1.709,
      "step": 6750
    },
    {
      "epoch": 2.1632,
      "grad_norm": 0.31040143966674805,
      "learning_rate": 6.201256370747897e-05,
      "loss": 0.995,
      "step": 6760
    },
    {
      "epoch": 2.1664,
      "grad_norm": 0.3480767607688904,
      "learning_rate": 6.177551262297026e-05,
      "loss": 0.8835,
      "step": 6770
    },
    {
      "epoch": 2.1696,
      "grad_norm": 0.38927161693573,
      "learning_rate": 6.153846153846155e-05,
      "loss": 1.0067,
      "step": 6780
    },
    {
      "epoch": 2.1728,
      "grad_norm": 0.39523404836654663,
      "learning_rate": 6.130141045395284e-05,
      "loss": 0.9466,
      "step": 6790
    },
    {
      "epoch": 2.176,
      "grad_norm": 0.31325143575668335,
      "learning_rate": 6.106435936944411e-05,
      "loss": 0.939,
      "step": 6800
    },
    {
      "epoch": 2.176,
      "eval_loss": 1.071377158164978,
      "eval_runtime": 2.3425,
      "eval_samples_per_second": 85.378,
      "eval_steps_per_second": 1.708,
      "step": 6800
    },
    {
      "epoch": 2.1792,
      "grad_norm": 0.28601714968681335,
      "learning_rate": 6.08273082849354e-05,
      "loss": 0.9537,
      "step": 6810
    },
    {
      "epoch": 2.1824,
      "grad_norm": 0.36575964093208313,
      "learning_rate": 6.0590257200426695e-05,
      "loss": 1.0047,
      "step": 6820
    },
    {
      "epoch": 2.1856,
      "grad_norm": 0.3716566264629364,
      "learning_rate": 6.035320611591798e-05,
      "loss": 1.0218,
      "step": 6830
    },
    {
      "epoch": 2.1888,
      "grad_norm": 0.37006062269210815,
      "learning_rate": 6.011615503140927e-05,
      "loss": 0.964,
      "step": 6840
    },
    {
      "epoch": 2.192,
      "grad_norm": 0.3331722319126129,
      "learning_rate": 5.987910394690056e-05,
      "loss": 0.9895,
      "step": 6850
    },
    {
      "epoch": 2.192,
      "eval_loss": 1.0708049535751343,
      "eval_runtime": 2.3403,
      "eval_samples_per_second": 85.459,
      "eval_steps_per_second": 1.709,
      "step": 6850
    },
    {
      "epoch": 2.1952,
      "grad_norm": 0.387960821390152,
      "learning_rate": 5.964205286239185e-05,
      "loss": 0.9504,
      "step": 6860
    },
    {
      "epoch": 2.1984,
      "grad_norm": 0.30300039052963257,
      "learning_rate": 5.940500177788314e-05,
      "loss": 0.9289,
      "step": 6870
    },
    {
      "epoch": 2.2016,
      "grad_norm": 0.375034898519516,
      "learning_rate": 5.916795069337443e-05,
      "loss": 0.9659,
      "step": 6880
    },
    {
      "epoch": 2.2048,
      "grad_norm": 0.3288053572177887,
      "learning_rate": 5.8930899608865706e-05,
      "loss": 0.9304,
      "step": 6890
    },
    {
      "epoch": 2.208,
      "grad_norm": 0.3189418911933899,
      "learning_rate": 5.8693848524357e-05,
      "loss": 0.9274,
      "step": 6900
    },
    {
      "epoch": 2.208,
      "eval_loss": 1.073197603225708,
      "eval_runtime": 2.3404,
      "eval_samples_per_second": 85.457,
      "eval_steps_per_second": 1.709,
      "step": 6900
    },
    {
      "epoch": 2.2112,
      "grad_norm": 0.3143325448036194,
      "learning_rate": 5.845679743984829e-05,
      "loss": 0.9275,
      "step": 6910
    },
    {
      "epoch": 2.2144,
      "grad_norm": 0.35258951783180237,
      "learning_rate": 5.821974635533958e-05,
      "loss": 0.9833,
      "step": 6920
    },
    {
      "epoch": 2.2176,
      "grad_norm": 0.3657931685447693,
      "learning_rate": 5.7982695270830866e-05,
      "loss": 1.0146,
      "step": 6930
    },
    {
      "epoch": 2.2208,
      "grad_norm": 0.35542032122612,
      "learning_rate": 5.7745644186322154e-05,
      "loss": 0.9331,
      "step": 6940
    },
    {
      "epoch": 2.224,
      "grad_norm": 0.3095228672027588,
      "learning_rate": 5.750859310181344e-05,
      "loss": 0.9839,
      "step": 6950
    },
    {
      "epoch": 2.224,
      "eval_loss": 1.0721142292022705,
      "eval_runtime": 2.3401,
      "eval_samples_per_second": 85.467,
      "eval_steps_per_second": 1.709,
      "step": 6950
    },
    {
      "epoch": 2.2272,
      "grad_norm": 0.3084930181503296,
      "learning_rate": 5.727154201730474e-05,
      "loss": 0.9583,
      "step": 6960
    },
    {
      "epoch": 2.2304,
      "grad_norm": 0.4106477200984955,
      "learning_rate": 5.7034490932796026e-05,
      "loss": 0.9835,
      "step": 6970
    },
    {
      "epoch": 2.2336,
      "grad_norm": 0.32001373171806335,
      "learning_rate": 5.67974398482873e-05,
      "loss": 0.9646,
      "step": 6980
    },
    {
      "epoch": 2.2368,
      "grad_norm": 0.3887721002101898,
      "learning_rate": 5.6560388763778596e-05,
      "loss": 0.9699,
      "step": 6990
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.31724813580513,
      "learning_rate": 5.6323337679269884e-05,
      "loss": 0.9419,
      "step": 7000
    },
    {
      "epoch": 2.24,
      "eval_loss": 1.0711947679519653,
      "eval_runtime": 2.3417,
      "eval_samples_per_second": 85.408,
      "eval_steps_per_second": 1.708,
      "step": 7000
    },
    {
      "epoch": 2.2432,
      "grad_norm": 0.31025880575180054,
      "learning_rate": 5.608628659476117e-05,
      "loss": 0.9293,
      "step": 7010
    },
    {
      "epoch": 2.2464,
      "grad_norm": 0.37720346450805664,
      "learning_rate": 5.584923551025246e-05,
      "loss": 0.9905,
      "step": 7020
    },
    {
      "epoch": 2.2496,
      "grad_norm": 0.3349294364452362,
      "learning_rate": 5.561218442574375e-05,
      "loss": 0.9435,
      "step": 7030
    },
    {
      "epoch": 2.2528,
      "grad_norm": 0.3071615397930145,
      "learning_rate": 5.5375133341235044e-05,
      "loss": 0.8767,
      "step": 7040
    },
    {
      "epoch": 2.2560000000000002,
      "grad_norm": 0.37924298644065857,
      "learning_rate": 5.513808225672633e-05,
      "loss": 0.9511,
      "step": 7050
    },
    {
      "epoch": 2.2560000000000002,
      "eval_loss": 1.0716842412948608,
      "eval_runtime": 2.3408,
      "eval_samples_per_second": 85.442,
      "eval_steps_per_second": 1.709,
      "step": 7050
    },
    {
      "epoch": 2.2592,
      "grad_norm": 0.34547659754753113,
      "learning_rate": 5.490103117221762e-05,
      "loss": 0.9716,
      "step": 7060
    },
    {
      "epoch": 2.2624,
      "grad_norm": 0.344346821308136,
      "learning_rate": 5.46639800877089e-05,
      "loss": 1.0169,
      "step": 7070
    },
    {
      "epoch": 2.2656,
      "grad_norm": 0.4094424545764923,
      "learning_rate": 5.442692900320019e-05,
      "loss": 0.9839,
      "step": 7080
    },
    {
      "epoch": 2.2688,
      "grad_norm": 0.3117005527019501,
      "learning_rate": 5.418987791869148e-05,
      "loss": 1.0032,
      "step": 7090
    },
    {
      "epoch": 2.2720000000000002,
      "grad_norm": 0.40438252687454224,
      "learning_rate": 5.395282683418277e-05,
      "loss": 1.0303,
      "step": 7100
    },
    {
      "epoch": 2.2720000000000002,
      "eval_loss": 1.0686700344085693,
      "eval_runtime": 2.341,
      "eval_samples_per_second": 85.433,
      "eval_steps_per_second": 1.709,
      "step": 7100
    },
    {
      "epoch": 2.2752,
      "grad_norm": 0.3767719864845276,
      "learning_rate": 5.3715775749674055e-05,
      "loss": 0.9914,
      "step": 7110
    },
    {
      "epoch": 2.2784,
      "grad_norm": 0.3158678114414215,
      "learning_rate": 5.347872466516535e-05,
      "loss": 0.9636,
      "step": 7120
    },
    {
      "epoch": 2.2816,
      "grad_norm": 0.2966751754283905,
      "learning_rate": 5.324167358065664e-05,
      "loss": 1.0034,
      "step": 7130
    },
    {
      "epoch": 2.2848,
      "grad_norm": 0.3081394135951996,
      "learning_rate": 5.300462249614793e-05,
      "loss": 0.946,
      "step": 7140
    },
    {
      "epoch": 2.288,
      "grad_norm": 0.36231619119644165,
      "learning_rate": 5.2767571411639215e-05,
      "loss": 0.9097,
      "step": 7150
    },
    {
      "epoch": 2.288,
      "eval_loss": 1.0694172382354736,
      "eval_runtime": 2.341,
      "eval_samples_per_second": 85.433,
      "eval_steps_per_second": 1.709,
      "step": 7150
    },
    {
      "epoch": 2.2912,
      "grad_norm": 0.36614611744880676,
      "learning_rate": 5.2530520327130497e-05,
      "loss": 0.9488,
      "step": 7160
    },
    {
      "epoch": 2.2944,
      "grad_norm": 0.35046717524528503,
      "learning_rate": 5.2293469242621785e-05,
      "loss": 0.9221,
      "step": 7170
    },
    {
      "epoch": 2.2976,
      "grad_norm": 0.33013805747032166,
      "learning_rate": 5.205641815811307e-05,
      "loss": 0.8621,
      "step": 7180
    },
    {
      "epoch": 2.3008,
      "grad_norm": 0.3413900136947632,
      "learning_rate": 5.181936707360436e-05,
      "loss": 0.9747,
      "step": 7190
    },
    {
      "epoch": 2.304,
      "grad_norm": 0.3913830816745758,
      "learning_rate": 5.158231598909565e-05,
      "loss": 1.0168,
      "step": 7200
    },
    {
      "epoch": 2.304,
      "eval_loss": 1.0689713954925537,
      "eval_runtime": 2.3406,
      "eval_samples_per_second": 85.449,
      "eval_steps_per_second": 1.709,
      "step": 7200
    },
    {
      "epoch": 2.3072,
      "grad_norm": 0.3595251142978668,
      "learning_rate": 5.1345264904586945e-05,
      "loss": 0.9593,
      "step": 7210
    },
    {
      "epoch": 2.3104,
      "grad_norm": 0.35284584760665894,
      "learning_rate": 5.110821382007823e-05,
      "loss": 0.9943,
      "step": 7220
    },
    {
      "epoch": 2.3136,
      "grad_norm": 0.38188451528549194,
      "learning_rate": 5.087116273556952e-05,
      "loss": 1.0744,
      "step": 7230
    },
    {
      "epoch": 2.3168,
      "grad_norm": 0.3199000954627991,
      "learning_rate": 5.063411165106081e-05,
      "loss": 0.9608,
      "step": 7240
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.37118634581565857,
      "learning_rate": 5.039706056655209e-05,
      "loss": 0.973,
      "step": 7250
    },
    {
      "epoch": 2.32,
      "eval_loss": 1.0678654909133911,
      "eval_runtime": 2.34,
      "eval_samples_per_second": 85.471,
      "eval_steps_per_second": 1.709,
      "step": 7250
    },
    {
      "epoch": 2.3232,
      "grad_norm": 0.34442928433418274,
      "learning_rate": 5.016000948204338e-05,
      "loss": 0.9563,
      "step": 7260
    },
    {
      "epoch": 2.3264,
      "grad_norm": 0.3819333612918854,
      "learning_rate": 4.992295839753467e-05,
      "loss": 0.9909,
      "step": 7270
    },
    {
      "epoch": 2.3296,
      "grad_norm": 0.2799692451953888,
      "learning_rate": 4.9685907313025956e-05,
      "loss": 0.966,
      "step": 7280
    },
    {
      "epoch": 2.3327999999999998,
      "grad_norm": 0.35742002725601196,
      "learning_rate": 4.944885622851725e-05,
      "loss": 0.9988,
      "step": 7290
    },
    {
      "epoch": 2.336,
      "grad_norm": 0.3064686357975006,
      "learning_rate": 4.921180514400854e-05,
      "loss": 0.9884,
      "step": 7300
    },
    {
      "epoch": 2.336,
      "eval_loss": 1.0688846111297607,
      "eval_runtime": 2.3409,
      "eval_samples_per_second": 85.439,
      "eval_steps_per_second": 1.709,
      "step": 7300
    },
    {
      "epoch": 2.3392,
      "grad_norm": 0.37882885336875916,
      "learning_rate": 4.897475405949982e-05,
      "loss": 0.9903,
      "step": 7310
    },
    {
      "epoch": 2.3424,
      "grad_norm": 0.3443366587162018,
      "learning_rate": 4.873770297499111e-05,
      "loss": 0.9454,
      "step": 7320
    },
    {
      "epoch": 2.3456,
      "grad_norm": 0.32272106409072876,
      "learning_rate": 4.8500651890482404e-05,
      "loss": 0.9683,
      "step": 7330
    },
    {
      "epoch": 2.3487999999999998,
      "grad_norm": 0.3658377528190613,
      "learning_rate": 4.826360080597369e-05,
      "loss": 0.9459,
      "step": 7340
    },
    {
      "epoch": 2.352,
      "grad_norm": 0.40348055958747864,
      "learning_rate": 4.802654972146498e-05,
      "loss": 0.9979,
      "step": 7350
    },
    {
      "epoch": 2.352,
      "eval_loss": 1.0665583610534668,
      "eval_runtime": 2.3411,
      "eval_samples_per_second": 85.43,
      "eval_steps_per_second": 1.709,
      "step": 7350
    },
    {
      "epoch": 2.3552,
      "grad_norm": 0.357089638710022,
      "learning_rate": 4.778949863695626e-05,
      "loss": 1.0039,
      "step": 7360
    },
    {
      "epoch": 2.3584,
      "grad_norm": 0.3176729381084442,
      "learning_rate": 4.755244755244756e-05,
      "loss": 0.9447,
      "step": 7370
    },
    {
      "epoch": 2.3616,
      "grad_norm": 0.32051849365234375,
      "learning_rate": 4.7315396467938846e-05,
      "loss": 0.9841,
      "step": 7380
    },
    {
      "epoch": 2.3648,
      "grad_norm": 0.3352671265602112,
      "learning_rate": 4.7078345383430134e-05,
      "loss": 0.99,
      "step": 7390
    },
    {
      "epoch": 2.368,
      "grad_norm": 0.31408312916755676,
      "learning_rate": 4.6841294298921415e-05,
      "loss": 0.9282,
      "step": 7400
    },
    {
      "epoch": 2.368,
      "eval_loss": 1.067991852760315,
      "eval_runtime": 2.3403,
      "eval_samples_per_second": 85.46,
      "eval_steps_per_second": 1.709,
      "step": 7400
    },
    {
      "epoch": 2.3712,
      "grad_norm": 0.3363882601261139,
      "learning_rate": 4.660424321441271e-05,
      "loss": 0.983,
      "step": 7410
    },
    {
      "epoch": 2.3744,
      "grad_norm": 0.3458035886287689,
      "learning_rate": 4.6367192129904e-05,
      "loss": 0.8992,
      "step": 7420
    },
    {
      "epoch": 2.3776,
      "grad_norm": 0.35502439737319946,
      "learning_rate": 4.613014104539529e-05,
      "loss": 0.9597,
      "step": 7430
    },
    {
      "epoch": 2.3808,
      "grad_norm": 0.3243822455406189,
      "learning_rate": 4.589308996088657e-05,
      "loss": 0.9593,
      "step": 7440
    },
    {
      "epoch": 2.384,
      "grad_norm": 0.29411715269088745,
      "learning_rate": 4.5656038876377864e-05,
      "loss": 0.8949,
      "step": 7450
    },
    {
      "epoch": 2.384,
      "eval_loss": 1.0685842037200928,
      "eval_runtime": 2.3403,
      "eval_samples_per_second": 85.46,
      "eval_steps_per_second": 1.709,
      "step": 7450
    },
    {
      "epoch": 2.3872,
      "grad_norm": 0.3772355914115906,
      "learning_rate": 4.541898779186915e-05,
      "loss": 0.98,
      "step": 7460
    },
    {
      "epoch": 2.3904,
      "grad_norm": 0.28651130199432373,
      "learning_rate": 4.518193670736044e-05,
      "loss": 0.9305,
      "step": 7470
    },
    {
      "epoch": 2.3936,
      "grad_norm": 0.3387807309627533,
      "learning_rate": 4.494488562285173e-05,
      "loss": 0.9799,
      "step": 7480
    },
    {
      "epoch": 2.3968,
      "grad_norm": 0.3075792193412781,
      "learning_rate": 4.470783453834301e-05,
      "loss": 0.9843,
      "step": 7490
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.4233008027076721,
      "learning_rate": 4.4470783453834305e-05,
      "loss": 1.0221,
      "step": 7500
    },
    {
      "epoch": 2.4,
      "eval_loss": 1.0674540996551514,
      "eval_runtime": 2.3403,
      "eval_samples_per_second": 85.459,
      "eval_steps_per_second": 1.709,
      "step": 7500
    },
    {
      "epoch": 2.4032,
      "grad_norm": 0.38025063276290894,
      "learning_rate": 4.423373236932559e-05,
      "loss": 0.902,
      "step": 7510
    },
    {
      "epoch": 2.4064,
      "grad_norm": 0.3521290719509125,
      "learning_rate": 4.399668128481688e-05,
      "loss": 0.8742,
      "step": 7520
    },
    {
      "epoch": 2.4096,
      "grad_norm": 0.32746827602386475,
      "learning_rate": 4.375963020030816e-05,
      "loss": 0.9213,
      "step": 7530
    },
    {
      "epoch": 2.4128,
      "grad_norm": 0.35088443756103516,
      "learning_rate": 4.352257911579946e-05,
      "loss": 1.0037,
      "step": 7540
    },
    {
      "epoch": 2.416,
      "grad_norm": 0.3290359675884247,
      "learning_rate": 4.3285528031290746e-05,
      "loss": 0.9691,
      "step": 7550
    },
    {
      "epoch": 2.416,
      "eval_loss": 1.067177176475525,
      "eval_runtime": 2.3432,
      "eval_samples_per_second": 85.355,
      "eval_steps_per_second": 1.707,
      "step": 7550
    },
    {
      "epoch": 2.4192,
      "grad_norm": 0.3541285991668701,
      "learning_rate": 4.3048476946782035e-05,
      "loss": 0.9833,
      "step": 7560
    },
    {
      "epoch": 2.4224,
      "grad_norm": 0.35512760281562805,
      "learning_rate": 4.281142586227332e-05,
      "loss": 0.9276,
      "step": 7570
    },
    {
      "epoch": 2.4256,
      "grad_norm": 0.4290691316127777,
      "learning_rate": 4.257437477776461e-05,
      "loss": 0.9293,
      "step": 7580
    },
    {
      "epoch": 2.4288,
      "grad_norm": 0.3713274300098419,
      "learning_rate": 4.23373236932559e-05,
      "loss": 1.0426,
      "step": 7590
    },
    {
      "epoch": 2.432,
      "grad_norm": 0.3059721887111664,
      "learning_rate": 4.210027260874719e-05,
      "loss": 0.986,
      "step": 7600
    },
    {
      "epoch": 2.432,
      "eval_loss": 1.0664705038070679,
      "eval_runtime": 2.3417,
      "eval_samples_per_second": 85.408,
      "eval_steps_per_second": 1.708,
      "step": 7600
    },
    {
      "epoch": 2.4352,
      "grad_norm": 0.3627067506313324,
      "learning_rate": 4.1863221524238476e-05,
      "loss": 0.9985,
      "step": 7610
    },
    {
      "epoch": 2.4384,
      "grad_norm": 0.33847543597221375,
      "learning_rate": 4.1626170439729764e-05,
      "loss": 1.0165,
      "step": 7620
    },
    {
      "epoch": 2.4416,
      "grad_norm": 0.3026062250137329,
      "learning_rate": 4.138911935522105e-05,
      "loss": 0.9115,
      "step": 7630
    },
    {
      "epoch": 2.4448,
      "grad_norm": 0.40930771827697754,
      "learning_rate": 4.115206827071234e-05,
      "loss": 0.9713,
      "step": 7640
    },
    {
      "epoch": 2.448,
      "grad_norm": 0.41384223103523254,
      "learning_rate": 4.091501718620363e-05,
      "loss": 0.9887,
      "step": 7650
    },
    {
      "epoch": 2.448,
      "eval_loss": 1.066932201385498,
      "eval_runtime": 2.3425,
      "eval_samples_per_second": 85.379,
      "eval_steps_per_second": 1.708,
      "step": 7650
    },
    {
      "epoch": 2.4512,
      "grad_norm": 0.35228803753852844,
      "learning_rate": 4.067796610169492e-05,
      "loss": 1.0053,
      "step": 7660
    },
    {
      "epoch": 2.4544,
      "grad_norm": 0.3435889184474945,
      "learning_rate": 4.0440915017186206e-05,
      "loss": 0.9742,
      "step": 7670
    },
    {
      "epoch": 2.4576000000000002,
      "grad_norm": 0.30103766918182373,
      "learning_rate": 4.0203863932677494e-05,
      "loss": 0.8629,
      "step": 7680
    },
    {
      "epoch": 2.4608,
      "grad_norm": 0.34976062178611755,
      "learning_rate": 3.996681284816878e-05,
      "loss": 0.9608,
      "step": 7690
    },
    {
      "epoch": 2.464,
      "grad_norm": 0.3238690495491028,
      "learning_rate": 3.972976176366007e-05,
      "loss": 0.9667,
      "step": 7700
    },
    {
      "epoch": 2.464,
      "eval_loss": 1.0648212432861328,
      "eval_runtime": 2.3432,
      "eval_samples_per_second": 85.355,
      "eval_steps_per_second": 1.707,
      "step": 7700
    },
    {
      "epoch": 2.4672,
      "grad_norm": 0.3653905689716339,
      "learning_rate": 3.949271067915136e-05,
      "loss": 0.9608,
      "step": 7710
    },
    {
      "epoch": 2.4704,
      "grad_norm": 0.3082335293292999,
      "learning_rate": 3.925565959464265e-05,
      "loss": 1.0348,
      "step": 7720
    },
    {
      "epoch": 2.4736000000000002,
      "grad_norm": 0.3515460193157196,
      "learning_rate": 3.9018608510133935e-05,
      "loss": 0.9716,
      "step": 7730
    },
    {
      "epoch": 2.4768,
      "grad_norm": 0.3727116882801056,
      "learning_rate": 3.8781557425625224e-05,
      "loss": 0.9602,
      "step": 7740
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.3452833294868469,
      "learning_rate": 3.854450634111651e-05,
      "loss": 0.9689,
      "step": 7750
    },
    {
      "epoch": 2.48,
      "eval_loss": 1.0652449131011963,
      "eval_runtime": 2.3399,
      "eval_samples_per_second": 85.473,
      "eval_steps_per_second": 1.709,
      "step": 7750
    },
    {
      "epoch": 2.4832,
      "grad_norm": 0.33123472332954407,
      "learning_rate": 3.83074552566078e-05,
      "loss": 0.9183,
      "step": 7760
    },
    {
      "epoch": 2.4864,
      "grad_norm": 0.3285512328147888,
      "learning_rate": 3.807040417209909e-05,
      "loss": 0.8806,
      "step": 7770
    },
    {
      "epoch": 2.4896,
      "grad_norm": 0.32339662313461304,
      "learning_rate": 3.783335308759038e-05,
      "loss": 0.9949,
      "step": 7780
    },
    {
      "epoch": 2.4928,
      "grad_norm": 0.35810941457748413,
      "learning_rate": 3.7596302003081665e-05,
      "loss": 1.024,
      "step": 7790
    },
    {
      "epoch": 2.496,
      "grad_norm": 0.34472939372062683,
      "learning_rate": 3.735925091857295e-05,
      "loss": 0.9359,
      "step": 7800
    },
    {
      "epoch": 2.496,
      "eval_loss": 1.0664353370666504,
      "eval_runtime": 2.3399,
      "eval_samples_per_second": 85.473,
      "eval_steps_per_second": 1.709,
      "step": 7800
    },
    {
      "epoch": 2.4992,
      "grad_norm": 0.3023620843887329,
      "learning_rate": 3.712219983406424e-05,
      "loss": 0.9068,
      "step": 7810
    },
    {
      "epoch": 2.5023999999999997,
      "grad_norm": 0.34179139137268066,
      "learning_rate": 3.688514874955553e-05,
      "loss": 0.974,
      "step": 7820
    },
    {
      "epoch": 2.5056000000000003,
      "grad_norm": 0.287352055311203,
      "learning_rate": 3.664809766504682e-05,
      "loss": 0.9348,
      "step": 7830
    },
    {
      "epoch": 2.5088,
      "grad_norm": 0.4158824682235718,
      "learning_rate": 3.6411046580538106e-05,
      "loss": 0.9567,
      "step": 7840
    },
    {
      "epoch": 2.512,
      "grad_norm": 0.3821295201778412,
      "learning_rate": 3.6173995496029395e-05,
      "loss": 0.9683,
      "step": 7850
    },
    {
      "epoch": 2.512,
      "eval_loss": 1.0648221969604492,
      "eval_runtime": 2.3398,
      "eval_samples_per_second": 85.477,
      "eval_steps_per_second": 1.71,
      "step": 7850
    },
    {
      "epoch": 2.5152,
      "grad_norm": 0.31761470437049866,
      "learning_rate": 3.593694441152068e-05,
      "loss": 1.0382,
      "step": 7860
    },
    {
      "epoch": 2.5183999999999997,
      "grad_norm": 0.3040400743484497,
      "learning_rate": 3.569989332701197e-05,
      "loss": 1.0677,
      "step": 7870
    },
    {
      "epoch": 2.5216,
      "grad_norm": 0.3641401529312134,
      "learning_rate": 3.5462842242503266e-05,
      "loss": 0.9724,
      "step": 7880
    },
    {
      "epoch": 2.5248,
      "grad_norm": 0.3679693937301636,
      "learning_rate": 3.522579115799455e-05,
      "loss": 1.0283,
      "step": 7890
    },
    {
      "epoch": 2.528,
      "grad_norm": 0.32765865325927734,
      "learning_rate": 3.4988740073485836e-05,
      "loss": 0.9613,
      "step": 7900
    },
    {
      "epoch": 2.528,
      "eval_loss": 1.0651047229766846,
      "eval_runtime": 2.3398,
      "eval_samples_per_second": 85.478,
      "eval_steps_per_second": 1.71,
      "step": 7900
    },
    {
      "epoch": 2.5312,
      "grad_norm": 0.37537333369255066,
      "learning_rate": 3.4751688988977124e-05,
      "loss": 0.9562,
      "step": 7910
    },
    {
      "epoch": 2.5343999999999998,
      "grad_norm": 0.312249094247818,
      "learning_rate": 3.451463790446842e-05,
      "loss": 0.9481,
      "step": 7920
    },
    {
      "epoch": 2.5376,
      "grad_norm": 0.35311830043792725,
      "learning_rate": 3.42775868199597e-05,
      "loss": 0.9882,
      "step": 7930
    },
    {
      "epoch": 2.5408,
      "grad_norm": 0.3125495910644531,
      "learning_rate": 3.404053573545099e-05,
      "loss": 0.9748,
      "step": 7940
    },
    {
      "epoch": 2.544,
      "grad_norm": 0.31623685359954834,
      "learning_rate": 3.380348465094228e-05,
      "loss": 0.9344,
      "step": 7950
    },
    {
      "epoch": 2.544,
      "eval_loss": 1.0649091005325317,
      "eval_runtime": 2.3409,
      "eval_samples_per_second": 85.436,
      "eval_steps_per_second": 1.709,
      "step": 7950
    },
    {
      "epoch": 2.5472,
      "grad_norm": 0.38804417848587036,
      "learning_rate": 3.356643356643357e-05,
      "loss": 1.0362,
      "step": 7960
    },
    {
      "epoch": 2.5504,
      "grad_norm": 0.34692516922950745,
      "learning_rate": 3.332938248192486e-05,
      "loss": 0.9296,
      "step": 7970
    },
    {
      "epoch": 2.5536,
      "grad_norm": 0.32177841663360596,
      "learning_rate": 3.309233139741614e-05,
      "loss": 0.9152,
      "step": 7980
    },
    {
      "epoch": 2.5568,
      "grad_norm": 0.366031289100647,
      "learning_rate": 3.285528031290743e-05,
      "loss": 1.0007,
      "step": 7990
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.31022152304649353,
      "learning_rate": 3.261822922839872e-05,
      "loss": 0.9224,
      "step": 8000
    },
    {
      "epoch": 2.56,
      "eval_loss": 1.065171480178833,
      "eval_runtime": 2.3399,
      "eval_samples_per_second": 85.473,
      "eval_steps_per_second": 1.709,
      "step": 8000
    },
    {
      "epoch": 2.5632,
      "grad_norm": 0.3070114850997925,
      "learning_rate": 3.2381178143890014e-05,
      "loss": 0.954,
      "step": 8010
    },
    {
      "epoch": 2.5664,
      "grad_norm": 0.4139796197414398,
      "learning_rate": 3.2144127059381296e-05,
      "loss": 0.9436,
      "step": 8020
    },
    {
      "epoch": 2.5696,
      "grad_norm": 0.3104746639728546,
      "learning_rate": 3.1907075974872584e-05,
      "loss": 0.9795,
      "step": 8030
    },
    {
      "epoch": 2.5728,
      "grad_norm": 0.36175212264060974,
      "learning_rate": 3.167002489036387e-05,
      "loss": 0.9738,
      "step": 8040
    },
    {
      "epoch": 2.576,
      "grad_norm": 0.29921236634254456,
      "learning_rate": 3.143297380585517e-05,
      "loss": 0.9529,
      "step": 8050
    },
    {
      "epoch": 2.576,
      "eval_loss": 1.064441204071045,
      "eval_runtime": 2.3397,
      "eval_samples_per_second": 85.481,
      "eval_steps_per_second": 1.71,
      "step": 8050
    },
    {
      "epoch": 2.5792,
      "grad_norm": 0.3586767017841339,
      "learning_rate": 3.119592272134645e-05,
      "loss": 1.0574,
      "step": 8060
    },
    {
      "epoch": 2.5824,
      "grad_norm": 0.3327908217906952,
      "learning_rate": 3.095887163683774e-05,
      "loss": 0.9405,
      "step": 8070
    },
    {
      "epoch": 2.5856,
      "grad_norm": 0.35614296793937683,
      "learning_rate": 3.0721820552329025e-05,
      "loss": 1.089,
      "step": 8080
    },
    {
      "epoch": 2.5888,
      "grad_norm": 0.33985915780067444,
      "learning_rate": 3.0484769467820317e-05,
      "loss": 0.9096,
      "step": 8090
    },
    {
      "epoch": 2.592,
      "grad_norm": 0.3332396447658539,
      "learning_rate": 3.024771838331161e-05,
      "loss": 1.0777,
      "step": 8100
    },
    {
      "epoch": 2.592,
      "eval_loss": 1.064081072807312,
      "eval_runtime": 2.3404,
      "eval_samples_per_second": 85.454,
      "eval_steps_per_second": 1.709,
      "step": 8100
    },
    {
      "epoch": 2.5952,
      "grad_norm": 0.34973394870758057,
      "learning_rate": 3.001066729880289e-05,
      "loss": 0.9011,
      "step": 8110
    },
    {
      "epoch": 2.5984,
      "grad_norm": 0.4044238328933716,
      "learning_rate": 2.9773616214294182e-05,
      "loss": 0.974,
      "step": 8120
    },
    {
      "epoch": 2.6016,
      "grad_norm": 0.34142038226127625,
      "learning_rate": 2.953656512978547e-05,
      "loss": 0.9751,
      "step": 8130
    },
    {
      "epoch": 2.6048,
      "grad_norm": 0.34558308124542236,
      "learning_rate": 2.9299514045276762e-05,
      "loss": 0.9524,
      "step": 8140
    },
    {
      "epoch": 2.608,
      "grad_norm": 0.3659697473049164,
      "learning_rate": 2.9062462960768043e-05,
      "loss": 0.9692,
      "step": 8150
    },
    {
      "epoch": 2.608,
      "eval_loss": 1.063001275062561,
      "eval_runtime": 2.3412,
      "eval_samples_per_second": 85.427,
      "eval_steps_per_second": 1.709,
      "step": 8150
    },
    {
      "epoch": 2.6112,
      "grad_norm": 0.3566141128540039,
      "learning_rate": 2.8825411876259335e-05,
      "loss": 0.9461,
      "step": 8160
    },
    {
      "epoch": 2.6144,
      "grad_norm": 0.3172319829463959,
      "learning_rate": 2.8588360791750623e-05,
      "loss": 0.9428,
      "step": 8170
    },
    {
      "epoch": 2.6176,
      "grad_norm": 0.3255424201488495,
      "learning_rate": 2.8351309707241915e-05,
      "loss": 1.006,
      "step": 8180
    },
    {
      "epoch": 2.6208,
      "grad_norm": 0.37573885917663574,
      "learning_rate": 2.8114258622733203e-05,
      "loss": 0.9774,
      "step": 8190
    },
    {
      "epoch": 2.624,
      "grad_norm": 0.34166622161865234,
      "learning_rate": 2.7877207538224488e-05,
      "loss": 0.9535,
      "step": 8200
    },
    {
      "epoch": 2.624,
      "eval_loss": 1.0630817413330078,
      "eval_runtime": 2.3417,
      "eval_samples_per_second": 85.407,
      "eval_steps_per_second": 1.708,
      "step": 8200
    },
    {
      "epoch": 2.6272,
      "grad_norm": 0.35089704394340515,
      "learning_rate": 2.7640156453715776e-05,
      "loss": 0.8948,
      "step": 8210
    },
    {
      "epoch": 2.6304,
      "grad_norm": 0.376810759305954,
      "learning_rate": 2.7403105369207065e-05,
      "loss": 0.9815,
      "step": 8220
    },
    {
      "epoch": 2.6336,
      "grad_norm": 0.3674387037754059,
      "learning_rate": 2.7166054284698356e-05,
      "loss": 0.9551,
      "step": 8230
    },
    {
      "epoch": 2.6368,
      "grad_norm": 0.3308737874031067,
      "learning_rate": 2.692900320018964e-05,
      "loss": 0.9687,
      "step": 8240
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.31816670298576355,
      "learning_rate": 2.669195211568093e-05,
      "loss": 0.9933,
      "step": 8250
    },
    {
      "epoch": 2.64,
      "eval_loss": 1.0629180669784546,
      "eval_runtime": 2.3403,
      "eval_samples_per_second": 85.46,
      "eval_steps_per_second": 1.709,
      "step": 8250
    },
    {
      "epoch": 2.6432,
      "grad_norm": 0.3919084370136261,
      "learning_rate": 2.6454901031172218e-05,
      "loss": 0.98,
      "step": 8260
    },
    {
      "epoch": 2.6464,
      "grad_norm": 0.4014974534511566,
      "learning_rate": 2.621784994666351e-05,
      "loss": 0.9913,
      "step": 8270
    },
    {
      "epoch": 2.6496,
      "grad_norm": 0.3427165746688843,
      "learning_rate": 2.5980798862154798e-05,
      "loss": 0.9431,
      "step": 8280
    },
    {
      "epoch": 2.6528,
      "grad_norm": 0.3074370324611664,
      "learning_rate": 2.5743747777646083e-05,
      "loss": 0.9715,
      "step": 8290
    },
    {
      "epoch": 2.656,
      "grad_norm": 0.30180954933166504,
      "learning_rate": 2.550669669313737e-05,
      "loss": 0.8894,
      "step": 8300
    },
    {
      "epoch": 2.656,
      "eval_loss": 1.0631228685379028,
      "eval_runtime": 2.3421,
      "eval_samples_per_second": 85.394,
      "eval_steps_per_second": 1.708,
      "step": 8300
    },
    {
      "epoch": 2.6592000000000002,
      "grad_norm": 0.32321831583976746,
      "learning_rate": 2.5269645608628662e-05,
      "loss": 0.9802,
      "step": 8310
    },
    {
      "epoch": 2.6624,
      "grad_norm": 0.3300118148326874,
      "learning_rate": 2.503259452411995e-05,
      "loss": 0.9849,
      "step": 8320
    },
    {
      "epoch": 2.6656,
      "grad_norm": 0.3232341706752777,
      "learning_rate": 2.479554343961124e-05,
      "loss": 0.9002,
      "step": 8330
    },
    {
      "epoch": 2.6688,
      "grad_norm": 0.4130435883998871,
      "learning_rate": 2.4558492355102524e-05,
      "loss": 0.9599,
      "step": 8340
    },
    {
      "epoch": 2.672,
      "grad_norm": 0.31280791759490967,
      "learning_rate": 2.4321441270593816e-05,
      "loss": 0.9886,
      "step": 8350
    },
    {
      "epoch": 2.672,
      "eval_loss": 1.0630052089691162,
      "eval_runtime": 2.342,
      "eval_samples_per_second": 85.396,
      "eval_steps_per_second": 1.708,
      "step": 8350
    },
    {
      "epoch": 2.6752000000000002,
      "grad_norm": 0.3992112874984741,
      "learning_rate": 2.40843901860851e-05,
      "loss": 1.0627,
      "step": 8360
    },
    {
      "epoch": 2.6784,
      "grad_norm": 0.3470398783683777,
      "learning_rate": 2.3847339101576392e-05,
      "loss": 0.8936,
      "step": 8370
    },
    {
      "epoch": 2.6816,
      "grad_norm": 0.5425071716308594,
      "learning_rate": 2.361028801706768e-05,
      "loss": 1.0059,
      "step": 8380
    },
    {
      "epoch": 2.6848,
      "grad_norm": 0.301321417093277,
      "learning_rate": 2.337323693255897e-05,
      "loss": 0.9403,
      "step": 8390
    },
    {
      "epoch": 2.6879999999999997,
      "grad_norm": 0.3456324636936188,
      "learning_rate": 2.3136185848050257e-05,
      "loss": 0.979,
      "step": 8400
    },
    {
      "epoch": 2.6879999999999997,
      "eval_loss": 1.0636889934539795,
      "eval_runtime": 2.3461,
      "eval_samples_per_second": 85.248,
      "eval_steps_per_second": 1.705,
      "step": 8400
    },
    {
      "epoch": 2.6912000000000003,
      "grad_norm": 0.29365795850753784,
      "learning_rate": 2.2899134763541545e-05,
      "loss": 0.9255,
      "step": 8410
    },
    {
      "epoch": 2.6944,
      "grad_norm": 0.31505173444747925,
      "learning_rate": 2.2662083679032834e-05,
      "loss": 1.0159,
      "step": 8420
    },
    {
      "epoch": 2.6976,
      "grad_norm": 0.3793385922908783,
      "learning_rate": 2.2425032594524122e-05,
      "loss": 1.0059,
      "step": 8430
    },
    {
      "epoch": 2.7008,
      "grad_norm": 0.3299741744995117,
      "learning_rate": 2.218798151001541e-05,
      "loss": 0.9872,
      "step": 8440
    },
    {
      "epoch": 2.7039999999999997,
      "grad_norm": 0.32409971952438354,
      "learning_rate": 2.1950930425506695e-05,
      "loss": 0.9274,
      "step": 8450
    },
    {
      "epoch": 2.7039999999999997,
      "eval_loss": 1.0629709959030151,
      "eval_runtime": 2.3409,
      "eval_samples_per_second": 85.437,
      "eval_steps_per_second": 1.709,
      "step": 8450
    },
    {
      "epoch": 2.7072000000000003,
      "grad_norm": 0.35076001286506653,
      "learning_rate": 2.1713879340997987e-05,
      "loss": 1.0096,
      "step": 8460
    },
    {
      "epoch": 2.7104,
      "grad_norm": 0.40979400277137756,
      "learning_rate": 2.147682825648927e-05,
      "loss": 0.9386,
      "step": 8470
    },
    {
      "epoch": 2.7136,
      "grad_norm": 0.3626849353313446,
      "learning_rate": 2.1239777171980563e-05,
      "loss": 1.0293,
      "step": 8480
    },
    {
      "epoch": 2.7168,
      "grad_norm": 0.337624192237854,
      "learning_rate": 2.100272608747185e-05,
      "loss": 0.9739,
      "step": 8490
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 0.3493864834308624,
      "learning_rate": 2.076567500296314e-05,
      "loss": 0.9882,
      "step": 8500
    },
    {
      "epoch": 2.7199999999999998,
      "eval_loss": 1.0613770484924316,
      "eval_runtime": 2.3408,
      "eval_samples_per_second": 85.442,
      "eval_steps_per_second": 1.709,
      "step": 8500
    },
    {
      "epoch": 2.7232,
      "grad_norm": 0.30811381340026855,
      "learning_rate": 2.0528623918454428e-05,
      "loss": 0.966,
      "step": 8510
    },
    {
      "epoch": 2.7264,
      "grad_norm": 0.3633500635623932,
      "learning_rate": 2.0291572833945716e-05,
      "loss": 0.8406,
      "step": 8520
    },
    {
      "epoch": 2.7296,
      "grad_norm": 0.3881363868713379,
      "learning_rate": 2.0054521749437005e-05,
      "loss": 0.9852,
      "step": 8530
    },
    {
      "epoch": 2.7328,
      "grad_norm": 0.34363916516304016,
      "learning_rate": 1.9817470664928293e-05,
      "loss": 0.9379,
      "step": 8540
    },
    {
      "epoch": 2.7359999999999998,
      "grad_norm": 0.3125852942466736,
      "learning_rate": 1.958041958041958e-05,
      "loss": 1.0457,
      "step": 8550
    },
    {
      "epoch": 2.7359999999999998,
      "eval_loss": 1.062057375907898,
      "eval_runtime": 2.3405,
      "eval_samples_per_second": 85.454,
      "eval_steps_per_second": 1.709,
      "step": 8550
    },
    {
      "epoch": 2.7392,
      "grad_norm": 0.3254782557487488,
      "learning_rate": 1.934336849591087e-05,
      "loss": 0.9987,
      "step": 8560
    },
    {
      "epoch": 2.7424,
      "grad_norm": 0.3240622878074646,
      "learning_rate": 1.9106317411402158e-05,
      "loss": 0.9864,
      "step": 8570
    },
    {
      "epoch": 2.7456,
      "grad_norm": 0.3401871621608734,
      "learning_rate": 1.886926632689345e-05,
      "loss": 0.9779,
      "step": 8580
    },
    {
      "epoch": 2.7488,
      "grad_norm": 0.3002453148365021,
      "learning_rate": 1.8632215242384734e-05,
      "loss": 0.9505,
      "step": 8590
    },
    {
      "epoch": 2.752,
      "grad_norm": 0.33802759647369385,
      "learning_rate": 1.8395164157876023e-05,
      "loss": 0.9627,
      "step": 8600
    },
    {
      "epoch": 2.752,
      "eval_loss": 1.0621981620788574,
      "eval_runtime": 2.3406,
      "eval_samples_per_second": 85.449,
      "eval_steps_per_second": 1.709,
      "step": 8600
    },
    {
      "epoch": 2.7552,
      "grad_norm": 0.3661730885505676,
      "learning_rate": 1.815811307336731e-05,
      "loss": 0.9777,
      "step": 8610
    },
    {
      "epoch": 2.7584,
      "grad_norm": 0.37021592259407043,
      "learning_rate": 1.79210619888586e-05,
      "loss": 0.9504,
      "step": 8620
    },
    {
      "epoch": 2.7616,
      "grad_norm": 0.3170717656612396,
      "learning_rate": 1.7684010904349887e-05,
      "loss": 0.9742,
      "step": 8630
    },
    {
      "epoch": 2.7648,
      "grad_norm": 0.3820982873439789,
      "learning_rate": 1.7446959819841176e-05,
      "loss": 1.0515,
      "step": 8640
    },
    {
      "epoch": 2.768,
      "grad_norm": 0.35155391693115234,
      "learning_rate": 1.7209908735332464e-05,
      "loss": 0.9763,
      "step": 8650
    },
    {
      "epoch": 2.768,
      "eval_loss": 1.0621614456176758,
      "eval_runtime": 2.3397,
      "eval_samples_per_second": 85.481,
      "eval_steps_per_second": 1.71,
      "step": 8650
    },
    {
      "epoch": 2.7712,
      "grad_norm": 0.3596459627151489,
      "learning_rate": 1.6972857650823752e-05,
      "loss": 0.9406,
      "step": 8660
    },
    {
      "epoch": 2.7744,
      "grad_norm": 0.2968301773071289,
      "learning_rate": 1.673580656631504e-05,
      "loss": 0.923,
      "step": 8670
    },
    {
      "epoch": 2.7776,
      "grad_norm": 0.3520532548427582,
      "learning_rate": 1.649875548180633e-05,
      "loss": 0.9929,
      "step": 8680
    },
    {
      "epoch": 2.7808,
      "grad_norm": 0.38645440340042114,
      "learning_rate": 1.626170439729762e-05,
      "loss": 0.9828,
      "step": 8690
    },
    {
      "epoch": 2.784,
      "grad_norm": 0.3054627776145935,
      "learning_rate": 1.6024653312788905e-05,
      "loss": 0.9943,
      "step": 8700
    },
    {
      "epoch": 2.784,
      "eval_loss": 1.062335729598999,
      "eval_runtime": 2.3402,
      "eval_samples_per_second": 85.463,
      "eval_steps_per_second": 1.709,
      "step": 8700
    },
    {
      "epoch": 2.7872,
      "grad_norm": 0.3406955301761627,
      "learning_rate": 1.5787602228280197e-05,
      "loss": 0.9774,
      "step": 8710
    },
    {
      "epoch": 2.7904,
      "grad_norm": 0.369613379240036,
      "learning_rate": 1.5550551143771482e-05,
      "loss": 0.9658,
      "step": 8720
    },
    {
      "epoch": 2.7936,
      "grad_norm": 0.319487065076828,
      "learning_rate": 1.5313500059262774e-05,
      "loss": 0.9367,
      "step": 8730
    },
    {
      "epoch": 2.7968,
      "grad_norm": 0.3539482057094574,
      "learning_rate": 1.5076448974754059e-05,
      "loss": 0.9436,
      "step": 8740
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.35394802689552307,
      "learning_rate": 1.4839397890245349e-05,
      "loss": 0.92,
      "step": 8750
    },
    {
      "epoch": 2.8,
      "eval_loss": 1.063269019126892,
      "eval_runtime": 2.3402,
      "eval_samples_per_second": 85.462,
      "eval_steps_per_second": 1.709,
      "step": 8750
    },
    {
      "epoch": 2.8032,
      "grad_norm": 0.3635937571525574,
      "learning_rate": 1.4602346805736635e-05,
      "loss": 0.9282,
      "step": 8760
    },
    {
      "epoch": 2.8064,
      "grad_norm": 0.38863134384155273,
      "learning_rate": 1.4365295721227925e-05,
      "loss": 0.9685,
      "step": 8770
    },
    {
      "epoch": 2.8096,
      "grad_norm": 0.298180490732193,
      "learning_rate": 1.4128244636719215e-05,
      "loss": 1.0031,
      "step": 8780
    },
    {
      "epoch": 2.8128,
      "grad_norm": 0.3359992802143097,
      "learning_rate": 1.3891193552210502e-05,
      "loss": 0.9604,
      "step": 8790
    },
    {
      "epoch": 2.816,
      "grad_norm": 0.316172331571579,
      "learning_rate": 1.3654142467701792e-05,
      "loss": 0.9032,
      "step": 8800
    },
    {
      "epoch": 2.816,
      "eval_loss": 1.0626330375671387,
      "eval_runtime": 2.3398,
      "eval_samples_per_second": 85.478,
      "eval_steps_per_second": 1.71,
      "step": 8800
    },
    {
      "epoch": 2.8192,
      "grad_norm": 0.380510151386261,
      "learning_rate": 1.3417091383193078e-05,
      "loss": 1.0185,
      "step": 8810
    },
    {
      "epoch": 2.8224,
      "grad_norm": 0.3026512861251831,
      "learning_rate": 1.3180040298684368e-05,
      "loss": 0.9603,
      "step": 8820
    },
    {
      "epoch": 2.8256,
      "grad_norm": 0.3863116204738617,
      "learning_rate": 1.2942989214175655e-05,
      "loss": 0.979,
      "step": 8830
    },
    {
      "epoch": 2.8288,
      "grad_norm": 0.3804794251918793,
      "learning_rate": 1.2705938129666945e-05,
      "loss": 0.9118,
      "step": 8840
    },
    {
      "epoch": 2.832,
      "grad_norm": 0.36132317781448364,
      "learning_rate": 1.2468887045158233e-05,
      "loss": 1.0014,
      "step": 8850
    },
    {
      "epoch": 2.832,
      "eval_loss": 1.0624322891235352,
      "eval_runtime": 2.3425,
      "eval_samples_per_second": 85.377,
      "eval_steps_per_second": 1.708,
      "step": 8850
    },
    {
      "epoch": 2.8352,
      "grad_norm": 0.36210891604423523,
      "learning_rate": 1.2231835960649521e-05,
      "loss": 1.0357,
      "step": 8860
    },
    {
      "epoch": 2.8384,
      "grad_norm": 0.33524495363235474,
      "learning_rate": 1.199478487614081e-05,
      "loss": 0.9705,
      "step": 8870
    },
    {
      "epoch": 2.8416,
      "grad_norm": 0.37117594480514526,
      "learning_rate": 1.1757733791632098e-05,
      "loss": 0.9075,
      "step": 8880
    },
    {
      "epoch": 2.8448,
      "grad_norm": 0.3043408989906311,
      "learning_rate": 1.1520682707123386e-05,
      "loss": 0.9846,
      "step": 8890
    },
    {
      "epoch": 2.848,
      "grad_norm": 0.3834265172481537,
      "learning_rate": 1.1283631622614674e-05,
      "loss": 1.0823,
      "step": 8900
    },
    {
      "epoch": 2.848,
      "eval_loss": 1.062496304512024,
      "eval_runtime": 2.3411,
      "eval_samples_per_second": 85.429,
      "eval_steps_per_second": 1.709,
      "step": 8900
    },
    {
      "epoch": 2.8512,
      "grad_norm": 0.34689754247665405,
      "learning_rate": 1.1046580538105963e-05,
      "loss": 1.0089,
      "step": 8910
    },
    {
      "epoch": 2.8544,
      "grad_norm": 0.33222851157188416,
      "learning_rate": 1.0809529453597251e-05,
      "loss": 0.9161,
      "step": 8920
    },
    {
      "epoch": 2.8576,
      "grad_norm": 0.4146907925605774,
      "learning_rate": 1.057247836908854e-05,
      "loss": 0.9845,
      "step": 8930
    },
    {
      "epoch": 2.8608000000000002,
      "grad_norm": 0.33770430088043213,
      "learning_rate": 1.0335427284579828e-05,
      "loss": 0.9359,
      "step": 8940
    },
    {
      "epoch": 2.864,
      "grad_norm": 0.3249496519565582,
      "learning_rate": 1.0098376200071116e-05,
      "loss": 0.9205,
      "step": 8950
    },
    {
      "epoch": 2.864,
      "eval_loss": 1.063090205192566,
      "eval_runtime": 2.341,
      "eval_samples_per_second": 85.433,
      "eval_steps_per_second": 1.709,
      "step": 8950
    },
    {
      "epoch": 2.8672,
      "grad_norm": 0.41152653098106384,
      "learning_rate": 9.861325115562404e-06,
      "loss": 0.9659,
      "step": 8960
    },
    {
      "epoch": 2.8704,
      "grad_norm": 0.3497976064682007,
      "learning_rate": 9.624274031053692e-06,
      "loss": 0.9293,
      "step": 8970
    },
    {
      "epoch": 2.8736,
      "grad_norm": 0.33539751172065735,
      "learning_rate": 9.38722294654498e-06,
      "loss": 0.9926,
      "step": 8980
    },
    {
      "epoch": 2.8768000000000002,
      "grad_norm": 0.3141480088233948,
      "learning_rate": 9.150171862036269e-06,
      "loss": 0.8855,
      "step": 8990
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.33343303203582764,
      "learning_rate": 8.913120777527557e-06,
      "loss": 0.952,
      "step": 9000
    },
    {
      "epoch": 2.88,
      "eval_loss": 1.0630093812942505,
      "eval_runtime": 2.34,
      "eval_samples_per_second": 85.469,
      "eval_steps_per_second": 1.709,
      "step": 9000
    },
    {
      "epoch": 2.8832,
      "grad_norm": 0.37992000579833984,
      "learning_rate": 8.676069693018846e-06,
      "loss": 1.0173,
      "step": 9010
    },
    {
      "epoch": 2.8864,
      "grad_norm": 0.3046736419200897,
      "learning_rate": 8.439018608510134e-06,
      "loss": 0.9241,
      "step": 9020
    },
    {
      "epoch": 2.8895999999999997,
      "grad_norm": 0.3414881229400635,
      "learning_rate": 8.201967524001422e-06,
      "loss": 0.958,
      "step": 9030
    },
    {
      "epoch": 2.8928000000000003,
      "grad_norm": 0.32708847522735596,
      "learning_rate": 7.964916439492712e-06,
      "loss": 0.9506,
      "step": 9040
    },
    {
      "epoch": 2.896,
      "grad_norm": 0.3433462083339691,
      "learning_rate": 7.727865354984e-06,
      "loss": 0.9984,
      "step": 9050
    },
    {
      "epoch": 2.896,
      "eval_loss": 1.0622326135635376,
      "eval_runtime": 2.341,
      "eval_samples_per_second": 85.435,
      "eval_steps_per_second": 1.709,
      "step": 9050
    },
    {
      "epoch": 2.8992,
      "grad_norm": 0.3699628412723541,
      "learning_rate": 7.490814270475288e-06,
      "loss": 0.9331,
      "step": 9060
    },
    {
      "epoch": 2.9024,
      "grad_norm": 0.3718436360359192,
      "learning_rate": 7.253763185966576e-06,
      "loss": 0.9663,
      "step": 9070
    },
    {
      "epoch": 2.9055999999999997,
      "grad_norm": 0.33544278144836426,
      "learning_rate": 7.016712101457864e-06,
      "loss": 0.9695,
      "step": 9080
    },
    {
      "epoch": 2.9088000000000003,
      "grad_norm": 0.3138790428638458,
      "learning_rate": 6.779661016949153e-06,
      "loss": 0.9231,
      "step": 9090
    },
    {
      "epoch": 2.912,
      "grad_norm": 0.42407214641571045,
      "learning_rate": 6.542609932440441e-06,
      "loss": 0.9954,
      "step": 9100
    },
    {
      "epoch": 2.912,
      "eval_loss": 1.0620287656784058,
      "eval_runtime": 2.3405,
      "eval_samples_per_second": 85.45,
      "eval_steps_per_second": 1.709,
      "step": 9100
    },
    {
      "epoch": 2.9152,
      "grad_norm": 0.3573414385318756,
      "learning_rate": 6.305558847931729e-06,
      "loss": 0.9588,
      "step": 9110
    },
    {
      "epoch": 2.9184,
      "grad_norm": 0.3700793981552124,
      "learning_rate": 6.068507763423018e-06,
      "loss": 0.9227,
      "step": 9120
    },
    {
      "epoch": 2.9215999999999998,
      "grad_norm": 0.33339813351631165,
      "learning_rate": 5.831456678914307e-06,
      "loss": 0.9956,
      "step": 9130
    },
    {
      "epoch": 2.9248,
      "grad_norm": 0.3570539653301239,
      "learning_rate": 5.594405594405595e-06,
      "loss": 1.0023,
      "step": 9140
    },
    {
      "epoch": 2.928,
      "grad_norm": 0.3727496862411499,
      "learning_rate": 5.357354509896883e-06,
      "loss": 1.007,
      "step": 9150
    },
    {
      "epoch": 2.928,
      "eval_loss": 1.06227445602417,
      "eval_runtime": 2.3403,
      "eval_samples_per_second": 85.46,
      "eval_steps_per_second": 1.709,
      "step": 9150
    },
    {
      "epoch": 2.9312,
      "grad_norm": 0.404427170753479,
      "learning_rate": 5.1203034253881714e-06,
      "loss": 0.9931,
      "step": 9160
    },
    {
      "epoch": 2.9344,
      "grad_norm": 0.3127802312374115,
      "learning_rate": 4.88325234087946e-06,
      "loss": 0.9485,
      "step": 9170
    },
    {
      "epoch": 2.9375999999999998,
      "grad_norm": 0.3438279330730438,
      "learning_rate": 4.646201256370748e-06,
      "loss": 0.973,
      "step": 9180
    },
    {
      "epoch": 2.9408,
      "grad_norm": 0.3497769236564636,
      "learning_rate": 4.409150171862036e-06,
      "loss": 0.9981,
      "step": 9190
    },
    {
      "epoch": 2.944,
      "grad_norm": 0.2996133267879486,
      "learning_rate": 4.1720990873533246e-06,
      "loss": 0.9444,
      "step": 9200
    },
    {
      "epoch": 2.944,
      "eval_loss": 1.062538743019104,
      "eval_runtime": 2.3402,
      "eval_samples_per_second": 85.461,
      "eval_steps_per_second": 1.709,
      "step": 9200
    },
    {
      "epoch": 2.9472,
      "grad_norm": 0.43506747484207153,
      "learning_rate": 3.935048002844613e-06,
      "loss": 1.0263,
      "step": 9210
    },
    {
      "epoch": 2.9504,
      "grad_norm": 0.310928076505661,
      "learning_rate": 3.697996918335902e-06,
      "loss": 0.9478,
      "step": 9220
    },
    {
      "epoch": 2.9536,
      "grad_norm": 0.29382291436195374,
      "learning_rate": 3.4609458338271903e-06,
      "loss": 0.9956,
      "step": 9230
    },
    {
      "epoch": 2.9568,
      "grad_norm": 0.3063294589519501,
      "learning_rate": 3.223894749318478e-06,
      "loss": 0.9077,
      "step": 9240
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.36215755343437195,
      "learning_rate": 2.9868436648097664e-06,
      "loss": 1.0183,
      "step": 9250
    },
    {
      "epoch": 2.96,
      "eval_loss": 1.062548041343689,
      "eval_runtime": 2.3408,
      "eval_samples_per_second": 85.44,
      "eval_steps_per_second": 1.709,
      "step": 9250
    },
    {
      "epoch": 2.9632,
      "grad_norm": 0.36387187242507935,
      "learning_rate": 2.749792580301055e-06,
      "loss": 0.9319,
      "step": 9260
    },
    {
      "epoch": 2.9664,
      "grad_norm": 0.35026875138282776,
      "learning_rate": 2.5127414957923434e-06,
      "loss": 0.947,
      "step": 9270
    },
    {
      "epoch": 2.9696,
      "grad_norm": 0.3099668025970459,
      "learning_rate": 2.2756904112836317e-06,
      "loss": 1.0163,
      "step": 9280
    },
    {
      "epoch": 2.9728,
      "grad_norm": 0.3356853127479553,
      "learning_rate": 2.03863932677492e-06,
      "loss": 0.9741,
      "step": 9290
    },
    {
      "epoch": 2.976,
      "grad_norm": 0.3267165422439575,
      "learning_rate": 1.8015882422662084e-06,
      "loss": 0.9302,
      "step": 9300
    },
    {
      "epoch": 2.976,
      "eval_loss": 1.0621246099472046,
      "eval_runtime": 2.3413,
      "eval_samples_per_second": 85.421,
      "eval_steps_per_second": 1.708,
      "step": 9300
    },
    {
      "epoch": 2.9792,
      "grad_norm": 0.3366844654083252,
      "learning_rate": 1.564537157757497e-06,
      "loss": 0.9895,
      "step": 9310
    },
    {
      "epoch": 2.9824,
      "grad_norm": 0.37419870495796204,
      "learning_rate": 1.3274860732487852e-06,
      "loss": 0.9264,
      "step": 9320
    },
    {
      "epoch": 2.9856,
      "grad_norm": 0.40417468547821045,
      "learning_rate": 1.0904349887400735e-06,
      "loss": 1.0215,
      "step": 9330
    },
    {
      "epoch": 2.9888,
      "grad_norm": 0.31121569871902466,
      "learning_rate": 8.53383904231362e-07,
      "loss": 0.8793,
      "step": 9340
    },
    {
      "epoch": 2.992,
      "grad_norm": 0.34278422594070435,
      "learning_rate": 6.163328197226503e-07,
      "loss": 0.981,
      "step": 9350
    },
    {
      "epoch": 2.992,
      "eval_loss": 1.0623948574066162,
      "eval_runtime": 2.3423,
      "eval_samples_per_second": 85.386,
      "eval_steps_per_second": 1.708,
      "step": 9350
    },
    {
      "epoch": 2.9952,
      "grad_norm": 0.35952064394950867,
      "learning_rate": 3.7928173521393864e-07,
      "loss": 0.953,
      "step": 9360
    },
    {
      "epoch": 2.9984,
      "grad_norm": 0.3807585835456848,
      "learning_rate": 1.4223065070522698e-07,
      "loss": 0.9689,
      "step": 9370
    }
  ],
  "logging_steps": 10,
  "max_steps": 9375,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
