{
  "best_global_step": 12400,
  "best_metric": 1.2734639644622803,
  "best_model_checkpoint": "/kaggle/working/models/mt5-base/checkpoint-12400",
  "epoch": 3.0,
  "eval_steps": 50,
  "global_step": 12501,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0023998080153587713,
      "grad_norm": 1253.904052734375,
      "learning_rate": 7.194244604316547e-07,
      "loss": 39.0224,
      "step": 10
    },
    {
      "epoch": 0.004799616030717543,
      "grad_norm": 445.04852294921875,
      "learning_rate": 1.5187849720223823e-06,
      "loss": 39.5896,
      "step": 20
    },
    {
      "epoch": 0.007199424046076314,
      "grad_norm": 797.670654296875,
      "learning_rate": 2.3181454836131098e-06,
      "loss": 40.0303,
      "step": 30
    },
    {
      "epoch": 0.009599232061435085,
      "grad_norm": 871.3683471679688,
      "learning_rate": 3.1175059952038373e-06,
      "loss": 38.2528,
      "step": 40
    },
    {
      "epoch": 0.011999040076793857,
      "grad_norm": 648.2852783203125,
      "learning_rate": 3.916866506794564e-06,
      "loss": 37.4134,
      "step": 50
    },
    {
      "epoch": 0.011999040076793857,
      "eval_loss": 35.263240814208984,
      "eval_runtime": 3.5337,
      "eval_samples_per_second": 56.598,
      "eval_steps_per_second": 2.547,
      "step": 50
    },
    {
      "epoch": 0.014398848092152628,
      "grad_norm": 536.08740234375,
      "learning_rate": 4.716227018385292e-06,
      "loss": 38.8255,
      "step": 60
    },
    {
      "epoch": 0.016798656107511398,
      "grad_norm": 951.621826171875,
      "learning_rate": 5.515587529976019e-06,
      "loss": 38.9633,
      "step": 70
    },
    {
      "epoch": 0.01919846412287017,
      "grad_norm": 576.4312744140625,
      "learning_rate": 6.314948041566747e-06,
      "loss": 38.9382,
      "step": 80
    },
    {
      "epoch": 0.02159827213822894,
      "grad_norm": 1033.6429443359375,
      "learning_rate": 7.114308553157474e-06,
      "loss": 38.5916,
      "step": 90
    },
    {
      "epoch": 0.023998080153587713,
      "grad_norm": 535.99365234375,
      "learning_rate": 7.913669064748202e-06,
      "loss": 39.4216,
      "step": 100
    },
    {
      "epoch": 0.023998080153587713,
      "eval_loss": 35.23484420776367,
      "eval_runtime": 3.5327,
      "eval_samples_per_second": 56.614,
      "eval_steps_per_second": 2.548,
      "step": 100
    },
    {
      "epoch": 0.026397888168946483,
      "grad_norm": 754.1907958984375,
      "learning_rate": 8.71302957633893e-06,
      "loss": 38.6705,
      "step": 110
    },
    {
      "epoch": 0.028797696184305256,
      "grad_norm": 809.5234985351562,
      "learning_rate": 9.512390087929657e-06,
      "loss": 37.7468,
      "step": 120
    },
    {
      "epoch": 0.031197504199664026,
      "grad_norm": 2657.4892578125,
      "learning_rate": 1.0311750599520384e-05,
      "loss": 38.0544,
      "step": 130
    },
    {
      "epoch": 0.033597312215022795,
      "grad_norm": 5698.33447265625,
      "learning_rate": 1.1111111111111112e-05,
      "loss": 38.3645,
      "step": 140
    },
    {
      "epoch": 0.03599712023038157,
      "grad_norm": 1003.05126953125,
      "learning_rate": 1.1910471622701839e-05,
      "loss": 39.2105,
      "step": 150
    },
    {
      "epoch": 0.03599712023038157,
      "eval_loss": 35.050411224365234,
      "eval_runtime": 3.5366,
      "eval_samples_per_second": 56.551,
      "eval_steps_per_second": 2.545,
      "step": 150
    },
    {
      "epoch": 0.03839692824574034,
      "grad_norm": 815.7269897460938,
      "learning_rate": 1.2709832134292565e-05,
      "loss": 37.8781,
      "step": 160
    },
    {
      "epoch": 0.040796736261099115,
      "grad_norm": 841.6932983398438,
      "learning_rate": 1.3509192645883296e-05,
      "loss": 38.7915,
      "step": 170
    },
    {
      "epoch": 0.04319654427645788,
      "grad_norm": 715.7621459960938,
      "learning_rate": 1.4308553157474022e-05,
      "loss": 38.2649,
      "step": 180
    },
    {
      "epoch": 0.045596352291816654,
      "grad_norm": 4273.6064453125,
      "learning_rate": 1.5107913669064749e-05,
      "loss": 38.3555,
      "step": 190
    },
    {
      "epoch": 0.04799616030717543,
      "grad_norm": 631.83544921875,
      "learning_rate": 1.5907274180655477e-05,
      "loss": 38.5476,
      "step": 200
    },
    {
      "epoch": 0.04799616030717543,
      "eval_loss": 34.47084426879883,
      "eval_runtime": 3.533,
      "eval_samples_per_second": 56.609,
      "eval_steps_per_second": 2.547,
      "step": 200
    },
    {
      "epoch": 0.0503959683225342,
      "grad_norm": 784.0667724609375,
      "learning_rate": 1.6706634692246204e-05,
      "loss": 36.8476,
      "step": 210
    },
    {
      "epoch": 0.052795776337892966,
      "grad_norm": 555.44970703125,
      "learning_rate": 1.750599520383693e-05,
      "loss": 37.0699,
      "step": 220
    },
    {
      "epoch": 0.05519558435325174,
      "grad_norm": 459.09271240234375,
      "learning_rate": 1.830535571542766e-05,
      "loss": 37.5582,
      "step": 230
    },
    {
      "epoch": 0.05759539236861051,
      "grad_norm": 788.9882202148438,
      "learning_rate": 1.9104716227018386e-05,
      "loss": 37.0217,
      "step": 240
    },
    {
      "epoch": 0.059995200383969285,
      "grad_norm": 976.8116455078125,
      "learning_rate": 1.9904076738609114e-05,
      "loss": 35.4673,
      "step": 250
    },
    {
      "epoch": 0.059995200383969285,
      "eval_loss": 32.937007904052734,
      "eval_runtime": 3.5342,
      "eval_samples_per_second": 56.59,
      "eval_steps_per_second": 2.547,
      "step": 250
    },
    {
      "epoch": 0.06239500839932805,
      "grad_norm": 2296.378662109375,
      "learning_rate": 2.070343725019984e-05,
      "loss": 34.8025,
      "step": 260
    },
    {
      "epoch": 0.06479481641468683,
      "grad_norm": 1047.450439453125,
      "learning_rate": 2.150279776179057e-05,
      "loss": 34.7095,
      "step": 270
    },
    {
      "epoch": 0.06719462443004559,
      "grad_norm": 1343.2738037109375,
      "learning_rate": 2.2302158273381296e-05,
      "loss": 33.8649,
      "step": 280
    },
    {
      "epoch": 0.06959443244540436,
      "grad_norm": 410.08502197265625,
      "learning_rate": 2.3101518784972024e-05,
      "loss": 34.3237,
      "step": 290
    },
    {
      "epoch": 0.07199424046076314,
      "grad_norm": 365.88861083984375,
      "learning_rate": 2.390087929656275e-05,
      "loss": 33.5473,
      "step": 300
    },
    {
      "epoch": 0.07199424046076314,
      "eval_loss": 30.205127716064453,
      "eval_runtime": 3.5337,
      "eval_samples_per_second": 56.597,
      "eval_steps_per_second": 2.547,
      "step": 300
    },
    {
      "epoch": 0.07439404847612191,
      "grad_norm": 697.2623901367188,
      "learning_rate": 2.470023980815348e-05,
      "loss": 32.2168,
      "step": 310
    },
    {
      "epoch": 0.07679385649148068,
      "grad_norm": 1685.843017578125,
      "learning_rate": 2.5499600319744203e-05,
      "loss": 30.4563,
      "step": 320
    },
    {
      "epoch": 0.07919366450683946,
      "grad_norm": 713.8228759765625,
      "learning_rate": 2.6298960831334934e-05,
      "loss": 30.005,
      "step": 330
    },
    {
      "epoch": 0.08159347252219823,
      "grad_norm": 1336.036865234375,
      "learning_rate": 2.7098321342925658e-05,
      "loss": 29.2537,
      "step": 340
    },
    {
      "epoch": 0.08399328053755699,
      "grad_norm": 749.2225341796875,
      "learning_rate": 2.789768185451639e-05,
      "loss": 28.0997,
      "step": 350
    },
    {
      "epoch": 0.08399328053755699,
      "eval_loss": 26.297128677368164,
      "eval_runtime": 3.5361,
      "eval_samples_per_second": 56.559,
      "eval_steps_per_second": 2.545,
      "step": 350
    },
    {
      "epoch": 0.08639308855291576,
      "grad_norm": 921.3932495117188,
      "learning_rate": 2.8697042366107113e-05,
      "loss": 28.3363,
      "step": 360
    },
    {
      "epoch": 0.08879289656827453,
      "grad_norm": 8581.677734375,
      "learning_rate": 2.9496402877697844e-05,
      "loss": 26.9747,
      "step": 370
    },
    {
      "epoch": 0.09119270458363331,
      "grad_norm": 582.1158447265625,
      "learning_rate": 3.029576338928857e-05,
      "loss": 26.6485,
      "step": 380
    },
    {
      "epoch": 0.09359251259899208,
      "grad_norm": 857.537109375,
      "learning_rate": 3.1095123900879295e-05,
      "loss": 25.0433,
      "step": 390
    },
    {
      "epoch": 0.09599232061435085,
      "grad_norm": 2305.95263671875,
      "learning_rate": 3.1894484412470026e-05,
      "loss": 24.1887,
      "step": 400
    },
    {
      "epoch": 0.09599232061435085,
      "eval_loss": 21.384199142456055,
      "eval_runtime": 3.5341,
      "eval_samples_per_second": 56.592,
      "eval_steps_per_second": 2.547,
      "step": 400
    },
    {
      "epoch": 0.09839212862970963,
      "grad_norm": 661.3485717773438,
      "learning_rate": 3.269384492406075e-05,
      "loss": 22.8855,
      "step": 410
    },
    {
      "epoch": 0.1007919366450684,
      "grad_norm": 802.1090698242188,
      "learning_rate": 3.349320543565148e-05,
      "loss": 22.1021,
      "step": 420
    },
    {
      "epoch": 0.10319174466042716,
      "grad_norm": 2973.479736328125,
      "learning_rate": 3.4292565947242205e-05,
      "loss": 20.7333,
      "step": 430
    },
    {
      "epoch": 0.10559155267578593,
      "grad_norm": 1482.7247314453125,
      "learning_rate": 3.5091926458832936e-05,
      "loss": 19.6975,
      "step": 440
    },
    {
      "epoch": 0.1079913606911447,
      "grad_norm": 4084.480712890625,
      "learning_rate": 3.589128697042367e-05,
      "loss": 18.9831,
      "step": 450
    },
    {
      "epoch": 0.1079913606911447,
      "eval_loss": 16.55506134033203,
      "eval_runtime": 3.5327,
      "eval_samples_per_second": 56.613,
      "eval_steps_per_second": 2.548,
      "step": 450
    },
    {
      "epoch": 0.11039116870650348,
      "grad_norm": 1016.520751953125,
      "learning_rate": 3.669064748201439e-05,
      "loss": 17.8557,
      "step": 460
    },
    {
      "epoch": 0.11279097672186225,
      "grad_norm": 1291.028076171875,
      "learning_rate": 3.749000799360512e-05,
      "loss": 16.5267,
      "step": 470
    },
    {
      "epoch": 0.11519078473722102,
      "grad_norm": 1190.7479248046875,
      "learning_rate": 3.8289368505195846e-05,
      "loss": 15.435,
      "step": 480
    },
    {
      "epoch": 0.1175905927525798,
      "grad_norm": 564.7034912109375,
      "learning_rate": 3.908872901678658e-05,
      "loss": 14.2659,
      "step": 490
    },
    {
      "epoch": 0.11999040076793857,
      "grad_norm": 3273.925048828125,
      "learning_rate": 3.98880895283773e-05,
      "loss": 13.381,
      "step": 500
    },
    {
      "epoch": 0.11999040076793857,
      "eval_loss": 9.740848541259766,
      "eval_runtime": 3.5338,
      "eval_samples_per_second": 56.597,
      "eval_steps_per_second": 2.547,
      "step": 500
    },
    {
      "epoch": 0.12239020878329733,
      "grad_norm": 1025.7908935546875,
      "learning_rate": 4.0687450039968025e-05,
      "loss": 11.897,
      "step": 510
    },
    {
      "epoch": 0.1247900167986561,
      "grad_norm": 830.360107421875,
      "learning_rate": 4.148681055155875e-05,
      "loss": 10.9509,
      "step": 520
    },
    {
      "epoch": 0.1271898248140149,
      "grad_norm": 1750.0487060546875,
      "learning_rate": 4.228617106314948e-05,
      "loss": 9.5827,
      "step": 530
    },
    {
      "epoch": 0.12958963282937366,
      "grad_norm": 2280.88916015625,
      "learning_rate": 4.308553157474021e-05,
      "loss": 8.8461,
      "step": 540
    },
    {
      "epoch": 0.1319894408447324,
      "grad_norm": 330.0394592285156,
      "learning_rate": 4.3884892086330935e-05,
      "loss": 8.1002,
      "step": 550
    },
    {
      "epoch": 0.1319894408447324,
      "eval_loss": 6.136446475982666,
      "eval_runtime": 3.5334,
      "eval_samples_per_second": 56.603,
      "eval_steps_per_second": 2.547,
      "step": 550
    },
    {
      "epoch": 0.13438924886009118,
      "grad_norm": 158.31195068359375,
      "learning_rate": 4.4684252597921666e-05,
      "loss": 7.43,
      "step": 560
    },
    {
      "epoch": 0.13678905687544995,
      "grad_norm": 458.92291259765625,
      "learning_rate": 4.548361310951239e-05,
      "loss": 7.0442,
      "step": 570
    },
    {
      "epoch": 0.13918886489080873,
      "grad_norm": 200.6309814453125,
      "learning_rate": 4.628297362110312e-05,
      "loss": 6.6715,
      "step": 580
    },
    {
      "epoch": 0.1415886729061675,
      "grad_norm": 663.9535522460938,
      "learning_rate": 4.7082334132693845e-05,
      "loss": 6.2199,
      "step": 590
    },
    {
      "epoch": 0.14398848092152627,
      "grad_norm": 280.0034484863281,
      "learning_rate": 4.7881694644284576e-05,
      "loss": 5.8222,
      "step": 600
    },
    {
      "epoch": 0.14398848092152627,
      "eval_loss": 4.96762228012085,
      "eval_runtime": 3.5326,
      "eval_samples_per_second": 56.615,
      "eval_steps_per_second": 2.548,
      "step": 600
    },
    {
      "epoch": 0.14638828893688505,
      "grad_norm": 64.81444549560547,
      "learning_rate": 4.868105515587531e-05,
      "loss": 5.3493,
      "step": 610
    },
    {
      "epoch": 0.14878809695224382,
      "grad_norm": 271.94793701171875,
      "learning_rate": 4.948041566746603e-05,
      "loss": 4.864,
      "step": 620
    },
    {
      "epoch": 0.1511879049676026,
      "grad_norm": 125.07612609863281,
      "learning_rate": 5.027977617905676e-05,
      "loss": 4.3805,
      "step": 630
    },
    {
      "epoch": 0.15358771298296137,
      "grad_norm": 108.51145935058594,
      "learning_rate": 5.1079136690647486e-05,
      "loss": 3.8653,
      "step": 640
    },
    {
      "epoch": 0.15598752099832014,
      "grad_norm": 37.20057678222656,
      "learning_rate": 5.187849720223821e-05,
      "loss": 3.4682,
      "step": 650
    },
    {
      "epoch": 0.15598752099832014,
      "eval_loss": 3.0887584686279297,
      "eval_runtime": 3.5332,
      "eval_samples_per_second": 56.607,
      "eval_steps_per_second": 2.547,
      "step": 650
    },
    {
      "epoch": 0.1583873290136789,
      "grad_norm": 32.050472259521484,
      "learning_rate": 5.267785771382894e-05,
      "loss": 3.3094,
      "step": 660
    },
    {
      "epoch": 0.16078713702903769,
      "grad_norm": 13.571475982666016,
      "learning_rate": 5.3477218225419665e-05,
      "loss": 3.1232,
      "step": 670
    },
    {
      "epoch": 0.16318694504439646,
      "grad_norm": 34.07176208496094,
      "learning_rate": 5.4276578737010396e-05,
      "loss": 2.9848,
      "step": 680
    },
    {
      "epoch": 0.16558675305975523,
      "grad_norm": 54.359466552734375,
      "learning_rate": 5.5075939248601126e-05,
      "loss": 2.8818,
      "step": 690
    },
    {
      "epoch": 0.16798656107511398,
      "grad_norm": 54.666175842285156,
      "learning_rate": 5.5875299760191844e-05,
      "loss": 2.7115,
      "step": 700
    },
    {
      "epoch": 0.16798656107511398,
      "eval_loss": 2.7540111541748047,
      "eval_runtime": 3.5382,
      "eval_samples_per_second": 56.527,
      "eval_steps_per_second": 2.544,
      "step": 700
    },
    {
      "epoch": 0.17038636909047275,
      "grad_norm": 75.738525390625,
      "learning_rate": 5.6674660271782575e-05,
      "loss": 2.7564,
      "step": 710
    },
    {
      "epoch": 0.17278617710583152,
      "grad_norm": 8.923945426940918,
      "learning_rate": 5.7474020783373306e-05,
      "loss": 2.857,
      "step": 720
    },
    {
      "epoch": 0.1751859851211903,
      "grad_norm": 28.076087951660156,
      "learning_rate": 5.8273381294964036e-05,
      "loss": 2.8437,
      "step": 730
    },
    {
      "epoch": 0.17758579313654907,
      "grad_norm": 27.839685440063477,
      "learning_rate": 5.9072741806554754e-05,
      "loss": 2.6909,
      "step": 740
    },
    {
      "epoch": 0.17998560115190784,
      "grad_norm": 10.10289478302002,
      "learning_rate": 5.9872102318145485e-05,
      "loss": 2.4839,
      "step": 750
    },
    {
      "epoch": 0.17998560115190784,
      "eval_loss": 2.6042003631591797,
      "eval_runtime": 3.534,
      "eval_samples_per_second": 56.593,
      "eval_steps_per_second": 2.547,
      "step": 750
    },
    {
      "epoch": 0.18238540916726662,
      "grad_norm": 7.858004093170166,
      "learning_rate": 6.0671462829736215e-05,
      "loss": 2.5123,
      "step": 760
    },
    {
      "epoch": 0.1847852171826254,
      "grad_norm": 8.220105171203613,
      "learning_rate": 6.147082334132694e-05,
      "loss": 2.5328,
      "step": 770
    },
    {
      "epoch": 0.18718502519798416,
      "grad_norm": 11.651849746704102,
      "learning_rate": 6.227018385291767e-05,
      "loss": 2.3914,
      "step": 780
    },
    {
      "epoch": 0.18958483321334293,
      "grad_norm": 4.3369340896606445,
      "learning_rate": 6.306954436450839e-05,
      "loss": 2.3852,
      "step": 790
    },
    {
      "epoch": 0.1919846412287017,
      "grad_norm": 50.97649383544922,
      "learning_rate": 6.386890487609912e-05,
      "loss": 2.6435,
      "step": 800
    },
    {
      "epoch": 0.1919846412287017,
      "eval_loss": 2.4978604316711426,
      "eval_runtime": 3.5343,
      "eval_samples_per_second": 56.589,
      "eval_steps_per_second": 2.546,
      "step": 800
    },
    {
      "epoch": 0.19438444924406048,
      "grad_norm": 72.24800872802734,
      "learning_rate": 6.466826538768985e-05,
      "loss": 2.2962,
      "step": 810
    },
    {
      "epoch": 0.19678425725941925,
      "grad_norm": 42.11671447753906,
      "learning_rate": 6.546762589928058e-05,
      "loss": 2.557,
      "step": 820
    },
    {
      "epoch": 0.19918406527477803,
      "grad_norm": 101.18547821044922,
      "learning_rate": 6.62669864108713e-05,
      "loss": 2.4721,
      "step": 830
    },
    {
      "epoch": 0.2015838732901368,
      "grad_norm": 2.8198606967926025,
      "learning_rate": 6.706634692246203e-05,
      "loss": 2.4852,
      "step": 840
    },
    {
      "epoch": 0.20398368130549557,
      "grad_norm": 15.123994827270508,
      "learning_rate": 6.786570743405276e-05,
      "loss": 2.3691,
      "step": 850
    },
    {
      "epoch": 0.20398368130549557,
      "eval_loss": 2.3938074111938477,
      "eval_runtime": 3.5337,
      "eval_samples_per_second": 56.599,
      "eval_steps_per_second": 2.547,
      "step": 850
    },
    {
      "epoch": 0.20638348932085432,
      "grad_norm": 3.1589674949645996,
      "learning_rate": 6.866506794564349e-05,
      "loss": 2.5121,
      "step": 860
    },
    {
      "epoch": 0.2087832973362131,
      "grad_norm": 15.079723358154297,
      "learning_rate": 6.946442845723422e-05,
      "loss": 2.3612,
      "step": 870
    },
    {
      "epoch": 0.21118310535157186,
      "grad_norm": 3.220297336578369,
      "learning_rate": 7.026378896882494e-05,
      "loss": 2.3983,
      "step": 880
    },
    {
      "epoch": 0.21358291336693064,
      "grad_norm": 3.0987708568573,
      "learning_rate": 7.106314948041567e-05,
      "loss": 2.3669,
      "step": 890
    },
    {
      "epoch": 0.2159827213822894,
      "grad_norm": 8.319130897521973,
      "learning_rate": 7.18625099920064e-05,
      "loss": 2.2441,
      "step": 900
    },
    {
      "epoch": 0.2159827213822894,
      "eval_loss": 2.179056406021118,
      "eval_runtime": 3.5329,
      "eval_samples_per_second": 56.611,
      "eval_steps_per_second": 2.547,
      "step": 900
    },
    {
      "epoch": 0.21838252939764818,
      "grad_norm": 3.232095718383789,
      "learning_rate": 7.266187050359713e-05,
      "loss": 2.2203,
      "step": 910
    },
    {
      "epoch": 0.22078233741300696,
      "grad_norm": 5.025664329528809,
      "learning_rate": 7.346123101518785e-05,
      "loss": 2.4085,
      "step": 920
    },
    {
      "epoch": 0.22318214542836573,
      "grad_norm": 3.735668420791626,
      "learning_rate": 7.426059152677858e-05,
      "loss": 2.1942,
      "step": 930
    },
    {
      "epoch": 0.2255819534437245,
      "grad_norm": 4.675115585327148,
      "learning_rate": 7.505995203836931e-05,
      "loss": 2.0862,
      "step": 940
    },
    {
      "epoch": 0.22798176145908328,
      "grad_norm": 7.877604961395264,
      "learning_rate": 7.585931254996004e-05,
      "loss": 1.9532,
      "step": 950
    },
    {
      "epoch": 0.22798176145908328,
      "eval_loss": 1.868385910987854,
      "eval_runtime": 3.5326,
      "eval_samples_per_second": 56.615,
      "eval_steps_per_second": 2.548,
      "step": 950
    },
    {
      "epoch": 0.23038156947444205,
      "grad_norm": 1.7342036962509155,
      "learning_rate": 7.665867306155077e-05,
      "loss": 2.066,
      "step": 960
    },
    {
      "epoch": 0.23278137748980082,
      "grad_norm": 2.8326995372772217,
      "learning_rate": 7.745803357314149e-05,
      "loss": 1.9134,
      "step": 970
    },
    {
      "epoch": 0.2351811855051596,
      "grad_norm": 1.6353471279144287,
      "learning_rate": 7.825739408473222e-05,
      "loss": 2.0402,
      "step": 980
    },
    {
      "epoch": 0.23758099352051837,
      "grad_norm": 0.8671401739120483,
      "learning_rate": 7.905675459632295e-05,
      "loss": 1.7991,
      "step": 990
    },
    {
      "epoch": 0.23998080153587714,
      "grad_norm": 2.2177860736846924,
      "learning_rate": 7.985611510791368e-05,
      "loss": 1.701,
      "step": 1000
    },
    {
      "epoch": 0.23998080153587714,
      "eval_loss": 1.5901343822479248,
      "eval_runtime": 3.5325,
      "eval_samples_per_second": 56.616,
      "eval_steps_per_second": 2.548,
      "step": 1000
    },
    {
      "epoch": 0.24238060955123591,
      "grad_norm": 0.6679611206054688,
      "learning_rate": 8.065547561950441e-05,
      "loss": 1.7572,
      "step": 1010
    },
    {
      "epoch": 0.24478041756659466,
      "grad_norm": 0.6650682687759399,
      "learning_rate": 8.145483613109513e-05,
      "loss": 1.4492,
      "step": 1020
    },
    {
      "epoch": 0.24718022558195343,
      "grad_norm": 0.9345138072967529,
      "learning_rate": 8.225419664268586e-05,
      "loss": 1.5943,
      "step": 1030
    },
    {
      "epoch": 0.2495800335973122,
      "grad_norm": 5.165161609649658,
      "learning_rate": 8.305355715427658e-05,
      "loss": 1.7607,
      "step": 1040
    },
    {
      "epoch": 0.251979841612671,
      "grad_norm": 0.5197814702987671,
      "learning_rate": 8.385291766586731e-05,
      "loss": 1.5752,
      "step": 1050
    },
    {
      "epoch": 0.251979841612671,
      "eval_loss": 1.5148968696594238,
      "eval_runtime": 3.5319,
      "eval_samples_per_second": 56.627,
      "eval_steps_per_second": 2.548,
      "step": 1050
    },
    {
      "epoch": 0.2543796496280298,
      "grad_norm": 0.3492355942726135,
      "learning_rate": 8.465227817745804e-05,
      "loss": 1.592,
      "step": 1060
    },
    {
      "epoch": 0.25677945764338855,
      "grad_norm": 0.6175285577774048,
      "learning_rate": 8.545163868904876e-05,
      "loss": 1.5884,
      "step": 1070
    },
    {
      "epoch": 0.2591792656587473,
      "grad_norm": 0.35305213928222656,
      "learning_rate": 8.625099920063949e-05,
      "loss": 1.6157,
      "step": 1080
    },
    {
      "epoch": 0.26157907367410604,
      "grad_norm": 0.4196368455886841,
      "learning_rate": 8.705035971223022e-05,
      "loss": 1.5064,
      "step": 1090
    },
    {
      "epoch": 0.2639788816894648,
      "grad_norm": 0.3530399799346924,
      "learning_rate": 8.784972022382095e-05,
      "loss": 1.5976,
      "step": 1100
    },
    {
      "epoch": 0.2639788816894648,
      "eval_loss": 1.4676381349563599,
      "eval_runtime": 3.5328,
      "eval_samples_per_second": 56.613,
      "eval_steps_per_second": 2.548,
      "step": 1100
    },
    {
      "epoch": 0.2663786897048236,
      "grad_norm": 0.3239336311817169,
      "learning_rate": 8.864908073541167e-05,
      "loss": 1.4591,
      "step": 1110
    },
    {
      "epoch": 0.26877849772018236,
      "grad_norm": 0.406488835811615,
      "learning_rate": 8.94484412470024e-05,
      "loss": 1.5571,
      "step": 1120
    },
    {
      "epoch": 0.27117830573554114,
      "grad_norm": 0.35631263256073,
      "learning_rate": 9.024780175859313e-05,
      "loss": 1.3977,
      "step": 1130
    },
    {
      "epoch": 0.2735781137508999,
      "grad_norm": 0.32898005843162537,
      "learning_rate": 9.104716227018386e-05,
      "loss": 1.4761,
      "step": 1140
    },
    {
      "epoch": 0.2759779217662587,
      "grad_norm": 0.29275473952293396,
      "learning_rate": 9.184652278177458e-05,
      "loss": 1.4447,
      "step": 1150
    },
    {
      "epoch": 0.2759779217662587,
      "eval_loss": 1.4448715448379517,
      "eval_runtime": 3.5311,
      "eval_samples_per_second": 56.64,
      "eval_steps_per_second": 2.549,
      "step": 1150
    },
    {
      "epoch": 0.27837772978161746,
      "grad_norm": 0.3923865556716919,
      "learning_rate": 9.264588329336531e-05,
      "loss": 1.5689,
      "step": 1160
    },
    {
      "epoch": 0.28077753779697623,
      "grad_norm": 0.35231250524520874,
      "learning_rate": 9.344524380495604e-05,
      "loss": 1.3927,
      "step": 1170
    },
    {
      "epoch": 0.283177345812335,
      "grad_norm": 0.2779305577278137,
      "learning_rate": 9.424460431654677e-05,
      "loss": 1.5266,
      "step": 1180
    },
    {
      "epoch": 0.2855771538276938,
      "grad_norm": 0.29937297105789185,
      "learning_rate": 9.50439648281375e-05,
      "loss": 1.5743,
      "step": 1190
    },
    {
      "epoch": 0.28797696184305255,
      "grad_norm": 0.3915446400642395,
      "learning_rate": 9.584332533972822e-05,
      "loss": 1.4056,
      "step": 1200
    },
    {
      "epoch": 0.28797696184305255,
      "eval_loss": 1.4223082065582275,
      "eval_runtime": 3.5325,
      "eval_samples_per_second": 56.617,
      "eval_steps_per_second": 2.548,
      "step": 1200
    },
    {
      "epoch": 0.2903767698584113,
      "grad_norm": 0.405159592628479,
      "learning_rate": 9.664268585131895e-05,
      "loss": 1.5927,
      "step": 1210
    },
    {
      "epoch": 0.2927765778737701,
      "grad_norm": 0.2919314503669739,
      "learning_rate": 9.744204636290968e-05,
      "loss": 1.556,
      "step": 1220
    },
    {
      "epoch": 0.29517638588912887,
      "grad_norm": 0.34753674268722534,
      "learning_rate": 9.824140687450041e-05,
      "loss": 1.563,
      "step": 1230
    },
    {
      "epoch": 0.29757619390448764,
      "grad_norm": 1.139778971672058,
      "learning_rate": 9.904076738609113e-05,
      "loss": 1.411,
      "step": 1240
    },
    {
      "epoch": 0.2999760019198464,
      "grad_norm": 0.4294786751270294,
      "learning_rate": 9.984012789768186e-05,
      "loss": 1.4311,
      "step": 1250
    },
    {
      "epoch": 0.2999760019198464,
      "eval_loss": 1.4066743850708008,
      "eval_runtime": 3.5365,
      "eval_samples_per_second": 56.553,
      "eval_steps_per_second": 2.545,
      "step": 1250
    },
    {
      "epoch": 0.3023758099352052,
      "grad_norm": 0.5305262207984924,
      "learning_rate": 9.99288888888889e-05,
      "loss": 1.3259,
      "step": 1260
    },
    {
      "epoch": 0.30477561795056396,
      "grad_norm": 0.3720366358757019,
      "learning_rate": 9.984e-05,
      "loss": 1.4699,
      "step": 1270
    },
    {
      "epoch": 0.30717542596592273,
      "grad_norm": 0.2637713849544525,
      "learning_rate": 9.975111111111112e-05,
      "loss": 1.3521,
      "step": 1280
    },
    {
      "epoch": 0.3095752339812815,
      "grad_norm": 0.4111570417881012,
      "learning_rate": 9.966222222222223e-05,
      "loss": 1.4984,
      "step": 1290
    },
    {
      "epoch": 0.3119750419966403,
      "grad_norm": 0.40454813838005066,
      "learning_rate": 9.957333333333334e-05,
      "loss": 1.4435,
      "step": 1300
    },
    {
      "epoch": 0.3119750419966403,
      "eval_loss": 1.3947868347167969,
      "eval_runtime": 3.5322,
      "eval_samples_per_second": 56.622,
      "eval_steps_per_second": 2.548,
      "step": 1300
    },
    {
      "epoch": 0.31437485001199905,
      "grad_norm": 21.323081970214844,
      "learning_rate": 9.948444444444445e-05,
      "loss": 1.5006,
      "step": 1310
    },
    {
      "epoch": 0.3167746580273578,
      "grad_norm": 0.37921229004859924,
      "learning_rate": 9.939555555555556e-05,
      "loss": 1.4973,
      "step": 1320
    },
    {
      "epoch": 0.3191744660427166,
      "grad_norm": 0.27844104170799255,
      "learning_rate": 9.930666666666667e-05,
      "loss": 1.5084,
      "step": 1330
    },
    {
      "epoch": 0.32157427405807537,
      "grad_norm": 0.25288552045822144,
      "learning_rate": 9.921777777777779e-05,
      "loss": 1.3817,
      "step": 1340
    },
    {
      "epoch": 0.32397408207343414,
      "grad_norm": 0.3789837062358856,
      "learning_rate": 9.912888888888889e-05,
      "loss": 1.5541,
      "step": 1350
    },
    {
      "epoch": 0.32397408207343414,
      "eval_loss": 1.3859983682632446,
      "eval_runtime": 3.5433,
      "eval_samples_per_second": 56.444,
      "eval_steps_per_second": 2.54,
      "step": 1350
    },
    {
      "epoch": 0.3263738900887929,
      "grad_norm": 0.28338584303855896,
      "learning_rate": 9.904e-05,
      "loss": 1.4253,
      "step": 1360
    },
    {
      "epoch": 0.3287736981041517,
      "grad_norm": 0.3520510196685791,
      "learning_rate": 9.895111111111111e-05,
      "loss": 1.4222,
      "step": 1370
    },
    {
      "epoch": 0.33117350611951046,
      "grad_norm": 0.29364317655563354,
      "learning_rate": 9.886222222222222e-05,
      "loss": 1.4704,
      "step": 1380
    },
    {
      "epoch": 0.33357331413486924,
      "grad_norm": 0.4010985791683197,
      "learning_rate": 9.877333333333335e-05,
      "loss": 1.341,
      "step": 1390
    },
    {
      "epoch": 0.33597312215022795,
      "grad_norm": 0.22897715866565704,
      "learning_rate": 9.868444444444444e-05,
      "loss": 1.398,
      "step": 1400
    },
    {
      "epoch": 0.33597312215022795,
      "eval_loss": 1.3797146081924438,
      "eval_runtime": 3.54,
      "eval_samples_per_second": 56.498,
      "eval_steps_per_second": 2.542,
      "step": 1400
    },
    {
      "epoch": 0.3383729301655867,
      "grad_norm": 0.30681663751602173,
      "learning_rate": 9.859555555555557e-05,
      "loss": 1.3864,
      "step": 1410
    },
    {
      "epoch": 0.3407727381809455,
      "grad_norm": 0.3049071431159973,
      "learning_rate": 9.850666666666666e-05,
      "loss": 1.4313,
      "step": 1420
    },
    {
      "epoch": 0.3431725461963043,
      "grad_norm": 0.2731112241744995,
      "learning_rate": 9.841777777777779e-05,
      "loss": 1.4329,
      "step": 1430
    },
    {
      "epoch": 0.34557235421166305,
      "grad_norm": 0.32599520683288574,
      "learning_rate": 9.83288888888889e-05,
      "loss": 1.3816,
      "step": 1440
    },
    {
      "epoch": 0.3479721622270218,
      "grad_norm": 0.2854572534561157,
      "learning_rate": 9.824000000000001e-05,
      "loss": 1.2908,
      "step": 1450
    },
    {
      "epoch": 0.3479721622270218,
      "eval_loss": 1.3708946704864502,
      "eval_runtime": 3.5368,
      "eval_samples_per_second": 56.548,
      "eval_steps_per_second": 2.545,
      "step": 1450
    },
    {
      "epoch": 0.3503719702423806,
      "grad_norm": 0.2790869474411011,
      "learning_rate": 9.815111111111112e-05,
      "loss": 1.3719,
      "step": 1460
    },
    {
      "epoch": 0.35277177825773937,
      "grad_norm": 0.334494948387146,
      "learning_rate": 9.806222222222222e-05,
      "loss": 1.3839,
      "step": 1470
    },
    {
      "epoch": 0.35517158627309814,
      "grad_norm": 0.2800653576850891,
      "learning_rate": 9.797333333333334e-05,
      "loss": 1.4173,
      "step": 1480
    },
    {
      "epoch": 0.3575713942884569,
      "grad_norm": 0.35549986362457275,
      "learning_rate": 9.788444444444445e-05,
      "loss": 1.4539,
      "step": 1490
    },
    {
      "epoch": 0.3599712023038157,
      "grad_norm": 1.2219239473342896,
      "learning_rate": 9.779555555555556e-05,
      "loss": 1.3547,
      "step": 1500
    },
    {
      "epoch": 0.3599712023038157,
      "eval_loss": 1.3693511486053467,
      "eval_runtime": 3.5422,
      "eval_samples_per_second": 56.463,
      "eval_steps_per_second": 2.541,
      "step": 1500
    },
    {
      "epoch": 0.36237101031917446,
      "grad_norm": 0.29655593633651733,
      "learning_rate": 9.770666666666667e-05,
      "loss": 1.4115,
      "step": 1510
    },
    {
      "epoch": 0.36477081833453323,
      "grad_norm": 0.32850712537765503,
      "learning_rate": 9.761777777777778e-05,
      "loss": 1.2947,
      "step": 1520
    },
    {
      "epoch": 0.367170626349892,
      "grad_norm": 0.31669187545776367,
      "learning_rate": 9.752888888888889e-05,
      "loss": 1.424,
      "step": 1530
    },
    {
      "epoch": 0.3695704343652508,
      "grad_norm": 0.37592193484306335,
      "learning_rate": 9.744000000000002e-05,
      "loss": 1.4219,
      "step": 1540
    },
    {
      "epoch": 0.37197024238060955,
      "grad_norm": 0.33424511551856995,
      "learning_rate": 9.735111111111111e-05,
      "loss": 1.4208,
      "step": 1550
    },
    {
      "epoch": 0.37197024238060955,
      "eval_loss": 1.3627070188522339,
      "eval_runtime": 3.5373,
      "eval_samples_per_second": 56.541,
      "eval_steps_per_second": 2.544,
      "step": 1550
    },
    {
      "epoch": 0.3743700503959683,
      "grad_norm": 0.5350868105888367,
      "learning_rate": 9.726222222222224e-05,
      "loss": 1.4161,
      "step": 1560
    },
    {
      "epoch": 0.3767698584113271,
      "grad_norm": 0.2529236674308777,
      "learning_rate": 9.717333333333333e-05,
      "loss": 1.3354,
      "step": 1570
    },
    {
      "epoch": 0.37916966642668587,
      "grad_norm": 0.3135429322719574,
      "learning_rate": 9.708444444444444e-05,
      "loss": 1.3468,
      "step": 1580
    },
    {
      "epoch": 0.38156947444204464,
      "grad_norm": 0.2959218919277191,
      "learning_rate": 9.699555555555557e-05,
      "loss": 1.4593,
      "step": 1590
    },
    {
      "epoch": 0.3839692824574034,
      "grad_norm": 0.3493456244468689,
      "learning_rate": 9.690666666666666e-05,
      "loss": 1.523,
      "step": 1600
    },
    {
      "epoch": 0.3839692824574034,
      "eval_loss": 1.3582711219787598,
      "eval_runtime": 3.5369,
      "eval_samples_per_second": 56.546,
      "eval_steps_per_second": 2.545,
      "step": 1600
    },
    {
      "epoch": 0.3863690904727622,
      "grad_norm": 0.266381174325943,
      "learning_rate": 9.681777777777779e-05,
      "loss": 1.3416,
      "step": 1610
    },
    {
      "epoch": 0.38876889848812096,
      "grad_norm": 0.31851497292518616,
      "learning_rate": 9.672888888888889e-05,
      "loss": 1.3671,
      "step": 1620
    },
    {
      "epoch": 0.39116870650347974,
      "grad_norm": 0.31342554092407227,
      "learning_rate": 9.664000000000001e-05,
      "loss": 1.4276,
      "step": 1630
    },
    {
      "epoch": 0.3935685145188385,
      "grad_norm": 0.2638597786426544,
      "learning_rate": 9.655111111111112e-05,
      "loss": 1.3287,
      "step": 1640
    },
    {
      "epoch": 0.3959683225341973,
      "grad_norm": 0.31207147240638733,
      "learning_rate": 9.646222222222223e-05,
      "loss": 1.3935,
      "step": 1650
    },
    {
      "epoch": 0.3959683225341973,
      "eval_loss": 1.3530502319335938,
      "eval_runtime": 3.5386,
      "eval_samples_per_second": 56.52,
      "eval_steps_per_second": 2.543,
      "step": 1650
    },
    {
      "epoch": 0.39836813054955605,
      "grad_norm": 0.28676265478134155,
      "learning_rate": 9.637333333333334e-05,
      "loss": 1.4627,
      "step": 1660
    },
    {
      "epoch": 0.4007679385649148,
      "grad_norm": 0.3122779130935669,
      "learning_rate": 9.628444444444444e-05,
      "loss": 1.3697,
      "step": 1670
    },
    {
      "epoch": 0.4031677465802736,
      "grad_norm": 0.2854672968387604,
      "learning_rate": 9.619555555555556e-05,
      "loss": 1.4558,
      "step": 1680
    },
    {
      "epoch": 0.4055675545956324,
      "grad_norm": 0.3367665112018585,
      "learning_rate": 9.610666666666667e-05,
      "loss": 1.4043,
      "step": 1690
    },
    {
      "epoch": 0.40796736261099115,
      "grad_norm": 0.3046903908252716,
      "learning_rate": 9.601777777777778e-05,
      "loss": 1.2933,
      "step": 1700
    },
    {
      "epoch": 0.40796736261099115,
      "eval_loss": 1.350296139717102,
      "eval_runtime": 3.5365,
      "eval_samples_per_second": 56.553,
      "eval_steps_per_second": 2.545,
      "step": 1700
    },
    {
      "epoch": 0.4103671706263499,
      "grad_norm": 0.2549399435520172,
      "learning_rate": 9.59288888888889e-05,
      "loss": 1.4234,
      "step": 1710
    },
    {
      "epoch": 0.41276697864170864,
      "grad_norm": 0.340299129486084,
      "learning_rate": 9.584e-05,
      "loss": 1.5562,
      "step": 1720
    },
    {
      "epoch": 0.4151667866570674,
      "grad_norm": 0.312583863735199,
      "learning_rate": 9.575111111111111e-05,
      "loss": 1.3175,
      "step": 1730
    },
    {
      "epoch": 0.4175665946724262,
      "grad_norm": 0.33660420775413513,
      "learning_rate": 9.566222222222222e-05,
      "loss": 1.4242,
      "step": 1740
    },
    {
      "epoch": 0.41996640268778496,
      "grad_norm": 0.30836448073387146,
      "learning_rate": 9.557333333333334e-05,
      "loss": 1.4704,
      "step": 1750
    },
    {
      "epoch": 0.41996640268778496,
      "eval_loss": 1.3503036499023438,
      "eval_runtime": 3.5358,
      "eval_samples_per_second": 56.564,
      "eval_steps_per_second": 2.545,
      "step": 1750
    },
    {
      "epoch": 0.42236621070314373,
      "grad_norm": 243.95797729492188,
      "learning_rate": 9.548444444444446e-05,
      "loss": 1.4827,
      "step": 1760
    },
    {
      "epoch": 0.4247660187185025,
      "grad_norm": 0.32481950521469116,
      "learning_rate": 9.539555555555556e-05,
      "loss": 1.4931,
      "step": 1770
    },
    {
      "epoch": 0.4271658267338613,
      "grad_norm": 0.31564566493034363,
      "learning_rate": 9.530666666666667e-05,
      "loss": 1.2852,
      "step": 1780
    },
    {
      "epoch": 0.42956563474922005,
      "grad_norm": 0.36674076318740845,
      "learning_rate": 9.521777777777778e-05,
      "loss": 1.4531,
      "step": 1790
    },
    {
      "epoch": 0.4319654427645788,
      "grad_norm": 0.2684743404388428,
      "learning_rate": 9.512888888888889e-05,
      "loss": 1.3169,
      "step": 1800
    },
    {
      "epoch": 0.4319654427645788,
      "eval_loss": 1.3476893901824951,
      "eval_runtime": 3.5368,
      "eval_samples_per_second": 56.549,
      "eval_steps_per_second": 2.545,
      "step": 1800
    },
    {
      "epoch": 0.4343652507799376,
      "grad_norm": 0.41066986322402954,
      "learning_rate": 9.504000000000001e-05,
      "loss": 1.3467,
      "step": 1810
    },
    {
      "epoch": 0.43676505879529637,
      "grad_norm": 0.3244982361793518,
      "learning_rate": 9.495111111111111e-05,
      "loss": 1.2897,
      "step": 1820
    },
    {
      "epoch": 0.43916486681065514,
      "grad_norm": 0.3236263692378998,
      "learning_rate": 9.486222222222223e-05,
      "loss": 1.3595,
      "step": 1830
    },
    {
      "epoch": 0.4415646748260139,
      "grad_norm": 0.3058781921863556,
      "learning_rate": 9.477333333333333e-05,
      "loss": 1.3842,
      "step": 1840
    },
    {
      "epoch": 0.4439644828413727,
      "grad_norm": 0.29845619201660156,
      "learning_rate": 9.468444444444445e-05,
      "loss": 1.3699,
      "step": 1850
    },
    {
      "epoch": 0.4439644828413727,
      "eval_loss": 1.3431854248046875,
      "eval_runtime": 3.5366,
      "eval_samples_per_second": 56.551,
      "eval_steps_per_second": 2.545,
      "step": 1850
    },
    {
      "epoch": 0.44636429085673146,
      "grad_norm": 0.8415424227714539,
      "learning_rate": 9.459555555555556e-05,
      "loss": 1.3692,
      "step": 1860
    },
    {
      "epoch": 0.44876409887209023,
      "grad_norm": 0.3054139018058777,
      "learning_rate": 9.450666666666667e-05,
      "loss": 1.4245,
      "step": 1870
    },
    {
      "epoch": 0.451163906887449,
      "grad_norm": 0.2769217789173126,
      "learning_rate": 9.441777777777778e-05,
      "loss": 1.3585,
      "step": 1880
    },
    {
      "epoch": 0.4535637149028078,
      "grad_norm": 0.41467583179473877,
      "learning_rate": 9.43288888888889e-05,
      "loss": 1.4158,
      "step": 1890
    },
    {
      "epoch": 0.45596352291816655,
      "grad_norm": 0.29008749127388,
      "learning_rate": 9.424e-05,
      "loss": 1.2847,
      "step": 1900
    },
    {
      "epoch": 0.45596352291816655,
      "eval_loss": 1.3422263860702515,
      "eval_runtime": 3.5368,
      "eval_samples_per_second": 56.549,
      "eval_steps_per_second": 2.545,
      "step": 1900
    },
    {
      "epoch": 0.4583633309335253,
      "grad_norm": 0.3188832700252533,
      "learning_rate": 9.415111111111112e-05,
      "loss": 1.3333,
      "step": 1910
    },
    {
      "epoch": 0.4607631389488841,
      "grad_norm": 0.31362590193748474,
      "learning_rate": 9.406222222222223e-05,
      "loss": 1.3035,
      "step": 1920
    },
    {
      "epoch": 0.46316294696424287,
      "grad_norm": 0.26490750908851624,
      "learning_rate": 9.397333333333334e-05,
      "loss": 1.3917,
      "step": 1930
    },
    {
      "epoch": 0.46556275497960165,
      "grad_norm": 0.30137157440185547,
      "learning_rate": 9.388444444444445e-05,
      "loss": 1.3748,
      "step": 1940
    },
    {
      "epoch": 0.4679625629949604,
      "grad_norm": 0.3140799105167389,
      "learning_rate": 9.379555555555556e-05,
      "loss": 1.3977,
      "step": 1950
    },
    {
      "epoch": 0.4679625629949604,
      "eval_loss": 1.342210292816162,
      "eval_runtime": 3.5362,
      "eval_samples_per_second": 56.557,
      "eval_steps_per_second": 2.545,
      "step": 1950
    },
    {
      "epoch": 0.4703623710103192,
      "grad_norm": 0.4609602987766266,
      "learning_rate": 9.370666666666668e-05,
      "loss": 1.4146,
      "step": 1960
    },
    {
      "epoch": 0.47276217902567796,
      "grad_norm": 0.28111860156059265,
      "learning_rate": 9.361777777777778e-05,
      "loss": 1.3738,
      "step": 1970
    },
    {
      "epoch": 0.47516198704103674,
      "grad_norm": 0.2525692880153656,
      "learning_rate": 9.352888888888889e-05,
      "loss": 1.3423,
      "step": 1980
    },
    {
      "epoch": 0.4775617950563955,
      "grad_norm": 0.25644242763519287,
      "learning_rate": 9.344e-05,
      "loss": 1.3286,
      "step": 1990
    },
    {
      "epoch": 0.4799616030717543,
      "grad_norm": 0.31404533982276917,
      "learning_rate": 9.335111111111111e-05,
      "loss": 1.4791,
      "step": 2000
    },
    {
      "epoch": 0.4799616030717543,
      "eval_loss": 1.338631272315979,
      "eval_runtime": 3.5355,
      "eval_samples_per_second": 56.568,
      "eval_steps_per_second": 2.546,
      "step": 2000
    },
    {
      "epoch": 0.48236141108711306,
      "grad_norm": 0.28025534749031067,
      "learning_rate": 9.326222222222223e-05,
      "loss": 1.3313,
      "step": 2010
    },
    {
      "epoch": 0.48476121910247183,
      "grad_norm": 0.30410829186439514,
      "learning_rate": 9.317333333333333e-05,
      "loss": 1.4066,
      "step": 2020
    },
    {
      "epoch": 0.48716102711783055,
      "grad_norm": 0.27760666608810425,
      "learning_rate": 9.308444444444446e-05,
      "loss": 1.2761,
      "step": 2030
    },
    {
      "epoch": 0.4895608351331893,
      "grad_norm": 0.3105944097042084,
      "learning_rate": 9.299555555555555e-05,
      "loss": 1.4149,
      "step": 2040
    },
    {
      "epoch": 0.4919606431485481,
      "grad_norm": 0.2843204140663147,
      "learning_rate": 9.290666666666668e-05,
      "loss": 1.2886,
      "step": 2050
    },
    {
      "epoch": 0.4919606431485481,
      "eval_loss": 1.3349348306655884,
      "eval_runtime": 3.5406,
      "eval_samples_per_second": 56.487,
      "eval_steps_per_second": 2.542,
      "step": 2050
    },
    {
      "epoch": 0.49436045116390687,
      "grad_norm": 0.3652426302433014,
      "learning_rate": 9.281777777777779e-05,
      "loss": 1.3612,
      "step": 2060
    },
    {
      "epoch": 0.49676025917926564,
      "grad_norm": 0.3036597967147827,
      "learning_rate": 9.27288888888889e-05,
      "loss": 1.4431,
      "step": 2070
    },
    {
      "epoch": 0.4991600671946244,
      "grad_norm": 0.2730458378791809,
      "learning_rate": 9.264000000000001e-05,
      "loss": 1.4873,
      "step": 2080
    },
    {
      "epoch": 0.5015598752099832,
      "grad_norm": 0.3694162368774414,
      "learning_rate": 9.25511111111111e-05,
      "loss": 1.3072,
      "step": 2090
    },
    {
      "epoch": 0.503959683225342,
      "grad_norm": 0.30263054370880127,
      "learning_rate": 9.246222222222223e-05,
      "loss": 1.4427,
      "step": 2100
    },
    {
      "epoch": 0.503959683225342,
      "eval_loss": 1.3333265781402588,
      "eval_runtime": 3.5362,
      "eval_samples_per_second": 56.558,
      "eval_steps_per_second": 2.545,
      "step": 2100
    },
    {
      "epoch": 0.5063594912407008,
      "grad_norm": 0.30135977268218994,
      "learning_rate": 9.237333333333334e-05,
      "loss": 1.4061,
      "step": 2110
    },
    {
      "epoch": 0.5087592992560596,
      "grad_norm": 0.31420791149139404,
      "learning_rate": 9.228444444444445e-05,
      "loss": 1.3993,
      "step": 2120
    },
    {
      "epoch": 0.5111591072714183,
      "grad_norm": 0.4156636893749237,
      "learning_rate": 9.219555555555556e-05,
      "loss": 1.3809,
      "step": 2130
    },
    {
      "epoch": 0.5135589152867771,
      "grad_norm": 0.2827709913253784,
      "learning_rate": 9.210666666666667e-05,
      "loss": 1.3147,
      "step": 2140
    },
    {
      "epoch": 0.5159587233021359,
      "grad_norm": 0.2939750552177429,
      "learning_rate": 9.201777777777778e-05,
      "loss": 1.3413,
      "step": 2150
    },
    {
      "epoch": 0.5159587233021359,
      "eval_loss": 1.3324774503707886,
      "eval_runtime": 3.5366,
      "eval_samples_per_second": 56.552,
      "eval_steps_per_second": 2.545,
      "step": 2150
    },
    {
      "epoch": 0.5183585313174947,
      "grad_norm": 0.23919551074504852,
      "learning_rate": 9.192888888888889e-05,
      "loss": 1.3771,
      "step": 2160
    },
    {
      "epoch": 0.5207583393328534,
      "grad_norm": 0.3276335299015045,
      "learning_rate": 9.184e-05,
      "loss": 1.4289,
      "step": 2170
    },
    {
      "epoch": 0.5231581473482121,
      "grad_norm": 0.26857563853263855,
      "learning_rate": 9.175111111111113e-05,
      "loss": 1.2943,
      "step": 2180
    },
    {
      "epoch": 0.5255579553635709,
      "grad_norm": 0.2943052053451538,
      "learning_rate": 9.166222222222222e-05,
      "loss": 1.3419,
      "step": 2190
    },
    {
      "epoch": 0.5279577633789296,
      "grad_norm": 0.2855285406112671,
      "learning_rate": 9.157333333333333e-05,
      "loss": 1.3192,
      "step": 2200
    },
    {
      "epoch": 0.5279577633789296,
      "eval_loss": 1.3293875455856323,
      "eval_runtime": 3.5364,
      "eval_samples_per_second": 56.555,
      "eval_steps_per_second": 2.545,
      "step": 2200
    },
    {
      "epoch": 0.5303575713942884,
      "grad_norm": 0.3537975549697876,
      "learning_rate": 9.148444444444446e-05,
      "loss": 1.3345,
      "step": 2210
    },
    {
      "epoch": 0.5327573794096472,
      "grad_norm": 0.4157085120677948,
      "learning_rate": 9.139555555555555e-05,
      "loss": 1.4337,
      "step": 2220
    },
    {
      "epoch": 0.535157187425006,
      "grad_norm": 0.29411080479621887,
      "learning_rate": 9.130666666666668e-05,
      "loss": 1.3267,
      "step": 2230
    },
    {
      "epoch": 0.5375569954403647,
      "grad_norm": 0.373637855052948,
      "learning_rate": 9.121777777777777e-05,
      "loss": 1.3003,
      "step": 2240
    },
    {
      "epoch": 0.5399568034557235,
      "grad_norm": 0.2798888385295868,
      "learning_rate": 9.11288888888889e-05,
      "loss": 1.3932,
      "step": 2250
    },
    {
      "epoch": 0.5399568034557235,
      "eval_loss": 1.329349160194397,
      "eval_runtime": 3.5385,
      "eval_samples_per_second": 56.521,
      "eval_steps_per_second": 2.543,
      "step": 2250
    },
    {
      "epoch": 0.5423566114710823,
      "grad_norm": 0.301588237285614,
      "learning_rate": 9.104000000000001e-05,
      "loss": 1.3195,
      "step": 2260
    },
    {
      "epoch": 0.544756419486441,
      "grad_norm": 0.3039500415325165,
      "learning_rate": 9.095111111111112e-05,
      "loss": 1.3412,
      "step": 2270
    },
    {
      "epoch": 0.5471562275017998,
      "grad_norm": 0.4012596607208252,
      "learning_rate": 9.086222222222223e-05,
      "loss": 1.3779,
      "step": 2280
    },
    {
      "epoch": 0.5495560355171586,
      "grad_norm": 0.3086996078491211,
      "learning_rate": 9.077333333333333e-05,
      "loss": 1.3702,
      "step": 2290
    },
    {
      "epoch": 0.5519558435325174,
      "grad_norm": 0.2795708477497101,
      "learning_rate": 9.068444444444445e-05,
      "loss": 1.3075,
      "step": 2300
    },
    {
      "epoch": 0.5519558435325174,
      "eval_loss": 1.328912377357483,
      "eval_runtime": 3.5375,
      "eval_samples_per_second": 56.537,
      "eval_steps_per_second": 2.544,
      "step": 2300
    },
    {
      "epoch": 0.5543556515478761,
      "grad_norm": 0.2849600315093994,
      "learning_rate": 9.059555555555556e-05,
      "loss": 1.2704,
      "step": 2310
    },
    {
      "epoch": 0.5567554595632349,
      "grad_norm": 0.3233558237552643,
      "learning_rate": 9.050666666666667e-05,
      "loss": 1.3958,
      "step": 2320
    },
    {
      "epoch": 0.5591552675785937,
      "grad_norm": 0.33143243193626404,
      "learning_rate": 9.041777777777778e-05,
      "loss": 1.3412,
      "step": 2330
    },
    {
      "epoch": 0.5615550755939525,
      "grad_norm": 0.3229215145111084,
      "learning_rate": 9.032888888888889e-05,
      "loss": 1.3171,
      "step": 2340
    },
    {
      "epoch": 0.5639548836093112,
      "grad_norm": 0.32398566603660583,
      "learning_rate": 9.024e-05,
      "loss": 1.4106,
      "step": 2350
    },
    {
      "epoch": 0.5639548836093112,
      "eval_loss": 1.3307058811187744,
      "eval_runtime": 3.5399,
      "eval_samples_per_second": 56.499,
      "eval_steps_per_second": 2.542,
      "step": 2350
    },
    {
      "epoch": 0.56635469162467,
      "grad_norm": 0.29795557260513306,
      "learning_rate": 9.015111111111111e-05,
      "loss": 1.2969,
      "step": 2360
    },
    {
      "epoch": 0.5687544996400288,
      "grad_norm": 0.28299179673194885,
      "learning_rate": 9.006222222222222e-05,
      "loss": 1.3529,
      "step": 2370
    },
    {
      "epoch": 0.5711543076553875,
      "grad_norm": 0.2659205198287964,
      "learning_rate": 8.997333333333335e-05,
      "loss": 1.379,
      "step": 2380
    },
    {
      "epoch": 0.5735541156707463,
      "grad_norm": 0.2888360917568207,
      "learning_rate": 8.988444444444445e-05,
      "loss": 1.2812,
      "step": 2390
    },
    {
      "epoch": 0.5759539236861051,
      "grad_norm": 0.28835201263427734,
      "learning_rate": 8.979555555555556e-05,
      "loss": 1.3714,
      "step": 2400
    },
    {
      "epoch": 0.5759539236861051,
      "eval_loss": 1.3273653984069824,
      "eval_runtime": 3.5328,
      "eval_samples_per_second": 56.612,
      "eval_steps_per_second": 2.548,
      "step": 2400
    },
    {
      "epoch": 0.5783537317014639,
      "grad_norm": 0.2519093453884125,
      "learning_rate": 8.970666666666667e-05,
      "loss": 1.3239,
      "step": 2410
    },
    {
      "epoch": 0.5807535397168226,
      "grad_norm": 0.2917173206806183,
      "learning_rate": 8.961777777777778e-05,
      "loss": 1.2577,
      "step": 2420
    },
    {
      "epoch": 0.5831533477321814,
      "grad_norm": 0.28930091857910156,
      "learning_rate": 8.95288888888889e-05,
      "loss": 1.3822,
      "step": 2430
    },
    {
      "epoch": 0.5855531557475402,
      "grad_norm": 0.33180809020996094,
      "learning_rate": 8.944e-05,
      "loss": 1.3408,
      "step": 2440
    },
    {
      "epoch": 0.587952963762899,
      "grad_norm": 0.3086482882499695,
      "learning_rate": 8.935111111111112e-05,
      "loss": 1.3828,
      "step": 2450
    },
    {
      "epoch": 0.587952963762899,
      "eval_loss": 1.3263589143753052,
      "eval_runtime": 3.5312,
      "eval_samples_per_second": 56.637,
      "eval_steps_per_second": 2.549,
      "step": 2450
    },
    {
      "epoch": 0.5903527717782577,
      "grad_norm": 0.31529292464256287,
      "learning_rate": 8.926222222222222e-05,
      "loss": 1.3612,
      "step": 2460
    },
    {
      "epoch": 0.5927525797936165,
      "grad_norm": 0.34227195382118225,
      "learning_rate": 8.917333333333334e-05,
      "loss": 1.4177,
      "step": 2470
    },
    {
      "epoch": 0.5951523878089753,
      "grad_norm": 0.31558704376220703,
      "learning_rate": 8.908444444444445e-05,
      "loss": 1.2921,
      "step": 2480
    },
    {
      "epoch": 0.597552195824334,
      "grad_norm": 0.33060523867607117,
      "learning_rate": 8.899555555555556e-05,
      "loss": 1.2758,
      "step": 2490
    },
    {
      "epoch": 0.5999520038396928,
      "grad_norm": 0.28621718287467957,
      "learning_rate": 8.890666666666667e-05,
      "loss": 1.4769,
      "step": 2500
    },
    {
      "epoch": 0.5999520038396928,
      "eval_loss": 1.3251678943634033,
      "eval_runtime": 3.5372,
      "eval_samples_per_second": 56.543,
      "eval_steps_per_second": 2.544,
      "step": 2500
    },
    {
      "epoch": 0.6023518118550516,
      "grad_norm": 0.2842170298099518,
      "learning_rate": 8.881777777777778e-05,
      "loss": 1.3562,
      "step": 2510
    },
    {
      "epoch": 0.6047516198704104,
      "grad_norm": 0.29782596230506897,
      "learning_rate": 8.87288888888889e-05,
      "loss": 1.3372,
      "step": 2520
    },
    {
      "epoch": 0.6071514278857691,
      "grad_norm": 0.3387080430984497,
      "learning_rate": 8.864e-05,
      "loss": 1.3429,
      "step": 2530
    },
    {
      "epoch": 0.6095512359011279,
      "grad_norm": 0.3012627065181732,
      "learning_rate": 8.855111111111112e-05,
      "loss": 1.2456,
      "step": 2540
    },
    {
      "epoch": 0.6119510439164867,
      "grad_norm": 0.32223352789878845,
      "learning_rate": 8.846222222222223e-05,
      "loss": 1.2679,
      "step": 2550
    },
    {
      "epoch": 0.6119510439164867,
      "eval_loss": 1.325910210609436,
      "eval_runtime": 3.5351,
      "eval_samples_per_second": 56.576,
      "eval_steps_per_second": 2.546,
      "step": 2550
    },
    {
      "epoch": 0.6143508519318455,
      "grad_norm": 0.30215898156166077,
      "learning_rate": 8.837333333333334e-05,
      "loss": 1.4398,
      "step": 2560
    },
    {
      "epoch": 0.6167506599472042,
      "grad_norm": 0.28281837701797485,
      "learning_rate": 8.828444444444445e-05,
      "loss": 1.2983,
      "step": 2570
    },
    {
      "epoch": 0.619150467962563,
      "grad_norm": 0.2735907733440399,
      "learning_rate": 8.819555555555557e-05,
      "loss": 1.3197,
      "step": 2580
    },
    {
      "epoch": 0.6215502759779218,
      "grad_norm": 0.3315005600452423,
      "learning_rate": 8.810666666666667e-05,
      "loss": 1.3305,
      "step": 2590
    },
    {
      "epoch": 0.6239500839932806,
      "grad_norm": 0.35945361852645874,
      "learning_rate": 8.801777777777778e-05,
      "loss": 1.4006,
      "step": 2600
    },
    {
      "epoch": 0.6239500839932806,
      "eval_loss": 1.3211007118225098,
      "eval_runtime": 3.5372,
      "eval_samples_per_second": 56.543,
      "eval_steps_per_second": 2.544,
      "step": 2600
    },
    {
      "epoch": 0.6263498920086393,
      "grad_norm": 0.35089150071144104,
      "learning_rate": 8.792888888888889e-05,
      "loss": 1.4853,
      "step": 2610
    },
    {
      "epoch": 0.6287497000239981,
      "grad_norm": 0.2756786644458771,
      "learning_rate": 8.784e-05,
      "loss": 1.2841,
      "step": 2620
    },
    {
      "epoch": 0.6311495080393569,
      "grad_norm": 0.3369687497615814,
      "learning_rate": 8.775111111111112e-05,
      "loss": 1.3883,
      "step": 2630
    },
    {
      "epoch": 0.6335493160547156,
      "grad_norm": 0.23693682253360748,
      "learning_rate": 8.766222222222222e-05,
      "loss": 1.2027,
      "step": 2640
    },
    {
      "epoch": 0.6359491240700744,
      "grad_norm": 0.3434893786907196,
      "learning_rate": 8.757333333333334e-05,
      "loss": 1.3714,
      "step": 2650
    },
    {
      "epoch": 0.6359491240700744,
      "eval_loss": 1.3209055662155151,
      "eval_runtime": 3.5367,
      "eval_samples_per_second": 56.55,
      "eval_steps_per_second": 2.545,
      "step": 2650
    },
    {
      "epoch": 0.6383489320854332,
      "grad_norm": 0.3237434923648834,
      "learning_rate": 8.748444444444444e-05,
      "loss": 1.3446,
      "step": 2660
    },
    {
      "epoch": 0.640748740100792,
      "grad_norm": 0.48908740282058716,
      "learning_rate": 8.739555555555557e-05,
      "loss": 1.4429,
      "step": 2670
    },
    {
      "epoch": 0.6431485481161507,
      "grad_norm": 0.28266841173171997,
      "learning_rate": 8.730666666666668e-05,
      "loss": 1.2863,
      "step": 2680
    },
    {
      "epoch": 0.6455483561315095,
      "grad_norm": 0.27248406410217285,
      "learning_rate": 8.721777777777779e-05,
      "loss": 1.3267,
      "step": 2690
    },
    {
      "epoch": 0.6479481641468683,
      "grad_norm": 0.2869902551174164,
      "learning_rate": 8.71288888888889e-05,
      "loss": 1.279,
      "step": 2700
    },
    {
      "epoch": 0.6479481641468683,
      "eval_loss": 1.319106101989746,
      "eval_runtime": 3.5357,
      "eval_samples_per_second": 56.566,
      "eval_steps_per_second": 2.545,
      "step": 2700
    },
    {
      "epoch": 0.6503479721622271,
      "grad_norm": 0.3946305215358734,
      "learning_rate": 8.704e-05,
      "loss": 1.3089,
      "step": 2710
    },
    {
      "epoch": 0.6527477801775858,
      "grad_norm": 0.27328434586524963,
      "learning_rate": 8.695111111111112e-05,
      "loss": 1.392,
      "step": 2720
    },
    {
      "epoch": 0.6551475881929446,
      "grad_norm": 0.33506590127944946,
      "learning_rate": 8.686222222222223e-05,
      "loss": 1.3925,
      "step": 2730
    },
    {
      "epoch": 0.6575473962083034,
      "grad_norm": 0.30449870228767395,
      "learning_rate": 8.677333333333334e-05,
      "loss": 1.4036,
      "step": 2740
    },
    {
      "epoch": 0.6599472042236622,
      "grad_norm": 0.3119390904903412,
      "learning_rate": 8.668444444444445e-05,
      "loss": 1.3466,
      "step": 2750
    },
    {
      "epoch": 0.6599472042236622,
      "eval_loss": 1.3234186172485352,
      "eval_runtime": 3.5333,
      "eval_samples_per_second": 56.605,
      "eval_steps_per_second": 2.547,
      "step": 2750
    },
    {
      "epoch": 0.6623470122390209,
      "grad_norm": 0.30466794967651367,
      "learning_rate": 8.659555555555556e-05,
      "loss": 1.337,
      "step": 2760
    },
    {
      "epoch": 0.6647468202543797,
      "grad_norm": 0.2545129954814911,
      "learning_rate": 8.650666666666667e-05,
      "loss": 1.2801,
      "step": 2770
    },
    {
      "epoch": 0.6671466282697385,
      "grad_norm": 0.3140033185482025,
      "learning_rate": 8.641777777777778e-05,
      "loss": 1.3974,
      "step": 2780
    },
    {
      "epoch": 0.6695464362850972,
      "grad_norm": 0.29043498635292053,
      "learning_rate": 8.632888888888889e-05,
      "loss": 1.282,
      "step": 2790
    },
    {
      "epoch": 0.6719462443004559,
      "grad_norm": 0.329184353351593,
      "learning_rate": 8.624000000000001e-05,
      "loss": 1.3659,
      "step": 2800
    },
    {
      "epoch": 0.6719462443004559,
      "eval_loss": 1.324283242225647,
      "eval_runtime": 3.5298,
      "eval_samples_per_second": 56.66,
      "eval_steps_per_second": 2.55,
      "step": 2800
    },
    {
      "epoch": 0.6743460523158147,
      "grad_norm": 0.2496257722377777,
      "learning_rate": 8.615111111111111e-05,
      "loss": 1.2682,
      "step": 2810
    },
    {
      "epoch": 0.6767458603311735,
      "grad_norm": 0.2683573365211487,
      "learning_rate": 8.606222222222222e-05,
      "loss": 1.3102,
      "step": 2820
    },
    {
      "epoch": 0.6791456683465322,
      "grad_norm": 0.28293710947036743,
      "learning_rate": 8.597333333333333e-05,
      "loss": 1.455,
      "step": 2830
    },
    {
      "epoch": 0.681545476361891,
      "grad_norm": 0.30502980947494507,
      "learning_rate": 8.588444444444444e-05,
      "loss": 1.3032,
      "step": 2840
    },
    {
      "epoch": 0.6839452843772498,
      "grad_norm": 0.37377917766571045,
      "learning_rate": 8.579555555555557e-05,
      "loss": 1.3354,
      "step": 2850
    },
    {
      "epoch": 0.6839452843772498,
      "eval_loss": 1.3170044422149658,
      "eval_runtime": 3.527,
      "eval_samples_per_second": 56.706,
      "eval_steps_per_second": 2.552,
      "step": 2850
    },
    {
      "epoch": 0.6863450923926085,
      "grad_norm": 0.30532243847846985,
      "learning_rate": 8.570666666666666e-05,
      "loss": 1.3245,
      "step": 2860
    },
    {
      "epoch": 0.6887449004079673,
      "grad_norm": 0.3003859519958496,
      "learning_rate": 8.561777777777779e-05,
      "loss": 1.3315,
      "step": 2870
    },
    {
      "epoch": 0.6911447084233261,
      "grad_norm": 0.32860812544822693,
      "learning_rate": 8.55288888888889e-05,
      "loss": 1.3983,
      "step": 2880
    },
    {
      "epoch": 0.6935445164386849,
      "grad_norm": 0.2588593363761902,
      "learning_rate": 8.544000000000001e-05,
      "loss": 1.2934,
      "step": 2890
    },
    {
      "epoch": 0.6959443244540436,
      "grad_norm": 0.2525445222854614,
      "learning_rate": 8.535111111111112e-05,
      "loss": 1.2556,
      "step": 2900
    },
    {
      "epoch": 0.6959443244540436,
      "eval_loss": 1.3208892345428467,
      "eval_runtime": 3.5274,
      "eval_samples_per_second": 56.7,
      "eval_steps_per_second": 2.551,
      "step": 2900
    },
    {
      "epoch": 0.6983441324694024,
      "grad_norm": 0.3416239321231842,
      "learning_rate": 8.526222222222222e-05,
      "loss": 1.3555,
      "step": 2910
    },
    {
      "epoch": 0.7007439404847612,
      "grad_norm": 0.3015773594379425,
      "learning_rate": 8.517333333333334e-05,
      "loss": 1.3229,
      "step": 2920
    },
    {
      "epoch": 0.70314374850012,
      "grad_norm": 0.27658164501190186,
      "learning_rate": 8.508444444444445e-05,
      "loss": 1.3367,
      "step": 2930
    },
    {
      "epoch": 0.7055435565154787,
      "grad_norm": 0.2980910837650299,
      "learning_rate": 8.499555555555556e-05,
      "loss": 1.3184,
      "step": 2940
    },
    {
      "epoch": 0.7079433645308375,
      "grad_norm": 0.29635089635849,
      "learning_rate": 8.490666666666667e-05,
      "loss": 1.3567,
      "step": 2950
    },
    {
      "epoch": 0.7079433645308375,
      "eval_loss": 1.3161423206329346,
      "eval_runtime": 3.5268,
      "eval_samples_per_second": 56.709,
      "eval_steps_per_second": 2.552,
      "step": 2950
    },
    {
      "epoch": 0.7103431725461963,
      "grad_norm": 0.3130621612071991,
      "learning_rate": 8.481777777777778e-05,
      "loss": 1.3896,
      "step": 2960
    },
    {
      "epoch": 0.712742980561555,
      "grad_norm": 0.30697357654571533,
      "learning_rate": 8.472888888888889e-05,
      "loss": 1.3326,
      "step": 2970
    },
    {
      "epoch": 0.7151427885769138,
      "grad_norm": 0.3255085349082947,
      "learning_rate": 8.464e-05,
      "loss": 1.3853,
      "step": 2980
    },
    {
      "epoch": 0.7175425965922726,
      "grad_norm": 0.3358516991138458,
      "learning_rate": 8.455111111111111e-05,
      "loss": 1.3264,
      "step": 2990
    },
    {
      "epoch": 0.7199424046076314,
      "grad_norm": 0.34746065735816956,
      "learning_rate": 8.446222222222224e-05,
      "loss": 1.3501,
      "step": 3000
    },
    {
      "epoch": 0.7199424046076314,
      "eval_loss": 1.3168209791183472,
      "eval_runtime": 3.5318,
      "eval_samples_per_second": 56.629,
      "eval_steps_per_second": 2.548,
      "step": 3000
    },
    {
      "epoch": 0.7223422126229901,
      "grad_norm": 0.31118619441986084,
      "learning_rate": 8.437333333333333e-05,
      "loss": 1.4032,
      "step": 3010
    },
    {
      "epoch": 0.7247420206383489,
      "grad_norm": 0.33196771144866943,
      "learning_rate": 8.428444444444444e-05,
      "loss": 1.3125,
      "step": 3020
    },
    {
      "epoch": 0.7271418286537077,
      "grad_norm": 0.30853307247161865,
      "learning_rate": 8.419555555555556e-05,
      "loss": 1.3208,
      "step": 3030
    },
    {
      "epoch": 0.7295416366690665,
      "grad_norm": 0.3784986734390259,
      "learning_rate": 8.410666666666667e-05,
      "loss": 1.4543,
      "step": 3040
    },
    {
      "epoch": 0.7319414446844252,
      "grad_norm": 0.3145313858985901,
      "learning_rate": 8.401777777777779e-05,
      "loss": 1.4169,
      "step": 3050
    },
    {
      "epoch": 0.7319414446844252,
      "eval_loss": 1.3125381469726562,
      "eval_runtime": 3.53,
      "eval_samples_per_second": 56.657,
      "eval_steps_per_second": 2.55,
      "step": 3050
    },
    {
      "epoch": 0.734341252699784,
      "grad_norm": 0.2846410572528839,
      "learning_rate": 8.392888888888889e-05,
      "loss": 1.3358,
      "step": 3060
    },
    {
      "epoch": 0.7367410607151428,
      "grad_norm": 0.25033265352249146,
      "learning_rate": 8.384000000000001e-05,
      "loss": 1.3073,
      "step": 3070
    },
    {
      "epoch": 0.7391408687305016,
      "grad_norm": 0.3268294632434845,
      "learning_rate": 8.375111111111111e-05,
      "loss": 1.3263,
      "step": 3080
    },
    {
      "epoch": 0.7415406767458603,
      "grad_norm": 0.2947307527065277,
      "learning_rate": 8.366222222222223e-05,
      "loss": 1.3653,
      "step": 3090
    },
    {
      "epoch": 0.7439404847612191,
      "grad_norm": 0.2525169551372528,
      "learning_rate": 8.357333333333334e-05,
      "loss": 1.3627,
      "step": 3100
    },
    {
      "epoch": 0.7439404847612191,
      "eval_loss": 1.3144029378890991,
      "eval_runtime": 3.5315,
      "eval_samples_per_second": 56.633,
      "eval_steps_per_second": 2.548,
      "step": 3100
    },
    {
      "epoch": 0.7463402927765779,
      "grad_norm": 0.299161821603775,
      "learning_rate": 8.348444444444444e-05,
      "loss": 1.3402,
      "step": 3110
    },
    {
      "epoch": 0.7487401007919366,
      "grad_norm": 0.2875206768512726,
      "learning_rate": 8.339555555555556e-05,
      "loss": 1.2196,
      "step": 3120
    },
    {
      "epoch": 0.7511399088072954,
      "grad_norm": 0.35463759303092957,
      "learning_rate": 8.330666666666666e-05,
      "loss": 1.4406,
      "step": 3130
    },
    {
      "epoch": 0.7535397168226542,
      "grad_norm": 0.34001925587654114,
      "learning_rate": 8.321777777777778e-05,
      "loss": 1.3882,
      "step": 3140
    },
    {
      "epoch": 0.755939524838013,
      "grad_norm": 0.32092079520225525,
      "learning_rate": 8.31288888888889e-05,
      "loss": 1.3902,
      "step": 3150
    },
    {
      "epoch": 0.755939524838013,
      "eval_loss": 1.3142318725585938,
      "eval_runtime": 3.5332,
      "eval_samples_per_second": 56.606,
      "eval_steps_per_second": 2.547,
      "step": 3150
    },
    {
      "epoch": 0.7583393328533717,
      "grad_norm": 0.3143981397151947,
      "learning_rate": 8.304e-05,
      "loss": 1.3619,
      "step": 3160
    },
    {
      "epoch": 0.7607391408687305,
      "grad_norm": 0.2649715840816498,
      "learning_rate": 8.295111111111111e-05,
      "loss": 1.5315,
      "step": 3170
    },
    {
      "epoch": 0.7631389488840893,
      "grad_norm": 0.29471397399902344,
      "learning_rate": 8.286222222222223e-05,
      "loss": 1.2644,
      "step": 3180
    },
    {
      "epoch": 0.7655387568994481,
      "grad_norm": 0.25796884298324585,
      "learning_rate": 8.277333333333334e-05,
      "loss": 1.2534,
      "step": 3190
    },
    {
      "epoch": 0.7679385649148068,
      "grad_norm": 0.33578744530677795,
      "learning_rate": 8.268444444444446e-05,
      "loss": 1.3322,
      "step": 3200
    },
    {
      "epoch": 0.7679385649148068,
      "eval_loss": 1.3152649402618408,
      "eval_runtime": 3.5308,
      "eval_samples_per_second": 56.644,
      "eval_steps_per_second": 2.549,
      "step": 3200
    },
    {
      "epoch": 0.7703383729301656,
      "grad_norm": 0.3200642764568329,
      "learning_rate": 8.259555555555556e-05,
      "loss": 1.3549,
      "step": 3210
    },
    {
      "epoch": 0.7727381809455244,
      "grad_norm": 0.30939292907714844,
      "learning_rate": 8.250666666666667e-05,
      "loss": 1.3671,
      "step": 3220
    },
    {
      "epoch": 0.7751379889608832,
      "grad_norm": 0.3351829946041107,
      "learning_rate": 8.241777777777778e-05,
      "loss": 1.4434,
      "step": 3230
    },
    {
      "epoch": 0.7775377969762419,
      "grad_norm": 0.3548327088356018,
      "learning_rate": 8.232888888888889e-05,
      "loss": 1.3814,
      "step": 3240
    },
    {
      "epoch": 0.7799376049916007,
      "grad_norm": 0.3605601191520691,
      "learning_rate": 8.224000000000001e-05,
      "loss": 1.3825,
      "step": 3250
    },
    {
      "epoch": 0.7799376049916007,
      "eval_loss": 1.315700888633728,
      "eval_runtime": 3.5318,
      "eval_samples_per_second": 56.629,
      "eval_steps_per_second": 2.548,
      "step": 3250
    },
    {
      "epoch": 0.7823374130069595,
      "grad_norm": 0.29194873571395874,
      "learning_rate": 8.215111111111111e-05,
      "loss": 1.3968,
      "step": 3260
    },
    {
      "epoch": 0.7847372210223182,
      "grad_norm": 0.2969072759151459,
      "learning_rate": 8.206222222222223e-05,
      "loss": 1.2679,
      "step": 3270
    },
    {
      "epoch": 0.787137029037677,
      "grad_norm": 0.31980687379837036,
      "learning_rate": 8.197333333333333e-05,
      "loss": 1.4197,
      "step": 3280
    },
    {
      "epoch": 0.7895368370530358,
      "grad_norm": 0.24533021450042725,
      "learning_rate": 8.188444444444445e-05,
      "loss": 1.2848,
      "step": 3290
    },
    {
      "epoch": 0.7919366450683946,
      "grad_norm": 0.266130268573761,
      "learning_rate": 8.179555555555556e-05,
      "loss": 1.2878,
      "step": 3300
    },
    {
      "epoch": 0.7919366450683946,
      "eval_loss": 1.3163868188858032,
      "eval_runtime": 3.5316,
      "eval_samples_per_second": 56.631,
      "eval_steps_per_second": 2.548,
      "step": 3300
    },
    {
      "epoch": 0.7943364530837533,
      "grad_norm": 0.3819082975387573,
      "learning_rate": 8.170666666666667e-05,
      "loss": 1.3745,
      "step": 3310
    },
    {
      "epoch": 0.7967362610991121,
      "grad_norm": 0.34913474321365356,
      "learning_rate": 8.161777777777779e-05,
      "loss": 1.4006,
      "step": 3320
    },
    {
      "epoch": 0.7991360691144709,
      "grad_norm": 0.3474138081073761,
      "learning_rate": 8.152888888888888e-05,
      "loss": 1.2628,
      "step": 3330
    },
    {
      "epoch": 0.8015358771298297,
      "grad_norm": 0.26455214619636536,
      "learning_rate": 8.144e-05,
      "loss": 1.3136,
      "step": 3340
    },
    {
      "epoch": 0.8039356851451884,
      "grad_norm": 0.3386317789554596,
      "learning_rate": 8.135111111111112e-05,
      "loss": 1.2848,
      "step": 3350
    },
    {
      "epoch": 0.8039356851451884,
      "eval_loss": 1.3124655485153198,
      "eval_runtime": 3.531,
      "eval_samples_per_second": 56.641,
      "eval_steps_per_second": 2.549,
      "step": 3350
    },
    {
      "epoch": 0.8063354931605472,
      "grad_norm": 0.29962942004203796,
      "learning_rate": 8.126222222222223e-05,
      "loss": 1.3218,
      "step": 3360
    },
    {
      "epoch": 0.808735301175906,
      "grad_norm": 0.3251079022884369,
      "learning_rate": 8.117333333333334e-05,
      "loss": 1.3216,
      "step": 3370
    },
    {
      "epoch": 0.8111351091912647,
      "grad_norm": 0.347189337015152,
      "learning_rate": 8.108444444444445e-05,
      "loss": 1.2789,
      "step": 3380
    },
    {
      "epoch": 0.8135349172066235,
      "grad_norm": 0.2558158040046692,
      "learning_rate": 8.099555555555556e-05,
      "loss": 1.2263,
      "step": 3390
    },
    {
      "epoch": 0.8159347252219823,
      "grad_norm": 0.2777668833732605,
      "learning_rate": 8.090666666666667e-05,
      "loss": 1.378,
      "step": 3400
    },
    {
      "epoch": 0.8159347252219823,
      "eval_loss": 1.3139947652816772,
      "eval_runtime": 3.5376,
      "eval_samples_per_second": 56.535,
      "eval_steps_per_second": 2.544,
      "step": 3400
    },
    {
      "epoch": 0.8183345332373411,
      "grad_norm": 0.3474610149860382,
      "learning_rate": 8.081777777777778e-05,
      "loss": 1.3995,
      "step": 3410
    },
    {
      "epoch": 0.8207343412526998,
      "grad_norm": 0.2827257513999939,
      "learning_rate": 8.072888888888889e-05,
      "loss": 1.3369,
      "step": 3420
    },
    {
      "epoch": 0.8231341492680585,
      "grad_norm": 0.32108864188194275,
      "learning_rate": 8.064e-05,
      "loss": 1.2807,
      "step": 3430
    },
    {
      "epoch": 0.8255339572834173,
      "grad_norm": 0.2880210280418396,
      "learning_rate": 8.055111111111111e-05,
      "loss": 1.3155,
      "step": 3440
    },
    {
      "epoch": 0.827933765298776,
      "grad_norm": 0.3077884912490845,
      "learning_rate": 8.046222222222222e-05,
      "loss": 1.359,
      "step": 3450
    },
    {
      "epoch": 0.827933765298776,
      "eval_loss": 1.3113573789596558,
      "eval_runtime": 3.5318,
      "eval_samples_per_second": 56.628,
      "eval_steps_per_second": 2.548,
      "step": 3450
    },
    {
      "epoch": 0.8303335733141348,
      "grad_norm": 0.3041512668132782,
      "learning_rate": 8.037333333333333e-05,
      "loss": 1.3776,
      "step": 3460
    },
    {
      "epoch": 0.8327333813294936,
      "grad_norm": 0.2933758497238159,
      "learning_rate": 8.028444444444446e-05,
      "loss": 1.3066,
      "step": 3470
    },
    {
      "epoch": 0.8351331893448524,
      "grad_norm": 0.3535304069519043,
      "learning_rate": 8.019555555555555e-05,
      "loss": 1.3683,
      "step": 3480
    },
    {
      "epoch": 0.8375329973602111,
      "grad_norm": 0.367105096578598,
      "learning_rate": 8.010666666666668e-05,
      "loss": 1.2764,
      "step": 3490
    },
    {
      "epoch": 0.8399328053755699,
      "grad_norm": 0.35551339387893677,
      "learning_rate": 8.001777777777779e-05,
      "loss": 1.2893,
      "step": 3500
    },
    {
      "epoch": 0.8399328053755699,
      "eval_loss": 1.3079628944396973,
      "eval_runtime": 3.5329,
      "eval_samples_per_second": 56.611,
      "eval_steps_per_second": 2.548,
      "step": 3500
    },
    {
      "epoch": 0.8423326133909287,
      "grad_norm": 0.3733997046947479,
      "learning_rate": 7.99288888888889e-05,
      "loss": 1.352,
      "step": 3510
    },
    {
      "epoch": 0.8447324214062875,
      "grad_norm": 0.30850309133529663,
      "learning_rate": 7.984000000000001e-05,
      "loss": 1.3651,
      "step": 3520
    },
    {
      "epoch": 0.8471322294216462,
      "grad_norm": 0.3786466121673584,
      "learning_rate": 7.97511111111111e-05,
      "loss": 1.3856,
      "step": 3530
    },
    {
      "epoch": 0.849532037437005,
      "grad_norm": 0.3149852752685547,
      "learning_rate": 7.966222222222223e-05,
      "loss": 1.3924,
      "step": 3540
    },
    {
      "epoch": 0.8519318454523638,
      "grad_norm": 0.32546287775039673,
      "learning_rate": 7.957333333333334e-05,
      "loss": 1.3643,
      "step": 3550
    },
    {
      "epoch": 0.8519318454523638,
      "eval_loss": 1.3108009099960327,
      "eval_runtime": 3.5364,
      "eval_samples_per_second": 56.554,
      "eval_steps_per_second": 2.545,
      "step": 3550
    },
    {
      "epoch": 0.8543316534677226,
      "grad_norm": 0.32001230120658875,
      "learning_rate": 7.948444444444445e-05,
      "loss": 1.3087,
      "step": 3560
    },
    {
      "epoch": 0.8567314614830813,
      "grad_norm": 0.29659727215766907,
      "learning_rate": 7.939555555555556e-05,
      "loss": 1.3287,
      "step": 3570
    },
    {
      "epoch": 0.8591312694984401,
      "grad_norm": 0.3183649182319641,
      "learning_rate": 7.930666666666667e-05,
      "loss": 1.2733,
      "step": 3580
    },
    {
      "epoch": 0.8615310775137989,
      "grad_norm": 0.2918538451194763,
      "learning_rate": 7.921777777777778e-05,
      "loss": 1.3254,
      "step": 3590
    },
    {
      "epoch": 0.8639308855291576,
      "grad_norm": 0.3316797614097595,
      "learning_rate": 7.912888888888889e-05,
      "loss": 1.3455,
      "step": 3600
    },
    {
      "epoch": 0.8639308855291576,
      "eval_loss": 1.3091635704040527,
      "eval_runtime": 3.5335,
      "eval_samples_per_second": 56.601,
      "eval_steps_per_second": 2.547,
      "step": 3600
    },
    {
      "epoch": 0.8663306935445164,
      "grad_norm": 0.28772982954978943,
      "learning_rate": 7.904e-05,
      "loss": 1.3597,
      "step": 3610
    },
    {
      "epoch": 0.8687305015598752,
      "grad_norm": 0.3682860732078552,
      "learning_rate": 7.895111111111113e-05,
      "loss": 1.4666,
      "step": 3620
    },
    {
      "epoch": 0.871130309575234,
      "grad_norm": 0.27259114384651184,
      "learning_rate": 7.886222222222222e-05,
      "loss": 1.1677,
      "step": 3630
    },
    {
      "epoch": 0.8735301175905927,
      "grad_norm": 0.3429013788700104,
      "learning_rate": 7.877333333333333e-05,
      "loss": 1.3979,
      "step": 3640
    },
    {
      "epoch": 0.8759299256059515,
      "grad_norm": 0.3301968574523926,
      "learning_rate": 7.868444444444444e-05,
      "loss": 1.2866,
      "step": 3650
    },
    {
      "epoch": 0.8759299256059515,
      "eval_loss": 1.3091517686843872,
      "eval_runtime": 3.5319,
      "eval_samples_per_second": 56.626,
      "eval_steps_per_second": 2.548,
      "step": 3650
    },
    {
      "epoch": 0.8783297336213103,
      "grad_norm": 0.3477672040462494,
      "learning_rate": 7.859555555555555e-05,
      "loss": 1.3691,
      "step": 3660
    },
    {
      "epoch": 0.880729541636669,
      "grad_norm": 0.29563435912132263,
      "learning_rate": 7.850666666666668e-05,
      "loss": 1.3763,
      "step": 3670
    },
    {
      "epoch": 0.8831293496520278,
      "grad_norm": 0.29236018657684326,
      "learning_rate": 7.841777777777778e-05,
      "loss": 1.3944,
      "step": 3680
    },
    {
      "epoch": 0.8855291576673866,
      "grad_norm": 0.3626365661621094,
      "learning_rate": 7.83288888888889e-05,
      "loss": 1.2903,
      "step": 3690
    },
    {
      "epoch": 0.8879289656827454,
      "grad_norm": 0.35657477378845215,
      "learning_rate": 7.824e-05,
      "loss": 1.2978,
      "step": 3700
    },
    {
      "epoch": 0.8879289656827454,
      "eval_loss": 1.3111846446990967,
      "eval_runtime": 3.5317,
      "eval_samples_per_second": 56.63,
      "eval_steps_per_second": 2.548,
      "step": 3700
    },
    {
      "epoch": 0.8903287736981041,
      "grad_norm": 0.30378633737564087,
      "learning_rate": 7.815111111111112e-05,
      "loss": 1.3528,
      "step": 3710
    },
    {
      "epoch": 0.8927285817134629,
      "grad_norm": 0.3495618402957916,
      "learning_rate": 7.806222222222223e-05,
      "loss": 1.3234,
      "step": 3720
    },
    {
      "epoch": 0.8951283897288217,
      "grad_norm": 0.33244186639785767,
      "learning_rate": 7.797333333333333e-05,
      "loss": 1.3145,
      "step": 3730
    },
    {
      "epoch": 0.8975281977441805,
      "grad_norm": 0.37435299158096313,
      "learning_rate": 7.788444444444445e-05,
      "loss": 1.3648,
      "step": 3740
    },
    {
      "epoch": 0.8999280057595392,
      "grad_norm": 0.2927950918674469,
      "learning_rate": 7.779555555555555e-05,
      "loss": 1.3839,
      "step": 3750
    },
    {
      "epoch": 0.8999280057595392,
      "eval_loss": 1.307959794998169,
      "eval_runtime": 3.5337,
      "eval_samples_per_second": 56.597,
      "eval_steps_per_second": 2.547,
      "step": 3750
    },
    {
      "epoch": 0.902327813774898,
      "grad_norm": 0.2850854992866516,
      "learning_rate": 7.770666666666667e-05,
      "loss": 1.4128,
      "step": 3760
    },
    {
      "epoch": 0.9047276217902568,
      "grad_norm": 0.3250395655632019,
      "learning_rate": 7.761777777777778e-05,
      "loss": 1.2431,
      "step": 3770
    },
    {
      "epoch": 0.9071274298056156,
      "grad_norm": 0.2845466136932373,
      "learning_rate": 7.75288888888889e-05,
      "loss": 1.2933,
      "step": 3780
    },
    {
      "epoch": 0.9095272378209743,
      "grad_norm": 0.34354448318481445,
      "learning_rate": 7.744e-05,
      "loss": 1.2485,
      "step": 3790
    },
    {
      "epoch": 0.9119270458363331,
      "grad_norm": 0.3516523540019989,
      "learning_rate": 7.735111111111111e-05,
      "loss": 1.2398,
      "step": 3800
    },
    {
      "epoch": 0.9119270458363331,
      "eval_loss": 1.3107566833496094,
      "eval_runtime": 3.5313,
      "eval_samples_per_second": 56.637,
      "eval_steps_per_second": 2.549,
      "step": 3800
    },
    {
      "epoch": 0.9143268538516919,
      "grad_norm": 0.36199846863746643,
      "learning_rate": 7.726222222222222e-05,
      "loss": 1.2718,
      "step": 3810
    },
    {
      "epoch": 0.9167266618670507,
      "grad_norm": 0.3044877350330353,
      "learning_rate": 7.717333333333334e-05,
      "loss": 1.2946,
      "step": 3820
    },
    {
      "epoch": 0.9191264698824094,
      "grad_norm": 0.2962128520011902,
      "learning_rate": 7.708444444444445e-05,
      "loss": 1.2999,
      "step": 3830
    },
    {
      "epoch": 0.9215262778977682,
      "grad_norm": 0.2765519917011261,
      "learning_rate": 7.699555555555556e-05,
      "loss": 1.2136,
      "step": 3840
    },
    {
      "epoch": 0.923926085913127,
      "grad_norm": 0.3289791941642761,
      "learning_rate": 7.690666666666667e-05,
      "loss": 1.2803,
      "step": 3850
    },
    {
      "epoch": 0.923926085913127,
      "eval_loss": 1.3076329231262207,
      "eval_runtime": 3.5363,
      "eval_samples_per_second": 56.556,
      "eval_steps_per_second": 2.545,
      "step": 3850
    },
    {
      "epoch": 0.9263258939284857,
      "grad_norm": 0.3507562279701233,
      "learning_rate": 7.681777777777778e-05,
      "loss": 1.4333,
      "step": 3860
    },
    {
      "epoch": 0.9287257019438445,
      "grad_norm": 0.2960822284221649,
      "learning_rate": 7.67288888888889e-05,
      "loss": 1.3192,
      "step": 3870
    },
    {
      "epoch": 0.9311255099592033,
      "grad_norm": 0.34461966156959534,
      "learning_rate": 7.664e-05,
      "loss": 1.2763,
      "step": 3880
    },
    {
      "epoch": 0.9335253179745621,
      "grad_norm": 0.379903644323349,
      "learning_rate": 7.655111111111112e-05,
      "loss": 1.2901,
      "step": 3890
    },
    {
      "epoch": 0.9359251259899208,
      "grad_norm": 0.2688215970993042,
      "learning_rate": 7.646222222222222e-05,
      "loss": 1.2558,
      "step": 3900
    },
    {
      "epoch": 0.9359251259899208,
      "eval_loss": 1.3069849014282227,
      "eval_runtime": 3.5365,
      "eval_samples_per_second": 56.553,
      "eval_steps_per_second": 2.545,
      "step": 3900
    },
    {
      "epoch": 0.9383249340052796,
      "grad_norm": 0.30129432678222656,
      "learning_rate": 7.637333333333334e-05,
      "loss": 1.2451,
      "step": 3910
    },
    {
      "epoch": 0.9407247420206384,
      "grad_norm": 0.3779987394809723,
      "learning_rate": 7.628444444444445e-05,
      "loss": 1.2648,
      "step": 3920
    },
    {
      "epoch": 0.9431245500359972,
      "grad_norm": 0.3355669677257538,
      "learning_rate": 7.619555555555556e-05,
      "loss": 1.4007,
      "step": 3930
    },
    {
      "epoch": 0.9455243580513559,
      "grad_norm": 0.2919895350933075,
      "learning_rate": 7.610666666666667e-05,
      "loss": 1.3153,
      "step": 3940
    },
    {
      "epoch": 0.9479241660667147,
      "grad_norm": 0.24402864277362823,
      "learning_rate": 7.601777777777777e-05,
      "loss": 1.27,
      "step": 3950
    },
    {
      "epoch": 0.9479241660667147,
      "eval_loss": 1.304099440574646,
      "eval_runtime": 3.5372,
      "eval_samples_per_second": 56.541,
      "eval_steps_per_second": 2.544,
      "step": 3950
    },
    {
      "epoch": 0.9503239740820735,
      "grad_norm": 0.261695921421051,
      "learning_rate": 7.59288888888889e-05,
      "loss": 1.1702,
      "step": 3960
    },
    {
      "epoch": 0.9527237820974322,
      "grad_norm": 0.3616449534893036,
      "learning_rate": 7.584e-05,
      "loss": 1.318,
      "step": 3970
    },
    {
      "epoch": 0.955123590112791,
      "grad_norm": 0.3673456013202667,
      "learning_rate": 7.575111111111112e-05,
      "loss": 1.2579,
      "step": 3980
    },
    {
      "epoch": 0.9575233981281498,
      "grad_norm": 0.34960922598838806,
      "learning_rate": 7.566222222222223e-05,
      "loss": 1.2847,
      "step": 3990
    },
    {
      "epoch": 0.9599232061435086,
      "grad_norm": 0.3558236360549927,
      "learning_rate": 7.557333333333334e-05,
      "loss": 1.3351,
      "step": 4000
    },
    {
      "epoch": 0.9599232061435086,
      "eval_loss": 1.3062727451324463,
      "eval_runtime": 3.5398,
      "eval_samples_per_second": 56.501,
      "eval_steps_per_second": 2.543,
      "step": 4000
    },
    {
      "epoch": 0.9623230141588673,
      "grad_norm": 0.2944057285785675,
      "learning_rate": 7.548444444444445e-05,
      "loss": 1.1951,
      "step": 4010
    },
    {
      "epoch": 0.9647228221742261,
      "grad_norm": 6.139296054840088,
      "learning_rate": 7.539555555555556e-05,
      "loss": 1.2553,
      "step": 4020
    },
    {
      "epoch": 0.9671226301895849,
      "grad_norm": 0.3490421772003174,
      "learning_rate": 7.530666666666667e-05,
      "loss": 1.2694,
      "step": 4030
    },
    {
      "epoch": 0.9695224382049437,
      "grad_norm": 0.3569429814815521,
      "learning_rate": 7.521777777777778e-05,
      "loss": 1.3573,
      "step": 4040
    },
    {
      "epoch": 0.9719222462203023,
      "grad_norm": 0.3448775112628937,
      "learning_rate": 7.512888888888889e-05,
      "loss": 1.4091,
      "step": 4050
    },
    {
      "epoch": 0.9719222462203023,
      "eval_loss": 1.3046619892120361,
      "eval_runtime": 3.5361,
      "eval_samples_per_second": 56.56,
      "eval_steps_per_second": 2.545,
      "step": 4050
    },
    {
      "epoch": 0.9743220542356611,
      "grad_norm": 0.3218424618244171,
      "learning_rate": 7.504e-05,
      "loss": 1.3401,
      "step": 4060
    },
    {
      "epoch": 0.9767218622510199,
      "grad_norm": 0.26919084787368774,
      "learning_rate": 7.495111111111111e-05,
      "loss": 1.3256,
      "step": 4070
    },
    {
      "epoch": 0.9791216702663786,
      "grad_norm": 0.3170817196369171,
      "learning_rate": 7.486222222222222e-05,
      "loss": 1.3922,
      "step": 4080
    },
    {
      "epoch": 0.9815214782817374,
      "grad_norm": 0.3270367681980133,
      "learning_rate": 7.477333333333334e-05,
      "loss": 1.2919,
      "step": 4090
    },
    {
      "epoch": 0.9839212862970962,
      "grad_norm": 0.3007572293281555,
      "learning_rate": 7.468444444444444e-05,
      "loss": 1.2559,
      "step": 4100
    },
    {
      "epoch": 0.9839212862970962,
      "eval_loss": 1.305812120437622,
      "eval_runtime": 3.5366,
      "eval_samples_per_second": 56.551,
      "eval_steps_per_second": 2.545,
      "step": 4100
    },
    {
      "epoch": 0.986321094312455,
      "grad_norm": 0.3186650276184082,
      "learning_rate": 7.459555555555557e-05,
      "loss": 1.2427,
      "step": 4110
    },
    {
      "epoch": 0.9887209023278137,
      "grad_norm": 0.2767306864261627,
      "learning_rate": 7.450666666666666e-05,
      "loss": 1.2128,
      "step": 4120
    },
    {
      "epoch": 0.9911207103431725,
      "grad_norm": 0.30723848938941956,
      "learning_rate": 7.441777777777779e-05,
      "loss": 1.3412,
      "step": 4130
    },
    {
      "epoch": 0.9935205183585313,
      "grad_norm": 0.33831727504730225,
      "learning_rate": 7.43288888888889e-05,
      "loss": 1.3116,
      "step": 4140
    },
    {
      "epoch": 0.99592032637389,
      "grad_norm": 0.3288393020629883,
      "learning_rate": 7.424e-05,
      "loss": 1.3548,
      "step": 4150
    },
    {
      "epoch": 0.99592032637389,
      "eval_loss": 1.305416464805603,
      "eval_runtime": 3.5363,
      "eval_samples_per_second": 56.557,
      "eval_steps_per_second": 2.545,
      "step": 4150
    },
    {
      "epoch": 0.9983201343892488,
      "grad_norm": 0.590942919254303,
      "learning_rate": 7.415111111111112e-05,
      "loss": 1.3873,
      "step": 4160
    },
    {
      "epoch": 1.0007199424046076,
      "grad_norm": 0.289512574672699,
      "learning_rate": 7.406222222222223e-05,
      "loss": 1.3484,
      "step": 4170
    },
    {
      "epoch": 1.0031197504199665,
      "grad_norm": 0.30920830368995667,
      "learning_rate": 7.397333333333334e-05,
      "loss": 1.3171,
      "step": 4180
    },
    {
      "epoch": 1.0055195584353251,
      "grad_norm": 0.36552324891090393,
      "learning_rate": 7.388444444444445e-05,
      "loss": 1.3388,
      "step": 4190
    },
    {
      "epoch": 1.007919366450684,
      "grad_norm": 0.33953192830085754,
      "learning_rate": 7.379555555555556e-05,
      "loss": 1.3275,
      "step": 4200
    },
    {
      "epoch": 1.007919366450684,
      "eval_loss": 1.303521752357483,
      "eval_runtime": 3.5352,
      "eval_samples_per_second": 56.574,
      "eval_steps_per_second": 2.546,
      "step": 4200
    },
    {
      "epoch": 1.0103191744660427,
      "grad_norm": 0.32815444469451904,
      "learning_rate": 7.370666666666667e-05,
      "loss": 1.2595,
      "step": 4210
    },
    {
      "epoch": 1.0127189824814016,
      "grad_norm": 0.30347055196762085,
      "learning_rate": 7.361777777777778e-05,
      "loss": 1.2387,
      "step": 4220
    },
    {
      "epoch": 1.0151187904967602,
      "grad_norm": 0.24074546992778778,
      "learning_rate": 7.352888888888889e-05,
      "loss": 1.1769,
      "step": 4230
    },
    {
      "epoch": 1.0175185985121191,
      "grad_norm": 0.33719831705093384,
      "learning_rate": 7.344000000000002e-05,
      "loss": 1.4365,
      "step": 4240
    },
    {
      "epoch": 1.0199184065274778,
      "grad_norm": 0.4775293171405792,
      "learning_rate": 7.335111111111111e-05,
      "loss": 1.3084,
      "step": 4250
    },
    {
      "epoch": 1.0199184065274778,
      "eval_loss": 1.3069251775741577,
      "eval_runtime": 3.5363,
      "eval_samples_per_second": 56.557,
      "eval_steps_per_second": 2.545,
      "step": 4250
    },
    {
      "epoch": 1.0223182145428367,
      "grad_norm": 0.354834645986557,
      "learning_rate": 7.326222222222222e-05,
      "loss": 1.3396,
      "step": 4260
    },
    {
      "epoch": 1.0247180225581953,
      "grad_norm": 0.39809730648994446,
      "learning_rate": 7.317333333333333e-05,
      "loss": 1.42,
      "step": 4270
    },
    {
      "epoch": 1.0271178305735542,
      "grad_norm": 0.3247867822647095,
      "learning_rate": 7.308444444444444e-05,
      "loss": 1.396,
      "step": 4280
    },
    {
      "epoch": 1.0295176385889129,
      "grad_norm": 0.3257281184196472,
      "learning_rate": 7.299555555555557e-05,
      "loss": 1.3194,
      "step": 4290
    },
    {
      "epoch": 1.0319174466042718,
      "grad_norm": 0.35424861311912537,
      "learning_rate": 7.290666666666666e-05,
      "loss": 1.4439,
      "step": 4300
    },
    {
      "epoch": 1.0319174466042718,
      "eval_loss": 1.3043383359909058,
      "eval_runtime": 3.5358,
      "eval_samples_per_second": 56.565,
      "eval_steps_per_second": 2.545,
      "step": 4300
    },
    {
      "epoch": 1.0343172546196304,
      "grad_norm": 0.32320815324783325,
      "learning_rate": 7.281777777777779e-05,
      "loss": 1.267,
      "step": 4310
    },
    {
      "epoch": 1.0367170626349893,
      "grad_norm": 0.36593759059906006,
      "learning_rate": 7.272888888888889e-05,
      "loss": 1.2433,
      "step": 4320
    },
    {
      "epoch": 1.039116870650348,
      "grad_norm": 0.3177471160888672,
      "learning_rate": 7.264000000000001e-05,
      "loss": 1.3467,
      "step": 4330
    },
    {
      "epoch": 1.0415166786657069,
      "grad_norm": 0.35651206970214844,
      "learning_rate": 7.255111111111112e-05,
      "loss": 1.3404,
      "step": 4340
    },
    {
      "epoch": 1.0439164866810655,
      "grad_norm": 0.31916308403015137,
      "learning_rate": 7.246222222222222e-05,
      "loss": 1.155,
      "step": 4350
    },
    {
      "epoch": 1.0439164866810655,
      "eval_loss": 1.3033440113067627,
      "eval_runtime": 3.537,
      "eval_samples_per_second": 56.545,
      "eval_steps_per_second": 2.545,
      "step": 4350
    },
    {
      "epoch": 1.0463162946964242,
      "grad_norm": 0.34247955679893494,
      "learning_rate": 7.237333333333334e-05,
      "loss": 1.2514,
      "step": 4360
    },
    {
      "epoch": 1.048716102711783,
      "grad_norm": 0.3008522391319275,
      "learning_rate": 7.228444444444444e-05,
      "loss": 1.2162,
      "step": 4370
    },
    {
      "epoch": 1.0511159107271417,
      "grad_norm": 0.3593212366104126,
      "learning_rate": 7.219555555555556e-05,
      "loss": 1.2794,
      "step": 4380
    },
    {
      "epoch": 1.0535157187425006,
      "grad_norm": 0.3691323399543762,
      "learning_rate": 7.210666666666667e-05,
      "loss": 1.3267,
      "step": 4390
    },
    {
      "epoch": 1.0559155267578593,
      "grad_norm": 0.3504723906517029,
      "learning_rate": 7.201777777777778e-05,
      "loss": 1.4504,
      "step": 4400
    },
    {
      "epoch": 1.0559155267578593,
      "eval_loss": 1.3023916482925415,
      "eval_runtime": 3.5356,
      "eval_samples_per_second": 56.568,
      "eval_steps_per_second": 2.546,
      "step": 4400
    },
    {
      "epoch": 1.0583153347732182,
      "grad_norm": 0.29291102290153503,
      "learning_rate": 7.192888888888889e-05,
      "loss": 1.3213,
      "step": 4410
    },
    {
      "epoch": 1.0607151427885768,
      "grad_norm": 0.32266971468925476,
      "learning_rate": 7.184e-05,
      "loss": 1.1719,
      "step": 4420
    },
    {
      "epoch": 1.0631149508039357,
      "grad_norm": 0.43361765146255493,
      "learning_rate": 7.175111111111111e-05,
      "loss": 1.3984,
      "step": 4430
    },
    {
      "epoch": 1.0655147588192944,
      "grad_norm": 0.2945074737071991,
      "learning_rate": 7.166222222222222e-05,
      "loss": 1.3331,
      "step": 4440
    },
    {
      "epoch": 1.0679145668346532,
      "grad_norm": 0.3966146409511566,
      "learning_rate": 7.157333333333333e-05,
      "loss": 1.4132,
      "step": 4450
    },
    {
      "epoch": 1.0679145668346532,
      "eval_loss": 1.3008373975753784,
      "eval_runtime": 3.5359,
      "eval_samples_per_second": 56.562,
      "eval_steps_per_second": 2.545,
      "step": 4450
    },
    {
      "epoch": 1.070314374850012,
      "grad_norm": 0.26982593536376953,
      "learning_rate": 7.148444444444445e-05,
      "loss": 1.3888,
      "step": 4460
    },
    {
      "epoch": 1.0727141828653708,
      "grad_norm": 0.34652477502822876,
      "learning_rate": 7.139555555555556e-05,
      "loss": 1.3441,
      "step": 4470
    },
    {
      "epoch": 1.0751139908807295,
      "grad_norm": 0.7225623726844788,
      "learning_rate": 7.130666666666667e-05,
      "loss": 1.2965,
      "step": 4480
    },
    {
      "epoch": 1.0775137988960883,
      "grad_norm": 0.4044768512248993,
      "learning_rate": 7.121777777777778e-05,
      "loss": 1.2242,
      "step": 4490
    },
    {
      "epoch": 1.079913606911447,
      "grad_norm": 0.28045350313186646,
      "learning_rate": 7.112888888888889e-05,
      "loss": 1.2956,
      "step": 4500
    },
    {
      "epoch": 1.079913606911447,
      "eval_loss": 1.303761601448059,
      "eval_runtime": 3.5352,
      "eval_samples_per_second": 56.573,
      "eval_steps_per_second": 2.546,
      "step": 4500
    },
    {
      "epoch": 1.0823134149268059,
      "grad_norm": 0.25948479771614075,
      "learning_rate": 7.104000000000001e-05,
      "loss": 1.2576,
      "step": 4510
    },
    {
      "epoch": 1.0847132229421645,
      "grad_norm": 0.34218114614486694,
      "learning_rate": 7.095111111111111e-05,
      "loss": 1.3268,
      "step": 4520
    },
    {
      "epoch": 1.0871130309575234,
      "grad_norm": 0.32668787240982056,
      "learning_rate": 7.086222222222223e-05,
      "loss": 1.2241,
      "step": 4530
    },
    {
      "epoch": 1.089512838972882,
      "grad_norm": 0.2931811511516571,
      "learning_rate": 7.077333333333334e-05,
      "loss": 1.3236,
      "step": 4540
    },
    {
      "epoch": 1.091912646988241,
      "grad_norm": 0.3347562253475189,
      "learning_rate": 7.068444444444445e-05,
      "loss": 1.3588,
      "step": 4550
    },
    {
      "epoch": 1.091912646988241,
      "eval_loss": 1.3007888793945312,
      "eval_runtime": 3.5347,
      "eval_samples_per_second": 56.582,
      "eval_steps_per_second": 2.546,
      "step": 4550
    },
    {
      "epoch": 1.0943124550035996,
      "grad_norm": 0.3165552318096161,
      "learning_rate": 7.059555555555556e-05,
      "loss": 1.377,
      "step": 4560
    },
    {
      "epoch": 1.0967122630189585,
      "grad_norm": 0.3086143434047699,
      "learning_rate": 7.050666666666666e-05,
      "loss": 1.2706,
      "step": 4570
    },
    {
      "epoch": 1.0991120710343172,
      "grad_norm": 0.32496005296707153,
      "learning_rate": 7.041777777777778e-05,
      "loss": 1.3329,
      "step": 4580
    },
    {
      "epoch": 1.101511879049676,
      "grad_norm": 0.3284814655780792,
      "learning_rate": 7.03288888888889e-05,
      "loss": 1.2309,
      "step": 4590
    },
    {
      "epoch": 1.1039116870650347,
      "grad_norm": 0.25526416301727295,
      "learning_rate": 7.024e-05,
      "loss": 1.2934,
      "step": 4600
    },
    {
      "epoch": 1.1039116870650347,
      "eval_loss": 1.2993305921554565,
      "eval_runtime": 3.5355,
      "eval_samples_per_second": 56.569,
      "eval_steps_per_second": 2.546,
      "step": 4600
    },
    {
      "epoch": 1.1063114950803936,
      "grad_norm": 0.35964056849479675,
      "learning_rate": 7.015111111111112e-05,
      "loss": 1.372,
      "step": 4610
    },
    {
      "epoch": 1.1087113030957523,
      "grad_norm": 0.30225899815559387,
      "learning_rate": 7.006222222222223e-05,
      "loss": 1.3009,
      "step": 4620
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 0.32294076681137085,
      "learning_rate": 6.997333333333334e-05,
      "loss": 1.2692,
      "step": 4630
    },
    {
      "epoch": 1.1135109191264698,
      "grad_norm": 0.34645208716392517,
      "learning_rate": 6.988444444444445e-05,
      "loss": 1.2811,
      "step": 4640
    },
    {
      "epoch": 1.1159107271418287,
      "grad_norm": 0.24088089168071747,
      "learning_rate": 6.979555555555556e-05,
      "loss": 1.1669,
      "step": 4650
    },
    {
      "epoch": 1.1159107271418287,
      "eval_loss": 1.301790714263916,
      "eval_runtime": 3.5322,
      "eval_samples_per_second": 56.622,
      "eval_steps_per_second": 2.548,
      "step": 4650
    },
    {
      "epoch": 1.1183105351571874,
      "grad_norm": 0.3200704753398895,
      "learning_rate": 6.970666666666667e-05,
      "loss": 1.2501,
      "step": 4660
    },
    {
      "epoch": 1.1207103431725463,
      "grad_norm": 0.3069581389427185,
      "learning_rate": 6.961777777777778e-05,
      "loss": 1.3378,
      "step": 4670
    },
    {
      "epoch": 1.123110151187905,
      "grad_norm": 0.3406137228012085,
      "learning_rate": 6.952888888888889e-05,
      "loss": 1.3354,
      "step": 4680
    },
    {
      "epoch": 1.1255099592032638,
      "grad_norm": 0.3451369106769562,
      "learning_rate": 6.944e-05,
      "loss": 1.2964,
      "step": 4690
    },
    {
      "epoch": 1.1279097672186225,
      "grad_norm": 0.29441124200820923,
      "learning_rate": 6.935111111111111e-05,
      "loss": 1.3366,
      "step": 4700
    },
    {
      "epoch": 1.1279097672186225,
      "eval_loss": 1.2982646226882935,
      "eval_runtime": 3.5322,
      "eval_samples_per_second": 56.622,
      "eval_steps_per_second": 2.548,
      "step": 4700
    },
    {
      "epoch": 1.1303095752339813,
      "grad_norm": 0.3279000520706177,
      "learning_rate": 6.926222222222223e-05,
      "loss": 1.294,
      "step": 4710
    },
    {
      "epoch": 1.13270938324934,
      "grad_norm": 0.3321491777896881,
      "learning_rate": 6.917333333333333e-05,
      "loss": 1.3306,
      "step": 4720
    },
    {
      "epoch": 1.135109191264699,
      "grad_norm": 0.3233364522457123,
      "learning_rate": 6.908444444444445e-05,
      "loss": 1.3719,
      "step": 4730
    },
    {
      "epoch": 1.1375089992800576,
      "grad_norm": 0.36605408787727356,
      "learning_rate": 6.899555555555555e-05,
      "loss": 1.2776,
      "step": 4740
    },
    {
      "epoch": 1.1399088072954164,
      "grad_norm": 0.39024558663368225,
      "learning_rate": 6.890666666666668e-05,
      "loss": 1.2875,
      "step": 4750
    },
    {
      "epoch": 1.1399088072954164,
      "eval_loss": 1.299357295036316,
      "eval_runtime": 3.5317,
      "eval_samples_per_second": 56.629,
      "eval_steps_per_second": 2.548,
      "step": 4750
    },
    {
      "epoch": 1.142308615310775,
      "grad_norm": 0.35892990231513977,
      "learning_rate": 6.881777777777779e-05,
      "loss": 1.2828,
      "step": 4760
    },
    {
      "epoch": 1.144708423326134,
      "grad_norm": 0.317638099193573,
      "learning_rate": 6.872888888888888e-05,
      "loss": 1.3078,
      "step": 4770
    },
    {
      "epoch": 1.1471082313414926,
      "grad_norm": 0.30307361483573914,
      "learning_rate": 6.864000000000001e-05,
      "loss": 1.4009,
      "step": 4780
    },
    {
      "epoch": 1.1495080393568515,
      "grad_norm": 0.3828076124191284,
      "learning_rate": 6.85511111111111e-05,
      "loss": 1.3365,
      "step": 4790
    },
    {
      "epoch": 1.1519078473722102,
      "grad_norm": 0.32279154658317566,
      "learning_rate": 6.846222222222223e-05,
      "loss": 1.2379,
      "step": 4800
    },
    {
      "epoch": 1.1519078473722102,
      "eval_loss": 1.2999664545059204,
      "eval_runtime": 3.532,
      "eval_samples_per_second": 56.625,
      "eval_steps_per_second": 2.548,
      "step": 4800
    },
    {
      "epoch": 1.154307655387569,
      "grad_norm": 0.2940959334373474,
      "learning_rate": 6.837333333333334e-05,
      "loss": 1.206,
      "step": 4810
    },
    {
      "epoch": 1.1567074634029277,
      "grad_norm": 0.3797525465488434,
      "learning_rate": 6.828444444444445e-05,
      "loss": 1.3569,
      "step": 4820
    },
    {
      "epoch": 1.1591072714182866,
      "grad_norm": 0.28508996963500977,
      "learning_rate": 6.819555555555556e-05,
      "loss": 1.2919,
      "step": 4830
    },
    {
      "epoch": 1.1615070794336453,
      "grad_norm": 0.3321746289730072,
      "learning_rate": 6.810666666666667e-05,
      "loss": 1.3902,
      "step": 4840
    },
    {
      "epoch": 1.1639068874490042,
      "grad_norm": 0.26438748836517334,
      "learning_rate": 6.801777777777778e-05,
      "loss": 1.2297,
      "step": 4850
    },
    {
      "epoch": 1.1639068874490042,
      "eval_loss": 1.3005781173706055,
      "eval_runtime": 3.5339,
      "eval_samples_per_second": 56.595,
      "eval_steps_per_second": 2.547,
      "step": 4850
    },
    {
      "epoch": 1.1663066954643628,
      "grad_norm": 0.33961740136146545,
      "learning_rate": 6.79288888888889e-05,
      "loss": 1.232,
      "step": 4860
    },
    {
      "epoch": 1.1687065034797217,
      "grad_norm": 0.34566399455070496,
      "learning_rate": 6.784e-05,
      "loss": 1.2356,
      "step": 4870
    },
    {
      "epoch": 1.1711063114950804,
      "grad_norm": 0.2912333011627197,
      "learning_rate": 6.775111111111111e-05,
      "loss": 1.2124,
      "step": 4880
    },
    {
      "epoch": 1.1735061195104393,
      "grad_norm": 0.3187244236469269,
      "learning_rate": 6.766222222222222e-05,
      "loss": 1.2896,
      "step": 4890
    },
    {
      "epoch": 1.175905927525798,
      "grad_norm": 0.3302593529224396,
      "learning_rate": 6.757333333333333e-05,
      "loss": 1.2367,
      "step": 4900
    },
    {
      "epoch": 1.175905927525798,
      "eval_loss": 1.2986677885055542,
      "eval_runtime": 3.5324,
      "eval_samples_per_second": 56.618,
      "eval_steps_per_second": 2.548,
      "step": 4900
    },
    {
      "epoch": 1.1783057355411568,
      "grad_norm": 0.39599519968032837,
      "learning_rate": 6.748444444444446e-05,
      "loss": 1.3227,
      "step": 4910
    },
    {
      "epoch": 1.1807055435565155,
      "grad_norm": 0.28695499897003174,
      "learning_rate": 6.739555555555555e-05,
      "loss": 1.2623,
      "step": 4920
    },
    {
      "epoch": 1.1831053515718741,
      "grad_norm": 0.3132385015487671,
      "learning_rate": 6.730666666666668e-05,
      "loss": 1.2309,
      "step": 4930
    },
    {
      "epoch": 1.185505159587233,
      "grad_norm": 0.37320828437805176,
      "learning_rate": 6.721777777777777e-05,
      "loss": 1.3002,
      "step": 4940
    },
    {
      "epoch": 1.187904967602592,
      "grad_norm": 0.3356764614582062,
      "learning_rate": 6.71288888888889e-05,
      "loss": 1.3802,
      "step": 4950
    },
    {
      "epoch": 1.187904967602592,
      "eval_loss": 1.2995796203613281,
      "eval_runtime": 3.532,
      "eval_samples_per_second": 56.625,
      "eval_steps_per_second": 2.548,
      "step": 4950
    },
    {
      "epoch": 1.1903047756179506,
      "grad_norm": 0.3461994528770447,
      "learning_rate": 6.704000000000001e-05,
      "loss": 1.3483,
      "step": 4960
    },
    {
      "epoch": 1.1927045836333092,
      "grad_norm": 0.3458450734615326,
      "learning_rate": 6.69511111111111e-05,
      "loss": 1.2472,
      "step": 4970
    },
    {
      "epoch": 1.195104391648668,
      "grad_norm": 0.30516156554222107,
      "learning_rate": 6.686222222222223e-05,
      "loss": 1.4158,
      "step": 4980
    },
    {
      "epoch": 1.197504199664027,
      "grad_norm": 0.3038570284843445,
      "learning_rate": 6.677333333333333e-05,
      "loss": 1.2967,
      "step": 4990
    },
    {
      "epoch": 1.1999040076793857,
      "grad_norm": 0.3125206232070923,
      "learning_rate": 6.668444444444445e-05,
      "loss": 1.3015,
      "step": 5000
    },
    {
      "epoch": 1.1999040076793857,
      "eval_loss": 1.2992581129074097,
      "eval_runtime": 3.5311,
      "eval_samples_per_second": 56.64,
      "eval_steps_per_second": 2.549,
      "step": 5000
    },
    {
      "epoch": 1.2023038156947443,
      "grad_norm": 0.3764801621437073,
      "learning_rate": 6.659555555555556e-05,
      "loss": 1.3524,
      "step": 5010
    },
    {
      "epoch": 1.2047036237101032,
      "grad_norm": 0.33723393082618713,
      "learning_rate": 6.650666666666667e-05,
      "loss": 1.3112,
      "step": 5020
    },
    {
      "epoch": 1.207103431725462,
      "grad_norm": 0.31630244851112366,
      "learning_rate": 6.641777777777778e-05,
      "loss": 1.3907,
      "step": 5030
    },
    {
      "epoch": 1.2095032397408207,
      "grad_norm": 0.3606168329715729,
      "learning_rate": 6.632888888888889e-05,
      "loss": 1.2746,
      "step": 5040
    },
    {
      "epoch": 1.2119030477561794,
      "grad_norm": 0.3380216956138611,
      "learning_rate": 6.624e-05,
      "loss": 1.1978,
      "step": 5050
    },
    {
      "epoch": 1.2119030477561794,
      "eval_loss": 1.2976802587509155,
      "eval_runtime": 3.5317,
      "eval_samples_per_second": 56.63,
      "eval_steps_per_second": 2.548,
      "step": 5050
    },
    {
      "epoch": 1.2143028557715383,
      "grad_norm": 0.3801824152469635,
      "learning_rate": 6.615111111111111e-05,
      "loss": 1.3786,
      "step": 5060
    },
    {
      "epoch": 1.216702663786897,
      "grad_norm": 0.3912866413593292,
      "learning_rate": 6.606222222222222e-05,
      "loss": 1.2806,
      "step": 5070
    },
    {
      "epoch": 1.2191024718022558,
      "grad_norm": 0.32487982511520386,
      "learning_rate": 6.597333333333333e-05,
      "loss": 1.3984,
      "step": 5080
    },
    {
      "epoch": 1.2215022798176145,
      "grad_norm": 0.377658873796463,
      "learning_rate": 6.588444444444444e-05,
      "loss": 1.1902,
      "step": 5090
    },
    {
      "epoch": 1.2239020878329734,
      "grad_norm": 0.2877253293991089,
      "learning_rate": 6.579555555555556e-05,
      "loss": 1.257,
      "step": 5100
    },
    {
      "epoch": 1.2239020878329734,
      "eval_loss": 1.3000739812850952,
      "eval_runtime": 3.5327,
      "eval_samples_per_second": 56.613,
      "eval_steps_per_second": 2.548,
      "step": 5100
    },
    {
      "epoch": 1.226301895848332,
      "grad_norm": 0.3272137939929962,
      "learning_rate": 6.570666666666667e-05,
      "loss": 1.3229,
      "step": 5110
    },
    {
      "epoch": 1.228701703863691,
      "grad_norm": 0.3493025004863739,
      "learning_rate": 6.561777777777778e-05,
      "loss": 1.3514,
      "step": 5120
    },
    {
      "epoch": 1.2311015118790496,
      "grad_norm": 0.34251540899276733,
      "learning_rate": 6.55288888888889e-05,
      "loss": 1.2809,
      "step": 5130
    },
    {
      "epoch": 1.2335013198944085,
      "grad_norm": 0.3563038408756256,
      "learning_rate": 6.544e-05,
      "loss": 1.2771,
      "step": 5140
    },
    {
      "epoch": 1.2359011279097671,
      "grad_norm": 0.35565659403800964,
      "learning_rate": 6.535111111111112e-05,
      "loss": 1.4792,
      "step": 5150
    },
    {
      "epoch": 1.2359011279097671,
      "eval_loss": 1.2952615022659302,
      "eval_runtime": 3.5308,
      "eval_samples_per_second": 56.644,
      "eval_steps_per_second": 2.549,
      "step": 5150
    },
    {
      "epoch": 1.238300935925126,
      "grad_norm": 0.3897645175457001,
      "learning_rate": 6.526222222222223e-05,
      "loss": 1.4248,
      "step": 5160
    },
    {
      "epoch": 1.2407007439404847,
      "grad_norm": 0.3177753686904907,
      "learning_rate": 6.517333333333334e-05,
      "loss": 1.1744,
      "step": 5170
    },
    {
      "epoch": 1.2431005519558436,
      "grad_norm": 0.3855390250682831,
      "learning_rate": 6.508444444444445e-05,
      "loss": 1.3419,
      "step": 5180
    },
    {
      "epoch": 1.2455003599712022,
      "grad_norm": 0.3133086860179901,
      "learning_rate": 6.499555555555555e-05,
      "loss": 1.2531,
      "step": 5190
    },
    {
      "epoch": 1.2479001679865611,
      "grad_norm": 0.3215276002883911,
      "learning_rate": 6.490666666666667e-05,
      "loss": 1.3595,
      "step": 5200
    },
    {
      "epoch": 1.2479001679865611,
      "eval_loss": 1.2940646409988403,
      "eval_runtime": 3.5344,
      "eval_samples_per_second": 56.587,
      "eval_steps_per_second": 2.546,
      "step": 5200
    },
    {
      "epoch": 1.2502999760019198,
      "grad_norm": 0.2811169922351837,
      "learning_rate": 6.481777777777778e-05,
      "loss": 1.2821,
      "step": 5210
    },
    {
      "epoch": 1.2526997840172787,
      "grad_norm": 0.3736538589000702,
      "learning_rate": 6.47288888888889e-05,
      "loss": 1.2685,
      "step": 5220
    },
    {
      "epoch": 1.2550995920326373,
      "grad_norm": 0.37521427869796753,
      "learning_rate": 6.464e-05,
      "loss": 1.3049,
      "step": 5230
    },
    {
      "epoch": 1.2574994000479962,
      "grad_norm": 0.3192354142665863,
      "learning_rate": 6.455111111111111e-05,
      "loss": 1.3148,
      "step": 5240
    },
    {
      "epoch": 1.2598992080633549,
      "grad_norm": 0.30908429622650146,
      "learning_rate": 6.446222222222223e-05,
      "loss": 1.2428,
      "step": 5250
    },
    {
      "epoch": 1.2598992080633549,
      "eval_loss": 1.298294186592102,
      "eval_runtime": 3.533,
      "eval_samples_per_second": 56.61,
      "eval_steps_per_second": 2.547,
      "step": 5250
    },
    {
      "epoch": 1.2622990160787138,
      "grad_norm": 0.352337509393692,
      "learning_rate": 6.437333333333334e-05,
      "loss": 1.3693,
      "step": 5260
    },
    {
      "epoch": 1.2646988240940724,
      "grad_norm": 0.29318735003471375,
      "learning_rate": 6.428444444444445e-05,
      "loss": 1.3311,
      "step": 5270
    },
    {
      "epoch": 1.2670986321094313,
      "grad_norm": 0.3459298312664032,
      "learning_rate": 6.419555555555556e-05,
      "loss": 1.2703,
      "step": 5280
    },
    {
      "epoch": 1.26949844012479,
      "grad_norm": 0.3238379955291748,
      "learning_rate": 6.410666666666667e-05,
      "loss": 1.2802,
      "step": 5290
    },
    {
      "epoch": 1.2718982481401488,
      "grad_norm": 0.35627683997154236,
      "learning_rate": 6.401777777777778e-05,
      "loss": 1.3748,
      "step": 5300
    },
    {
      "epoch": 1.2718982481401488,
      "eval_loss": 1.295932650566101,
      "eval_runtime": 3.5318,
      "eval_samples_per_second": 56.628,
      "eval_steps_per_second": 2.548,
      "step": 5300
    },
    {
      "epoch": 1.2742980561555075,
      "grad_norm": 0.33727264404296875,
      "learning_rate": 6.392888888888889e-05,
      "loss": 1.3663,
      "step": 5310
    },
    {
      "epoch": 1.2766978641708664,
      "grad_norm": 0.32063525915145874,
      "learning_rate": 6.384e-05,
      "loss": 1.2221,
      "step": 5320
    },
    {
      "epoch": 1.279097672186225,
      "grad_norm": 0.33684635162353516,
      "learning_rate": 6.375111111111112e-05,
      "loss": 1.3474,
      "step": 5330
    },
    {
      "epoch": 1.281497480201584,
      "grad_norm": 0.3085356652736664,
      "learning_rate": 6.366222222222222e-05,
      "loss": 1.2472,
      "step": 5340
    },
    {
      "epoch": 1.2838972882169426,
      "grad_norm": 0.37213635444641113,
      "learning_rate": 6.357333333333334e-05,
      "loss": 1.3672,
      "step": 5350
    },
    {
      "epoch": 1.2838972882169426,
      "eval_loss": 1.2962732315063477,
      "eval_runtime": 3.5322,
      "eval_samples_per_second": 56.622,
      "eval_steps_per_second": 2.548,
      "step": 5350
    },
    {
      "epoch": 1.2862970962323015,
      "grad_norm": 0.3700927495956421,
      "learning_rate": 6.348444444444444e-05,
      "loss": 1.2991,
      "step": 5360
    },
    {
      "epoch": 1.2886969042476601,
      "grad_norm": 0.3350711166858673,
      "learning_rate": 6.339555555555556e-05,
      "loss": 1.4384,
      "step": 5370
    },
    {
      "epoch": 1.291096712263019,
      "grad_norm": 0.3760921359062195,
      "learning_rate": 6.330666666666667e-05,
      "loss": 1.448,
      "step": 5380
    },
    {
      "epoch": 1.2934965202783777,
      "grad_norm": 0.2969050407409668,
      "learning_rate": 6.321777777777777e-05,
      "loss": 1.2934,
      "step": 5390
    },
    {
      "epoch": 1.2958963282937366,
      "grad_norm": 0.3798830807209015,
      "learning_rate": 6.31288888888889e-05,
      "loss": 1.4301,
      "step": 5400
    },
    {
      "epoch": 1.2958963282937366,
      "eval_loss": 1.295444130897522,
      "eval_runtime": 3.5338,
      "eval_samples_per_second": 56.596,
      "eval_steps_per_second": 2.547,
      "step": 5400
    },
    {
      "epoch": 1.2982961363090952,
      "grad_norm": 0.45659950375556946,
      "learning_rate": 6.303999999999999e-05,
      "loss": 1.2082,
      "step": 5410
    },
    {
      "epoch": 1.3006959443244541,
      "grad_norm": 0.34396007657051086,
      "learning_rate": 6.295111111111112e-05,
      "loss": 1.3401,
      "step": 5420
    },
    {
      "epoch": 1.3030957523398128,
      "grad_norm": 0.3771006166934967,
      "learning_rate": 6.286222222222223e-05,
      "loss": 1.3018,
      "step": 5430
    },
    {
      "epoch": 1.3054955603551717,
      "grad_norm": 0.3441501557826996,
      "learning_rate": 6.277333333333334e-05,
      "loss": 1.3033,
      "step": 5440
    },
    {
      "epoch": 1.3078953683705303,
      "grad_norm": 0.30201196670532227,
      "learning_rate": 6.268444444444445e-05,
      "loss": 1.3517,
      "step": 5450
    },
    {
      "epoch": 1.3078953683705303,
      "eval_loss": 1.2964423894882202,
      "eval_runtime": 3.5373,
      "eval_samples_per_second": 56.54,
      "eval_steps_per_second": 2.544,
      "step": 5450
    },
    {
      "epoch": 1.310295176385889,
      "grad_norm": 0.32974672317504883,
      "learning_rate": 6.259555555555556e-05,
      "loss": 1.2398,
      "step": 5460
    },
    {
      "epoch": 1.3126949844012479,
      "grad_norm": 0.30305516719818115,
      "learning_rate": 6.250666666666667e-05,
      "loss": 1.2878,
      "step": 5470
    },
    {
      "epoch": 1.3150947924166068,
      "grad_norm": 0.30639874935150146,
      "learning_rate": 6.241777777777778e-05,
      "loss": 1.2566,
      "step": 5480
    },
    {
      "epoch": 1.3174946004319654,
      "grad_norm": 0.32535886764526367,
      "learning_rate": 6.232888888888889e-05,
      "loss": 1.2953,
      "step": 5490
    },
    {
      "epoch": 1.319894408447324,
      "grad_norm": 0.3573625087738037,
      "learning_rate": 6.224e-05,
      "loss": 1.3376,
      "step": 5500
    },
    {
      "epoch": 1.319894408447324,
      "eval_loss": 1.2952256202697754,
      "eval_runtime": 3.5327,
      "eval_samples_per_second": 56.614,
      "eval_steps_per_second": 2.548,
      "step": 5500
    },
    {
      "epoch": 1.322294216462683,
      "grad_norm": 0.3357219696044922,
      "learning_rate": 6.215111111111111e-05,
      "loss": 1.3483,
      "step": 5510
    },
    {
      "epoch": 1.3246940244780419,
      "grad_norm": 0.3751657009124756,
      "learning_rate": 6.206222222222222e-05,
      "loss": 1.3116,
      "step": 5520
    },
    {
      "epoch": 1.3270938324934005,
      "grad_norm": 0.390675812959671,
      "learning_rate": 6.197333333333335e-05,
      "loss": 1.2846,
      "step": 5530
    },
    {
      "epoch": 1.3294936405087592,
      "grad_norm": 0.2891653776168823,
      "learning_rate": 6.188444444444444e-05,
      "loss": 1.2009,
      "step": 5540
    },
    {
      "epoch": 1.331893448524118,
      "grad_norm": 0.3310675621032715,
      "learning_rate": 6.179555555555557e-05,
      "loss": 1.3095,
      "step": 5550
    },
    {
      "epoch": 1.331893448524118,
      "eval_loss": 1.2971529960632324,
      "eval_runtime": 3.5321,
      "eval_samples_per_second": 56.624,
      "eval_steps_per_second": 2.548,
      "step": 5550
    },
    {
      "epoch": 1.334293256539477,
      "grad_norm": 0.34828439354896545,
      "learning_rate": 6.170666666666666e-05,
      "loss": 1.3099,
      "step": 5560
    },
    {
      "epoch": 1.3366930645548356,
      "grad_norm": 0.2852403521537781,
      "learning_rate": 6.161777777777779e-05,
      "loss": 1.2796,
      "step": 5570
    },
    {
      "epoch": 1.3390928725701943,
      "grad_norm": 0.35906118154525757,
      "learning_rate": 6.15288888888889e-05,
      "loss": 1.2845,
      "step": 5580
    },
    {
      "epoch": 1.3414926805855532,
      "grad_norm": 0.3299841582775116,
      "learning_rate": 6.144e-05,
      "loss": 1.3157,
      "step": 5590
    },
    {
      "epoch": 1.343892488600912,
      "grad_norm": 0.3174583911895752,
      "learning_rate": 6.135111111111112e-05,
      "loss": 1.4875,
      "step": 5600
    },
    {
      "epoch": 1.343892488600912,
      "eval_loss": 1.2959702014923096,
      "eval_runtime": 3.5387,
      "eval_samples_per_second": 56.518,
      "eval_steps_per_second": 2.543,
      "step": 5600
    },
    {
      "epoch": 1.3462922966162707,
      "grad_norm": 0.30300217866897583,
      "learning_rate": 6.126222222222222e-05,
      "loss": 1.2729,
      "step": 5610
    },
    {
      "epoch": 1.3486921046316294,
      "grad_norm": 0.44751521944999695,
      "learning_rate": 6.117333333333334e-05,
      "loss": 1.3689,
      "step": 5620
    },
    {
      "epoch": 1.3510919126469882,
      "grad_norm": 0.2955614924430847,
      "learning_rate": 6.108444444444445e-05,
      "loss": 1.258,
      "step": 5630
    },
    {
      "epoch": 1.3534917206623471,
      "grad_norm": 0.28359875082969666,
      "learning_rate": 6.099555555555556e-05,
      "loss": 1.3611,
      "step": 5640
    },
    {
      "epoch": 1.3558915286777058,
      "grad_norm": 0.32255831360816956,
      "learning_rate": 6.090666666666667e-05,
      "loss": 1.2259,
      "step": 5650
    },
    {
      "epoch": 1.3558915286777058,
      "eval_loss": 1.294524073600769,
      "eval_runtime": 3.5332,
      "eval_samples_per_second": 56.607,
      "eval_steps_per_second": 2.547,
      "step": 5650
    },
    {
      "epoch": 1.3582913366930645,
      "grad_norm": 0.4194245934486389,
      "learning_rate": 6.081777777777778e-05,
      "loss": 1.3155,
      "step": 5660
    },
    {
      "epoch": 1.3606911447084233,
      "grad_norm": 0.3284362256526947,
      "learning_rate": 6.072888888888889e-05,
      "loss": 1.3309,
      "step": 5670
    },
    {
      "epoch": 1.3630909527237822,
      "grad_norm": 0.28897762298583984,
      "learning_rate": 6.064000000000001e-05,
      "loss": 1.2493,
      "step": 5680
    },
    {
      "epoch": 1.3654907607391409,
      "grad_norm": 0.2889641523361206,
      "learning_rate": 6.055111111111111e-05,
      "loss": 1.2184,
      "step": 5690
    },
    {
      "epoch": 1.3678905687544995,
      "grad_norm": 0.3424968719482422,
      "learning_rate": 6.046222222222222e-05,
      "loss": 1.3108,
      "step": 5700
    },
    {
      "epoch": 1.3678905687544995,
      "eval_loss": 1.2945976257324219,
      "eval_runtime": 3.5333,
      "eval_samples_per_second": 56.604,
      "eval_steps_per_second": 2.547,
      "step": 5700
    },
    {
      "epoch": 1.3702903767698584,
      "grad_norm": 0.30851128697395325,
      "learning_rate": 6.037333333333334e-05,
      "loss": 1.311,
      "step": 5710
    },
    {
      "epoch": 1.3726901847852173,
      "grad_norm": 0.2698401212692261,
      "learning_rate": 6.0284444444444444e-05,
      "loss": 1.1434,
      "step": 5720
    },
    {
      "epoch": 1.375089992800576,
      "grad_norm": 0.33115923404693604,
      "learning_rate": 6.019555555555556e-05,
      "loss": 1.2023,
      "step": 5730
    },
    {
      "epoch": 1.3774898008159346,
      "grad_norm": 0.34954479336738586,
      "learning_rate": 6.0106666666666665e-05,
      "loss": 1.2716,
      "step": 5740
    },
    {
      "epoch": 1.3798896088312935,
      "grad_norm": 0.2586539089679718,
      "learning_rate": 6.001777777777778e-05,
      "loss": 1.2112,
      "step": 5750
    },
    {
      "epoch": 1.3798896088312935,
      "eval_loss": 1.292350172996521,
      "eval_runtime": 3.5331,
      "eval_samples_per_second": 56.608,
      "eval_steps_per_second": 2.547,
      "step": 5750
    },
    {
      "epoch": 1.3822894168466522,
      "grad_norm": 0.2720370888710022,
      "learning_rate": 5.992888888888889e-05,
      "loss": 1.3042,
      "step": 5760
    },
    {
      "epoch": 1.384689224862011,
      "grad_norm": 0.30428260564804077,
      "learning_rate": 5.984000000000001e-05,
      "loss": 1.1944,
      "step": 5770
    },
    {
      "epoch": 1.3870890328773697,
      "grad_norm": 0.34811967611312866,
      "learning_rate": 5.9751111111111114e-05,
      "loss": 1.2711,
      "step": 5780
    },
    {
      "epoch": 1.3894888408927286,
      "grad_norm": 0.26754194498062134,
      "learning_rate": 5.966222222222223e-05,
      "loss": 1.3369,
      "step": 5790
    },
    {
      "epoch": 1.3918886489080873,
      "grad_norm": 0.29573097825050354,
      "learning_rate": 5.9573333333333334e-05,
      "loss": 1.3062,
      "step": 5800
    },
    {
      "epoch": 1.3918886489080873,
      "eval_loss": 1.2941665649414062,
      "eval_runtime": 3.5321,
      "eval_samples_per_second": 56.624,
      "eval_steps_per_second": 2.548,
      "step": 5800
    },
    {
      "epoch": 1.3942884569234462,
      "grad_norm": 0.2990478277206421,
      "learning_rate": 5.9484444444444445e-05,
      "loss": 1.2242,
      "step": 5810
    },
    {
      "epoch": 1.3966882649388048,
      "grad_norm": 0.35325756669044495,
      "learning_rate": 5.939555555555556e-05,
      "loss": 1.3299,
      "step": 5820
    },
    {
      "epoch": 1.3990880729541637,
      "grad_norm": 0.32884106040000916,
      "learning_rate": 5.9306666666666666e-05,
      "loss": 1.2453,
      "step": 5830
    },
    {
      "epoch": 1.4014878809695224,
      "grad_norm": 0.27708926796913147,
      "learning_rate": 5.921777777777778e-05,
      "loss": 1.3173,
      "step": 5840
    },
    {
      "epoch": 1.4038876889848813,
      "grad_norm": 0.34813380241394043,
      "learning_rate": 5.912888888888889e-05,
      "loss": 1.4245,
      "step": 5850
    },
    {
      "epoch": 1.4038876889848813,
      "eval_loss": 1.292808175086975,
      "eval_runtime": 3.5336,
      "eval_samples_per_second": 56.6,
      "eval_steps_per_second": 2.547,
      "step": 5850
    },
    {
      "epoch": 1.40628749700024,
      "grad_norm": 0.3280571699142456,
      "learning_rate": 5.9040000000000004e-05,
      "loss": 1.4222,
      "step": 5860
    },
    {
      "epoch": 1.4086873050155988,
      "grad_norm": 0.33662477135658264,
      "learning_rate": 5.8951111111111114e-05,
      "loss": 1.2645,
      "step": 5870
    },
    {
      "epoch": 1.4110871130309575,
      "grad_norm": 0.3057081997394562,
      "learning_rate": 5.886222222222223e-05,
      "loss": 1.2285,
      "step": 5880
    },
    {
      "epoch": 1.4134869210463163,
      "grad_norm": 0.2984599769115448,
      "learning_rate": 5.8773333333333335e-05,
      "loss": 1.3366,
      "step": 5890
    },
    {
      "epoch": 1.415886729061675,
      "grad_norm": 0.3610319197177887,
      "learning_rate": 5.868444444444444e-05,
      "loss": 1.3623,
      "step": 5900
    },
    {
      "epoch": 1.415886729061675,
      "eval_loss": 1.2911920547485352,
      "eval_runtime": 3.5328,
      "eval_samples_per_second": 56.613,
      "eval_steps_per_second": 2.548,
      "step": 5900
    },
    {
      "epoch": 1.418286537077034,
      "grad_norm": 0.32455363869667053,
      "learning_rate": 5.8595555555555556e-05,
      "loss": 1.217,
      "step": 5910
    },
    {
      "epoch": 1.4206863450923926,
      "grad_norm": 0.34353476762771606,
      "learning_rate": 5.850666666666667e-05,
      "loss": 1.2018,
      "step": 5920
    },
    {
      "epoch": 1.4230861531077514,
      "grad_norm": 0.34093570709228516,
      "learning_rate": 5.8417777777777784e-05,
      "loss": 1.1391,
      "step": 5930
    },
    {
      "epoch": 1.42548596112311,
      "grad_norm": 0.34911438822746277,
      "learning_rate": 5.832888888888889e-05,
      "loss": 1.1896,
      "step": 5940
    },
    {
      "epoch": 1.427885769138469,
      "grad_norm": 0.3128146231174469,
      "learning_rate": 5.8240000000000005e-05,
      "loss": 1.287,
      "step": 5950
    },
    {
      "epoch": 1.427885769138469,
      "eval_loss": 1.291558027267456,
      "eval_runtime": 3.5317,
      "eval_samples_per_second": 56.63,
      "eval_steps_per_second": 2.548,
      "step": 5950
    },
    {
      "epoch": 1.4302855771538276,
      "grad_norm": 0.3072166442871094,
      "learning_rate": 5.815111111111111e-05,
      "loss": 1.2993,
      "step": 5960
    },
    {
      "epoch": 1.4326853851691865,
      "grad_norm": 0.3109295964241028,
      "learning_rate": 5.8062222222222226e-05,
      "loss": 1.3156,
      "step": 5970
    },
    {
      "epoch": 1.4350851931845452,
      "grad_norm": 0.3264777660369873,
      "learning_rate": 5.7973333333333336e-05,
      "loss": 1.3905,
      "step": 5980
    },
    {
      "epoch": 1.437485001199904,
      "grad_norm": 0.3563268482685089,
      "learning_rate": 5.7884444444444453e-05,
      "loss": 1.4176,
      "step": 5990
    },
    {
      "epoch": 1.4398848092152627,
      "grad_norm": 0.2893684208393097,
      "learning_rate": 5.779555555555556e-05,
      "loss": 1.2903,
      "step": 6000
    },
    {
      "epoch": 1.4398848092152627,
      "eval_loss": 1.2911514043807983,
      "eval_runtime": 3.5309,
      "eval_samples_per_second": 56.642,
      "eval_steps_per_second": 2.549,
      "step": 6000
    },
    {
      "epoch": 1.4422846172306216,
      "grad_norm": 0.31128624081611633,
      "learning_rate": 5.770666666666667e-05,
      "loss": 1.231,
      "step": 6010
    },
    {
      "epoch": 1.4446844252459803,
      "grad_norm": 0.3531804382801056,
      "learning_rate": 5.7617777777777785e-05,
      "loss": 1.27,
      "step": 6020
    },
    {
      "epoch": 1.4470842332613392,
      "grad_norm": 0.3339522182941437,
      "learning_rate": 5.752888888888889e-05,
      "loss": 1.3267,
      "step": 6030
    },
    {
      "epoch": 1.4494840412766978,
      "grad_norm": 0.26994311809539795,
      "learning_rate": 5.7440000000000006e-05,
      "loss": 1.1621,
      "step": 6040
    },
    {
      "epoch": 1.4518838492920567,
      "grad_norm": 0.35506176948547363,
      "learning_rate": 5.735111111111111e-05,
      "loss": 1.2748,
      "step": 6050
    },
    {
      "epoch": 1.4518838492920567,
      "eval_loss": 1.2919803857803345,
      "eval_runtime": 3.529,
      "eval_samples_per_second": 56.673,
      "eval_steps_per_second": 2.55,
      "step": 6050
    },
    {
      "epoch": 1.4542836573074154,
      "grad_norm": 0.2813566327095032,
      "learning_rate": 5.726222222222223e-05,
      "loss": 1.2642,
      "step": 6060
    },
    {
      "epoch": 1.456683465322774,
      "grad_norm": 0.2811560332775116,
      "learning_rate": 5.717333333333334e-05,
      "loss": 1.3146,
      "step": 6070
    },
    {
      "epoch": 1.459083273338133,
      "grad_norm": 0.35193389654159546,
      "learning_rate": 5.7084444444444454e-05,
      "loss": 1.2794,
      "step": 6080
    },
    {
      "epoch": 1.4614830813534918,
      "grad_norm": 0.2853989601135254,
      "learning_rate": 5.699555555555556e-05,
      "loss": 1.2346,
      "step": 6090
    },
    {
      "epoch": 1.4638828893688505,
      "grad_norm": 0.38112950325012207,
      "learning_rate": 5.6906666666666675e-05,
      "loss": 1.327,
      "step": 6100
    },
    {
      "epoch": 1.4638828893688505,
      "eval_loss": 1.2935398817062378,
      "eval_runtime": 3.5348,
      "eval_samples_per_second": 56.581,
      "eval_steps_per_second": 2.546,
      "step": 6100
    },
    {
      "epoch": 1.4662826973842091,
      "grad_norm": 0.3121603727340698,
      "learning_rate": 5.681777777777778e-05,
      "loss": 1.2011,
      "step": 6110
    },
    {
      "epoch": 1.468682505399568,
      "grad_norm": 0.38156232237815857,
      "learning_rate": 5.672888888888889e-05,
      "loss": 1.3764,
      "step": 6120
    },
    {
      "epoch": 1.471082313414927,
      "grad_norm": 0.282961368560791,
      "learning_rate": 5.6640000000000007e-05,
      "loss": 1.1988,
      "step": 6130
    },
    {
      "epoch": 1.4734821214302856,
      "grad_norm": 0.30010300874710083,
      "learning_rate": 5.655111111111111e-05,
      "loss": 1.246,
      "step": 6140
    },
    {
      "epoch": 1.4758819294456442,
      "grad_norm": 0.3336307406425476,
      "learning_rate": 5.646222222222223e-05,
      "loss": 1.2654,
      "step": 6150
    },
    {
      "epoch": 1.4758819294456442,
      "eval_loss": 1.29209566116333,
      "eval_runtime": 3.5262,
      "eval_samples_per_second": 56.718,
      "eval_steps_per_second": 2.552,
      "step": 6150
    },
    {
      "epoch": 1.478281737461003,
      "grad_norm": 0.2971433103084564,
      "learning_rate": 5.637333333333333e-05,
      "loss": 1.2604,
      "step": 6160
    },
    {
      "epoch": 1.480681545476362,
      "grad_norm": 0.31650450825691223,
      "learning_rate": 5.628444444444445e-05,
      "loss": 1.2297,
      "step": 6170
    },
    {
      "epoch": 1.4830813534917207,
      "grad_norm": 0.3739614486694336,
      "learning_rate": 5.619555555555556e-05,
      "loss": 1.2803,
      "step": 6180
    },
    {
      "epoch": 1.4854811615070793,
      "grad_norm": 0.3716123104095459,
      "learning_rate": 5.6106666666666676e-05,
      "loss": 1.2323,
      "step": 6190
    },
    {
      "epoch": 1.4878809695224382,
      "grad_norm": 0.31011173129081726,
      "learning_rate": 5.601777777777778e-05,
      "loss": 1.3215,
      "step": 6200
    },
    {
      "epoch": 1.4878809695224382,
      "eval_loss": 1.2900185585021973,
      "eval_runtime": 3.5253,
      "eval_samples_per_second": 56.733,
      "eval_steps_per_second": 2.553,
      "step": 6200
    },
    {
      "epoch": 1.490280777537797,
      "grad_norm": 0.30098095536231995,
      "learning_rate": 5.5928888888888883e-05,
      "loss": 1.244,
      "step": 6210
    },
    {
      "epoch": 1.4926805855531557,
      "grad_norm": 0.3427521288394928,
      "learning_rate": 5.584e-05,
      "loss": 1.3052,
      "step": 6220
    },
    {
      "epoch": 1.4950803935685144,
      "grad_norm": 0.3348725140094757,
      "learning_rate": 5.575111111111111e-05,
      "loss": 1.2506,
      "step": 6230
    },
    {
      "epoch": 1.4974802015838733,
      "grad_norm": 0.32523947954177856,
      "learning_rate": 5.566222222222223e-05,
      "loss": 1.286,
      "step": 6240
    },
    {
      "epoch": 1.4998800095992322,
      "grad_norm": 0.31762948632240295,
      "learning_rate": 5.557333333333333e-05,
      "loss": 1.2506,
      "step": 6250
    },
    {
      "epoch": 1.4998800095992322,
      "eval_loss": 1.2923016548156738,
      "eval_runtime": 3.5262,
      "eval_samples_per_second": 56.719,
      "eval_steps_per_second": 2.552,
      "step": 6250
    },
    {
      "epoch": 1.5022798176145908,
      "grad_norm": 0.32902079820632935,
      "learning_rate": 5.548444444444445e-05,
      "loss": 1.3364,
      "step": 6260
    },
    {
      "epoch": 1.5046796256299495,
      "grad_norm": 0.3451676070690155,
      "learning_rate": 5.539555555555555e-05,
      "loss": 1.3621,
      "step": 6270
    },
    {
      "epoch": 1.5070794336453084,
      "grad_norm": 0.3100070059299469,
      "learning_rate": 5.530666666666667e-05,
      "loss": 1.2886,
      "step": 6280
    },
    {
      "epoch": 1.5094792416606673,
      "grad_norm": 0.3732980489730835,
      "learning_rate": 5.521777777777778e-05,
      "loss": 1.2007,
      "step": 6290
    },
    {
      "epoch": 1.511879049676026,
      "grad_norm": 0.2738664448261261,
      "learning_rate": 5.51288888888889e-05,
      "loss": 1.2084,
      "step": 6300
    },
    {
      "epoch": 1.511879049676026,
      "eval_loss": 1.2934198379516602,
      "eval_runtime": 3.5252,
      "eval_samples_per_second": 56.734,
      "eval_steps_per_second": 2.553,
      "step": 6300
    },
    {
      "epoch": 1.5142788576913846,
      "grad_norm": 0.33442723751068115,
      "learning_rate": 5.504e-05,
      "loss": 1.3469,
      "step": 6310
    },
    {
      "epoch": 1.5166786657067435,
      "grad_norm": 0.4225369393825531,
      "learning_rate": 5.495111111111111e-05,
      "loss": 1.176,
      "step": 6320
    },
    {
      "epoch": 1.5190784737221024,
      "grad_norm": 0.30119702219963074,
      "learning_rate": 5.486222222222223e-05,
      "loss": 1.2824,
      "step": 6330
    },
    {
      "epoch": 1.521478281737461,
      "grad_norm": 0.3651871979236603,
      "learning_rate": 5.477333333333333e-05,
      "loss": 1.2518,
      "step": 6340
    },
    {
      "epoch": 1.5238780897528197,
      "grad_norm": 0.3599008023738861,
      "learning_rate": 5.468444444444445e-05,
      "loss": 1.2099,
      "step": 6350
    },
    {
      "epoch": 1.5238780897528197,
      "eval_loss": 1.2907910346984863,
      "eval_runtime": 3.5265,
      "eval_samples_per_second": 56.713,
      "eval_steps_per_second": 2.552,
      "step": 6350
    },
    {
      "epoch": 1.5262778977681786,
      "grad_norm": 0.3093687891960144,
      "learning_rate": 5.4595555555555554e-05,
      "loss": 1.2455,
      "step": 6360
    },
    {
      "epoch": 1.5286777057835375,
      "grad_norm": 0.40577685832977295,
      "learning_rate": 5.450666666666667e-05,
      "loss": 1.365,
      "step": 6370
    },
    {
      "epoch": 1.5310775137988961,
      "grad_norm": 0.32298898696899414,
      "learning_rate": 5.441777777777778e-05,
      "loss": 1.2911,
      "step": 6380
    },
    {
      "epoch": 1.5334773218142548,
      "grad_norm": 0.37152355909347534,
      "learning_rate": 5.43288888888889e-05,
      "loss": 1.4006,
      "step": 6390
    },
    {
      "epoch": 1.5358771298296137,
      "grad_norm": 0.3170056641101837,
      "learning_rate": 5.424e-05,
      "loss": 1.2817,
      "step": 6400
    },
    {
      "epoch": 1.5358771298296137,
      "eval_loss": 1.2874184846878052,
      "eval_runtime": 3.5277,
      "eval_samples_per_second": 56.694,
      "eval_steps_per_second": 2.551,
      "step": 6400
    },
    {
      "epoch": 1.5382769378449725,
      "grad_norm": 0.3701598346233368,
      "learning_rate": 5.415111111111112e-05,
      "loss": 1.2479,
      "step": 6410
    },
    {
      "epoch": 1.5406767458603312,
      "grad_norm": 0.34838855266571045,
      "learning_rate": 5.406222222222222e-05,
      "loss": 1.3177,
      "step": 6420
    },
    {
      "epoch": 1.5430765538756899,
      "grad_norm": 0.3439404368400574,
      "learning_rate": 5.3973333333333334e-05,
      "loss": 1.3202,
      "step": 6430
    },
    {
      "epoch": 1.5454763618910488,
      "grad_norm": 0.29044562578201294,
      "learning_rate": 5.388444444444445e-05,
      "loss": 1.3072,
      "step": 6440
    },
    {
      "epoch": 1.5478761699064076,
      "grad_norm": 0.28609660267829895,
      "learning_rate": 5.3795555555555555e-05,
      "loss": 1.1864,
      "step": 6450
    },
    {
      "epoch": 1.5478761699064076,
      "eval_loss": 1.2905035018920898,
      "eval_runtime": 3.5261,
      "eval_samples_per_second": 56.72,
      "eval_steps_per_second": 2.552,
      "step": 6450
    },
    {
      "epoch": 1.5502759779217663,
      "grad_norm": 0.31426024436950684,
      "learning_rate": 5.370666666666667e-05,
      "loss": 1.236,
      "step": 6460
    },
    {
      "epoch": 1.552675785937125,
      "grad_norm": 0.2912605106830597,
      "learning_rate": 5.3617777777777776e-05,
      "loss": 1.269,
      "step": 6470
    },
    {
      "epoch": 1.5550755939524838,
      "grad_norm": 0.2753770053386688,
      "learning_rate": 5.352888888888889e-05,
      "loss": 1.2098,
      "step": 6480
    },
    {
      "epoch": 1.5574754019678427,
      "grad_norm": 0.3592393100261688,
      "learning_rate": 5.344e-05,
      "loss": 1.3649,
      "step": 6490
    },
    {
      "epoch": 1.5598752099832014,
      "grad_norm": 0.2935236990451813,
      "learning_rate": 5.335111111111112e-05,
      "loss": 1.2443,
      "step": 6500
    },
    {
      "epoch": 1.5598752099832014,
      "eval_loss": 1.29142427444458,
      "eval_runtime": 3.529,
      "eval_samples_per_second": 56.673,
      "eval_steps_per_second": 2.55,
      "step": 6500
    },
    {
      "epoch": 1.56227501799856,
      "grad_norm": 0.2959734797477722,
      "learning_rate": 5.3262222222222224e-05,
      "loss": 1.2309,
      "step": 6510
    },
    {
      "epoch": 1.564674826013919,
      "grad_norm": 0.3723770081996918,
      "learning_rate": 5.317333333333333e-05,
      "loss": 1.325,
      "step": 6520
    },
    {
      "epoch": 1.5670746340292778,
      "grad_norm": 0.3245941996574402,
      "learning_rate": 5.3084444444444445e-05,
      "loss": 1.4122,
      "step": 6530
    },
    {
      "epoch": 1.5694744420446365,
      "grad_norm": 0.3258364796638489,
      "learning_rate": 5.2995555555555556e-05,
      "loss": 1.1895,
      "step": 6540
    },
    {
      "epoch": 1.5718742500599951,
      "grad_norm": 0.36893850564956665,
      "learning_rate": 5.290666666666667e-05,
      "loss": 1.1728,
      "step": 6550
    },
    {
      "epoch": 1.5718742500599951,
      "eval_loss": 1.2917377948760986,
      "eval_runtime": 3.5245,
      "eval_samples_per_second": 56.746,
      "eval_steps_per_second": 2.554,
      "step": 6550
    },
    {
      "epoch": 1.5742740580753538,
      "grad_norm": 0.31354960799217224,
      "learning_rate": 5.2817777777777777e-05,
      "loss": 1.2549,
      "step": 6560
    },
    {
      "epoch": 1.5766738660907127,
      "grad_norm": 0.3281202018260956,
      "learning_rate": 5.2728888888888894e-05,
      "loss": 1.2513,
      "step": 6570
    },
    {
      "epoch": 1.5790736741060716,
      "grad_norm": 0.33095240592956543,
      "learning_rate": 5.264e-05,
      "loss": 1.241,
      "step": 6580
    },
    {
      "epoch": 1.5814734821214302,
      "grad_norm": 0.2897440493106842,
      "learning_rate": 5.2551111111111115e-05,
      "loss": 1.178,
      "step": 6590
    },
    {
      "epoch": 1.583873290136789,
      "grad_norm": 0.3326566517353058,
      "learning_rate": 5.2462222222222225e-05,
      "loss": 1.2427,
      "step": 6600
    },
    {
      "epoch": 1.583873290136789,
      "eval_loss": 1.2920690774917603,
      "eval_runtime": 3.5272,
      "eval_samples_per_second": 56.702,
      "eval_steps_per_second": 2.552,
      "step": 6600
    },
    {
      "epoch": 1.5862730981521478,
      "grad_norm": 0.3248234987258911,
      "learning_rate": 5.237333333333334e-05,
      "loss": 1.2824,
      "step": 6610
    },
    {
      "epoch": 1.5886729061675067,
      "grad_norm": 0.33392441272735596,
      "learning_rate": 5.2284444444444446e-05,
      "loss": 1.2311,
      "step": 6620
    },
    {
      "epoch": 1.5910727141828653,
      "grad_norm": 0.3504728376865387,
      "learning_rate": 5.219555555555555e-05,
      "loss": 1.3717,
      "step": 6630
    },
    {
      "epoch": 1.593472522198224,
      "grad_norm": 0.31832507252693176,
      "learning_rate": 5.210666666666667e-05,
      "loss": 1.3131,
      "step": 6640
    },
    {
      "epoch": 1.5958723302135829,
      "grad_norm": 0.32741105556488037,
      "learning_rate": 5.201777777777778e-05,
      "loss": 1.2986,
      "step": 6650
    },
    {
      "epoch": 1.5958723302135829,
      "eval_loss": 1.2913440465927124,
      "eval_runtime": 3.5348,
      "eval_samples_per_second": 56.581,
      "eval_steps_per_second": 2.546,
      "step": 6650
    },
    {
      "epoch": 1.5982721382289418,
      "grad_norm": 0.36608466506004333,
      "learning_rate": 5.1928888888888895e-05,
      "loss": 1.1755,
      "step": 6660
    },
    {
      "epoch": 1.6006719462443004,
      "grad_norm": 0.29282957315444946,
      "learning_rate": 5.184e-05,
      "loss": 1.2294,
      "step": 6670
    },
    {
      "epoch": 1.603071754259659,
      "grad_norm": 0.35524800419807434,
      "learning_rate": 5.1751111111111116e-05,
      "loss": 1.3198,
      "step": 6680
    },
    {
      "epoch": 1.605471562275018,
      "grad_norm": 0.343405544757843,
      "learning_rate": 5.1662222222222226e-05,
      "loss": 1.2307,
      "step": 6690
    },
    {
      "epoch": 1.6078713702903769,
      "grad_norm": 0.2988653779029846,
      "learning_rate": 5.157333333333334e-05,
      "loss": 1.2125,
      "step": 6700
    },
    {
      "epoch": 1.6078713702903769,
      "eval_loss": 1.2872607707977295,
      "eval_runtime": 3.5388,
      "eval_samples_per_second": 56.516,
      "eval_steps_per_second": 2.543,
      "step": 6700
    },
    {
      "epoch": 1.6102711783057355,
      "grad_norm": 0.3557484447956085,
      "learning_rate": 5.148444444444445e-05,
      "loss": 1.3704,
      "step": 6710
    },
    {
      "epoch": 1.6126709863210942,
      "grad_norm": 0.3804008662700653,
      "learning_rate": 5.1395555555555564e-05,
      "loss": 1.3189,
      "step": 6720
    },
    {
      "epoch": 1.615070794336453,
      "grad_norm": 0.32384341955184937,
      "learning_rate": 5.130666666666667e-05,
      "loss": 1.3088,
      "step": 6730
    },
    {
      "epoch": 1.617470602351812,
      "grad_norm": 0.35162681341171265,
      "learning_rate": 5.121777777777778e-05,
      "loss": 1.3225,
      "step": 6740
    },
    {
      "epoch": 1.6198704103671706,
      "grad_norm": 0.2832060754299164,
      "learning_rate": 5.1128888888888896e-05,
      "loss": 1.1938,
      "step": 6750
    },
    {
      "epoch": 1.6198704103671706,
      "eval_loss": 1.2878177165985107,
      "eval_runtime": 3.5353,
      "eval_samples_per_second": 56.572,
      "eval_steps_per_second": 2.546,
      "step": 6750
    },
    {
      "epoch": 1.6222702183825293,
      "grad_norm": 0.3356844484806061,
      "learning_rate": 5.104e-05,
      "loss": 1.2333,
      "step": 6760
    },
    {
      "epoch": 1.6246700263978882,
      "grad_norm": 0.36758166551589966,
      "learning_rate": 5.0951111111111116e-05,
      "loss": 1.3072,
      "step": 6770
    },
    {
      "epoch": 1.627069834413247,
      "grad_norm": 0.3626280128955841,
      "learning_rate": 5.086222222222222e-05,
      "loss": 1.3559,
      "step": 6780
    },
    {
      "epoch": 1.6294696424286057,
      "grad_norm": 0.346159964799881,
      "learning_rate": 5.077333333333334e-05,
      "loss": 1.3286,
      "step": 6790
    },
    {
      "epoch": 1.6318694504439644,
      "grad_norm": 0.3065231144428253,
      "learning_rate": 5.068444444444445e-05,
      "loss": 1.2479,
      "step": 6800
    },
    {
      "epoch": 1.6318694504439644,
      "eval_loss": 1.2878040075302124,
      "eval_runtime": 3.5356,
      "eval_samples_per_second": 56.567,
      "eval_steps_per_second": 2.546,
      "step": 6800
    },
    {
      "epoch": 1.6342692584593232,
      "grad_norm": 0.34742534160614014,
      "learning_rate": 5.0595555555555565e-05,
      "loss": 1.3257,
      "step": 6810
    },
    {
      "epoch": 1.6366690664746821,
      "grad_norm": 0.38429439067840576,
      "learning_rate": 5.050666666666667e-05,
      "loss": 1.3405,
      "step": 6820
    },
    {
      "epoch": 1.6390688744900408,
      "grad_norm": 0.2965291738510132,
      "learning_rate": 5.041777777777777e-05,
      "loss": 1.2744,
      "step": 6830
    },
    {
      "epoch": 1.6414686825053995,
      "grad_norm": 0.40993624925613403,
      "learning_rate": 5.032888888888889e-05,
      "loss": 1.397,
      "step": 6840
    },
    {
      "epoch": 1.6438684905207583,
      "grad_norm": 0.28131571412086487,
      "learning_rate": 5.024e-05,
      "loss": 1.2013,
      "step": 6850
    },
    {
      "epoch": 1.6438684905207583,
      "eval_loss": 1.2863432168960571,
      "eval_runtime": 3.5355,
      "eval_samples_per_second": 56.57,
      "eval_steps_per_second": 2.546,
      "step": 6850
    },
    {
      "epoch": 1.6462682985361172,
      "grad_norm": 0.35025206208229065,
      "learning_rate": 5.015111111111112e-05,
      "loss": 1.2502,
      "step": 6860
    },
    {
      "epoch": 1.6486681065514759,
      "grad_norm": 0.32966819405555725,
      "learning_rate": 5.006222222222222e-05,
      "loss": 1.2929,
      "step": 6870
    },
    {
      "epoch": 1.6510679145668345,
      "grad_norm": 0.33827680349349976,
      "learning_rate": 4.997333333333333e-05,
      "loss": 1.2596,
      "step": 6880
    },
    {
      "epoch": 1.6534677225821934,
      "grad_norm": 0.33211004734039307,
      "learning_rate": 4.988444444444444e-05,
      "loss": 1.2663,
      "step": 6890
    },
    {
      "epoch": 1.6558675305975523,
      "grad_norm": 0.3610765039920807,
      "learning_rate": 4.979555555555556e-05,
      "loss": 1.2928,
      "step": 6900
    },
    {
      "epoch": 1.6558675305975523,
      "eval_loss": 1.2881944179534912,
      "eval_runtime": 3.5369,
      "eval_samples_per_second": 56.547,
      "eval_steps_per_second": 2.545,
      "step": 6900
    },
    {
      "epoch": 1.658267338612911,
      "grad_norm": 0.359601765871048,
      "learning_rate": 4.970666666666667e-05,
      "loss": 1.2514,
      "step": 6910
    },
    {
      "epoch": 1.6606671466282696,
      "grad_norm": 0.31719955801963806,
      "learning_rate": 4.961777777777778e-05,
      "loss": 1.2255,
      "step": 6920
    },
    {
      "epoch": 1.6630669546436285,
      "grad_norm": 0.3643440008163452,
      "learning_rate": 4.952888888888889e-05,
      "loss": 1.4368,
      "step": 6930
    },
    {
      "epoch": 1.6654667626589874,
      "grad_norm": 0.3125104308128357,
      "learning_rate": 4.944e-05,
      "loss": 1.1856,
      "step": 6940
    },
    {
      "epoch": 1.667866570674346,
      "grad_norm": 0.39001578092575073,
      "learning_rate": 4.935111111111111e-05,
      "loss": 1.3014,
      "step": 6950
    },
    {
      "epoch": 1.667866570674346,
      "eval_loss": 1.2903027534484863,
      "eval_runtime": 3.5352,
      "eval_samples_per_second": 56.573,
      "eval_steps_per_second": 2.546,
      "step": 6950
    },
    {
      "epoch": 1.6702663786897047,
      "grad_norm": 0.28210094571113586,
      "learning_rate": 4.926222222222223e-05,
      "loss": 1.1993,
      "step": 6960
    },
    {
      "epoch": 1.6726661867050636,
      "grad_norm": 0.3117545545101166,
      "learning_rate": 4.917333333333334e-05,
      "loss": 1.1841,
      "step": 6970
    },
    {
      "epoch": 1.6750659947204225,
      "grad_norm": 0.3479435443878174,
      "learning_rate": 4.908444444444445e-05,
      "loss": 1.2805,
      "step": 6980
    },
    {
      "epoch": 1.6774658027357812,
      "grad_norm": 0.30373290181159973,
      "learning_rate": 4.899555555555555e-05,
      "loss": 1.1938,
      "step": 6990
    },
    {
      "epoch": 1.6798656107511398,
      "grad_norm": 0.3116286098957062,
      "learning_rate": 4.890666666666667e-05,
      "loss": 1.1148,
      "step": 7000
    },
    {
      "epoch": 1.6798656107511398,
      "eval_loss": 1.2877520322799683,
      "eval_runtime": 3.5368,
      "eval_samples_per_second": 56.548,
      "eval_steps_per_second": 2.545,
      "step": 7000
    },
    {
      "epoch": 1.6822654187664987,
      "grad_norm": 0.3011123239994049,
      "learning_rate": 4.881777777777778e-05,
      "loss": 1.2949,
      "step": 7010
    },
    {
      "epoch": 1.6846652267818576,
      "grad_norm": 0.36326634883880615,
      "learning_rate": 4.872888888888889e-05,
      "loss": 1.3159,
      "step": 7020
    },
    {
      "epoch": 1.6870650347972163,
      "grad_norm": 0.3439045548439026,
      "learning_rate": 4.864e-05,
      "loss": 1.2742,
      "step": 7030
    },
    {
      "epoch": 1.689464842812575,
      "grad_norm": 0.3720066547393799,
      "learning_rate": 4.855111111111111e-05,
      "loss": 1.2905,
      "step": 7040
    },
    {
      "epoch": 1.6918646508279338,
      "grad_norm": 0.2956206798553467,
      "learning_rate": 4.846222222222222e-05,
      "loss": 1.3168,
      "step": 7050
    },
    {
      "epoch": 1.6918646508279338,
      "eval_loss": 1.2886919975280762,
      "eval_runtime": 3.5354,
      "eval_samples_per_second": 56.571,
      "eval_steps_per_second": 2.546,
      "step": 7050
    },
    {
      "epoch": 1.6942644588432927,
      "grad_norm": 0.3354818522930145,
      "learning_rate": 4.837333333333334e-05,
      "loss": 1.2424,
      "step": 7060
    },
    {
      "epoch": 1.6966642668586513,
      "grad_norm": 0.31967443227767944,
      "learning_rate": 4.828444444444445e-05,
      "loss": 1.2705,
      "step": 7070
    },
    {
      "epoch": 1.69906407487401,
      "grad_norm": 0.3650164306163788,
      "learning_rate": 4.819555555555556e-05,
      "loss": 1.2401,
      "step": 7080
    },
    {
      "epoch": 1.701463882889369,
      "grad_norm": 0.3432820439338684,
      "learning_rate": 4.8106666666666665e-05,
      "loss": 1.3257,
      "step": 7090
    },
    {
      "epoch": 1.7038636909047278,
      "grad_norm": 0.366624116897583,
      "learning_rate": 4.8017777777777775e-05,
      "loss": 1.2761,
      "step": 7100
    },
    {
      "epoch": 1.7038636909047278,
      "eval_loss": 1.2861019372940063,
      "eval_runtime": 3.5372,
      "eval_samples_per_second": 56.542,
      "eval_steps_per_second": 2.544,
      "step": 7100
    },
    {
      "epoch": 1.7062634989200864,
      "grad_norm": 0.3916155695915222,
      "learning_rate": 4.792888888888889e-05,
      "loss": 1.3396,
      "step": 7110
    },
    {
      "epoch": 1.708663306935445,
      "grad_norm": 0.28047996759414673,
      "learning_rate": 4.784e-05,
      "loss": 1.2789,
      "step": 7120
    },
    {
      "epoch": 1.711063114950804,
      "grad_norm": 0.359667032957077,
      "learning_rate": 4.775111111111111e-05,
      "loss": 1.2626,
      "step": 7130
    },
    {
      "epoch": 1.7134629229661629,
      "grad_norm": 0.3200478255748749,
      "learning_rate": 4.7662222222222224e-05,
      "loss": 1.3669,
      "step": 7140
    },
    {
      "epoch": 1.7158627309815215,
      "grad_norm": 0.33851683139801025,
      "learning_rate": 4.7573333333333334e-05,
      "loss": 1.2326,
      "step": 7150
    },
    {
      "epoch": 1.7158627309815215,
      "eval_loss": 1.2848942279815674,
      "eval_runtime": 3.5363,
      "eval_samples_per_second": 56.556,
      "eval_steps_per_second": 2.545,
      "step": 7150
    },
    {
      "epoch": 1.7182625389968802,
      "grad_norm": 0.29723432660102844,
      "learning_rate": 4.748444444444445e-05,
      "loss": 1.1752,
      "step": 7160
    },
    {
      "epoch": 1.7206623470122389,
      "grad_norm": 0.34736308455467224,
      "learning_rate": 4.739555555555556e-05,
      "loss": 1.2318,
      "step": 7170
    },
    {
      "epoch": 1.7230621550275977,
      "grad_norm": 0.40740135312080383,
      "learning_rate": 4.730666666666667e-05,
      "loss": 1.2074,
      "step": 7180
    },
    {
      "epoch": 1.7254619630429566,
      "grad_norm": 0.3135243058204651,
      "learning_rate": 4.7217777777777776e-05,
      "loss": 1.2442,
      "step": 7190
    },
    {
      "epoch": 1.7278617710583153,
      "grad_norm": 0.34515437483787537,
      "learning_rate": 4.7128888888888886e-05,
      "loss": 1.1999,
      "step": 7200
    },
    {
      "epoch": 1.7278617710583153,
      "eval_loss": 1.2863280773162842,
      "eval_runtime": 3.536,
      "eval_samples_per_second": 56.561,
      "eval_steps_per_second": 2.545,
      "step": 7200
    },
    {
      "epoch": 1.730261579073674,
      "grad_norm": 0.3362411856651306,
      "learning_rate": 4.7040000000000004e-05,
      "loss": 1.2954,
      "step": 7210
    },
    {
      "epoch": 1.7326613870890328,
      "grad_norm": 0.32537516951560974,
      "learning_rate": 4.6951111111111114e-05,
      "loss": 1.3132,
      "step": 7220
    },
    {
      "epoch": 1.7350611951043917,
      "grad_norm": 0.31958669424057007,
      "learning_rate": 4.6862222222222225e-05,
      "loss": 1.1799,
      "step": 7230
    },
    {
      "epoch": 1.7374610031197504,
      "grad_norm": 0.3586839437484741,
      "learning_rate": 4.6773333333333335e-05,
      "loss": 1.3818,
      "step": 7240
    },
    {
      "epoch": 1.739860811135109,
      "grad_norm": 0.3145710825920105,
      "learning_rate": 4.6684444444444445e-05,
      "loss": 1.3793,
      "step": 7250
    },
    {
      "epoch": 1.739860811135109,
      "eval_loss": 1.2860045433044434,
      "eval_runtime": 3.5347,
      "eval_samples_per_second": 56.581,
      "eval_steps_per_second": 2.546,
      "step": 7250
    },
    {
      "epoch": 1.742260619150468,
      "grad_norm": 0.3368837833404541,
      "learning_rate": 4.6595555555555556e-05,
      "loss": 1.2756,
      "step": 7260
    },
    {
      "epoch": 1.7446604271658268,
      "grad_norm": 0.2935795187950134,
      "learning_rate": 4.650666666666667e-05,
      "loss": 1.2172,
      "step": 7270
    },
    {
      "epoch": 1.7470602351811855,
      "grad_norm": 0.2994029223918915,
      "learning_rate": 4.6417777777777784e-05,
      "loss": 1.2706,
      "step": 7280
    },
    {
      "epoch": 1.7494600431965441,
      "grad_norm": 0.3223652243614197,
      "learning_rate": 4.632888888888889e-05,
      "loss": 1.1776,
      "step": 7290
    },
    {
      "epoch": 1.751859851211903,
      "grad_norm": 0.36259347200393677,
      "learning_rate": 4.624e-05,
      "loss": 1.2227,
      "step": 7300
    },
    {
      "epoch": 1.751859851211903,
      "eval_loss": 1.2856141328811646,
      "eval_runtime": 3.5354,
      "eval_samples_per_second": 56.571,
      "eval_steps_per_second": 2.546,
      "step": 7300
    },
    {
      "epoch": 1.754259659227262,
      "grad_norm": 0.3356330394744873,
      "learning_rate": 4.6151111111111115e-05,
      "loss": 1.3463,
      "step": 7310
    },
    {
      "epoch": 1.7566594672426206,
      "grad_norm": 0.32490408420562744,
      "learning_rate": 4.6062222222222225e-05,
      "loss": 1.2749,
      "step": 7320
    },
    {
      "epoch": 1.7590592752579792,
      "grad_norm": 0.3574645519256592,
      "learning_rate": 4.5973333333333336e-05,
      "loss": 1.2344,
      "step": 7330
    },
    {
      "epoch": 1.761459083273338,
      "grad_norm": 0.32317012548446655,
      "learning_rate": 4.5884444444444446e-05,
      "loss": 1.3405,
      "step": 7340
    },
    {
      "epoch": 1.763858891288697,
      "grad_norm": 0.26372337341308594,
      "learning_rate": 4.579555555555556e-05,
      "loss": 1.2956,
      "step": 7350
    },
    {
      "epoch": 1.763858891288697,
      "eval_loss": 1.2869659662246704,
      "eval_runtime": 3.5361,
      "eval_samples_per_second": 56.56,
      "eval_steps_per_second": 2.545,
      "step": 7350
    },
    {
      "epoch": 1.7662586993040557,
      "grad_norm": 0.45262542366981506,
      "learning_rate": 4.570666666666667e-05,
      "loss": 1.3722,
      "step": 7360
    },
    {
      "epoch": 1.7686585073194143,
      "grad_norm": 0.2976006269454956,
      "learning_rate": 4.5617777777777784e-05,
      "loss": 1.2196,
      "step": 7370
    },
    {
      "epoch": 1.7710583153347732,
      "grad_norm": 0.32307517528533936,
      "learning_rate": 4.5528888888888895e-05,
      "loss": 1.1808,
      "step": 7380
    },
    {
      "epoch": 1.773458123350132,
      "grad_norm": 0.38644707202911377,
      "learning_rate": 4.5440000000000005e-05,
      "loss": 1.3406,
      "step": 7390
    },
    {
      "epoch": 1.7758579313654907,
      "grad_norm": 0.26842939853668213,
      "learning_rate": 4.535111111111111e-05,
      "loss": 1.3169,
      "step": 7400
    },
    {
      "epoch": 1.7758579313654907,
      "eval_loss": 1.2873114347457886,
      "eval_runtime": 3.5349,
      "eval_samples_per_second": 56.579,
      "eval_steps_per_second": 2.546,
      "step": 7400
    },
    {
      "epoch": 1.7782577393808494,
      "grad_norm": 0.34884658455848694,
      "learning_rate": 4.526222222222222e-05,
      "loss": 1.1885,
      "step": 7410
    },
    {
      "epoch": 1.7806575473962083,
      "grad_norm": 0.3107821047306061,
      "learning_rate": 4.517333333333334e-05,
      "loss": 1.2643,
      "step": 7420
    },
    {
      "epoch": 1.7830573554115672,
      "grad_norm": 0.31207412481307983,
      "learning_rate": 4.508444444444445e-05,
      "loss": 1.2447,
      "step": 7430
    },
    {
      "epoch": 1.7854571634269258,
      "grad_norm": 0.34860965609550476,
      "learning_rate": 4.499555555555556e-05,
      "loss": 1.2716,
      "step": 7440
    },
    {
      "epoch": 1.7878569714422845,
      "grad_norm": 0.2847636640071869,
      "learning_rate": 4.490666666666667e-05,
      "loss": 1.2702,
      "step": 7450
    },
    {
      "epoch": 1.7878569714422845,
      "eval_loss": 1.2871606349945068,
      "eval_runtime": 3.5343,
      "eval_samples_per_second": 56.588,
      "eval_steps_per_second": 2.546,
      "step": 7450
    },
    {
      "epoch": 1.7902567794576434,
      "grad_norm": 0.28379032015800476,
      "learning_rate": 4.481777777777778e-05,
      "loss": 1.2328,
      "step": 7460
    },
    {
      "epoch": 1.7926565874730023,
      "grad_norm": 0.2717922329902649,
      "learning_rate": 4.472888888888889e-05,
      "loss": 1.3064,
      "step": 7470
    },
    {
      "epoch": 1.795056395488361,
      "grad_norm": 0.2746894061565399,
      "learning_rate": 4.4640000000000006e-05,
      "loss": 1.2554,
      "step": 7480
    },
    {
      "epoch": 1.7974562035037196,
      "grad_norm": 0.31840530037879944,
      "learning_rate": 4.455111111111112e-05,
      "loss": 1.178,
      "step": 7490
    },
    {
      "epoch": 1.7998560115190785,
      "grad_norm": 0.2609604299068451,
      "learning_rate": 4.446222222222222e-05,
      "loss": 1.2074,
      "step": 7500
    },
    {
      "epoch": 1.7998560115190785,
      "eval_loss": 1.284574031829834,
      "eval_runtime": 3.5356,
      "eval_samples_per_second": 56.567,
      "eval_steps_per_second": 2.546,
      "step": 7500
    },
    {
      "epoch": 1.8022558195344374,
      "grad_norm": 0.30132877826690674,
      "learning_rate": 4.437333333333333e-05,
      "loss": 1.2334,
      "step": 7510
    },
    {
      "epoch": 1.804655627549796,
      "grad_norm": 0.3228699862957001,
      "learning_rate": 4.428444444444445e-05,
      "loss": 1.2128,
      "step": 7520
    },
    {
      "epoch": 1.8070554355651547,
      "grad_norm": 0.3562784790992737,
      "learning_rate": 4.419555555555556e-05,
      "loss": 1.2689,
      "step": 7530
    },
    {
      "epoch": 1.8094552435805136,
      "grad_norm": 0.33359700441360474,
      "learning_rate": 4.410666666666667e-05,
      "loss": 1.2514,
      "step": 7540
    },
    {
      "epoch": 1.8118550515958725,
      "grad_norm": 0.35565200448036194,
      "learning_rate": 4.401777777777778e-05,
      "loss": 1.211,
      "step": 7550
    },
    {
      "epoch": 1.8118550515958725,
      "eval_loss": 1.2850756645202637,
      "eval_runtime": 3.5364,
      "eval_samples_per_second": 56.555,
      "eval_steps_per_second": 2.545,
      "step": 7550
    },
    {
      "epoch": 1.8142548596112311,
      "grad_norm": 0.36223509907722473,
      "learning_rate": 4.392888888888889e-05,
      "loss": 1.3231,
      "step": 7560
    },
    {
      "epoch": 1.8166546676265898,
      "grad_norm": 0.33324703574180603,
      "learning_rate": 4.384e-05,
      "loss": 1.3455,
      "step": 7570
    },
    {
      "epoch": 1.8190544756419487,
      "grad_norm": 0.38174042105674744,
      "learning_rate": 4.375111111111112e-05,
      "loss": 1.2703,
      "step": 7580
    },
    {
      "epoch": 1.8214542836573075,
      "grad_norm": 0.3317127227783203,
      "learning_rate": 4.366222222222223e-05,
      "loss": 1.1376,
      "step": 7590
    },
    {
      "epoch": 1.8238540916726662,
      "grad_norm": 0.3775434195995331,
      "learning_rate": 4.357333333333333e-05,
      "loss": 1.3026,
      "step": 7600
    },
    {
      "epoch": 1.8238540916726662,
      "eval_loss": 1.2860536575317383,
      "eval_runtime": 3.5348,
      "eval_samples_per_second": 56.58,
      "eval_steps_per_second": 2.546,
      "step": 7600
    },
    {
      "epoch": 1.8262538996880249,
      "grad_norm": 0.3431389629840851,
      "learning_rate": 4.348444444444444e-05,
      "loss": 1.271,
      "step": 7610
    },
    {
      "epoch": 1.8286537077033838,
      "grad_norm": 0.3123006820678711,
      "learning_rate": 4.339555555555555e-05,
      "loss": 1.3762,
      "step": 7620
    },
    {
      "epoch": 1.8310535157187426,
      "grad_norm": 0.3350470960140228,
      "learning_rate": 4.330666666666667e-05,
      "loss": 1.2937,
      "step": 7630
    },
    {
      "epoch": 1.8334533237341013,
      "grad_norm": 0.3247019350528717,
      "learning_rate": 4.321777777777778e-05,
      "loss": 1.1652,
      "step": 7640
    },
    {
      "epoch": 1.83585313174946,
      "grad_norm": 0.33272501826286316,
      "learning_rate": 4.312888888888889e-05,
      "loss": 1.2385,
      "step": 7650
    },
    {
      "epoch": 1.83585313174946,
      "eval_loss": 1.2864041328430176,
      "eval_runtime": 3.5346,
      "eval_samples_per_second": 56.584,
      "eval_steps_per_second": 2.546,
      "step": 7650
    },
    {
      "epoch": 1.8382529397648188,
      "grad_norm": 0.39230212569236755,
      "learning_rate": 4.304e-05,
      "loss": 1.3702,
      "step": 7660
    },
    {
      "epoch": 1.8406527477801777,
      "grad_norm": 0.32445594668388367,
      "learning_rate": 4.295111111111111e-05,
      "loss": 1.2512,
      "step": 7670
    },
    {
      "epoch": 1.8430525557955364,
      "grad_norm": 0.36571091413497925,
      "learning_rate": 4.286222222222223e-05,
      "loss": 1.2544,
      "step": 7680
    },
    {
      "epoch": 1.845452363810895,
      "grad_norm": 0.392291396856308,
      "learning_rate": 4.277333333333334e-05,
      "loss": 1.3175,
      "step": 7690
    },
    {
      "epoch": 1.847852171826254,
      "grad_norm": 0.31862202286720276,
      "learning_rate": 4.268444444444445e-05,
      "loss": 1.26,
      "step": 7700
    },
    {
      "epoch": 1.847852171826254,
      "eval_loss": 1.2875618934631348,
      "eval_runtime": 3.5353,
      "eval_samples_per_second": 56.573,
      "eval_steps_per_second": 2.546,
      "step": 7700
    },
    {
      "epoch": 1.8502519798416128,
      "grad_norm": 0.3842618763446808,
      "learning_rate": 4.2595555555555554e-05,
      "loss": 1.3845,
      "step": 7710
    },
    {
      "epoch": 1.8526517878569715,
      "grad_norm": 0.2552223205566406,
      "learning_rate": 4.2506666666666664e-05,
      "loss": 1.2172,
      "step": 7720
    },
    {
      "epoch": 1.8550515958723302,
      "grad_norm": 0.34223443269729614,
      "learning_rate": 4.241777777777778e-05,
      "loss": 1.1505,
      "step": 7730
    },
    {
      "epoch": 1.857451403887689,
      "grad_norm": 0.34464362263679504,
      "learning_rate": 4.232888888888889e-05,
      "loss": 1.306,
      "step": 7740
    },
    {
      "epoch": 1.859851211903048,
      "grad_norm": 0.35275593400001526,
      "learning_rate": 4.224e-05,
      "loss": 1.2866,
      "step": 7750
    },
    {
      "epoch": 1.859851211903048,
      "eval_loss": 1.2846494913101196,
      "eval_runtime": 3.5356,
      "eval_samples_per_second": 56.568,
      "eval_steps_per_second": 2.546,
      "step": 7750
    },
    {
      "epoch": 1.8622510199184066,
      "grad_norm": 0.315179705619812,
      "learning_rate": 4.215111111111111e-05,
      "loss": 1.2791,
      "step": 7760
    },
    {
      "epoch": 1.8646508279337652,
      "grad_norm": 0.3402117192745209,
      "learning_rate": 4.206222222222222e-05,
      "loss": 1.3107,
      "step": 7770
    },
    {
      "epoch": 1.867050635949124,
      "grad_norm": 0.31917354464530945,
      "learning_rate": 4.1973333333333334e-05,
      "loss": 1.2017,
      "step": 7780
    },
    {
      "epoch": 1.8694504439644828,
      "grad_norm": 0.34867674112319946,
      "learning_rate": 4.188444444444445e-05,
      "loss": 1.3012,
      "step": 7790
    },
    {
      "epoch": 1.8718502519798417,
      "grad_norm": 0.31204697489738464,
      "learning_rate": 4.179555555555556e-05,
      "loss": 1.3432,
      "step": 7800
    },
    {
      "epoch": 1.8718502519798417,
      "eval_loss": 1.2854763269424438,
      "eval_runtime": 3.5367,
      "eval_samples_per_second": 56.55,
      "eval_steps_per_second": 2.545,
      "step": 7800
    },
    {
      "epoch": 1.8742500599952003,
      "grad_norm": 0.41893064975738525,
      "learning_rate": 4.1706666666666665e-05,
      "loss": 1.329,
      "step": 7810
    },
    {
      "epoch": 1.876649868010559,
      "grad_norm": 0.3405276834964752,
      "learning_rate": 4.1617777777777775e-05,
      "loss": 1.2705,
      "step": 7820
    },
    {
      "epoch": 1.8790496760259179,
      "grad_norm": 0.372580349445343,
      "learning_rate": 4.152888888888889e-05,
      "loss": 1.2576,
      "step": 7830
    },
    {
      "epoch": 1.8814494840412768,
      "grad_norm": 0.3347747325897217,
      "learning_rate": 4.144e-05,
      "loss": 1.3103,
      "step": 7840
    },
    {
      "epoch": 1.8838492920566354,
      "grad_norm": 0.3893839418888092,
      "learning_rate": 4.1351111111111113e-05,
      "loss": 1.2867,
      "step": 7850
    },
    {
      "epoch": 1.8838492920566354,
      "eval_loss": 1.2825335264205933,
      "eval_runtime": 3.5351,
      "eval_samples_per_second": 56.576,
      "eval_steps_per_second": 2.546,
      "step": 7850
    },
    {
      "epoch": 1.886249100071994,
      "grad_norm": 0.2822589576244354,
      "learning_rate": 4.1262222222222224e-05,
      "loss": 1.1977,
      "step": 7860
    },
    {
      "epoch": 1.888648908087353,
      "grad_norm": 0.40124672651290894,
      "learning_rate": 4.1173333333333334e-05,
      "loss": 1.3631,
      "step": 7870
    },
    {
      "epoch": 1.8910487161027119,
      "grad_norm": 0.35526251792907715,
      "learning_rate": 4.1084444444444445e-05,
      "loss": 1.1629,
      "step": 7880
    },
    {
      "epoch": 1.8934485241180705,
      "grad_norm": 0.33423855900764465,
      "learning_rate": 4.099555555555556e-05,
      "loss": 1.3247,
      "step": 7890
    },
    {
      "epoch": 1.8958483321334292,
      "grad_norm": 0.4176815152168274,
      "learning_rate": 4.090666666666667e-05,
      "loss": 1.3168,
      "step": 7900
    },
    {
      "epoch": 1.8958483321334292,
      "eval_loss": 1.2849236726760864,
      "eval_runtime": 3.5293,
      "eval_samples_per_second": 56.668,
      "eval_steps_per_second": 2.55,
      "step": 7900
    },
    {
      "epoch": 1.898248140148788,
      "grad_norm": 0.5727841258049011,
      "learning_rate": 4.0817777777777776e-05,
      "loss": 1.2452,
      "step": 7910
    },
    {
      "epoch": 1.900647948164147,
      "grad_norm": 0.3569164276123047,
      "learning_rate": 4.072888888888889e-05,
      "loss": 1.2287,
      "step": 7920
    },
    {
      "epoch": 1.9030477561795056,
      "grad_norm": 0.3296273350715637,
      "learning_rate": 4.064e-05,
      "loss": 1.2579,
      "step": 7930
    },
    {
      "epoch": 1.9054475641948643,
      "grad_norm": 0.2982783913612366,
      "learning_rate": 4.0551111111111114e-05,
      "loss": 1.264,
      "step": 7940
    },
    {
      "epoch": 1.9078473722102232,
      "grad_norm": 0.30044227838516235,
      "learning_rate": 4.0462222222222225e-05,
      "loss": 1.3675,
      "step": 7950
    },
    {
      "epoch": 1.9078473722102232,
      "eval_loss": 1.28607976436615,
      "eval_runtime": 3.5348,
      "eval_samples_per_second": 56.581,
      "eval_steps_per_second": 2.546,
      "step": 7950
    },
    {
      "epoch": 1.910247180225582,
      "grad_norm": 0.30510395765304565,
      "learning_rate": 4.0373333333333335e-05,
      "loss": 1.2023,
      "step": 7960
    },
    {
      "epoch": 1.9126469882409407,
      "grad_norm": 0.3876848518848419,
      "learning_rate": 4.0284444444444446e-05,
      "loss": 1.3143,
      "step": 7970
    },
    {
      "epoch": 1.9150467962562994,
      "grad_norm": 0.29325932264328003,
      "learning_rate": 4.0195555555555556e-05,
      "loss": 1.2559,
      "step": 7980
    },
    {
      "epoch": 1.9174466042716583,
      "grad_norm": 0.31036001443862915,
      "learning_rate": 4.0106666666666673e-05,
      "loss": 1.2154,
      "step": 7990
    },
    {
      "epoch": 1.9198464122870171,
      "grad_norm": 0.31525784730911255,
      "learning_rate": 4.0017777777777784e-05,
      "loss": 1.3217,
      "step": 8000
    },
    {
      "epoch": 1.9198464122870171,
      "eval_loss": 1.2841289043426514,
      "eval_runtime": 3.5355,
      "eval_samples_per_second": 56.57,
      "eval_steps_per_second": 2.546,
      "step": 8000
    },
    {
      "epoch": 1.9222462203023758,
      "grad_norm": 0.30463483929634094,
      "learning_rate": 3.9928888888888894e-05,
      "loss": 1.1342,
      "step": 8010
    },
    {
      "epoch": 1.9246460283177345,
      "grad_norm": 0.35244059562683105,
      "learning_rate": 3.984e-05,
      "loss": 1.2627,
      "step": 8020
    },
    {
      "epoch": 1.9270458363330933,
      "grad_norm": 0.31587478518486023,
      "learning_rate": 3.975111111111111e-05,
      "loss": 1.1798,
      "step": 8030
    },
    {
      "epoch": 1.9294456443484522,
      "grad_norm": 0.32988685369491577,
      "learning_rate": 3.9662222222222226e-05,
      "loss": 1.3948,
      "step": 8040
    },
    {
      "epoch": 1.9318454523638109,
      "grad_norm": 0.35725510120391846,
      "learning_rate": 3.9573333333333336e-05,
      "loss": 1.2485,
      "step": 8050
    },
    {
      "epoch": 1.9318454523638109,
      "eval_loss": 1.2832180261611938,
      "eval_runtime": 3.5346,
      "eval_samples_per_second": 56.583,
      "eval_steps_per_second": 2.546,
      "step": 8050
    },
    {
      "epoch": 1.9342452603791696,
      "grad_norm": 0.30683714151382446,
      "learning_rate": 3.948444444444445e-05,
      "loss": 1.2415,
      "step": 8060
    },
    {
      "epoch": 1.9366450683945284,
      "grad_norm": 0.345546692609787,
      "learning_rate": 3.939555555555556e-05,
      "loss": 1.2627,
      "step": 8070
    },
    {
      "epoch": 1.9390448764098873,
      "grad_norm": 0.30944520235061646,
      "learning_rate": 3.930666666666667e-05,
      "loss": 1.1773,
      "step": 8080
    },
    {
      "epoch": 1.941444684425246,
      "grad_norm": 0.3810195028781891,
      "learning_rate": 3.921777777777778e-05,
      "loss": 1.2385,
      "step": 8090
    },
    {
      "epoch": 1.9438444924406046,
      "grad_norm": 0.2953963577747345,
      "learning_rate": 3.9128888888888895e-05,
      "loss": 1.2939,
      "step": 8100
    },
    {
      "epoch": 1.9438444924406046,
      "eval_loss": 1.2837395668029785,
      "eval_runtime": 3.5366,
      "eval_samples_per_second": 56.551,
      "eval_steps_per_second": 2.545,
      "step": 8100
    },
    {
      "epoch": 1.9462443004559635,
      "grad_norm": 0.3123593032360077,
      "learning_rate": 3.9040000000000006e-05,
      "loss": 1.1503,
      "step": 8110
    },
    {
      "epoch": 1.9486441084713224,
      "grad_norm": 0.3680175840854645,
      "learning_rate": 3.895111111111111e-05,
      "loss": 1.1779,
      "step": 8120
    },
    {
      "epoch": 1.951043916486681,
      "grad_norm": 0.3970332741737366,
      "learning_rate": 3.886222222222222e-05,
      "loss": 1.3443,
      "step": 8130
    },
    {
      "epoch": 1.9534437245020397,
      "grad_norm": 0.35734328627586365,
      "learning_rate": 3.877333333333334e-05,
      "loss": 1.2066,
      "step": 8140
    },
    {
      "epoch": 1.9558435325173986,
      "grad_norm": 0.3218015730381012,
      "learning_rate": 3.868444444444445e-05,
      "loss": 1.2476,
      "step": 8150
    },
    {
      "epoch": 1.9558435325173986,
      "eval_loss": 1.2838845252990723,
      "eval_runtime": 3.5361,
      "eval_samples_per_second": 56.559,
      "eval_steps_per_second": 2.545,
      "step": 8150
    },
    {
      "epoch": 1.9582433405327575,
      "grad_norm": 0.36786288022994995,
      "learning_rate": 3.859555555555556e-05,
      "loss": 1.268,
      "step": 8160
    },
    {
      "epoch": 1.9606431485481162,
      "grad_norm": 0.30052921175956726,
      "learning_rate": 3.850666666666667e-05,
      "loss": 1.3015,
      "step": 8170
    },
    {
      "epoch": 1.9630429565634748,
      "grad_norm": 0.3264900743961334,
      "learning_rate": 3.841777777777778e-05,
      "loss": 1.2263,
      "step": 8180
    },
    {
      "epoch": 1.9654427645788337,
      "grad_norm": 0.3631174564361572,
      "learning_rate": 3.832888888888889e-05,
      "loss": 1.3057,
      "step": 8190
    },
    {
      "epoch": 1.9678425725941926,
      "grad_norm": 0.2966628968715668,
      "learning_rate": 3.8240000000000007e-05,
      "loss": 1.2696,
      "step": 8200
    },
    {
      "epoch": 1.9678425725941926,
      "eval_loss": 1.284040927886963,
      "eval_runtime": 3.5349,
      "eval_samples_per_second": 56.579,
      "eval_steps_per_second": 2.546,
      "step": 8200
    },
    {
      "epoch": 1.9702423806095513,
      "grad_norm": 0.3142508268356323,
      "learning_rate": 3.815111111111112e-05,
      "loss": 1.1524,
      "step": 8210
    },
    {
      "epoch": 1.97264218862491,
      "grad_norm": 0.3346129357814789,
      "learning_rate": 3.806222222222222e-05,
      "loss": 1.365,
      "step": 8220
    },
    {
      "epoch": 1.9750419966402688,
      "grad_norm": 0.3792155981063843,
      "learning_rate": 3.797333333333333e-05,
      "loss": 1.2006,
      "step": 8230
    },
    {
      "epoch": 1.9774418046556277,
      "grad_norm": 0.36573609709739685,
      "learning_rate": 3.788444444444444e-05,
      "loss": 1.2365,
      "step": 8240
    },
    {
      "epoch": 1.9798416126709864,
      "grad_norm": 0.3525393009185791,
      "learning_rate": 3.779555555555556e-05,
      "loss": 1.2804,
      "step": 8250
    },
    {
      "epoch": 1.9798416126709864,
      "eval_loss": 1.283652901649475,
      "eval_runtime": 3.5363,
      "eval_samples_per_second": 56.556,
      "eval_steps_per_second": 2.545,
      "step": 8250
    },
    {
      "epoch": 1.982241420686345,
      "grad_norm": 0.37263891100883484,
      "learning_rate": 3.770666666666667e-05,
      "loss": 1.2861,
      "step": 8260
    },
    {
      "epoch": 1.984641228701704,
      "grad_norm": 0.38862892985343933,
      "learning_rate": 3.761777777777778e-05,
      "loss": 1.3807,
      "step": 8270
    },
    {
      "epoch": 1.9870410367170628,
      "grad_norm": 0.29398590326309204,
      "learning_rate": 3.752888888888889e-05,
      "loss": 1.2325,
      "step": 8280
    },
    {
      "epoch": 1.9894408447324214,
      "grad_norm": 0.3875208795070648,
      "learning_rate": 3.744e-05,
      "loss": 1.2359,
      "step": 8290
    },
    {
      "epoch": 1.99184065274778,
      "grad_norm": 0.3217467963695526,
      "learning_rate": 3.735111111111111e-05,
      "loss": 1.2529,
      "step": 8300
    },
    {
      "epoch": 1.99184065274778,
      "eval_loss": 1.283431053161621,
      "eval_runtime": 3.5362,
      "eval_samples_per_second": 56.558,
      "eval_steps_per_second": 2.545,
      "step": 8300
    },
    {
      "epoch": 1.994240460763139,
      "grad_norm": 0.3324710428714752,
      "learning_rate": 3.726222222222223e-05,
      "loss": 1.2684,
      "step": 8310
    },
    {
      "epoch": 1.9966402687784979,
      "grad_norm": 0.33029699325561523,
      "learning_rate": 3.717333333333334e-05,
      "loss": 1.2257,
      "step": 8320
    },
    {
      "epoch": 1.9990400767938565,
      "grad_norm": 0.3156036138534546,
      "learning_rate": 3.708444444444444e-05,
      "loss": 1.1507,
      "step": 8330
    },
    {
      "epoch": 2.001439884809215,
      "grad_norm": 0.32151398062705994,
      "learning_rate": 3.699555555555555e-05,
      "loss": 1.2565,
      "step": 8340
    },
    {
      "epoch": 2.003839692824574,
      "grad_norm": 0.2951112389564514,
      "learning_rate": 3.690666666666667e-05,
      "loss": 1.2296,
      "step": 8350
    },
    {
      "epoch": 2.003839692824574,
      "eval_loss": 1.283358097076416,
      "eval_runtime": 3.5367,
      "eval_samples_per_second": 56.549,
      "eval_steps_per_second": 2.545,
      "step": 8350
    },
    {
      "epoch": 2.006239500839933,
      "grad_norm": 0.25542232394218445,
      "learning_rate": 3.681777777777778e-05,
      "loss": 1.1867,
      "step": 8360
    },
    {
      "epoch": 2.0086393088552916,
      "grad_norm": 0.32783880829811096,
      "learning_rate": 3.672888888888889e-05,
      "loss": 1.2667,
      "step": 8370
    },
    {
      "epoch": 2.0110391168706503,
      "grad_norm": 0.279574990272522,
      "learning_rate": 3.664e-05,
      "loss": 1.2509,
      "step": 8380
    },
    {
      "epoch": 2.013438924886009,
      "grad_norm": 0.3390772044658661,
      "learning_rate": 3.655111111111111e-05,
      "loss": 1.2924,
      "step": 8390
    },
    {
      "epoch": 2.015838732901368,
      "grad_norm": 0.3064298629760742,
      "learning_rate": 3.646222222222222e-05,
      "loss": 1.2969,
      "step": 8400
    },
    {
      "epoch": 2.015838732901368,
      "eval_loss": 1.2841626405715942,
      "eval_runtime": 3.536,
      "eval_samples_per_second": 56.561,
      "eval_steps_per_second": 2.545,
      "step": 8400
    },
    {
      "epoch": 2.0182385409167267,
      "grad_norm": 0.3363819718360901,
      "learning_rate": 3.637333333333334e-05,
      "loss": 1.361,
      "step": 8410
    },
    {
      "epoch": 2.0206383489320854,
      "grad_norm": 0.41465550661087036,
      "learning_rate": 3.628444444444445e-05,
      "loss": 1.3326,
      "step": 8420
    },
    {
      "epoch": 2.023038156947444,
      "grad_norm": 0.3251156210899353,
      "learning_rate": 3.6195555555555554e-05,
      "loss": 1.3242,
      "step": 8430
    },
    {
      "epoch": 2.025437964962803,
      "grad_norm": 0.2866440713405609,
      "learning_rate": 3.6106666666666664e-05,
      "loss": 1.2481,
      "step": 8440
    },
    {
      "epoch": 2.027837772978162,
      "grad_norm": 0.3015439808368683,
      "learning_rate": 3.6017777777777775e-05,
      "loss": 1.3263,
      "step": 8450
    },
    {
      "epoch": 2.027837772978162,
      "eval_loss": 1.2830779552459717,
      "eval_runtime": 3.5364,
      "eval_samples_per_second": 56.554,
      "eval_steps_per_second": 2.545,
      "step": 8450
    },
    {
      "epoch": 2.0302375809935205,
      "grad_norm": 0.27130183577537537,
      "learning_rate": 3.592888888888889e-05,
      "loss": 1.2287,
      "step": 8460
    },
    {
      "epoch": 2.032637389008879,
      "grad_norm": 0.3672339916229248,
      "learning_rate": 3.584e-05,
      "loss": 1.1959,
      "step": 8470
    },
    {
      "epoch": 2.0350371970242382,
      "grad_norm": 0.39766421914100647,
      "learning_rate": 3.575111111111111e-05,
      "loss": 1.3236,
      "step": 8480
    },
    {
      "epoch": 2.037437005039597,
      "grad_norm": 0.32497715950012207,
      "learning_rate": 3.566222222222222e-05,
      "loss": 1.2795,
      "step": 8490
    },
    {
      "epoch": 2.0398368130549556,
      "grad_norm": 0.38001251220703125,
      "learning_rate": 3.5573333333333334e-05,
      "loss": 1.3452,
      "step": 8500
    },
    {
      "epoch": 2.0398368130549556,
      "eval_loss": 1.2809618711471558,
      "eval_runtime": 3.5393,
      "eval_samples_per_second": 56.509,
      "eval_steps_per_second": 2.543,
      "step": 8500
    },
    {
      "epoch": 2.0422366210703142,
      "grad_norm": 0.34137243032455444,
      "learning_rate": 3.548444444444445e-05,
      "loss": 1.2698,
      "step": 8510
    },
    {
      "epoch": 2.0446364290856733,
      "grad_norm": 0.29750293493270874,
      "learning_rate": 3.539555555555556e-05,
      "loss": 1.2217,
      "step": 8520
    },
    {
      "epoch": 2.047036237101032,
      "grad_norm": 0.31098562479019165,
      "learning_rate": 3.5306666666666665e-05,
      "loss": 1.2911,
      "step": 8530
    },
    {
      "epoch": 2.0494360451163907,
      "grad_norm": 0.35423657298088074,
      "learning_rate": 3.5217777777777776e-05,
      "loss": 1.3084,
      "step": 8540
    },
    {
      "epoch": 2.0518358531317493,
      "grad_norm": 0.29822811484336853,
      "learning_rate": 3.5128888888888886e-05,
      "loss": 1.1699,
      "step": 8550
    },
    {
      "epoch": 2.0518358531317493,
      "eval_loss": 1.280664324760437,
      "eval_runtime": 3.5349,
      "eval_samples_per_second": 56.578,
      "eval_steps_per_second": 2.546,
      "step": 8550
    },
    {
      "epoch": 2.0542356611471084,
      "grad_norm": 0.3567841947078705,
      "learning_rate": 3.504e-05,
      "loss": 1.3049,
      "step": 8560
    },
    {
      "epoch": 2.056635469162467,
      "grad_norm": 0.3500699996948242,
      "learning_rate": 3.4951111111111114e-05,
      "loss": 1.3206,
      "step": 8570
    },
    {
      "epoch": 2.0590352771778258,
      "grad_norm": 0.36976704001426697,
      "learning_rate": 3.4862222222222224e-05,
      "loss": 1.2949,
      "step": 8580
    },
    {
      "epoch": 2.0614350851931844,
      "grad_norm": 0.37545549869537354,
      "learning_rate": 3.4773333333333335e-05,
      "loss": 1.3007,
      "step": 8590
    },
    {
      "epoch": 2.0638348932085435,
      "grad_norm": 0.3194769322872162,
      "learning_rate": 3.4684444444444445e-05,
      "loss": 1.2729,
      "step": 8600
    },
    {
      "epoch": 2.0638348932085435,
      "eval_loss": 1.280855417251587,
      "eval_runtime": 3.5366,
      "eval_samples_per_second": 56.552,
      "eval_steps_per_second": 2.545,
      "step": 8600
    },
    {
      "epoch": 2.066234701223902,
      "grad_norm": 0.307699978351593,
      "learning_rate": 3.4595555555555556e-05,
      "loss": 1.2624,
      "step": 8610
    },
    {
      "epoch": 2.068634509239261,
      "grad_norm": 0.3821360468864441,
      "learning_rate": 3.450666666666667e-05,
      "loss": 1.334,
      "step": 8620
    },
    {
      "epoch": 2.0710343172546195,
      "grad_norm": 0.31290310621261597,
      "learning_rate": 3.441777777777778e-05,
      "loss": 1.3558,
      "step": 8630
    },
    {
      "epoch": 2.0734341252699786,
      "grad_norm": 0.3486785590648651,
      "learning_rate": 3.432888888888889e-05,
      "loss": 1.2262,
      "step": 8640
    },
    {
      "epoch": 2.0758339332853373,
      "grad_norm": 0.3631117343902588,
      "learning_rate": 3.424e-05,
      "loss": 1.284,
      "step": 8650
    },
    {
      "epoch": 2.0758339332853373,
      "eval_loss": 1.28108811378479,
      "eval_runtime": 3.5373,
      "eval_samples_per_second": 56.54,
      "eval_steps_per_second": 2.544,
      "step": 8650
    },
    {
      "epoch": 2.078233741300696,
      "grad_norm": 0.3083369731903076,
      "learning_rate": 3.4151111111111115e-05,
      "loss": 1.3422,
      "step": 8660
    },
    {
      "epoch": 2.0806335493160546,
      "grad_norm": 0.3396109938621521,
      "learning_rate": 3.4062222222222225e-05,
      "loss": 1.3331,
      "step": 8670
    },
    {
      "epoch": 2.0830333573314137,
      "grad_norm": 0.3305330276489258,
      "learning_rate": 3.3973333333333336e-05,
      "loss": 1.2497,
      "step": 8680
    },
    {
      "epoch": 2.0854331653467724,
      "grad_norm": 0.2893492579460144,
      "learning_rate": 3.3884444444444446e-05,
      "loss": 1.2942,
      "step": 8690
    },
    {
      "epoch": 2.087832973362131,
      "grad_norm": 0.3697678744792938,
      "learning_rate": 3.3795555555555556e-05,
      "loss": 1.2808,
      "step": 8700
    },
    {
      "epoch": 2.087832973362131,
      "eval_loss": 1.2802224159240723,
      "eval_runtime": 3.5377,
      "eval_samples_per_second": 56.534,
      "eval_steps_per_second": 2.544,
      "step": 8700
    },
    {
      "epoch": 2.0902327813774897,
      "grad_norm": 0.2998722195625305,
      "learning_rate": 3.370666666666667e-05,
      "loss": 1.2899,
      "step": 8710
    },
    {
      "epoch": 2.0926325893928484,
      "grad_norm": 0.3055591285228729,
      "learning_rate": 3.3617777777777784e-05,
      "loss": 1.2705,
      "step": 8720
    },
    {
      "epoch": 2.0950323974082075,
      "grad_norm": 0.3456341624259949,
      "learning_rate": 3.3528888888888895e-05,
      "loss": 1.2464,
      "step": 8730
    },
    {
      "epoch": 2.097432205423566,
      "grad_norm": 0.3215457499027252,
      "learning_rate": 3.344e-05,
      "loss": 1.227,
      "step": 8740
    },
    {
      "epoch": 2.099832013438925,
      "grad_norm": 0.36205247044563293,
      "learning_rate": 3.335111111111111e-05,
      "loss": 1.3618,
      "step": 8750
    },
    {
      "epoch": 2.099832013438925,
      "eval_loss": 1.281166672706604,
      "eval_runtime": 3.5364,
      "eval_samples_per_second": 56.554,
      "eval_steps_per_second": 2.545,
      "step": 8750
    },
    {
      "epoch": 2.1022318214542834,
      "grad_norm": 0.27817776799201965,
      "learning_rate": 3.326222222222222e-05,
      "loss": 1.1458,
      "step": 8760
    },
    {
      "epoch": 2.1046316294696426,
      "grad_norm": 0.41859886050224304,
      "learning_rate": 3.3173333333333336e-05,
      "loss": 1.3062,
      "step": 8770
    },
    {
      "epoch": 2.107031437485001,
      "grad_norm": 0.3199387490749359,
      "learning_rate": 3.308444444444445e-05,
      "loss": 1.2293,
      "step": 8780
    },
    {
      "epoch": 2.10943124550036,
      "grad_norm": 0.4097621440887451,
      "learning_rate": 3.299555555555556e-05,
      "loss": 1.3628,
      "step": 8790
    },
    {
      "epoch": 2.1118310535157185,
      "grad_norm": 0.26766282320022583,
      "learning_rate": 3.290666666666667e-05,
      "loss": 1.2978,
      "step": 8800
    },
    {
      "epoch": 2.1118310535157185,
      "eval_loss": 1.2825523614883423,
      "eval_runtime": 3.5368,
      "eval_samples_per_second": 56.549,
      "eval_steps_per_second": 2.545,
      "step": 8800
    },
    {
      "epoch": 2.1142308615310776,
      "grad_norm": 0.31215646862983704,
      "learning_rate": 3.281777777777778e-05,
      "loss": 1.286,
      "step": 8810
    },
    {
      "epoch": 2.1166306695464363,
      "grad_norm": 0.3733428716659546,
      "learning_rate": 3.2728888888888896e-05,
      "loss": 1.3241,
      "step": 8820
    },
    {
      "epoch": 2.119030477561795,
      "grad_norm": 0.33117765188217163,
      "learning_rate": 3.2640000000000006e-05,
      "loss": 1.261,
      "step": 8830
    },
    {
      "epoch": 2.1214302855771536,
      "grad_norm": 0.35117805004119873,
      "learning_rate": 3.255111111111111e-05,
      "loss": 1.173,
      "step": 8840
    },
    {
      "epoch": 2.1238300935925127,
      "grad_norm": 0.39893433451652527,
      "learning_rate": 3.246222222222222e-05,
      "loss": 1.466,
      "step": 8850
    },
    {
      "epoch": 2.1238300935925127,
      "eval_loss": 1.2822216749191284,
      "eval_runtime": 3.5365,
      "eval_samples_per_second": 56.554,
      "eval_steps_per_second": 2.545,
      "step": 8850
    },
    {
      "epoch": 2.1262299016078714,
      "grad_norm": 0.38103944063186646,
      "learning_rate": 3.237333333333333e-05,
      "loss": 1.2942,
      "step": 8860
    },
    {
      "epoch": 2.12862970962323,
      "grad_norm": 0.32147783041000366,
      "learning_rate": 3.228444444444445e-05,
      "loss": 1.2043,
      "step": 8870
    },
    {
      "epoch": 2.1310295176385887,
      "grad_norm": 0.32203125953674316,
      "learning_rate": 3.219555555555556e-05,
      "loss": 1.2646,
      "step": 8880
    },
    {
      "epoch": 2.133429325653948,
      "grad_norm": 0.43610838055610657,
      "learning_rate": 3.210666666666667e-05,
      "loss": 1.3001,
      "step": 8890
    },
    {
      "epoch": 2.1358291336693065,
      "grad_norm": 0.3009035289287567,
      "learning_rate": 3.201777777777778e-05,
      "loss": 1.1725,
      "step": 8900
    },
    {
      "epoch": 2.1358291336693065,
      "eval_loss": 1.2798376083374023,
      "eval_runtime": 3.5337,
      "eval_samples_per_second": 56.598,
      "eval_steps_per_second": 2.547,
      "step": 8900
    },
    {
      "epoch": 2.138228941684665,
      "grad_norm": 0.29470112919807434,
      "learning_rate": 3.192888888888889e-05,
      "loss": 1.205,
      "step": 8910
    },
    {
      "epoch": 2.140628749700024,
      "grad_norm": 0.3510695993900299,
      "learning_rate": 3.184e-05,
      "loss": 1.3832,
      "step": 8920
    },
    {
      "epoch": 2.143028557715383,
      "grad_norm": 0.35327714681625366,
      "learning_rate": 3.175111111111112e-05,
      "loss": 1.2117,
      "step": 8930
    },
    {
      "epoch": 2.1454283657307416,
      "grad_norm": 0.34597334265708923,
      "learning_rate": 3.166222222222223e-05,
      "loss": 1.226,
      "step": 8940
    },
    {
      "epoch": 2.1478281737461002,
      "grad_norm": 0.35683485865592957,
      "learning_rate": 3.157333333333333e-05,
      "loss": 1.2502,
      "step": 8950
    },
    {
      "epoch": 2.1478281737461002,
      "eval_loss": 1.2800421714782715,
      "eval_runtime": 3.535,
      "eval_samples_per_second": 56.577,
      "eval_steps_per_second": 2.546,
      "step": 8950
    },
    {
      "epoch": 2.150227981761459,
      "grad_norm": 0.3672502934932709,
      "learning_rate": 3.148444444444444e-05,
      "loss": 1.2728,
      "step": 8960
    },
    {
      "epoch": 2.152627789776818,
      "grad_norm": 0.3847043812274933,
      "learning_rate": 3.139555555555556e-05,
      "loss": 1.1802,
      "step": 8970
    },
    {
      "epoch": 2.1550275977921767,
      "grad_norm": 0.36342233419418335,
      "learning_rate": 3.130666666666667e-05,
      "loss": 1.1963,
      "step": 8980
    },
    {
      "epoch": 2.1574274058075353,
      "grad_norm": 0.3958822190761566,
      "learning_rate": 3.121777777777778e-05,
      "loss": 1.2702,
      "step": 8990
    },
    {
      "epoch": 2.159827213822894,
      "grad_norm": 0.37931832671165466,
      "learning_rate": 3.112888888888889e-05,
      "loss": 1.2754,
      "step": 9000
    },
    {
      "epoch": 2.159827213822894,
      "eval_loss": 1.2791317701339722,
      "eval_runtime": 3.5336,
      "eval_samples_per_second": 56.6,
      "eval_steps_per_second": 2.547,
      "step": 9000
    },
    {
      "epoch": 2.162227021838253,
      "grad_norm": 0.3990023136138916,
      "learning_rate": 3.104e-05,
      "loss": 1.2731,
      "step": 9010
    },
    {
      "epoch": 2.1646268298536118,
      "grad_norm": 0.3867223262786865,
      "learning_rate": 3.095111111111111e-05,
      "loss": 1.3042,
      "step": 9020
    },
    {
      "epoch": 2.1670266378689704,
      "grad_norm": 0.3785845637321472,
      "learning_rate": 3.086222222222223e-05,
      "loss": 1.2284,
      "step": 9030
    },
    {
      "epoch": 2.169426445884329,
      "grad_norm": 0.41300347447395325,
      "learning_rate": 3.077333333333334e-05,
      "loss": 1.2866,
      "step": 9040
    },
    {
      "epoch": 2.171826253899688,
      "grad_norm": 0.3049955368041992,
      "learning_rate": 3.068444444444444e-05,
      "loss": 1.1617,
      "step": 9050
    },
    {
      "epoch": 2.171826253899688,
      "eval_loss": 1.279708743095398,
      "eval_runtime": 3.5343,
      "eval_samples_per_second": 56.588,
      "eval_steps_per_second": 2.546,
      "step": 9050
    },
    {
      "epoch": 2.174226061915047,
      "grad_norm": 0.35470691323280334,
      "learning_rate": 3.059555555555555e-05,
      "loss": 1.3187,
      "step": 9060
    },
    {
      "epoch": 2.1766258699304055,
      "grad_norm": 0.3340403139591217,
      "learning_rate": 3.0506666666666667e-05,
      "loss": 1.1906,
      "step": 9070
    },
    {
      "epoch": 2.179025677945764,
      "grad_norm": 0.31219616532325745,
      "learning_rate": 3.0417777777777778e-05,
      "loss": 1.2804,
      "step": 9080
    },
    {
      "epoch": 2.1814254859611233,
      "grad_norm": 0.3516976833343506,
      "learning_rate": 3.032888888888889e-05,
      "loss": 1.2882,
      "step": 9090
    },
    {
      "epoch": 2.183825293976482,
      "grad_norm": 0.36865824460983276,
      "learning_rate": 3.0240000000000002e-05,
      "loss": 1.2825,
      "step": 9100
    },
    {
      "epoch": 2.183825293976482,
      "eval_loss": 1.2799944877624512,
      "eval_runtime": 3.5239,
      "eval_samples_per_second": 56.756,
      "eval_steps_per_second": 2.554,
      "step": 9100
    },
    {
      "epoch": 2.1862251019918406,
      "grad_norm": 0.34938469529151917,
      "learning_rate": 3.0151111111111112e-05,
      "loss": 1.2912,
      "step": 9110
    },
    {
      "epoch": 2.1886249100071993,
      "grad_norm": 0.426151841878891,
      "learning_rate": 3.0062222222222226e-05,
      "loss": 1.2824,
      "step": 9120
    },
    {
      "epoch": 2.1910247180225584,
      "grad_norm": 0.3501405715942383,
      "learning_rate": 2.9973333333333337e-05,
      "loss": 1.3365,
      "step": 9130
    },
    {
      "epoch": 2.193424526037917,
      "grad_norm": 0.314697802066803,
      "learning_rate": 2.9884444444444447e-05,
      "loss": 1.1872,
      "step": 9140
    },
    {
      "epoch": 2.1958243340532757,
      "grad_norm": 0.2754902243614197,
      "learning_rate": 2.9795555555555554e-05,
      "loss": 1.2275,
      "step": 9150
    },
    {
      "epoch": 2.1958243340532757,
      "eval_loss": 1.2783740758895874,
      "eval_runtime": 3.5259,
      "eval_samples_per_second": 56.723,
      "eval_steps_per_second": 2.553,
      "step": 9150
    },
    {
      "epoch": 2.1982241420686344,
      "grad_norm": 0.3199480473995209,
      "learning_rate": 2.9706666666666665e-05,
      "loss": 1.2452,
      "step": 9160
    },
    {
      "epoch": 2.2006239500839935,
      "grad_norm": 0.3323460519313812,
      "learning_rate": 2.961777777777778e-05,
      "loss": 1.2355,
      "step": 9170
    },
    {
      "epoch": 2.203023758099352,
      "grad_norm": 0.3807618021965027,
      "learning_rate": 2.952888888888889e-05,
      "loss": 1.2295,
      "step": 9180
    },
    {
      "epoch": 2.205423566114711,
      "grad_norm": 0.33955034613609314,
      "learning_rate": 2.944e-05,
      "loss": 1.2692,
      "step": 9190
    },
    {
      "epoch": 2.2078233741300695,
      "grad_norm": 0.3281422555446625,
      "learning_rate": 2.9351111111111113e-05,
      "loss": 1.2055,
      "step": 9200
    },
    {
      "epoch": 2.2078233741300695,
      "eval_loss": 1.2802526950836182,
      "eval_runtime": 3.5277,
      "eval_samples_per_second": 56.694,
      "eval_steps_per_second": 2.551,
      "step": 9200
    },
    {
      "epoch": 2.2102231821454286,
      "grad_norm": 0.3342842757701874,
      "learning_rate": 2.9262222222222224e-05,
      "loss": 1.2086,
      "step": 9210
    },
    {
      "epoch": 2.2126229901607872,
      "grad_norm": 0.35762351751327515,
      "learning_rate": 2.9173333333333337e-05,
      "loss": 1.2775,
      "step": 9220
    },
    {
      "epoch": 2.215022798176146,
      "grad_norm": 0.39096808433532715,
      "learning_rate": 2.9084444444444448e-05,
      "loss": 1.2709,
      "step": 9230
    },
    {
      "epoch": 2.2174226061915046,
      "grad_norm": 0.3536871373653412,
      "learning_rate": 2.899555555555556e-05,
      "loss": 1.2812,
      "step": 9240
    },
    {
      "epoch": 2.2198224142068637,
      "grad_norm": 0.35192713141441345,
      "learning_rate": 2.8906666666666672e-05,
      "loss": 1.2662,
      "step": 9250
    },
    {
      "epoch": 2.2198224142068637,
      "eval_loss": 1.2796094417572021,
      "eval_runtime": 3.5277,
      "eval_samples_per_second": 56.694,
      "eval_steps_per_second": 2.551,
      "step": 9250
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 0.3639616072177887,
      "learning_rate": 2.8817777777777776e-05,
      "loss": 1.2626,
      "step": 9260
    },
    {
      "epoch": 2.224622030237581,
      "grad_norm": 0.36543169617652893,
      "learning_rate": 2.872888888888889e-05,
      "loss": 1.2069,
      "step": 9270
    },
    {
      "epoch": 2.2270218382529396,
      "grad_norm": 0.4237837493419647,
      "learning_rate": 2.864e-05,
      "loss": 1.3145,
      "step": 9280
    },
    {
      "epoch": 2.2294216462682988,
      "grad_norm": 0.29050305485725403,
      "learning_rate": 2.855111111111111e-05,
      "loss": 1.2475,
      "step": 9290
    },
    {
      "epoch": 2.2318214542836574,
      "grad_norm": 0.3352316617965698,
      "learning_rate": 2.8462222222222225e-05,
      "loss": 1.3438,
      "step": 9300
    },
    {
      "epoch": 2.2318214542836574,
      "eval_loss": 1.2791762351989746,
      "eval_runtime": 3.5255,
      "eval_samples_per_second": 56.73,
      "eval_steps_per_second": 2.553,
      "step": 9300
    },
    {
      "epoch": 2.234221262299016,
      "grad_norm": 0.378277063369751,
      "learning_rate": 2.8373333333333335e-05,
      "loss": 1.2209,
      "step": 9310
    },
    {
      "epoch": 2.2366210703143747,
      "grad_norm": 0.36987489461898804,
      "learning_rate": 2.8284444444444445e-05,
      "loss": 1.1866,
      "step": 9320
    },
    {
      "epoch": 2.2390208783297334,
      "grad_norm": 0.34331485629081726,
      "learning_rate": 2.819555555555556e-05,
      "loss": 1.2568,
      "step": 9330
    },
    {
      "epoch": 2.2414206863450925,
      "grad_norm": 0.3182719349861145,
      "learning_rate": 2.810666666666667e-05,
      "loss": 1.2001,
      "step": 9340
    },
    {
      "epoch": 2.243820494360451,
      "grad_norm": 0.3889472782611847,
      "learning_rate": 2.801777777777778e-05,
      "loss": 1.2213,
      "step": 9350
    },
    {
      "epoch": 2.243820494360451,
      "eval_loss": 1.279526710510254,
      "eval_runtime": 3.5253,
      "eval_samples_per_second": 56.733,
      "eval_steps_per_second": 2.553,
      "step": 9350
    },
    {
      "epoch": 2.24622030237581,
      "grad_norm": 0.46631214022636414,
      "learning_rate": 2.7928888888888887e-05,
      "loss": 1.3046,
      "step": 9360
    },
    {
      "epoch": 2.248620110391169,
      "grad_norm": 0.34633955359458923,
      "learning_rate": 2.7839999999999998e-05,
      "loss": 1.2212,
      "step": 9370
    },
    {
      "epoch": 2.2510199184065276,
      "grad_norm": 0.342803031206131,
      "learning_rate": 2.775111111111111e-05,
      "loss": 1.1503,
      "step": 9380
    },
    {
      "epoch": 2.2534197264218863,
      "grad_norm": 0.4247462749481201,
      "learning_rate": 2.7662222222222222e-05,
      "loss": 1.2219,
      "step": 9390
    },
    {
      "epoch": 2.255819534437245,
      "grad_norm": 0.3853135108947754,
      "learning_rate": 2.7573333333333336e-05,
      "loss": 1.202,
      "step": 9400
    },
    {
      "epoch": 2.255819534437245,
      "eval_loss": 1.2794629335403442,
      "eval_runtime": 3.5376,
      "eval_samples_per_second": 56.535,
      "eval_steps_per_second": 2.544,
      "step": 9400
    },
    {
      "epoch": 2.2582193424526036,
      "grad_norm": 0.3678300678730011,
      "learning_rate": 2.7484444444444446e-05,
      "loss": 1.2693,
      "step": 9410
    },
    {
      "epoch": 2.2606191504679627,
      "grad_norm": 0.3210104703903198,
      "learning_rate": 2.7395555555555557e-05,
      "loss": 1.3426,
      "step": 9420
    },
    {
      "epoch": 2.2630189584833214,
      "grad_norm": 0.3167092204093933,
      "learning_rate": 2.730666666666667e-05,
      "loss": 1.2907,
      "step": 9430
    },
    {
      "epoch": 2.26541876649868,
      "grad_norm": 0.42546308040618896,
      "learning_rate": 2.721777777777778e-05,
      "loss": 1.3306,
      "step": 9440
    },
    {
      "epoch": 2.267818574514039,
      "grad_norm": 0.33076319098472595,
      "learning_rate": 2.712888888888889e-05,
      "loss": 1.281,
      "step": 9450
    },
    {
      "epoch": 2.267818574514039,
      "eval_loss": 1.27747642993927,
      "eval_runtime": 3.5268,
      "eval_samples_per_second": 56.709,
      "eval_steps_per_second": 2.552,
      "step": 9450
    },
    {
      "epoch": 2.270218382529398,
      "grad_norm": 0.30823057889938354,
      "learning_rate": 2.704e-05,
      "loss": 1.2656,
      "step": 9460
    },
    {
      "epoch": 2.2726181905447564,
      "grad_norm": 0.3570599853992462,
      "learning_rate": 2.695111111111111e-05,
      "loss": 1.3211,
      "step": 9470
    },
    {
      "epoch": 2.275017998560115,
      "grad_norm": 0.3317955434322357,
      "learning_rate": 2.6862222222222223e-05,
      "loss": 1.2542,
      "step": 9480
    },
    {
      "epoch": 2.2774178065754738,
      "grad_norm": 0.3407318592071533,
      "learning_rate": 2.6773333333333333e-05,
      "loss": 1.2896,
      "step": 9490
    },
    {
      "epoch": 2.279817614590833,
      "grad_norm": 0.3389858305454254,
      "learning_rate": 2.6684444444444444e-05,
      "loss": 1.2746,
      "step": 9500
    },
    {
      "epoch": 2.279817614590833,
      "eval_loss": 1.2781280279159546,
      "eval_runtime": 3.526,
      "eval_samples_per_second": 56.722,
      "eval_steps_per_second": 2.552,
      "step": 9500
    },
    {
      "epoch": 2.2822174226061915,
      "grad_norm": 0.3083191514015198,
      "learning_rate": 2.6595555555555558e-05,
      "loss": 1.2665,
      "step": 9510
    },
    {
      "epoch": 2.28461723062155,
      "grad_norm": 0.3369757831096649,
      "learning_rate": 2.6506666666666668e-05,
      "loss": 1.2664,
      "step": 9520
    },
    {
      "epoch": 2.287017038636909,
      "grad_norm": 0.32753390073776245,
      "learning_rate": 2.641777777777778e-05,
      "loss": 1.1197,
      "step": 9530
    },
    {
      "epoch": 2.289416846652268,
      "grad_norm": 0.3639587461948395,
      "learning_rate": 2.6328888888888892e-05,
      "loss": 1.2402,
      "step": 9540
    },
    {
      "epoch": 2.2918166546676266,
      "grad_norm": 0.32499927282333374,
      "learning_rate": 2.6240000000000003e-05,
      "loss": 1.23,
      "step": 9550
    },
    {
      "epoch": 2.2918166546676266,
      "eval_loss": 1.278015375137329,
      "eval_runtime": 3.5274,
      "eval_samples_per_second": 56.699,
      "eval_steps_per_second": 2.551,
      "step": 9550
    },
    {
      "epoch": 2.2942164626829853,
      "grad_norm": 0.33457380533218384,
      "learning_rate": 2.6151111111111117e-05,
      "loss": 1.2143,
      "step": 9560
    },
    {
      "epoch": 2.296616270698344,
      "grad_norm": 0.24918876588344574,
      "learning_rate": 2.606222222222222e-05,
      "loss": 1.1208,
      "step": 9570
    },
    {
      "epoch": 2.299016078713703,
      "grad_norm": 0.396371990442276,
      "learning_rate": 2.5973333333333334e-05,
      "loss": 1.2844,
      "step": 9580
    },
    {
      "epoch": 2.3014158867290617,
      "grad_norm": 0.3391914665699005,
      "learning_rate": 2.5884444444444445e-05,
      "loss": 1.277,
      "step": 9590
    },
    {
      "epoch": 2.3038156947444204,
      "grad_norm": 0.3879251182079315,
      "learning_rate": 2.5795555555555555e-05,
      "loss": 1.2382,
      "step": 9600
    },
    {
      "epoch": 2.3038156947444204,
      "eval_loss": 1.2785300016403198,
      "eval_runtime": 3.5254,
      "eval_samples_per_second": 56.731,
      "eval_steps_per_second": 2.553,
      "step": 9600
    },
    {
      "epoch": 2.306215502759779,
      "grad_norm": 0.32998451590538025,
      "learning_rate": 2.570666666666667e-05,
      "loss": 1.2841,
      "step": 9610
    },
    {
      "epoch": 2.308615310775138,
      "grad_norm": 0.3201315701007843,
      "learning_rate": 2.561777777777778e-05,
      "loss": 1.273,
      "step": 9620
    },
    {
      "epoch": 2.311015118790497,
      "grad_norm": 0.35464394092559814,
      "learning_rate": 2.552888888888889e-05,
      "loss": 1.3065,
      "step": 9630
    },
    {
      "epoch": 2.3134149268058555,
      "grad_norm": 0.3188990354537964,
      "learning_rate": 2.5440000000000004e-05,
      "loss": 1.3806,
      "step": 9640
    },
    {
      "epoch": 2.315814734821214,
      "grad_norm": 0.2997027635574341,
      "learning_rate": 2.5351111111111114e-05,
      "loss": 1.2472,
      "step": 9650
    },
    {
      "epoch": 2.315814734821214,
      "eval_loss": 1.2770429849624634,
      "eval_runtime": 3.5261,
      "eval_samples_per_second": 56.719,
      "eval_steps_per_second": 2.552,
      "step": 9650
    },
    {
      "epoch": 2.3182145428365732,
      "grad_norm": 0.34198084473609924,
      "learning_rate": 2.5262222222222225e-05,
      "loss": 1.2293,
      "step": 9660
    },
    {
      "epoch": 2.320614350851932,
      "grad_norm": 0.35927078127861023,
      "learning_rate": 2.5173333333333332e-05,
      "loss": 1.291,
      "step": 9670
    },
    {
      "epoch": 2.3230141588672906,
      "grad_norm": 0.33051052689552307,
      "learning_rate": 2.5084444444444442e-05,
      "loss": 1.2744,
      "step": 9680
    },
    {
      "epoch": 2.3254139668826492,
      "grad_norm": 0.3447939157485962,
      "learning_rate": 2.4995555555555556e-05,
      "loss": 1.2756,
      "step": 9690
    },
    {
      "epoch": 2.3278137748980083,
      "grad_norm": 0.41782817244529724,
      "learning_rate": 2.4906666666666666e-05,
      "loss": 1.3119,
      "step": 9700
    },
    {
      "epoch": 2.3278137748980083,
      "eval_loss": 1.2785815000534058,
      "eval_runtime": 3.5258,
      "eval_samples_per_second": 56.725,
      "eval_steps_per_second": 2.553,
      "step": 9700
    },
    {
      "epoch": 2.330213582913367,
      "grad_norm": 0.3063536286354065,
      "learning_rate": 2.481777777777778e-05,
      "loss": 1.2556,
      "step": 9710
    },
    {
      "epoch": 2.3326133909287257,
      "grad_norm": 0.3093768358230591,
      "learning_rate": 2.472888888888889e-05,
      "loss": 1.2919,
      "step": 9720
    },
    {
      "epoch": 2.3350131989440843,
      "grad_norm": 0.39713114500045776,
      "learning_rate": 2.464e-05,
      "loss": 1.3278,
      "step": 9730
    },
    {
      "epoch": 2.3374130069594434,
      "grad_norm": 0.39626598358154297,
      "learning_rate": 2.4551111111111115e-05,
      "loss": 1.2222,
      "step": 9740
    },
    {
      "epoch": 2.339812814974802,
      "grad_norm": 0.27155622839927673,
      "learning_rate": 2.4462222222222222e-05,
      "loss": 1.2734,
      "step": 9750
    },
    {
      "epoch": 2.339812814974802,
      "eval_loss": 1.2791048288345337,
      "eval_runtime": 3.5255,
      "eval_samples_per_second": 56.729,
      "eval_steps_per_second": 2.553,
      "step": 9750
    },
    {
      "epoch": 2.3422126229901608,
      "grad_norm": 0.37657350301742554,
      "learning_rate": 2.4373333333333333e-05,
      "loss": 1.2738,
      "step": 9760
    },
    {
      "epoch": 2.3446124310055194,
      "grad_norm": 0.3292604982852936,
      "learning_rate": 2.4284444444444446e-05,
      "loss": 1.2852,
      "step": 9770
    },
    {
      "epoch": 2.3470122390208785,
      "grad_norm": 0.3206266760826111,
      "learning_rate": 2.4195555555555557e-05,
      "loss": 1.1554,
      "step": 9780
    },
    {
      "epoch": 2.349412047036237,
      "grad_norm": 0.30679401755332947,
      "learning_rate": 2.4106666666666667e-05,
      "loss": 1.2937,
      "step": 9790
    },
    {
      "epoch": 2.351811855051596,
      "grad_norm": 0.3668917119503021,
      "learning_rate": 2.4017777777777778e-05,
      "loss": 1.2721,
      "step": 9800
    },
    {
      "epoch": 2.351811855051596,
      "eval_loss": 1.2771706581115723,
      "eval_runtime": 3.5281,
      "eval_samples_per_second": 56.688,
      "eval_steps_per_second": 2.551,
      "step": 9800
    },
    {
      "epoch": 2.3542116630669545,
      "grad_norm": 0.39614149928092957,
      "learning_rate": 2.3928888888888888e-05,
      "loss": 1.3169,
      "step": 9810
    },
    {
      "epoch": 2.3566114710823136,
      "grad_norm": 0.34341031312942505,
      "learning_rate": 2.3840000000000002e-05,
      "loss": 1.2558,
      "step": 9820
    },
    {
      "epoch": 2.3590112790976723,
      "grad_norm": 0.33822107315063477,
      "learning_rate": 2.3751111111111113e-05,
      "loss": 1.237,
      "step": 9830
    },
    {
      "epoch": 2.361411087113031,
      "grad_norm": 0.30393314361572266,
      "learning_rate": 2.3662222222222223e-05,
      "loss": 1.2871,
      "step": 9840
    },
    {
      "epoch": 2.3638108951283896,
      "grad_norm": 0.37413489818573,
      "learning_rate": 2.3573333333333334e-05,
      "loss": 1.276,
      "step": 9850
    },
    {
      "epoch": 2.3638108951283896,
      "eval_loss": 1.278323769569397,
      "eval_runtime": 3.5254,
      "eval_samples_per_second": 56.731,
      "eval_steps_per_second": 2.553,
      "step": 9850
    },
    {
      "epoch": 2.3662107031437483,
      "grad_norm": 0.31594327092170715,
      "learning_rate": 2.3484444444444444e-05,
      "loss": 1.2317,
      "step": 9860
    },
    {
      "epoch": 2.3686105111591074,
      "grad_norm": 0.41346731781959534,
      "learning_rate": 2.3395555555555558e-05,
      "loss": 1.2339,
      "step": 9870
    },
    {
      "epoch": 2.371010319174466,
      "grad_norm": 0.41270512342453003,
      "learning_rate": 2.3306666666666668e-05,
      "loss": 1.2208,
      "step": 9880
    },
    {
      "epoch": 2.3734101271898247,
      "grad_norm": 0.28809183835983276,
      "learning_rate": 2.321777777777778e-05,
      "loss": 1.184,
      "step": 9890
    },
    {
      "epoch": 2.375809935205184,
      "grad_norm": 0.33757713437080383,
      "learning_rate": 2.312888888888889e-05,
      "loss": 1.2405,
      "step": 9900
    },
    {
      "epoch": 2.375809935205184,
      "eval_loss": 1.2786898612976074,
      "eval_runtime": 3.5241,
      "eval_samples_per_second": 56.751,
      "eval_steps_per_second": 2.554,
      "step": 9900
    },
    {
      "epoch": 2.3782097432205425,
      "grad_norm": 0.39770227670669556,
      "learning_rate": 2.304e-05,
      "loss": 1.2897,
      "step": 9910
    },
    {
      "epoch": 2.380609551235901,
      "grad_norm": 0.35707446932792664,
      "learning_rate": 2.2951111111111113e-05,
      "loss": 1.2487,
      "step": 9920
    },
    {
      "epoch": 2.38300935925126,
      "grad_norm": 0.33573609590530396,
      "learning_rate": 2.2862222222222224e-05,
      "loss": 1.2009,
      "step": 9930
    },
    {
      "epoch": 2.3854091672666184,
      "grad_norm": 0.37761393189430237,
      "learning_rate": 2.2773333333333334e-05,
      "loss": 1.1905,
      "step": 9940
    },
    {
      "epoch": 2.3878089752819776,
      "grad_norm": 0.34942516684532166,
      "learning_rate": 2.2684444444444445e-05,
      "loss": 1.3103,
      "step": 9950
    },
    {
      "epoch": 2.3878089752819776,
      "eval_loss": 1.2787127494812012,
      "eval_runtime": 3.5251,
      "eval_samples_per_second": 56.736,
      "eval_steps_per_second": 2.553,
      "step": 9950
    },
    {
      "epoch": 2.390208783297336,
      "grad_norm": 0.3255051076412201,
      "learning_rate": 2.2595555555555555e-05,
      "loss": 1.2136,
      "step": 9960
    },
    {
      "epoch": 2.392608591312695,
      "grad_norm": 0.3210659921169281,
      "learning_rate": 2.250666666666667e-05,
      "loss": 1.2592,
      "step": 9970
    },
    {
      "epoch": 2.395008399328054,
      "grad_norm": 0.3387027084827423,
      "learning_rate": 2.241777777777778e-05,
      "loss": 1.2962,
      "step": 9980
    },
    {
      "epoch": 2.3974082073434126,
      "grad_norm": 0.3620684742927551,
      "learning_rate": 2.232888888888889e-05,
      "loss": 1.3003,
      "step": 9990
    },
    {
      "epoch": 2.3998080153587713,
      "grad_norm": 0.36355695128440857,
      "learning_rate": 2.224e-05,
      "loss": 1.3224,
      "step": 10000
    },
    {
      "epoch": 2.3998080153587713,
      "eval_loss": 1.2777665853500366,
      "eval_runtime": 3.5241,
      "eval_samples_per_second": 56.753,
      "eval_steps_per_second": 2.554,
      "step": 10000
    },
    {
      "epoch": 2.40220782337413,
      "grad_norm": 0.3189482092857361,
      "learning_rate": 2.215111111111111e-05,
      "loss": 1.1085,
      "step": 10010
    },
    {
      "epoch": 2.4046076313894886,
      "grad_norm": 0.34399062395095825,
      "learning_rate": 2.206222222222222e-05,
      "loss": 1.1926,
      "step": 10020
    },
    {
      "epoch": 2.4070074394048477,
      "grad_norm": 0.30079546570777893,
      "learning_rate": 2.1973333333333335e-05,
      "loss": 1.2034,
      "step": 10030
    },
    {
      "epoch": 2.4094072474202064,
      "grad_norm": 0.4056393802165985,
      "learning_rate": 2.1884444444444446e-05,
      "loss": 1.1972,
      "step": 10040
    },
    {
      "epoch": 2.411807055435565,
      "grad_norm": 0.4224434792995453,
      "learning_rate": 2.179555555555556e-05,
      "loss": 1.3455,
      "step": 10050
    },
    {
      "epoch": 2.411807055435565,
      "eval_loss": 1.2772583961486816,
      "eval_runtime": 3.5254,
      "eval_samples_per_second": 56.732,
      "eval_steps_per_second": 2.553,
      "step": 10050
    },
    {
      "epoch": 2.414206863450924,
      "grad_norm": 0.30601930618286133,
      "learning_rate": 2.1706666666666667e-05,
      "loss": 1.2761,
      "step": 10060
    },
    {
      "epoch": 2.416606671466283,
      "grad_norm": 0.354190468788147,
      "learning_rate": 2.1617777777777777e-05,
      "loss": 1.283,
      "step": 10070
    },
    {
      "epoch": 2.4190064794816415,
      "grad_norm": 0.3214525878429413,
      "learning_rate": 2.152888888888889e-05,
      "loss": 1.244,
      "step": 10080
    },
    {
      "epoch": 2.421406287497,
      "grad_norm": 0.35270124673843384,
      "learning_rate": 2.144e-05,
      "loss": 1.1981,
      "step": 10090
    },
    {
      "epoch": 2.423806095512359,
      "grad_norm": 0.3415812849998474,
      "learning_rate": 2.1351111111111112e-05,
      "loss": 1.2121,
      "step": 10100
    },
    {
      "epoch": 2.423806095512359,
      "eval_loss": 1.2765613794326782,
      "eval_runtime": 3.5278,
      "eval_samples_per_second": 56.693,
      "eval_steps_per_second": 2.551,
      "step": 10100
    },
    {
      "epoch": 2.426205903527718,
      "grad_norm": 0.3201618790626526,
      "learning_rate": 2.1262222222222222e-05,
      "loss": 1.2507,
      "step": 10110
    },
    {
      "epoch": 2.4286057115430766,
      "grad_norm": 0.38290831446647644,
      "learning_rate": 2.1173333333333333e-05,
      "loss": 1.342,
      "step": 10120
    },
    {
      "epoch": 2.4310055195584352,
      "grad_norm": 0.31611478328704834,
      "learning_rate": 2.1084444444444447e-05,
      "loss": 1.3097,
      "step": 10130
    },
    {
      "epoch": 2.433405327573794,
      "grad_norm": 0.36091098189353943,
      "learning_rate": 2.0995555555555557e-05,
      "loss": 1.2721,
      "step": 10140
    },
    {
      "epoch": 2.435805135589153,
      "grad_norm": 0.38635459542274475,
      "learning_rate": 2.0906666666666668e-05,
      "loss": 1.2826,
      "step": 10150
    },
    {
      "epoch": 2.435805135589153,
      "eval_loss": 1.2765157222747803,
      "eval_runtime": 3.5275,
      "eval_samples_per_second": 56.697,
      "eval_steps_per_second": 2.551,
      "step": 10150
    },
    {
      "epoch": 2.4382049436045117,
      "grad_norm": 0.41234534978866577,
      "learning_rate": 2.0817777777777778e-05,
      "loss": 1.2895,
      "step": 10160
    },
    {
      "epoch": 2.4406047516198703,
      "grad_norm": 0.2724588215351105,
      "learning_rate": 2.072888888888889e-05,
      "loss": 1.2263,
      "step": 10170
    },
    {
      "epoch": 2.443004559635229,
      "grad_norm": 0.3469841778278351,
      "learning_rate": 2.0640000000000002e-05,
      "loss": 1.158,
      "step": 10180
    },
    {
      "epoch": 2.445404367650588,
      "grad_norm": 0.3928527235984802,
      "learning_rate": 2.0551111111111113e-05,
      "loss": 1.3182,
      "step": 10190
    },
    {
      "epoch": 2.4478041756659468,
      "grad_norm": 0.42757558822631836,
      "learning_rate": 2.0462222222222223e-05,
      "loss": 1.2575,
      "step": 10200
    },
    {
      "epoch": 2.4478041756659468,
      "eval_loss": 1.2757030725479126,
      "eval_runtime": 3.5277,
      "eval_samples_per_second": 56.694,
      "eval_steps_per_second": 2.551,
      "step": 10200
    },
    {
      "epoch": 2.4502039836813054,
      "grad_norm": 0.33419692516326904,
      "learning_rate": 2.0373333333333334e-05,
      "loss": 1.2433,
      "step": 10210
    },
    {
      "epoch": 2.452603791696664,
      "grad_norm": 0.2842854857444763,
      "learning_rate": 2.0284444444444444e-05,
      "loss": 1.2974,
      "step": 10220
    },
    {
      "epoch": 2.455003599712023,
      "grad_norm": 0.33718428015708923,
      "learning_rate": 2.0195555555555558e-05,
      "loss": 1.2134,
      "step": 10230
    },
    {
      "epoch": 2.457403407727382,
      "grad_norm": 0.36149099469184875,
      "learning_rate": 2.010666666666667e-05,
      "loss": 1.1472,
      "step": 10240
    },
    {
      "epoch": 2.4598032157427405,
      "grad_norm": 0.3090026080608368,
      "learning_rate": 2.001777777777778e-05,
      "loss": 1.2746,
      "step": 10250
    },
    {
      "epoch": 2.4598032157427405,
      "eval_loss": 1.2767791748046875,
      "eval_runtime": 3.5265,
      "eval_samples_per_second": 56.714,
      "eval_steps_per_second": 2.552,
      "step": 10250
    },
    {
      "epoch": 2.462203023758099,
      "grad_norm": 0.32537487149238586,
      "learning_rate": 1.992888888888889e-05,
      "loss": 1.202,
      "step": 10260
    },
    {
      "epoch": 2.4646028317734583,
      "grad_norm": 0.3888199031352997,
      "learning_rate": 1.984e-05,
      "loss": 1.2979,
      "step": 10270
    },
    {
      "epoch": 2.467002639788817,
      "grad_norm": 0.39139097929000854,
      "learning_rate": 1.975111111111111e-05,
      "loss": 1.2393,
      "step": 10280
    },
    {
      "epoch": 2.4694024478041756,
      "grad_norm": 0.29815351963043213,
      "learning_rate": 1.9662222222222224e-05,
      "loss": 1.3653,
      "step": 10290
    },
    {
      "epoch": 2.4718022558195343,
      "grad_norm": 0.3624531030654907,
      "learning_rate": 1.9573333333333335e-05,
      "loss": 1.2425,
      "step": 10300
    },
    {
      "epoch": 2.4718022558195343,
      "eval_loss": 1.276644229888916,
      "eval_runtime": 3.5302,
      "eval_samples_per_second": 56.654,
      "eval_steps_per_second": 2.549,
      "step": 10300
    },
    {
      "epoch": 2.4742020638348934,
      "grad_norm": 0.38204848766326904,
      "learning_rate": 1.9484444444444445e-05,
      "loss": 1.3124,
      "step": 10310
    },
    {
      "epoch": 2.476601871850252,
      "grad_norm": 0.2904958724975586,
      "learning_rate": 1.9395555555555555e-05,
      "loss": 1.2333,
      "step": 10320
    },
    {
      "epoch": 2.4790016798656107,
      "grad_norm": 0.3225856125354767,
      "learning_rate": 1.9306666666666666e-05,
      "loss": 1.2207,
      "step": 10330
    },
    {
      "epoch": 2.4814014878809694,
      "grad_norm": 0.4045051634311676,
      "learning_rate": 1.921777777777778e-05,
      "loss": 1.2652,
      "step": 10340
    },
    {
      "epoch": 2.4838012958963285,
      "grad_norm": 0.3647317588329315,
      "learning_rate": 1.912888888888889e-05,
      "loss": 1.2442,
      "step": 10350
    },
    {
      "epoch": 2.4838012958963285,
      "eval_loss": 1.2766553163528442,
      "eval_runtime": 3.5299,
      "eval_samples_per_second": 56.659,
      "eval_steps_per_second": 2.55,
      "step": 10350
    },
    {
      "epoch": 2.486201103911687,
      "grad_norm": 0.34531351923942566,
      "learning_rate": 1.904e-05,
      "loss": 1.1645,
      "step": 10360
    },
    {
      "epoch": 2.488600911927046,
      "grad_norm": 0.32855692505836487,
      "learning_rate": 1.895111111111111e-05,
      "loss": 1.2743,
      "step": 10370
    },
    {
      "epoch": 2.4910007199424045,
      "grad_norm": 0.35105839371681213,
      "learning_rate": 1.886222222222222e-05,
      "loss": 1.3191,
      "step": 10380
    },
    {
      "epoch": 2.4934005279577636,
      "grad_norm": 0.3461446166038513,
      "learning_rate": 1.8773333333333335e-05,
      "loss": 1.2932,
      "step": 10390
    },
    {
      "epoch": 2.4958003359731222,
      "grad_norm": 0.3568613529205322,
      "learning_rate": 1.8684444444444446e-05,
      "loss": 1.2226,
      "step": 10400
    },
    {
      "epoch": 2.4958003359731222,
      "eval_loss": 1.2771095037460327,
      "eval_runtime": 3.531,
      "eval_samples_per_second": 56.641,
      "eval_steps_per_second": 2.549,
      "step": 10400
    },
    {
      "epoch": 2.498200143988481,
      "grad_norm": 0.33972689509391785,
      "learning_rate": 1.8595555555555556e-05,
      "loss": 1.1954,
      "step": 10410
    },
    {
      "epoch": 2.5005999520038396,
      "grad_norm": 0.37328964471817017,
      "learning_rate": 1.8506666666666667e-05,
      "loss": 1.2188,
      "step": 10420
    },
    {
      "epoch": 2.5029997600191987,
      "grad_norm": 0.34157174825668335,
      "learning_rate": 1.8417777777777777e-05,
      "loss": 1.221,
      "step": 10430
    },
    {
      "epoch": 2.5053995680345573,
      "grad_norm": 0.332530677318573,
      "learning_rate": 1.832888888888889e-05,
      "loss": 1.2689,
      "step": 10440
    },
    {
      "epoch": 2.507799376049916,
      "grad_norm": 0.3606260418891907,
      "learning_rate": 1.824e-05,
      "loss": 1.1869,
      "step": 10450
    },
    {
      "epoch": 2.507799376049916,
      "eval_loss": 1.2766269445419312,
      "eval_runtime": 3.5313,
      "eval_samples_per_second": 56.637,
      "eval_steps_per_second": 2.549,
      "step": 10450
    },
    {
      "epoch": 2.5101991840652746,
      "grad_norm": 0.31076356768608093,
      "learning_rate": 1.8151111111111112e-05,
      "loss": 1.3117,
      "step": 10460
    },
    {
      "epoch": 2.5125989920806333,
      "grad_norm": 0.38201454281806946,
      "learning_rate": 1.8062222222222222e-05,
      "loss": 1.3119,
      "step": 10470
    },
    {
      "epoch": 2.5149988000959924,
      "grad_norm": 0.3367629647254944,
      "learning_rate": 1.7973333333333333e-05,
      "loss": 1.2916,
      "step": 10480
    },
    {
      "epoch": 2.517398608111351,
      "grad_norm": 0.3934573829174042,
      "learning_rate": 1.7884444444444447e-05,
      "loss": 1.321,
      "step": 10490
    },
    {
      "epoch": 2.5197984161267097,
      "grad_norm": 0.30986157059669495,
      "learning_rate": 1.7795555555555557e-05,
      "loss": 1.2885,
      "step": 10500
    },
    {
      "epoch": 2.5197984161267097,
      "eval_loss": 1.2765079736709595,
      "eval_runtime": 3.5318,
      "eval_samples_per_second": 56.629,
      "eval_steps_per_second": 2.548,
      "step": 10500
    },
    {
      "epoch": 2.522198224142069,
      "grad_norm": 0.3694734573364258,
      "learning_rate": 1.7706666666666668e-05,
      "loss": 1.2419,
      "step": 10510
    },
    {
      "epoch": 2.5245980321574275,
      "grad_norm": 0.43278470635414124,
      "learning_rate": 1.7617777777777778e-05,
      "loss": 1.3887,
      "step": 10520
    },
    {
      "epoch": 2.526997840172786,
      "grad_norm": 0.35282251238822937,
      "learning_rate": 1.752888888888889e-05,
      "loss": 1.2979,
      "step": 10530
    },
    {
      "epoch": 2.529397648188145,
      "grad_norm": 0.40711510181427,
      "learning_rate": 1.7440000000000002e-05,
      "loss": 1.2046,
      "step": 10540
    },
    {
      "epoch": 2.5317974562035035,
      "grad_norm": 0.3034060299396515,
      "learning_rate": 1.7351111111111113e-05,
      "loss": 1.2152,
      "step": 10550
    },
    {
      "epoch": 2.5317974562035035,
      "eval_loss": 1.2771000862121582,
      "eval_runtime": 3.5326,
      "eval_samples_per_second": 56.615,
      "eval_steps_per_second": 2.548,
      "step": 10550
    },
    {
      "epoch": 2.5341972642188626,
      "grad_norm": 0.31929752230644226,
      "learning_rate": 1.7262222222222223e-05,
      "loss": 1.2408,
      "step": 10560
    },
    {
      "epoch": 2.5365970722342213,
      "grad_norm": 0.3360678255558014,
      "learning_rate": 1.7173333333333334e-05,
      "loss": 1.3283,
      "step": 10570
    },
    {
      "epoch": 2.53899688024958,
      "grad_norm": 0.3866507411003113,
      "learning_rate": 1.7084444444444444e-05,
      "loss": 1.316,
      "step": 10580
    },
    {
      "epoch": 2.541396688264939,
      "grad_norm": 0.30281591415405273,
      "learning_rate": 1.6995555555555555e-05,
      "loss": 1.2055,
      "step": 10590
    },
    {
      "epoch": 2.5437964962802977,
      "grad_norm": 0.36319950222969055,
      "learning_rate": 1.690666666666667e-05,
      "loss": 1.2441,
      "step": 10600
    },
    {
      "epoch": 2.5437964962802977,
      "eval_loss": 1.2764906883239746,
      "eval_runtime": 3.5325,
      "eval_samples_per_second": 56.617,
      "eval_steps_per_second": 2.548,
      "step": 10600
    },
    {
      "epoch": 2.5461963042956564,
      "grad_norm": 0.3360298275947571,
      "learning_rate": 1.681777777777778e-05,
      "loss": 1.2714,
      "step": 10610
    },
    {
      "epoch": 2.548596112311015,
      "grad_norm": 0.3087821304798126,
      "learning_rate": 1.672888888888889e-05,
      "loss": 1.307,
      "step": 10620
    },
    {
      "epoch": 2.5509959203263737,
      "grad_norm": 0.3535369336605072,
      "learning_rate": 1.664e-05,
      "loss": 1.2226,
      "step": 10630
    },
    {
      "epoch": 2.553395728341733,
      "grad_norm": 0.33921778202056885,
      "learning_rate": 1.655111111111111e-05,
      "loss": 1.1556,
      "step": 10640
    },
    {
      "epoch": 2.5557955363570914,
      "grad_norm": 0.32178112864494324,
      "learning_rate": 1.6462222222222224e-05,
      "loss": 1.3009,
      "step": 10650
    },
    {
      "epoch": 2.5557955363570914,
      "eval_loss": 1.2759119272232056,
      "eval_runtime": 3.5364,
      "eval_samples_per_second": 56.554,
      "eval_steps_per_second": 2.545,
      "step": 10650
    },
    {
      "epoch": 2.55819534437245,
      "grad_norm": 0.4033571481704712,
      "learning_rate": 1.6373333333333335e-05,
      "loss": 1.1787,
      "step": 10660
    },
    {
      "epoch": 2.560595152387809,
      "grad_norm": 0.3433420956134796,
      "learning_rate": 1.6284444444444445e-05,
      "loss": 1.2462,
      "step": 10670
    },
    {
      "epoch": 2.562994960403168,
      "grad_norm": 0.2974731922149658,
      "learning_rate": 1.6195555555555556e-05,
      "loss": 1.2525,
      "step": 10680
    },
    {
      "epoch": 2.5653947684185265,
      "grad_norm": 0.39750877022743225,
      "learning_rate": 1.6106666666666666e-05,
      "loss": 1.1801,
      "step": 10690
    },
    {
      "epoch": 2.567794576433885,
      "grad_norm": 0.3633776605129242,
      "learning_rate": 1.601777777777778e-05,
      "loss": 1.3199,
      "step": 10700
    },
    {
      "epoch": 2.567794576433885,
      "eval_loss": 1.276208519935608,
      "eval_runtime": 3.5304,
      "eval_samples_per_second": 56.652,
      "eval_steps_per_second": 2.549,
      "step": 10700
    },
    {
      "epoch": 2.570194384449244,
      "grad_norm": 0.3505534529685974,
      "learning_rate": 1.592888888888889e-05,
      "loss": 1.2311,
      "step": 10710
    },
    {
      "epoch": 2.572594192464603,
      "grad_norm": 0.3345368206501007,
      "learning_rate": 1.584e-05,
      "loss": 1.2516,
      "step": 10720
    },
    {
      "epoch": 2.5749940004799616,
      "grad_norm": 0.32574066519737244,
      "learning_rate": 1.575111111111111e-05,
      "loss": 1.308,
      "step": 10730
    },
    {
      "epoch": 2.5773938084953203,
      "grad_norm": 0.3894500434398651,
      "learning_rate": 1.5662222222222222e-05,
      "loss": 1.1693,
      "step": 10740
    },
    {
      "epoch": 2.5797936165106794,
      "grad_norm": 0.39083197712898254,
      "learning_rate": 1.5573333333333336e-05,
      "loss": 1.392,
      "step": 10750
    },
    {
      "epoch": 2.5797936165106794,
      "eval_loss": 1.275938868522644,
      "eval_runtime": 3.53,
      "eval_samples_per_second": 56.658,
      "eval_steps_per_second": 2.55,
      "step": 10750
    },
    {
      "epoch": 2.582193424526038,
      "grad_norm": 0.38299816846847534,
      "learning_rate": 1.5484444444444446e-05,
      "loss": 1.1648,
      "step": 10760
    },
    {
      "epoch": 2.5845932325413967,
      "grad_norm": 0.3770471513271332,
      "learning_rate": 1.5395555555555556e-05,
      "loss": 1.3282,
      "step": 10770
    },
    {
      "epoch": 2.5869930405567554,
      "grad_norm": 0.3149946331977844,
      "learning_rate": 1.5306666666666667e-05,
      "loss": 1.232,
      "step": 10780
    },
    {
      "epoch": 2.589392848572114,
      "grad_norm": 0.31222957372665405,
      "learning_rate": 1.5217777777777777e-05,
      "loss": 1.3132,
      "step": 10790
    },
    {
      "epoch": 2.591792656587473,
      "grad_norm": 0.35255166888237,
      "learning_rate": 1.512888888888889e-05,
      "loss": 1.3361,
      "step": 10800
    },
    {
      "epoch": 2.591792656587473,
      "eval_loss": 1.2759838104248047,
      "eval_runtime": 3.5376,
      "eval_samples_per_second": 56.536,
      "eval_steps_per_second": 2.544,
      "step": 10800
    },
    {
      "epoch": 2.594192464602832,
      "grad_norm": 0.3402951955795288,
      "learning_rate": 1.5040000000000002e-05,
      "loss": 1.226,
      "step": 10810
    },
    {
      "epoch": 2.5965922726181905,
      "grad_norm": 0.373299241065979,
      "learning_rate": 1.4951111111111112e-05,
      "loss": 1.2576,
      "step": 10820
    },
    {
      "epoch": 2.5989920806335496,
      "grad_norm": 0.36391475796699524,
      "learning_rate": 1.4862222222222223e-05,
      "loss": 1.2557,
      "step": 10830
    },
    {
      "epoch": 2.6013918886489082,
      "grad_norm": 0.34751826524734497,
      "learning_rate": 1.4773333333333333e-05,
      "loss": 1.2576,
      "step": 10840
    },
    {
      "epoch": 2.603791696664267,
      "grad_norm": 0.32337281107902527,
      "learning_rate": 1.4684444444444445e-05,
      "loss": 1.1974,
      "step": 10850
    },
    {
      "epoch": 2.603791696664267,
      "eval_loss": 1.2755552530288696,
      "eval_runtime": 3.5313,
      "eval_samples_per_second": 56.636,
      "eval_steps_per_second": 2.549,
      "step": 10850
    },
    {
      "epoch": 2.6061915046796256,
      "grad_norm": 0.40807104110717773,
      "learning_rate": 1.4595555555555557e-05,
      "loss": 1.3075,
      "step": 10860
    },
    {
      "epoch": 2.6085913126949842,
      "grad_norm": 0.3592023253440857,
      "learning_rate": 1.4506666666666668e-05,
      "loss": 1.2203,
      "step": 10870
    },
    {
      "epoch": 2.6109911207103433,
      "grad_norm": 0.3781517446041107,
      "learning_rate": 1.4417777777777777e-05,
      "loss": 1.1549,
      "step": 10880
    },
    {
      "epoch": 2.613390928725702,
      "grad_norm": 0.36291855573654175,
      "learning_rate": 1.4328888888888889e-05,
      "loss": 1.2661,
      "step": 10890
    },
    {
      "epoch": 2.6157907367410607,
      "grad_norm": 0.3372093737125397,
      "learning_rate": 1.4240000000000001e-05,
      "loss": 1.2501,
      "step": 10900
    },
    {
      "epoch": 2.6157907367410607,
      "eval_loss": 1.2755284309387207,
      "eval_runtime": 3.5334,
      "eval_samples_per_second": 56.603,
      "eval_steps_per_second": 2.547,
      "step": 10900
    },
    {
      "epoch": 2.6181905447564193,
      "grad_norm": 0.33464980125427246,
      "learning_rate": 1.4151111111111113e-05,
      "loss": 1.2677,
      "step": 10910
    },
    {
      "epoch": 2.620590352771778,
      "grad_norm": 0.3386462926864624,
      "learning_rate": 1.4062222222222223e-05,
      "loss": 1.2634,
      "step": 10920
    },
    {
      "epoch": 2.622990160787137,
      "grad_norm": 0.38266411423683167,
      "learning_rate": 1.3973333333333332e-05,
      "loss": 1.3434,
      "step": 10930
    },
    {
      "epoch": 2.6253899688024958,
      "grad_norm": 0.31672656536102295,
      "learning_rate": 1.3884444444444444e-05,
      "loss": 1.1321,
      "step": 10940
    },
    {
      "epoch": 2.6277897768178544,
      "grad_norm": 0.3746475279331207,
      "learning_rate": 1.3795555555555557e-05,
      "loss": 1.2156,
      "step": 10950
    },
    {
      "epoch": 2.6277897768178544,
      "eval_loss": 1.2759298086166382,
      "eval_runtime": 3.5321,
      "eval_samples_per_second": 56.623,
      "eval_steps_per_second": 2.548,
      "step": 10950
    },
    {
      "epoch": 2.6301895848332135,
      "grad_norm": 0.4095974564552307,
      "learning_rate": 1.3706666666666667e-05,
      "loss": 1.2691,
      "step": 10960
    },
    {
      "epoch": 2.632589392848572,
      "grad_norm": 0.4071536660194397,
      "learning_rate": 1.361777777777778e-05,
      "loss": 1.2494,
      "step": 10970
    },
    {
      "epoch": 2.634989200863931,
      "grad_norm": 0.35690099000930786,
      "learning_rate": 1.3528888888888888e-05,
      "loss": 1.3205,
      "step": 10980
    },
    {
      "epoch": 2.6373890088792895,
      "grad_norm": 0.3544943034648895,
      "learning_rate": 1.344e-05,
      "loss": 1.2027,
      "step": 10990
    },
    {
      "epoch": 2.639788816894648,
      "grad_norm": 0.346610426902771,
      "learning_rate": 1.3351111111111112e-05,
      "loss": 1.3431,
      "step": 11000
    },
    {
      "epoch": 2.639788816894648,
      "eval_loss": 1.2753387689590454,
      "eval_runtime": 3.5292,
      "eval_samples_per_second": 56.669,
      "eval_steps_per_second": 2.55,
      "step": 11000
    },
    {
      "epoch": 2.6421886249100073,
      "grad_norm": 0.3377327620983124,
      "learning_rate": 1.3262222222222223e-05,
      "loss": 1.2415,
      "step": 11010
    },
    {
      "epoch": 2.644588432925366,
      "grad_norm": 0.33120644092559814,
      "learning_rate": 1.3173333333333335e-05,
      "loss": 1.2809,
      "step": 11020
    },
    {
      "epoch": 2.6469882409407246,
      "grad_norm": 0.30767741799354553,
      "learning_rate": 1.3084444444444447e-05,
      "loss": 1.2132,
      "step": 11030
    },
    {
      "epoch": 2.6493880489560837,
      "grad_norm": 0.3590918481349945,
      "learning_rate": 1.2995555555555556e-05,
      "loss": 1.2548,
      "step": 11040
    },
    {
      "epoch": 2.6517878569714424,
      "grad_norm": 0.4229523837566376,
      "learning_rate": 1.2906666666666666e-05,
      "loss": 1.2917,
      "step": 11050
    },
    {
      "epoch": 2.6517878569714424,
      "eval_loss": 1.2746691703796387,
      "eval_runtime": 3.5333,
      "eval_samples_per_second": 56.605,
      "eval_steps_per_second": 2.547,
      "step": 11050
    },
    {
      "epoch": 2.654187664986801,
      "grad_norm": 0.3438575863838196,
      "learning_rate": 1.2817777777777778e-05,
      "loss": 1.2045,
      "step": 11060
    },
    {
      "epoch": 2.6565874730021597,
      "grad_norm": 0.3616580367088318,
      "learning_rate": 1.272888888888889e-05,
      "loss": 1.2267,
      "step": 11070
    },
    {
      "epoch": 2.6589872810175184,
      "grad_norm": 0.27827414870262146,
      "learning_rate": 1.2640000000000003e-05,
      "loss": 1.168,
      "step": 11080
    },
    {
      "epoch": 2.6613870890328775,
      "grad_norm": 0.3228926956653595,
      "learning_rate": 1.2551111111111111e-05,
      "loss": 1.3595,
      "step": 11090
    },
    {
      "epoch": 2.663786897048236,
      "grad_norm": 0.29492393136024475,
      "learning_rate": 1.2462222222222222e-05,
      "loss": 1.105,
      "step": 11100
    },
    {
      "epoch": 2.663786897048236,
      "eval_loss": 1.2753428220748901,
      "eval_runtime": 3.531,
      "eval_samples_per_second": 56.642,
      "eval_steps_per_second": 2.549,
      "step": 11100
    },
    {
      "epoch": 2.666186705063595,
      "grad_norm": 0.300336629152298,
      "learning_rate": 1.2373333333333334e-05,
      "loss": 1.2057,
      "step": 11110
    },
    {
      "epoch": 2.668586513078954,
      "grad_norm": 0.3834681808948517,
      "learning_rate": 1.2284444444444446e-05,
      "loss": 1.24,
      "step": 11120
    },
    {
      "epoch": 2.6709863210943126,
      "grad_norm": 0.35893985629081726,
      "learning_rate": 1.2195555555555557e-05,
      "loss": 1.2905,
      "step": 11130
    },
    {
      "epoch": 2.673386129109671,
      "grad_norm": 0.3275596797466278,
      "learning_rate": 1.2106666666666667e-05,
      "loss": 1.223,
      "step": 11140
    },
    {
      "epoch": 2.67578593712503,
      "grad_norm": 0.34371548891067505,
      "learning_rate": 1.2017777777777778e-05,
      "loss": 1.2712,
      "step": 11150
    },
    {
      "epoch": 2.67578593712503,
      "eval_loss": 1.2755160331726074,
      "eval_runtime": 3.5333,
      "eval_samples_per_second": 56.604,
      "eval_steps_per_second": 2.547,
      "step": 11150
    },
    {
      "epoch": 2.6781857451403885,
      "grad_norm": 0.3197411596775055,
      "learning_rate": 1.192888888888889e-05,
      "loss": 1.1995,
      "step": 11160
    },
    {
      "epoch": 2.6805855531557476,
      "grad_norm": 0.3898102641105652,
      "learning_rate": 1.1840000000000002e-05,
      "loss": 1.3724,
      "step": 11170
    },
    {
      "epoch": 2.6829853611711063,
      "grad_norm": 0.3208252191543579,
      "learning_rate": 1.175111111111111e-05,
      "loss": 1.1376,
      "step": 11180
    },
    {
      "epoch": 2.685385169186465,
      "grad_norm": 0.34950900077819824,
      "learning_rate": 1.1662222222222223e-05,
      "loss": 1.2544,
      "step": 11190
    },
    {
      "epoch": 2.687784977201824,
      "grad_norm": 0.3208327889442444,
      "learning_rate": 1.1573333333333333e-05,
      "loss": 1.2324,
      "step": 11200
    },
    {
      "epoch": 2.687784977201824,
      "eval_loss": 1.2745319604873657,
      "eval_runtime": 3.5303,
      "eval_samples_per_second": 56.653,
      "eval_steps_per_second": 2.549,
      "step": 11200
    },
    {
      "epoch": 2.6901847852171827,
      "grad_norm": 0.3633638620376587,
      "learning_rate": 1.1484444444444445e-05,
      "loss": 1.2366,
      "step": 11210
    },
    {
      "epoch": 2.6925845932325414,
      "grad_norm": 0.3911115527153015,
      "learning_rate": 1.1395555555555556e-05,
      "loss": 1.3102,
      "step": 11220
    },
    {
      "epoch": 2.6949844012479,
      "grad_norm": 0.3815138339996338,
      "learning_rate": 1.1306666666666666e-05,
      "loss": 1.2593,
      "step": 11230
    },
    {
      "epoch": 2.6973842092632587,
      "grad_norm": 0.4043257534503937,
      "learning_rate": 1.1217777777777778e-05,
      "loss": 1.2569,
      "step": 11240
    },
    {
      "epoch": 2.699784017278618,
      "grad_norm": 0.3731943666934967,
      "learning_rate": 1.112888888888889e-05,
      "loss": 1.2822,
      "step": 11250
    },
    {
      "epoch": 2.699784017278618,
      "eval_loss": 1.2751966714859009,
      "eval_runtime": 3.5311,
      "eval_samples_per_second": 56.639,
      "eval_steps_per_second": 2.549,
      "step": 11250
    },
    {
      "epoch": 2.7021838252939765,
      "grad_norm": 0.31049424409866333,
      "learning_rate": 1.1040000000000001e-05,
      "loss": 1.1973,
      "step": 11260
    },
    {
      "epoch": 2.704583633309335,
      "grad_norm": 0.32284238934516907,
      "learning_rate": 1.0951111111111111e-05,
      "loss": 1.1971,
      "step": 11270
    },
    {
      "epoch": 2.7069834413246943,
      "grad_norm": 0.3628975450992584,
      "learning_rate": 1.0862222222222222e-05,
      "loss": 1.3442,
      "step": 11280
    },
    {
      "epoch": 2.709383249340053,
      "grad_norm": 0.37116539478302,
      "learning_rate": 1.0773333333333334e-05,
      "loss": 1.1982,
      "step": 11290
    },
    {
      "epoch": 2.7117830573554116,
      "grad_norm": 0.37473052740097046,
      "learning_rate": 1.0684444444444446e-05,
      "loss": 1.3422,
      "step": 11300
    },
    {
      "epoch": 2.7117830573554116,
      "eval_loss": 1.2750920057296753,
      "eval_runtime": 3.5294,
      "eval_samples_per_second": 56.667,
      "eval_steps_per_second": 2.55,
      "step": 11300
    },
    {
      "epoch": 2.7141828653707702,
      "grad_norm": 0.3408684730529785,
      "learning_rate": 1.0595555555555555e-05,
      "loss": 1.2357,
      "step": 11310
    },
    {
      "epoch": 2.716582673386129,
      "grad_norm": 0.2974463701248169,
      "learning_rate": 1.0506666666666667e-05,
      "loss": 1.3034,
      "step": 11320
    },
    {
      "epoch": 2.718982481401488,
      "grad_norm": 0.3470940887928009,
      "learning_rate": 1.0417777777777778e-05,
      "loss": 1.2415,
      "step": 11330
    },
    {
      "epoch": 2.7213822894168467,
      "grad_norm": 0.3071689307689667,
      "learning_rate": 1.032888888888889e-05,
      "loss": 1.3037,
      "step": 11340
    },
    {
      "epoch": 2.7237820974322053,
      "grad_norm": 0.32091954350471497,
      "learning_rate": 1.024e-05,
      "loss": 1.2427,
      "step": 11350
    },
    {
      "epoch": 2.7237820974322053,
      "eval_loss": 1.2745169401168823,
      "eval_runtime": 3.5287,
      "eval_samples_per_second": 56.678,
      "eval_steps_per_second": 2.55,
      "step": 11350
    },
    {
      "epoch": 2.7261819054475644,
      "grad_norm": 0.4467129111289978,
      "learning_rate": 1.015111111111111e-05,
      "loss": 1.1235,
      "step": 11360
    },
    {
      "epoch": 2.728581713462923,
      "grad_norm": 0.350492000579834,
      "learning_rate": 1.0062222222222223e-05,
      "loss": 1.2994,
      "step": 11370
    },
    {
      "epoch": 2.7309815214782818,
      "grad_norm": 0.38252341747283936,
      "learning_rate": 9.973333333333333e-06,
      "loss": 1.2277,
      "step": 11380
    },
    {
      "epoch": 2.7333813294936404,
      "grad_norm": 0.37775248289108276,
      "learning_rate": 9.884444444444445e-06,
      "loss": 1.308,
      "step": 11390
    },
    {
      "epoch": 2.735781137508999,
      "grad_norm": 0.3619266152381897,
      "learning_rate": 9.795555555555556e-06,
      "loss": 1.3254,
      "step": 11400
    },
    {
      "epoch": 2.735781137508999,
      "eval_loss": 1.2745263576507568,
      "eval_runtime": 3.5289,
      "eval_samples_per_second": 56.675,
      "eval_steps_per_second": 2.55,
      "step": 11400
    },
    {
      "epoch": 2.738180945524358,
      "grad_norm": 0.3256099820137024,
      "learning_rate": 9.706666666666666e-06,
      "loss": 1.2942,
      "step": 11410
    },
    {
      "epoch": 2.740580753539717,
      "grad_norm": 0.3096865713596344,
      "learning_rate": 9.617777777777778e-06,
      "loss": 1.2458,
      "step": 11420
    },
    {
      "epoch": 2.7429805615550755,
      "grad_norm": 0.32061368227005005,
      "learning_rate": 9.52888888888889e-06,
      "loss": 1.2419,
      "step": 11430
    },
    {
      "epoch": 2.7453803695704346,
      "grad_norm": 0.35650163888931274,
      "learning_rate": 9.44e-06,
      "loss": 1.2742,
      "step": 11440
    },
    {
      "epoch": 2.7477801775857933,
      "grad_norm": 0.3723407983779907,
      "learning_rate": 9.351111111111112e-06,
      "loss": 1.2355,
      "step": 11450
    },
    {
      "epoch": 2.7477801775857933,
      "eval_loss": 1.2744476795196533,
      "eval_runtime": 3.5312,
      "eval_samples_per_second": 56.638,
      "eval_steps_per_second": 2.549,
      "step": 11450
    },
    {
      "epoch": 2.750179985601152,
      "grad_norm": 0.2934977114200592,
      "learning_rate": 9.262222222222222e-06,
      "loss": 1.2319,
      "step": 11460
    },
    {
      "epoch": 2.7525797936165106,
      "grad_norm": 0.36269354820251465,
      "learning_rate": 9.173333333333334e-06,
      "loss": 1.2349,
      "step": 11470
    },
    {
      "epoch": 2.7549796016318693,
      "grad_norm": 0.37946680188179016,
      "learning_rate": 9.084444444444445e-06,
      "loss": 1.3058,
      "step": 11480
    },
    {
      "epoch": 2.7573794096472284,
      "grad_norm": 0.36847975850105286,
      "learning_rate": 8.995555555555555e-06,
      "loss": 1.2305,
      "step": 11490
    },
    {
      "epoch": 2.759779217662587,
      "grad_norm": 0.33008691668510437,
      "learning_rate": 8.906666666666667e-06,
      "loss": 1.222,
      "step": 11500
    },
    {
      "epoch": 2.759779217662587,
      "eval_loss": 1.2745163440704346,
      "eval_runtime": 3.5309,
      "eval_samples_per_second": 56.643,
      "eval_steps_per_second": 2.549,
      "step": 11500
    },
    {
      "epoch": 2.7621790256779457,
      "grad_norm": 0.37011095881462097,
      "learning_rate": 8.817777777777778e-06,
      "loss": 1.3509,
      "step": 11510
    },
    {
      "epoch": 2.7645788336933044,
      "grad_norm": 0.37422269582748413,
      "learning_rate": 8.72888888888889e-06,
      "loss": 1.322,
      "step": 11520
    },
    {
      "epoch": 2.766978641708663,
      "grad_norm": 0.32078585028648376,
      "learning_rate": 8.64e-06,
      "loss": 1.2237,
      "step": 11530
    },
    {
      "epoch": 2.769378449724022,
      "grad_norm": 0.2955359220504761,
      "learning_rate": 8.55111111111111e-06,
      "loss": 1.2904,
      "step": 11540
    },
    {
      "epoch": 2.771778257739381,
      "grad_norm": 0.33662018179893494,
      "learning_rate": 8.462222222222223e-06,
      "loss": 1.2044,
      "step": 11550
    },
    {
      "epoch": 2.771778257739381,
      "eval_loss": 1.2748435735702515,
      "eval_runtime": 3.5304,
      "eval_samples_per_second": 56.651,
      "eval_steps_per_second": 2.549,
      "step": 11550
    },
    {
      "epoch": 2.7741780657547395,
      "grad_norm": 0.3031269609928131,
      "learning_rate": 8.373333333333335e-06,
      "loss": 1.2264,
      "step": 11560
    },
    {
      "epoch": 2.7765778737700986,
      "grad_norm": 0.3139294385910034,
      "learning_rate": 8.284444444444446e-06,
      "loss": 1.1723,
      "step": 11570
    },
    {
      "epoch": 2.7789776817854572,
      "grad_norm": 0.33534178137779236,
      "learning_rate": 8.195555555555556e-06,
      "loss": 1.3074,
      "step": 11580
    },
    {
      "epoch": 2.781377489800816,
      "grad_norm": 0.3075105547904968,
      "learning_rate": 8.106666666666666e-06,
      "loss": 1.3271,
      "step": 11590
    },
    {
      "epoch": 2.7837772978161746,
      "grad_norm": 0.3355575203895569,
      "learning_rate": 8.017777777777779e-06,
      "loss": 1.2881,
      "step": 11600
    },
    {
      "epoch": 2.7837772978161746,
      "eval_loss": 1.2742997407913208,
      "eval_runtime": 3.5302,
      "eval_samples_per_second": 56.654,
      "eval_steps_per_second": 2.549,
      "step": 11600
    },
    {
      "epoch": 2.786177105831533,
      "grad_norm": 0.35961204767227173,
      "learning_rate": 7.928888888888889e-06,
      "loss": 1.291,
      "step": 11610
    },
    {
      "epoch": 2.7885769138468923,
      "grad_norm": 0.3248665928840637,
      "learning_rate": 7.84e-06,
      "loss": 1.2262,
      "step": 11620
    },
    {
      "epoch": 2.790976721862251,
      "grad_norm": 0.39061591029167175,
      "learning_rate": 7.751111111111112e-06,
      "loss": 1.3023,
      "step": 11630
    },
    {
      "epoch": 2.7933765298776096,
      "grad_norm": 0.29990875720977783,
      "learning_rate": 7.662222222222222e-06,
      "loss": 1.2098,
      "step": 11640
    },
    {
      "epoch": 2.7957763378929688,
      "grad_norm": 0.3552229702472687,
      "learning_rate": 7.573333333333333e-06,
      "loss": 1.2005,
      "step": 11650
    },
    {
      "epoch": 2.7957763378929688,
      "eval_loss": 1.273855447769165,
      "eval_runtime": 3.5281,
      "eval_samples_per_second": 56.688,
      "eval_steps_per_second": 2.551,
      "step": 11650
    },
    {
      "epoch": 2.7981761459083274,
      "grad_norm": 0.37964296340942383,
      "learning_rate": 7.4844444444444455e-06,
      "loss": 1.2052,
      "step": 11660
    },
    {
      "epoch": 2.800575953923686,
      "grad_norm": 0.41572192311286926,
      "learning_rate": 7.395555555555556e-06,
      "loss": 1.2138,
      "step": 11670
    },
    {
      "epoch": 2.8029757619390447,
      "grad_norm": 0.3431317210197449,
      "learning_rate": 7.306666666666667e-06,
      "loss": 1.2069,
      "step": 11680
    },
    {
      "epoch": 2.8053755699544034,
      "grad_norm": 0.296091228723526,
      "learning_rate": 7.217777777777778e-06,
      "loss": 1.2849,
      "step": 11690
    },
    {
      "epoch": 2.8077753779697625,
      "grad_norm": 0.3526875972747803,
      "learning_rate": 7.128888888888889e-06,
      "loss": 1.2951,
      "step": 11700
    },
    {
      "epoch": 2.8077753779697625,
      "eval_loss": 1.274422526359558,
      "eval_runtime": 3.5307,
      "eval_samples_per_second": 56.647,
      "eval_steps_per_second": 2.549,
      "step": 11700
    },
    {
      "epoch": 2.810175185985121,
      "grad_norm": 0.36011093854904175,
      "learning_rate": 7.04e-06,
      "loss": 1.2785,
      "step": 11710
    },
    {
      "epoch": 2.81257499400048,
      "grad_norm": 0.3697180151939392,
      "learning_rate": 6.951111111111111e-06,
      "loss": 1.2378,
      "step": 11720
    },
    {
      "epoch": 2.814974802015839,
      "grad_norm": 0.34261155128479004,
      "learning_rate": 6.862222222222223e-06,
      "loss": 1.1995,
      "step": 11730
    },
    {
      "epoch": 2.8173746100311976,
      "grad_norm": 0.3644919693470001,
      "learning_rate": 6.773333333333334e-06,
      "loss": 1.2085,
      "step": 11740
    },
    {
      "epoch": 2.8197744180465563,
      "grad_norm": 0.29924118518829346,
      "learning_rate": 6.684444444444445e-06,
      "loss": 1.3518,
      "step": 11750
    },
    {
      "epoch": 2.8197744180465563,
      "eval_loss": 1.2741484642028809,
      "eval_runtime": 3.531,
      "eval_samples_per_second": 56.64,
      "eval_steps_per_second": 2.549,
      "step": 11750
    },
    {
      "epoch": 2.822174226061915,
      "grad_norm": 0.2989620864391327,
      "learning_rate": 6.595555555555556e-06,
      "loss": 1.2463,
      "step": 11760
    },
    {
      "epoch": 2.8245740340772736,
      "grad_norm": 0.3300870954990387,
      "learning_rate": 6.5066666666666665e-06,
      "loss": 1.1928,
      "step": 11770
    },
    {
      "epoch": 2.8269738420926327,
      "grad_norm": 0.32461416721343994,
      "learning_rate": 6.417777777777778e-06,
      "loss": 1.3082,
      "step": 11780
    },
    {
      "epoch": 2.8293736501079914,
      "grad_norm": 0.294143408536911,
      "learning_rate": 6.32888888888889e-06,
      "loss": 1.1901,
      "step": 11790
    },
    {
      "epoch": 2.83177345812335,
      "grad_norm": 0.352705180644989,
      "learning_rate": 6.24e-06,
      "loss": 1.2805,
      "step": 11800
    },
    {
      "epoch": 2.83177345812335,
      "eval_loss": 1.274093747138977,
      "eval_runtime": 3.5329,
      "eval_samples_per_second": 56.61,
      "eval_steps_per_second": 2.547,
      "step": 11800
    },
    {
      "epoch": 2.834173266138709,
      "grad_norm": 0.43438035249710083,
      "learning_rate": 6.151111111111112e-06,
      "loss": 1.3243,
      "step": 11810
    },
    {
      "epoch": 2.836573074154068,
      "grad_norm": 0.32217058539390564,
      "learning_rate": 6.062222222222223e-06,
      "loss": 1.3345,
      "step": 11820
    },
    {
      "epoch": 2.8389728821694264,
      "grad_norm": 0.2967686355113983,
      "learning_rate": 5.9733333333333335e-06,
      "loss": 1.2078,
      "step": 11830
    },
    {
      "epoch": 2.841372690184785,
      "grad_norm": 0.3890146315097809,
      "learning_rate": 5.884444444444445e-06,
      "loss": 1.2251,
      "step": 11840
    },
    {
      "epoch": 2.8437724982001438,
      "grad_norm": 0.3646765649318695,
      "learning_rate": 5.795555555555556e-06,
      "loss": 1.2718,
      "step": 11850
    },
    {
      "epoch": 2.8437724982001438,
      "eval_loss": 1.2735161781311035,
      "eval_runtime": 3.5293,
      "eval_samples_per_second": 56.668,
      "eval_steps_per_second": 2.55,
      "step": 11850
    },
    {
      "epoch": 2.846172306215503,
      "grad_norm": 0.3285382091999054,
      "learning_rate": 5.706666666666667e-06,
      "loss": 1.3381,
      "step": 11860
    },
    {
      "epoch": 2.8485721142308615,
      "grad_norm": 0.29542773962020874,
      "learning_rate": 5.617777777777778e-06,
      "loss": 1.2591,
      "step": 11870
    },
    {
      "epoch": 2.85097192224622,
      "grad_norm": 0.5012708306312561,
      "learning_rate": 5.528888888888889e-06,
      "loss": 1.3684,
      "step": 11880
    },
    {
      "epoch": 2.8533717302615793,
      "grad_norm": 0.3240232765674591,
      "learning_rate": 5.44e-06,
      "loss": 1.2399,
      "step": 11890
    },
    {
      "epoch": 2.855771538276938,
      "grad_norm": 0.3625473380088806,
      "learning_rate": 5.351111111111112e-06,
      "loss": 1.2104,
      "step": 11900
    },
    {
      "epoch": 2.855771538276938,
      "eval_loss": 1.2737692594528198,
      "eval_runtime": 3.5313,
      "eval_samples_per_second": 56.636,
      "eval_steps_per_second": 2.549,
      "step": 11900
    },
    {
      "epoch": 2.8581713462922966,
      "grad_norm": 0.397241473197937,
      "learning_rate": 5.262222222222222e-06,
      "loss": 1.3192,
      "step": 11910
    },
    {
      "epoch": 2.8605711543076553,
      "grad_norm": 0.3541160523891449,
      "learning_rate": 5.1733333333333335e-06,
      "loss": 1.1835,
      "step": 11920
    },
    {
      "epoch": 2.862970962323014,
      "grad_norm": 0.3706960678100586,
      "learning_rate": 5.084444444444445e-06,
      "loss": 1.1257,
      "step": 11930
    },
    {
      "epoch": 2.865370770338373,
      "grad_norm": 0.3948012888431549,
      "learning_rate": 4.995555555555556e-06,
      "loss": 1.2525,
      "step": 11940
    },
    {
      "epoch": 2.8677705783537317,
      "grad_norm": 0.4109523892402649,
      "learning_rate": 4.906666666666667e-06,
      "loss": 1.3188,
      "step": 11950
    },
    {
      "epoch": 2.8677705783537317,
      "eval_loss": 1.2738381624221802,
      "eval_runtime": 3.5388,
      "eval_samples_per_second": 56.517,
      "eval_steps_per_second": 2.543,
      "step": 11950
    },
    {
      "epoch": 2.8701703863690904,
      "grad_norm": 0.3453289866447449,
      "learning_rate": 4.817777777777778e-06,
      "loss": 1.1574,
      "step": 11960
    },
    {
      "epoch": 2.8725701943844495,
      "grad_norm": 0.6444039940834045,
      "learning_rate": 4.728888888888889e-06,
      "loss": 1.309,
      "step": 11970
    },
    {
      "epoch": 2.874970002399808,
      "grad_norm": 0.34246060252189636,
      "learning_rate": 4.64e-06,
      "loss": 1.2246,
      "step": 11980
    },
    {
      "epoch": 2.877369810415167,
      "grad_norm": 0.3442760109901428,
      "learning_rate": 4.551111111111112e-06,
      "loss": 1.209,
      "step": 11990
    },
    {
      "epoch": 2.8797696184305255,
      "grad_norm": 0.4110427498817444,
      "learning_rate": 4.462222222222222e-06,
      "loss": 1.2135,
      "step": 12000
    },
    {
      "epoch": 2.8797696184305255,
      "eval_loss": 1.273701786994934,
      "eval_runtime": 3.5304,
      "eval_samples_per_second": 56.65,
      "eval_steps_per_second": 2.549,
      "step": 12000
    },
    {
      "epoch": 2.882169426445884,
      "grad_norm": 0.3432770073413849,
      "learning_rate": 4.3733333333333335e-06,
      "loss": 1.2588,
      "step": 12010
    },
    {
      "epoch": 2.8845692344612432,
      "grad_norm": 0.36361175775527954,
      "learning_rate": 4.284444444444444e-06,
      "loss": 1.3286,
      "step": 12020
    },
    {
      "epoch": 2.886969042476602,
      "grad_norm": 0.36693987250328064,
      "learning_rate": 4.195555555555556e-06,
      "loss": 1.1332,
      "step": 12030
    },
    {
      "epoch": 2.8893688504919606,
      "grad_norm": 0.3486575186252594,
      "learning_rate": 4.106666666666667e-06,
      "loss": 1.2336,
      "step": 12040
    },
    {
      "epoch": 2.8917686585073197,
      "grad_norm": 0.3520340621471405,
      "learning_rate": 4.017777777777778e-06,
      "loss": 1.234,
      "step": 12050
    },
    {
      "epoch": 2.8917686585073197,
      "eval_loss": 1.2737226486206055,
      "eval_runtime": 3.5299,
      "eval_samples_per_second": 56.658,
      "eval_steps_per_second": 2.55,
      "step": 12050
    },
    {
      "epoch": 2.8941684665226783,
      "grad_norm": 0.3196832835674286,
      "learning_rate": 3.928888888888889e-06,
      "loss": 1.3053,
      "step": 12060
    },
    {
      "epoch": 2.896568274538037,
      "grad_norm": 0.3457436263561249,
      "learning_rate": 3.84e-06,
      "loss": 1.233,
      "step": 12070
    },
    {
      "epoch": 2.8989680825533957,
      "grad_norm": 0.3432944715023041,
      "learning_rate": 3.7511111111111114e-06,
      "loss": 1.1931,
      "step": 12080
    },
    {
      "epoch": 2.9013678905687543,
      "grad_norm": 0.33575302362442017,
      "learning_rate": 3.6622222222222223e-06,
      "loss": 1.316,
      "step": 12090
    },
    {
      "epoch": 2.9037676985841134,
      "grad_norm": 0.2869761288166046,
      "learning_rate": 3.5733333333333336e-06,
      "loss": 1.1908,
      "step": 12100
    },
    {
      "epoch": 2.9037676985841134,
      "eval_loss": 1.27367103099823,
      "eval_runtime": 3.5314,
      "eval_samples_per_second": 56.635,
      "eval_steps_per_second": 2.549,
      "step": 12100
    },
    {
      "epoch": 2.906167506599472,
      "grad_norm": 0.35710522532463074,
      "learning_rate": 3.4844444444444444e-06,
      "loss": 1.2746,
      "step": 12110
    },
    {
      "epoch": 2.9085673146148308,
      "grad_norm": 0.33861401677131653,
      "learning_rate": 3.395555555555556e-06,
      "loss": 1.1568,
      "step": 12120
    },
    {
      "epoch": 2.9109671226301894,
      "grad_norm": 0.30952370166778564,
      "learning_rate": 3.306666666666667e-06,
      "loss": 1.2633,
      "step": 12130
    },
    {
      "epoch": 2.913366930645548,
      "grad_norm": 0.3207652270793915,
      "learning_rate": 3.217777777777778e-06,
      "loss": 1.2474,
      "step": 12140
    },
    {
      "epoch": 2.915766738660907,
      "grad_norm": 0.3775549829006195,
      "learning_rate": 3.128888888888889e-06,
      "loss": 1.2337,
      "step": 12150
    },
    {
      "epoch": 2.915766738660907,
      "eval_loss": 1.2737529277801514,
      "eval_runtime": 3.5289,
      "eval_samples_per_second": 56.674,
      "eval_steps_per_second": 2.55,
      "step": 12150
    },
    {
      "epoch": 2.918166546676266,
      "grad_norm": 0.3638303875923157,
      "learning_rate": 3.04e-06,
      "loss": 1.2121,
      "step": 12160
    },
    {
      "epoch": 2.9205663546916245,
      "grad_norm": 0.35871875286102295,
      "learning_rate": 2.951111111111111e-06,
      "loss": 1.3656,
      "step": 12170
    },
    {
      "epoch": 2.9229661627069836,
      "grad_norm": 0.32911890745162964,
      "learning_rate": 2.8622222222222223e-06,
      "loss": 1.2325,
      "step": 12180
    },
    {
      "epoch": 2.9253659707223423,
      "grad_norm": 0.4148510694503784,
      "learning_rate": 2.773333333333333e-06,
      "loss": 1.367,
      "step": 12190
    },
    {
      "epoch": 2.927765778737701,
      "grad_norm": 0.3876512348651886,
      "learning_rate": 2.6844444444444445e-06,
      "loss": 1.2326,
      "step": 12200
    },
    {
      "epoch": 2.927765778737701,
      "eval_loss": 1.2736438512802124,
      "eval_runtime": 3.5324,
      "eval_samples_per_second": 56.619,
      "eval_steps_per_second": 2.548,
      "step": 12200
    },
    {
      "epoch": 2.9301655867530596,
      "grad_norm": 0.3863348960876465,
      "learning_rate": 2.5955555555555558e-06,
      "loss": 1.2652,
      "step": 12210
    },
    {
      "epoch": 2.9325653947684183,
      "grad_norm": 0.3307357132434845,
      "learning_rate": 2.506666666666667e-06,
      "loss": 1.214,
      "step": 12220
    },
    {
      "epoch": 2.9349652027837774,
      "grad_norm": 0.3195914626121521,
      "learning_rate": 2.417777777777778e-06,
      "loss": 1.2827,
      "step": 12230
    },
    {
      "epoch": 2.937365010799136,
      "grad_norm": 0.40416935086250305,
      "learning_rate": 2.3288888888888893e-06,
      "loss": 1.2771,
      "step": 12240
    },
    {
      "epoch": 2.9397648188144947,
      "grad_norm": 0.38210171461105347,
      "learning_rate": 2.24e-06,
      "loss": 1.2584,
      "step": 12250
    },
    {
      "epoch": 2.9397648188144947,
      "eval_loss": 1.2738031148910522,
      "eval_runtime": 3.5312,
      "eval_samples_per_second": 56.638,
      "eval_steps_per_second": 2.549,
      "step": 12250
    },
    {
      "epoch": 2.942164626829854,
      "grad_norm": 0.3193931579589844,
      "learning_rate": 2.1511111111111115e-06,
      "loss": 1.2555,
      "step": 12260
    },
    {
      "epoch": 2.9445644348452125,
      "grad_norm": 0.42433616518974304,
      "learning_rate": 2.0622222222222223e-06,
      "loss": 1.2219,
      "step": 12270
    },
    {
      "epoch": 2.946964242860571,
      "grad_norm": 0.39194434881210327,
      "learning_rate": 1.9733333333333332e-06,
      "loss": 1.3168,
      "step": 12280
    },
    {
      "epoch": 2.94936405087593,
      "grad_norm": 0.3769737482070923,
      "learning_rate": 1.8844444444444445e-06,
      "loss": 1.2733,
      "step": 12290
    },
    {
      "epoch": 2.9517638588912885,
      "grad_norm": 0.3216787278652191,
      "learning_rate": 1.7955555555555556e-06,
      "loss": 1.2962,
      "step": 12300
    },
    {
      "epoch": 2.9517638588912885,
      "eval_loss": 1.2738137245178223,
      "eval_runtime": 3.5312,
      "eval_samples_per_second": 56.638,
      "eval_steps_per_second": 2.549,
      "step": 12300
    },
    {
      "epoch": 2.9541636669066476,
      "grad_norm": 0.3113343119621277,
      "learning_rate": 1.706666666666667e-06,
      "loss": 1.1854,
      "step": 12310
    },
    {
      "epoch": 2.956563474922006,
      "grad_norm": 0.32184818387031555,
      "learning_rate": 1.6177777777777778e-06,
      "loss": 1.2218,
      "step": 12320
    },
    {
      "epoch": 2.958963282937365,
      "grad_norm": 0.3636856973171234,
      "learning_rate": 1.5288888888888889e-06,
      "loss": 1.3972,
      "step": 12330
    },
    {
      "epoch": 2.961363090952724,
      "grad_norm": 0.3224107623100281,
      "learning_rate": 1.44e-06,
      "loss": 1.1857,
      "step": 12340
    },
    {
      "epoch": 2.9637628989680826,
      "grad_norm": 0.36817148327827454,
      "learning_rate": 1.351111111111111e-06,
      "loss": 1.2541,
      "step": 12350
    },
    {
      "epoch": 2.9637628989680826,
      "eval_loss": 1.2737621068954468,
      "eval_runtime": 3.533,
      "eval_samples_per_second": 56.608,
      "eval_steps_per_second": 2.547,
      "step": 12350
    },
    {
      "epoch": 2.9661627069834413,
      "grad_norm": 0.3234538435935974,
      "learning_rate": 1.2622222222222224e-06,
      "loss": 1.1633,
      "step": 12360
    },
    {
      "epoch": 2.9685625149988,
      "grad_norm": 0.36427465081214905,
      "learning_rate": 1.1733333333333335e-06,
      "loss": 1.3656,
      "step": 12370
    },
    {
      "epoch": 2.9709623230141586,
      "grad_norm": 0.31860223412513733,
      "learning_rate": 1.0844444444444446e-06,
      "loss": 1.2158,
      "step": 12380
    },
    {
      "epoch": 2.9733621310295177,
      "grad_norm": 0.3626091480255127,
      "learning_rate": 9.955555555555556e-07,
      "loss": 1.2917,
      "step": 12390
    },
    {
      "epoch": 2.9757619390448764,
      "grad_norm": 0.32657745480537415,
      "learning_rate": 9.066666666666667e-07,
      "loss": 1.1803,
      "step": 12400
    },
    {
      "epoch": 2.9757619390448764,
      "eval_loss": 1.2734639644622803,
      "eval_runtime": 3.5311,
      "eval_samples_per_second": 56.64,
      "eval_steps_per_second": 2.549,
      "step": 12400
    },
    {
      "epoch": 2.978161747060235,
      "grad_norm": 0.3192937970161438,
      "learning_rate": 8.177777777777779e-07,
      "loss": 1.2836,
      "step": 12410
    },
    {
      "epoch": 2.980561555075594,
      "grad_norm": 0.31558066606521606,
      "learning_rate": 7.288888888888889e-07,
      "loss": 1.2212,
      "step": 12420
    },
    {
      "epoch": 2.982961363090953,
      "grad_norm": 0.3939146399497986,
      "learning_rate": 6.4e-07,
      "loss": 1.3214,
      "step": 12430
    },
    {
      "epoch": 2.9853611711063115,
      "grad_norm": 0.4010111689567566,
      "learning_rate": 5.511111111111111e-07,
      "loss": 1.329,
      "step": 12440
    },
    {
      "epoch": 2.98776097912167,
      "grad_norm": 0.3634653389453888,
      "learning_rate": 4.6222222222222225e-07,
      "loss": 1.2232,
      "step": 12450
    },
    {
      "epoch": 2.98776097912167,
      "eval_loss": 1.2738016843795776,
      "eval_runtime": 3.5321,
      "eval_samples_per_second": 56.624,
      "eval_steps_per_second": 2.548,
      "step": 12450
    },
    {
      "epoch": 2.990160787137029,
      "grad_norm": 0.3137797713279724,
      "learning_rate": 3.7333333333333334e-07,
      "loss": 1.1852,
      "step": 12460
    },
    {
      "epoch": 2.992560595152388,
      "grad_norm": 0.385113000869751,
      "learning_rate": 2.844444444444445e-07,
      "loss": 1.2752,
      "step": 12470
    },
    {
      "epoch": 2.9949604031677466,
      "grad_norm": 0.3789392113685608,
      "learning_rate": 1.9555555555555555e-07,
      "loss": 1.2014,
      "step": 12480
    },
    {
      "epoch": 2.9973602111831052,
      "grad_norm": 0.3731553554534912,
      "learning_rate": 1.0666666666666668e-07,
      "loss": 1.3197,
      "step": 12490
    },
    {
      "epoch": 2.9997600191984644,
      "grad_norm": 0.3384092152118683,
      "learning_rate": 1.777777777777778e-08,
      "loss": 1.2267,
      "step": 12500
    },
    {
      "epoch": 2.9997600191984644,
      "eval_loss": 1.2736436128616333,
      "eval_runtime": 3.5298,
      "eval_samples_per_second": 56.66,
      "eval_steps_per_second": 2.55,
      "step": 12500
    }
  ],
  "logging_steps": 10,
  "max_steps": 12501,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 9.14898419712e+16,
  "train_batch_size": 24,
  "trial_name": null,
  "trial_params": null
}
