{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.6303501945525292,
  "eval_steps": 100,
  "global_step": 4400,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00037057624606262737,
      "grad_norm": 57.76443862915039,
      "learning_rate": 0.0,
      "loss": 37.7325,
      "step": 1
    },
    {
      "epoch": 0.03705762460626274,
      "grad_norm": 9.442436218261719,
      "learning_rate": 1.4677538917716829e-05,
      "loss": 31.9177,
      "step": 100
    },
    {
      "epoch": 0.07411524921252548,
      "grad_norm": 7.211108684539795,
      "learning_rate": 2.9503335804299483e-05,
      "loss": 22.3867,
      "step": 200
    },
    {
      "epoch": 0.11117287381878821,
      "grad_norm": 6.508985996246338,
      "learning_rate": 4.4329132690882135e-05,
      "loss": 21.5887,
      "step": 300
    },
    {
      "epoch": 0.14823049842505095,
      "grad_norm": 6.909822940826416,
      "learning_rate": 5.915492957746479e-05,
      "loss": 21.1742,
      "step": 400
    },
    {
      "epoch": 0.1852881230313137,
      "grad_norm": 6.174595832824707,
      "learning_rate": 7.398072646404744e-05,
      "loss": 20.8844,
      "step": 500
    },
    {
      "epoch": 0.22234574763757642,
      "grad_norm": 6.801006317138672,
      "learning_rate": 8.88065233506301e-05,
      "loss": 20.8547,
      "step": 600
    },
    {
      "epoch": 0.2594033722438392,
      "grad_norm": 5.8148064613342285,
      "learning_rate": 0.00010363232023721276,
      "loss": 20.6898,
      "step": 700
    },
    {
      "epoch": 0.2964609968501019,
      "grad_norm": 6.194868564605713,
      "learning_rate": 0.00011845811712379541,
      "loss": 20.4348,
      "step": 800
    },
    {
      "epoch": 0.33351862145636463,
      "grad_norm": 5.57415771484375,
      "learning_rate": 0.00013328391401037806,
      "loss": 20.3346,
      "step": 900
    },
    {
      "epoch": 0.3705762460626274,
      "grad_norm": 6.431851387023926,
      "learning_rate": 0.00014810971089696074,
      "loss": 20.2337,
      "step": 1000
    },
    {
      "epoch": 0.4076338706688901,
      "grad_norm": 6.378411293029785,
      "learning_rate": 0.0001629355077835434,
      "loss": 20.1625,
      "step": 1100
    },
    {
      "epoch": 0.44469149527515284,
      "grad_norm": 5.308300971984863,
      "learning_rate": 0.00017776130467012604,
      "loss": 20.1163,
      "step": 1200
    },
    {
      "epoch": 0.4817491198814156,
      "grad_norm": 4.748579502105713,
      "learning_rate": 0.00019258710155670869,
      "loss": 20.0015,
      "step": 1300
    },
    {
      "epoch": 0.5188067444876784,
      "grad_norm": 4.986832618713379,
      "learning_rate": 0.000199991637480341,
      "loss": 19.8945,
      "step": 1400
    },
    {
      "epoch": 0.5558643690939411,
      "grad_norm": 5.016798496246338,
      "learning_rate": 0.00019992474571464328,
      "loss": 19.8511,
      "step": 1500
    },
    {
      "epoch": 0.5929219937002038,
      "grad_norm": 4.668355464935303,
      "learning_rate": 0.0001997910069320731,
      "loss": 19.7855,
      "step": 1600
    },
    {
      "epoch": 0.6299796183064665,
      "grad_norm": 4.786577224731445,
      "learning_rate": 0.00019959051060034538,
      "loss": 19.802,
      "step": 1700
    },
    {
      "epoch": 0.6670372429127293,
      "grad_norm": 4.607687473297119,
      "learning_rate": 0.00019932339084621287,
      "loss": 19.6271,
      "step": 1800
    },
    {
      "epoch": 0.7040948675189921,
      "grad_norm": 4.700197696685791,
      "learning_rate": 0.00019898982636573919,
      "loss": 19.5742,
      "step": 1900
    },
    {
      "epoch": 0.7411524921252548,
      "grad_norm": 4.601294994354248,
      "learning_rate": 0.0001985900403047556,
      "loss": 19.5824,
      "step": 2000
    },
    {
      "epoch": 0.7782101167315175,
      "grad_norm": 4.671125888824463,
      "learning_rate": 0.00019812430010958268,
      "loss": 19.5958,
      "step": 2100
    },
    {
      "epoch": 0.8152677413377802,
      "grad_norm": 4.047983646392822,
      "learning_rate": 0.00019759291734811535,
      "loss": 19.4729,
      "step": 2200
    },
    {
      "epoch": 0.852325365944043,
      "grad_norm": 4.564198970794678,
      "learning_rate": 0.00019699624750139263,
      "loss": 19.4018,
      "step": 2300
    },
    {
      "epoch": 0.8893829905503057,
      "grad_norm": 4.958205699920654,
      "learning_rate": 0.00019633468972578982,
      "loss": 19.4329,
      "step": 2400
    },
    {
      "epoch": 0.9264406151565685,
      "grad_norm": 4.60046911239624,
      "learning_rate": 0.00019560868658599382,
      "loss": 19.4265,
      "step": 2500
    },
    {
      "epoch": 0.9634982397628312,
      "grad_norm": 4.765743255615234,
      "learning_rate": 0.00019481872375893858,
      "loss": 19.3809,
      "step": 2600
    },
    {
      "epoch": 1.0003705762460626,
      "grad_norm": 4.732804298400879,
      "learning_rate": 0.00019396532970890042,
      "loss": 19.2323,
      "step": 2700
    },
    {
      "epoch": 1.0374282008523255,
      "grad_norm": 4.554471015930176,
      "learning_rate": 0.00019304907533396927,
      "loss": 19.2153,
      "step": 2800
    },
    {
      "epoch": 1.074485825458588,
      "grad_norm": 4.405435562133789,
      "learning_rate": 0.00019207057358413285,
      "loss": 19.1436,
      "step": 2900
    },
    {
      "epoch": 1.111543450064851,
      "grad_norm": 5.244962215423584,
      "learning_rate": 0.00019103047905122937,
      "loss": 19.1225,
      "step": 3000
    },
    {
      "epoch": 1.1486010746711135,
      "grad_norm": 4.4846720695495605,
      "learning_rate": 0.00018992948753104288,
      "loss": 19.0773,
      "step": 3100
    },
    {
      "epoch": 1.1856586992773763,
      "grad_norm": 4.368771076202393,
      "learning_rate": 0.00018876833555783425,
      "loss": 19.1258,
      "step": 3200
    },
    {
      "epoch": 1.2227163238836392,
      "grad_norm": 4.662326812744141,
      "learning_rate": 0.00018754779991161916,
      "loss": 19.0203,
      "step": 3300
    },
    {
      "epoch": 1.2597739484899018,
      "grad_norm": 4.57615852355957,
      "learning_rate": 0.00018626869709852283,
      "loss": 18.9915,
      "step": 3400
    },
    {
      "epoch": 1.2968315730961646,
      "grad_norm": 4.268088340759277,
      "learning_rate": 0.00018493188280455894,
      "loss": 19.0432,
      "step": 3500
    },
    {
      "epoch": 1.3338891977024272,
      "grad_norm": 4.502762317657471,
      "learning_rate": 0.00018353825132319825,
      "loss": 18.9629,
      "step": 3600
    },
    {
      "epoch": 1.37094682230869,
      "grad_norm": 4.629462718963623,
      "learning_rate": 0.00018208873495711002,
      "loss": 18.8445,
      "step": 3700
    },
    {
      "epoch": 1.4080044469149526,
      "grad_norm": 4.440378665924072,
      "learning_rate": 0.00018058430339447593,
      "loss": 18.9876,
      "step": 3800
    },
    {
      "epoch": 1.4450620715212155,
      "grad_norm": 4.690705299377441,
      "learning_rate": 0.0001790259630602944,
      "loss": 18.9545,
      "step": 3900
    },
    {
      "epoch": 1.4821196961274783,
      "grad_norm": 5.215766429901123,
      "learning_rate": 0.00017741475644310895,
      "loss": 18.9246,
      "step": 4000
    },
    {
      "epoch": 1.519177320733741,
      "grad_norm": 4.066606521606445,
      "learning_rate": 0.00017575176139761055,
      "loss": 18.88,
      "step": 4100
    },
    {
      "epoch": 1.5562349453400037,
      "grad_norm": 4.525877475738525,
      "learning_rate": 0.0001740380904235817,
      "loss": 18.945,
      "step": 4200
    },
    {
      "epoch": 1.5932925699462666,
      "grad_norm": 4.406365871429443,
      "learning_rate": 0.00017227488992166312,
      "loss": 18.8801,
      "step": 4300
    },
    {
      "epoch": 1.6303501945525292,
      "grad_norm": 4.331666946411133,
      "learning_rate": 0.00017046333942644215,
      "loss": 18.7829,
      "step": 4400
    }
  ],
  "logging_steps": 100,
  "max_steps": 13495,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 24,
  "trial_name": null,
  "trial_params": null
}
